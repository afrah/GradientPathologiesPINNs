{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OybZJApDYGsi",
        "outputId": "dc7cdffa-8613-42ee-86cc-0bc5000b2998"
      },
      "outputs": [],
      "source": [
        "# # Switch to tensorflow 1.x\n",
        "# %tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7WkCgnRiYQSY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from Compute_Jacobian import jacobian # Please download 'Compute_Jacobian.py' in the repository \n",
        "import numpy as np\n",
        "import timeit\n",
        "from scipy.interpolate import griddata\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.environ[\"KMP_WARNINGS\"] = \"FALSE\" \n",
        "import timeit\n",
        "\n",
        "import sys\n",
        "\n",
        "import scipy\n",
        "import scipy.io\n",
        "import time\n",
        "import logging\n",
        "\n",
        "import os.path\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-y7cHTcJfBTR"
      },
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "    # Initialize the class\n",
        "    def __init__(self, dim, coords, func, name=None):\n",
        "        self.dim = dim\n",
        "        self.coords = coords\n",
        "        self.func = func\n",
        "        self.name = name\n",
        "\n",
        "    def sample(self, N):\n",
        "        x = self.coords[0:1, :] + (self.coords[1:2, :] - self.coords[0:1, :]) * np.random.rand(N, self.dim)\n",
        "        y = self.func(x)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SDqDWN3nfSAg"
      },
      "outputs": [],
      "source": [
        "class PINN:\n",
        "    def __init__(self, layers, X_u, Y_u, X_r, Y_r ,mode ,  sess):\n",
        "\n",
        "\n",
        "        self.mode = mode\n",
        "\n",
        "        self.dirname, logpath = self.make_output_dir()\n",
        "        self.logger = self.get_logger(logpath)     \n",
        "\n",
        "        self.mu_X, self.sigma_X = X_r.mean(0), X_r.std(0)\n",
        "        self.mu_x, self.sigma_x = self.mu_X[0], self.sigma_X[0]\n",
        "\n",
        "        # Normalize\n",
        "        self.X_u = (X_u - self.mu_X) / self.sigma_X\n",
        "        self.Y_u = Y_u\n",
        "        self.X_r = (X_r - self.mu_X) / self.sigma_X\n",
        "        self.Y_r = Y_r\n",
        "\n",
        "        # Initialize network weights and biases\n",
        "        self.layers = layers\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "            \n",
        "        # Define the size of the Kernel\n",
        "        self.kernel_size = X_u.shape[0]\n",
        "        # Define Tensorflow session\n",
        "        self.sess = sess# tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
        "\n",
        "        self.lam_bc =  np.array(1.0)\n",
        "        self.lam_res =  np.array(1.0)\n",
        "        self.lam_res_tf = tf.placeholder(tf.float32, shape=self.lam_res.shape)\n",
        "        self.lam_bc_tf = tf.placeholder(tf.float32, shape=self.lam_bc.shape)\n",
        "\n",
        "        # Define placeholders and computational graph\n",
        "        self.x_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.x_bc_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.u_bc_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.x_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        \n",
        "        self.x_u_ntk_tf = tf.placeholder(tf.float32, shape=(self.kernel_size, 1))\n",
        "        self.x_r_ntk_tf = tf.placeholder(tf.float32, shape=(self.kernel_size, 1))\n",
        "\n",
        "        self.lambda1 = tf.constant(1.0 , dtype=tf.float32)\n",
        "        self.lambda2 = tf.constant(500.0 , dtype=tf.float32 )\n",
        "\n",
        "        # Evaluate predictions\n",
        "        self.u_bc_pred = self.net_u(self.x_bc_tf)\n",
        "\n",
        "        self.u_pred = self.net_u(self.x_u_tf)\n",
        "        self.r_pred = self.net_r(self.x_r_tf)\n",
        "        \n",
        "        self.u_ntk_pred = self.net_u(self.x_u_ntk_tf)\n",
        "        self.r_ntk_pred = self.net_r(self.x_r_ntk_tf)\n",
        "     \n",
        "        # Boundary loss\n",
        "        self.loss_bcs = tf.reduce_mean(tf.square(self.u_bc_pred - self.u_bc_tf))\n",
        "\n",
        "        # Residual loss        \n",
        "        self.loss_res =  tf.reduce_mean(tf.square(self.r_tf - self.r_pred))\n",
        "        \n",
        "        # Total loss\n",
        "        self.loss = self.lam_res_tf * self.loss_res + self.lam_bc_tf *  self.loss_bcs\n",
        "\n",
        "        # Define optimizer with learning rate schedule\n",
        "        self.global_step = tf.Variable(0, trainable=False)\n",
        "        starter_learning_rate = 1e-5\n",
        "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step, 1000, 0.9, staircase=False)\n",
        "        # Passing global_step to minimize() will increment it at each step.\n",
        "        # To compute NTK, it is better to use SGD optimizer\n",
        "        # since the corresponding gradient flow is not exactly same.\n",
        "        # self.train_op = tf.train.GradientDescentOptimizer(starter_learning_rate).minimize(self.loss)\n",
        "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss, global_step=self.global_step)\n",
        "\n",
        "\n",
        "        \n",
        "        # Compute the Jacobian for weights and biases in each hidden layer  \n",
        "        self.J_u = self.compute_jacobian(self.u_ntk_pred) \n",
        "        self.J_r = self.compute_jacobian(self.r_ntk_pred)\n",
        "        \n",
        "        # The empirical NTK = J J^T, compute NTK of PINNs \n",
        "        self.K_uu = self.compute_ntk(self.J_u, self.x_u_ntk_tf, self.J_u, self.x_u_ntk_tf)\n",
        "        self.K_ur = self.compute_ntk(self.J_u, self.x_u_ntk_tf, self.J_r, self.x_r_ntk_tf)\n",
        "        self.K_rr = self.compute_ntk(self.J_r, self.x_r_ntk_tf, self.J_r, self.x_r_ntk_tf)\n",
        "        \n",
        "        # Logger\n",
        "        # Loss logger\n",
        "        self.loss_bcs_log = []\n",
        "        self.loss_res_log = []\n",
        "\n",
        "        # NTK logger \n",
        "        self.K_uu_log = []\n",
        "        self.K_rr_log = []\n",
        "        self.K_ur_log = []\n",
        "        \n",
        "        # Weights logger \n",
        "        self.weights_log = []\n",
        "        self.biases_log = []\n",
        "       # Gradients Storage\n",
        "\n",
        "\n",
        "\n",
        "        # Generate dicts for gradients storage\n",
        "        self.dict_gradients_res_layers = self.generate_grad_dict()\n",
        "        self.dict_gradients_bc_layers = self.generate_grad_dict()\n",
        "\n",
        "        self.grad_res = []\n",
        "        self.grad_bc = []\n",
        "        self.grad_res_list = []\n",
        "        self.grad_bc_list = []\n",
        "\n",
        "        for i in range(len(self.layers)-1):\n",
        "            self.grad_res.append(tf.gradients(self.loss_res, self.weights[i])[0])\n",
        "            self.grad_bc.append(tf.gradients(self.loss_bcs, self.weights[i])[0])\n",
        "\n",
        "\n",
        "        self.adaptive_constant_bcs_log = []\n",
        "\n",
        "        self.mean_grad_res_list = []\n",
        "        self.mean_grad_bcs_list = []\n",
        "    \n",
        "        self.mean_grad_res_list_log = []\n",
        "        self.mean_grad_bcs_list_log = []\n",
        "\n",
        "        for i in range( len(self.layers) -1):\n",
        "            self.mean_grad_res_list.append(tf.math.reduce_mean(tf.abs(self.grad_res[i]))) \n",
        "            self.mean_grad_bcs_list.append(tf.math.reduce_mean(tf.abs(self.grad_bc[i])))\n",
        "        \n",
        "        self.mean_grad_res = tf.math.reduce_mean(tf.stack(self.mean_grad_res_list))\n",
        "        self.mean_grad_bcs = tf.math.reduce_mean(tf.stack(self.mean_grad_bcs_list))\n",
        "    \n",
        "\n",
        "        # for i in range(1 , len(self.layers) - 2):\n",
        "        #     self.grad_res_list.append(tf.reduce_mean(tf.abs(self.grad_bc[i])))\n",
        "        #     self.grad_bc_list.append(tf.reduce_mean(tf.abs(self.grad_res[i])))\n",
        "\n",
        "        self.loss_tensor_list = [self.loss ,  self.loss_res,  self.loss_bcs] \n",
        "        self.loss_list = [\"total loss\" , \"loss_res\" , \"loss_bcs\"] \n",
        "\n",
        "        self.epoch_loss = dict.fromkeys(self.loss_list, 0)\n",
        "        self.loss_history = dict((loss, []) for loss in self.loss_list)\n",
        "        \n",
        "\n",
        "        # Initialize Tensorflow variables\n",
        "        init = tf.global_variables_initializer()\n",
        "\n",
        "        self.sess.run(init)\n",
        "        \n",
        "\n",
        "###############################################################################################################\n",
        "\n",
        "    def generate_grad_dict(self):\n",
        "        num = len(self.layers) - 1\n",
        "        grad_dict = {}\n",
        "        for i in range(num):\n",
        "            grad_dict['layer_{}'.format(i + 1)] = []\n",
        "        return grad_dict\n",
        "\n",
        "    # Xavier initialization\n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]\n",
        "        xavier_stddev = 1. / np.sqrt((in_dim + out_dim) / 2.)\n",
        "        return tf.Variable(tf.random.normal([in_dim, out_dim], dtype=tf.float32) * xavier_stddev,\n",
        "                           dtype=tf.float32)\n",
        "    \n",
        "    # NTK initialization\n",
        "    def NTK_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]\n",
        "        std = 1. / np.sqrt(in_dim)\n",
        "        return tf.Variable(tf.random.normal([in_dim, out_dim], dtype=tf.float32) * std,\n",
        "                           dtype=tf.float32)\n",
        "\n",
        "     # Initialize network weights and biases using Xavier initialization\n",
        "    def initialize_NN(self, layers):\n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 1):\n",
        "            W = self.NTK_init(size=[layers[l], layers[l + 1]])\n",
        "            b = tf.Variable(tf.random.normal([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "\n",
        "    # Evaluates the forward pass\n",
        "    def forward_pass(self, H):\n",
        "        num_layers = len(self.layers)\n",
        "        for l in range(0, num_layers - 2):\n",
        "            W = self.weights[l]\n",
        "            b = self.biases[l]\n",
        "            H = tf.nn.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = self.weights[-1]\n",
        "        b = self.biases[-1]\n",
        "        H = tf.add(tf.matmul(H, W), b)\n",
        "        return H\n",
        "\n",
        "    # Evaluates the PDE solution\n",
        "    def net_u(self, x):\n",
        "        u = self.forward_pass(x)\n",
        "        return u\n",
        "\n",
        "    # Forward pass for the residual\n",
        "    def net_r(self, x):\n",
        "        u = self.net_u(x)\n",
        "\n",
        "        u_x = tf.gradients(u, x)[0] / self.sigma_x\n",
        "        u_xx = tf.gradients(u_x, x)[0] / self.sigma_x\n",
        "\n",
        "        res_u = u_xx\n",
        "        return res_u\n",
        "    \n",
        "    # Compute Jacobian for each weights and biases in each layer and retrun a list \n",
        "    def compute_jacobian(self, f):\n",
        "        J_list =[]\n",
        "        L = len(self.weights)    \n",
        "        for i in range(L):\n",
        "            J_w = jacobian(f, self.weights[i])\n",
        "            J_list.append(J_w)\n",
        "     \n",
        "        for i in range(L):\n",
        "            J_b = jacobian(f, self.biases[i])\n",
        "            J_list.append(J_b)\n",
        "        return J_list\n",
        "    \n",
        "    # Compute the empirical NTK = J J^T\n",
        "    def compute_ntk(self, J1_list, x1, J2_list, x2):\n",
        "        D = x1.shape[0]\n",
        "        N = len(J1_list)\n",
        "        \n",
        "        Ker = tf.zeros((D,D))\n",
        "        for k in range(N):\n",
        "            J1 = tf.reshape(J1_list[k], shape=(D,-1))\n",
        "            J2 = tf.reshape(J2_list[k], shape=(D,-1))\n",
        "            \n",
        "            K = tf.matmul(J1, tf.transpose(J2))\n",
        "            Ker = Ker + K\n",
        "        return Ker\n",
        "            \n",
        " \n",
        "\n",
        "    def lambda_balance(self  , term  ):\n",
        "        histoy_mean =  np.mean(self.loss_history[term])\n",
        "        m = 3 #len(self.loss_list)\n",
        "        num = np.exp(  np.mean(self.loss_history[term][-99::]) )#/(self.T * histoy_mean)) np.exp( )\n",
        "        denum = 0 \n",
        "        loss_list = [ \"loss_res\" , \"loss_bcs\"] \n",
        "\n",
        "        for  key in loss_list:\n",
        "            denum +=  np.exp(   np.mean(self.loss_history[key][-99::]) +1e-8)# /(self.T * histoy_mean))  np.exp(self.loss_history[key][-1] )\n",
        "        return m * (num / denum)\n",
        "    \n",
        "    # Trains the model by minimizing the MSE loss\n",
        "    def trainmb(self, nIter=10000, batch_size=128, log_NTK=True, log_weights=True):\n",
        "\n",
        "\n",
        "        itValues = [1,100,1000,39999]\n",
        "        start_time = timeit.default_timer()\n",
        "        for it in range(nIter):\n",
        "            # Fetch boundary mini-batches\n",
        "            # Define a dictionary for associating placeholders with data\n",
        "            tf_dict = {self.x_bc_tf: self.X_u, self.u_bc_tf: self.Y_u,\n",
        "                       self.x_u_tf: self.X_u, self.x_r_tf: self.X_r,\n",
        "                       self.r_tf: self.Y_r,\n",
        "                       self.lam_bc_tf : self.lam_bc,\n",
        "                       self.lam_res_tf : self.lam_res\n",
        "                       }\n",
        "        \n",
        "            # Run the Tensorflow session to minimize the loss\n",
        "\n",
        "            # print(self.lam_bc_tf.shape)\n",
        "            _, batch_losses = self.sess.run([self.train_op, self.loss_tensor_list] ,tf_dict)\n",
        "            self.assign_batch_losses(batch_losses)\n",
        "            for key in self.loss_history:\n",
        "                self.loss_history[key].append(self.epoch_loss[key])\n",
        "            \n",
        "            # self.print\n",
        "            if it % 100 == 0:\n",
        "                elapsed = timeit.default_timer() - start_time\n",
        "                [loss ,  loss_res,  loss_bcs]  = batch_losses\n",
        "\n",
        "\n",
        "                self.print('It: %d, Loss: %.3e, Loss_bcs: %.3e, Loss_res: %.3e ,Time: %.2f' %  (it, loss, loss_bcs, loss_res, elapsed))\n",
        "                \n",
        "\n",
        "                update_res = self.lambda_balance( \"loss_res\"  )\n",
        "                update_bcs = self.lambda_balance( \"loss_bcs\"  )\n",
        "                \n",
        "                self.print('update_res: {:.3e}'.format( update_res))\n",
        "                self.print('update_bcs1: {:.3e}'.format( update_bcs))\n",
        "            \n",
        "            # provide x, x' for NTK\n",
        "            if it % 100 == 0:\n",
        "                mean_grad_bcs , mean_grad_res = self.sess.run([self.mean_grad_bcs , self.mean_grad_res],  tf_dict)\n",
        "\n",
        "                self.lam_bc = mean_grad_res / (mean_grad_bcs  +1e-8 )\n",
        "                self.lam_res = mean_grad_res\n",
        "\n",
        "                self.print(\"adaptive_constant_bc: \" ,  self.lam_bc)    \n",
        "                self.mean_grad_bcs_list_log.append(mean_grad_bcs)\n",
        "                self.mean_grad_res_list_log.append(mean_grad_res)\n",
        "\n",
        "                self.adaptive_constant_bcs_log.append(self.lam_bc)\n",
        "                self.print(\"Compute NTK...\")\n",
        "                tf_dict2 = {self.x_u_ntk_tf: self.X_u, \n",
        "                           self.x_r_ntk_tf: self.X_r\n",
        "                           }\n",
        "                K_uu_value, K_ur_value, K_rr_value = self.sess.run([self.K_uu,  self.K_ur,  self.K_rr], tf_dict2)\n",
        "                self.K_uu_log.append(K_uu_value)\n",
        "                self.K_ur_log.append(K_ur_value)\n",
        "                self.K_rr_log.append(K_rr_value)\n",
        "\n",
        "                start_time = timeit.default_timer()\n",
        "\n",
        "            if it in itValues:\n",
        "                    self.plot_layerLoss(tf_dict , it)\n",
        "                    self.print(\"Gradients information stored ...\")\n",
        "\n",
        "            sys.stdout.flush()\n",
        "  \n",
        "    # Evaluates predictions at test points\n",
        "    def predict_u(self, X_star):\n",
        "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
        "        tf_dict = {self.x_u_tf: X_star}\n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        return u_star\n",
        "\n",
        "    # Evaluates predictions at test points\n",
        "    def predict_r(self, X_star):\n",
        "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
        "        tf_dict = {self.x_r_tf: X_star}\n",
        "        r_star = self.sess.run(self.r_pred, tf_dict)\n",
        "        return r_star\n",
        " ############################################################\n",
        "\n",
        "    def assign_batch_losses(self, batch_losses):\n",
        "        for loss_values, key in zip(batch_losses, self.epoch_loss):\n",
        "            self.epoch_loss[key] = loss_values\n",
        "\n",
        "  ############################################################\n",
        "###################################################################################################################\n",
        "\n",
        "\n",
        "    def plot_layerLoss(self , tf_dict , epoch):\n",
        "        ## Gradients #\n",
        "        num_layers = len(self.layers)\n",
        "        for i in range(num_layers - 1):\n",
        "            grad_res, grad_bc  = self.sess.run([ self.grad_res[i],self.grad_bc[i]], feed_dict=tf_dict)\n",
        "\n",
        "            # save gradients of loss_r and loss_u\n",
        "            self.dict_gradients_res_layers['layer_' + str(i + 1)].append(grad_res.flatten())\n",
        "            self.dict_gradients_bc_layers['layer_' + str(i + 1)].append(grad_bc.flatten())\n",
        "\n",
        "        num_hidden_layers = num_layers -1\n",
        "        cnt = 1\n",
        "        fig = plt.figure(4, figsize=(13, 4))\n",
        "        for j in range(num_hidden_layers):\n",
        "            ax = plt.subplot(1, num_hidden_layers, cnt)\n",
        "            ax.set_title('Layer {}'.format(j + 1))\n",
        "            ax.set_yscale('symlog')\n",
        "            gradients_res = self.dict_gradients_res_layers['layer_' + str(j + 1)][-1]\n",
        "            gradients_bc = self.dict_gradients_bc_layers['layer_' + str(j + 1)][-1]\n",
        "\n",
        "            sns.distplot(gradients_res, hist=False,kde_kws={\"shade\": False},norm_hist=True,  label=r'$\\nabla_\\theta \\mathcal{L}_r$')\n",
        "\n",
        "            sns.distplot(gradients_bc, hist=False,kde_kws={\"shade\": False},norm_hist=True,   label=r'$\\nabla_\\theta \\mathcal{L}_{u_{bc}}$')\n",
        "\n",
        "            #ax.get_legend().remove()\n",
        "            ax.set_xlim([-1.0, 1.0])\n",
        "            #ax.set_ylim([0, 150])\n",
        "            cnt += 1\n",
        "        handles, labels = ax.get_legend_handles_labels()\n",
        "\n",
        "        fig.legend(handles, labels, loc=\"center\",  bbox_to_anchor=(0.5, -0.03),borderaxespad=0,bbox_transform=fig.transFigure, ncol=2)\n",
        "        text = 'layerLoss_epoch' + str(epoch) +'.png'\n",
        "        plt.savefig(os.path.join(self.dirname,text) , bbox_inches='tight')\n",
        "        plt.close(\"all\")\n",
        "\n",
        "    # #########################\n",
        "    # def make_output_dir(self):\n",
        "        \n",
        "    #     if not os.path.exists(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\"):\n",
        "    #         os.mkdir(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\")\n",
        "    #     dirname = os.path.join(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\", datetime.now().strftime(\"%b-%d-%Y_%H-%M-%S-%f_\") + self.mode)\n",
        "    #     os.mkdir(dirname)\n",
        "    #     text = 'output.log'\n",
        "    #     logpath = os.path.join(dirname, text)\n",
        "    #     shutil.copyfile('/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/M2.py', os.path.join(dirname, 'M2.py'))\n",
        "\n",
        "    #     return dirname, logpath\n",
        "    \n",
        "    # # ###########################################################\n",
        "    def make_output_dir(self):\n",
        "        \n",
        "        if not os.path.exists(\"checkpoints\"):\n",
        "            os.mkdir(\"checkpoints\")\n",
        "        dirname = os.path.join(\"checkpoints\", datetime.now().strftime(\"%b-%d-%Y_%H-%M-%S-%f_\") + self.mode)\n",
        "        os.mkdir(dirname)\n",
        "        text = 'output.log'\n",
        "        logpath = os.path.join(dirname, text)\n",
        "        shutil.copyfile('M1.ipynb', os.path.join(dirname, 'M1.ipynb'))\n",
        "        return dirname, logpath\n",
        "    \n",
        "\n",
        "    def get_logger(self, logpath):\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "        sh = logging.StreamHandler()\n",
        "        sh.setLevel(logging.DEBUG)        \n",
        "        sh.setFormatter(logging.Formatter('%(message)s'))\n",
        "        fh = logging.FileHandler(logpath)\n",
        "        logger.addHandler(sh)\n",
        "        logger.addHandler(fh)\n",
        "        return logger\n",
        "    \n",
        "    def print(self, *args):\n",
        "        for word in args:\n",
        "            if len(args) == 1:\n",
        "                self.logger.info(word)\n",
        "            elif word != args[-1]:\n",
        "                for handler in self.logger.handlers:\n",
        "                    handler.terminator = \"\"\n",
        "                if type(word) == float or type(word) == np.float64 or type(word) == np.float32: \n",
        "                    self.logger.info(\"%.4e\" % (word))\n",
        "                else:\n",
        "                    self.logger.info(word)\n",
        "            else:\n",
        "                for handler in self.logger.handlers:\n",
        "                    handler.terminator = \"\\n\"\n",
        "                if type(word) == float or type(word) == np.float64 or type(word) == np.float32:\n",
        "                    self.logger.info(\"%.4e\" % (word))\n",
        "                else:\n",
        "                    self.logger.info(word)\n",
        "\n",
        "\n",
        "    def plot_loss_history(self , path):\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches([15,8])\n",
        "        for key in self.loss_history:\n",
        "            self.print(\"Final loss %s: %e\" % (key, self.loss_history[key][-1]))\n",
        "            ax.semilogy(self.loss_history[key], label=key)\n",
        "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
        "        ax.set_ylabel(\"loss\", fontsize=15)\n",
        "        ax.tick_params(labelsize=15)\n",
        "        ax.legend()\n",
        "        plt.savefig(path)\n",
        "        #plt.show()\n",
        "       #######################\n",
        "    def save_NN(self):\n",
        "\n",
        "        uv_weights = self.sess.run(self.weights)\n",
        "        uv_biases = self.sess.run(self.biases)\n",
        "\n",
        "        with open(os.path.join(self.dirname,'model.pickle'), 'wb') as f:\n",
        "            pickle.dump([uv_weights, uv_biases], f)\n",
        "            self.print(\"Save uv NN parameters successfully in %s ...\" , self.dirname)\n",
        "\n",
        "        # with open(os.path.join(self.dirname,'loss_history_BFS.pickle'), 'wb') as f:\n",
        "        #     pickle.dump(self.loss_rec, f)\n",
        "        with open(os.path.join(self.dirname,'loss_history_BFS.png'), 'wb') as f:\n",
        "            self.plot_loss_history(f)\n",
        "\n",
        "        return self.dirname\n",
        "    \n",
        "    def plot_ntk(self):\n",
        "        # Create empty lists for storing the eigenvalues of NTK\n",
        "        lambda_K_log = []\n",
        "        lambda_K_uu_log = []\n",
        "        lambda_K_ur_log = []\n",
        "        lambda_K_rr_log = []\n",
        "\n",
        "        # Restore the NTK\n",
        "        K_uu_list = self.K_uu_log\n",
        "        K_ur_list = self.K_ur_log\n",
        "        K_rr_list = self.K_rr_log\n",
        "        K_list = []\n",
        "            \n",
        "        for k in range(len(K_uu_list)):\n",
        "            K_uu = K_uu_list[k]\n",
        "            K_ur = K_ur_list[k]\n",
        "            K_rr = K_rr_list[k]\n",
        "            \n",
        "            K = np.concatenate([np.concatenate([K_uu, K_ur], axis = 1), np.concatenate([K_ur.T, K_rr], axis = 1)], axis = 0)\n",
        "            K_list.append(K)\n",
        "\n",
        "            # Compute eigenvalues\n",
        "            lambda_K, _ = np.linalg.eig(K)\n",
        "            lambda_K_uu, _ = np.linalg.eig(K_uu)\n",
        "            lambda_K_rr, _ = np.linalg.eig(K_rr)\n",
        "            \n",
        "            # Sort in descresing order\n",
        "            lambda_K = np.sort(np.real(lambda_K))[::-1]\n",
        "            lambda_K_uu = np.sort(np.real(lambda_K_uu))[::-1]\n",
        "            lambda_K_rr = np.sort(np.real(lambda_K_rr))[::-1]\n",
        "            \n",
        "            # Store eigenvalues\n",
        "            lambda_K_log.append(lambda_K)\n",
        "            lambda_K_uu_log.append(lambda_K_uu)\n",
        "            lambda_K_rr_log.append(lambda_K_rr)\n",
        "        fig = plt.figure(figsize=(18, 5))\n",
        "        plt.subplot(1,3,1)\n",
        "        for i in range(1, len(lambda_K_log), 10):\n",
        "            plt.plot(lambda_K_log[i], '--')\n",
        "        plt.xscale('log')\n",
        "        plt.yscale('log')\n",
        "        plt.title(r'Eigenvalues of ${K}$')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(1,3,2)\n",
        "        for i in range(1, len(lambda_K_uu_log), 10):\n",
        "            plt.plot(lambda_K_uu_log[i], '--')\n",
        "        plt.xscale('log')\n",
        "        plt.yscale('log')\n",
        "        plt.title(r'Eigenvalues of ${K}_{uu}$')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(1,3,3)\n",
        "        for i in range(1, len(lambda_K_log), 10):\n",
        "            plt.plot(lambda_K_rr_log[i], '--')\n",
        "        plt.xscale('log')\n",
        "        plt.yscale('log')\n",
        "        plt.title(r'Eigenvalues of ${K}_{rr}$')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.dirname,\"ntk.png\"))\n",
        "        plt.close(\"all\")\n",
        "\n",
        "    def plt_prediction(self , X_star , u_star , u_pred):\n",
        "        fig = plt.figure(figsize=(12, 5))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.plot(X_star, u_star, label='Exact')\n",
        "        plt.plot(X_star, u_pred, '--', label='Predicted')\n",
        "        plt.xlabel('$x$')\n",
        "        plt.ylabel('$y$')\n",
        "        plt.legend(loc='upper right')\n",
        "\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.plot(X_star, np.abs(u_star - u_pred), label='Error')\n",
        "        plt.yscale('log')\n",
        "        plt.xlabel('$x$')\n",
        "        plt.ylabel('Point-wise error')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.dirname,\"prediction.png\"))\n",
        "        plt.close(\"all\")\n",
        "\n",
        "\n",
        "\n",
        "    def plot_grad(self):\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches([15,8])\n",
        "        ax.semilogy(self.mean_grad_res_list_log, label=r'$\\bar{\\nabla_\\theta \\mathcal{L}_{u_{phy}}}$')\n",
        "        ax.semilogy(self.mean_grad_bcs_list_log, label=r'$\\bar{\\nabla_\\theta \\mathcal{L}_{u_{bc}}}$')\n",
        "\n",
        "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
        "        ax.set_ylabel(\"loss\", fontsize=15)\n",
        "        ax.tick_params(labelsize=15)\n",
        "        ax.legend()\n",
        "        path = os.path.join(self.dirname,'grad_history.png')\n",
        "        plt.savefig(path)\n",
        "\n",
        "\n",
        "         \n",
        "    \n",
        "    def plot_lambda(self ):\n",
        "\n",
        "        fontsize = 17\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches([16,8])\n",
        "        ax.semilogy(self.mean_grad_bcs_list_log, label=r'$\\bar{\\nabla_\\theta {u_{bc}}}$' , color = 'tab:green')\n",
        "        ax.semilogy(self.mean_grad_res_list_log, label=r'$Max{\\nabla_\\theta {u_{phy}}}$' , color = 'tab:red')\n",
        "        ax.set_xlabel(\"epochs\", fontsize=fontsize)\n",
        "        ax.set_ylabel(r'$\\bar{\\nabla_\\theta {u}}$', fontsize=fontsize)\n",
        "        ax.tick_params(labelsize=fontsize)\n",
        "        ax.legend(loc='center left', bbox_to_anchor=(-0.25, 0.5))\n",
        "\n",
        "        ax2 = ax.twinx() \n",
        "\n",
        "        # fig, ax = plt.subplots()\n",
        "        # fig.set_size_inches([15,8])\n",
        "    \n",
        "        ax2.semilogy(self.adaptive_constant_bcs_log, label=r'$\\bar{\\lambda_{bc}}$'  ,  linestyle='dashed' , color = 'tab:green') \n",
        "        ax2.set_xlabel(\"epochs\", fontsize=fontsize)\n",
        "        ax2.set_ylabel(r'$\\bar{\\lambda}$', fontsize=fontsize)\n",
        "        ax2.tick_params(labelsize=fontsize)\n",
        "        ax2.legend(loc='center right', bbox_to_anchor=(1.2, 0.5))\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        path = os.path.join(self.dirname,'grad_history.png')\n",
        "        plt.savefig(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FN1jEdRwY90i"
      },
      "outputs": [],
      "source": [
        "# Define solution and its Laplace\n",
        "a = 4\n",
        "\n",
        "def u(x, a):\n",
        "  return np.sin(np.pi * a * x)\n",
        "\n",
        "def u_xx(x, a):\n",
        "  return -(np.pi * a)**2 * np.sin(np.pi * a * x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#test_method(mtd , layers,  X_u, Y_u, X_r, Y_r ,  X_star , u_star , r_star  , nIter ,batch_size , bcbatch_size , ubatch_size)\n",
        "def test_method(method , layers,  X_u, Y_u, X_r, Y_r , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size , mode):\n",
        "\n",
        "\n",
        "    gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "    tf.reset_default_graph()\n",
        "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) as sess:\n",
        "        # sess.run(init)\n",
        "\n",
        "        model = PINN(layers, X_u, Y_u, X_r, Y_r , mode , sess)    \n",
        "\n",
        "        # Train model\n",
        "        start_time = time.time()\n",
        "\n",
        "        if method ==\"full_batch\":\n",
        "            print(\"full_batch method is used\")\n",
        "            model.train(nIter  , bcbatch_size , ubatch_size  )\n",
        "        elif method ==\"mini_batch\":\n",
        "            print(\"mini_batch method is used\")\n",
        "            model.trainmb(nIter, mbbatch_size)\n",
        "        else:\n",
        "            print(\"unknown method!\")\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        # Predictions\n",
        "        u_pred = model.predict_u(X_star)\n",
        "        r_pred = model.predict_r(X_star)\n",
        "        # Predictions\n",
        "\n",
        "        sess.close()   \n",
        "\n",
        "    error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "    error_r = np.linalg.norm(r_star - r_pred, 2) / np.linalg.norm(r_star, 2)\n",
        "\n",
        "    print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "    print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "    print('Relative L2 error_r: {:.2e}'.format(error_r))\n",
        "\n",
        "\n",
        "    return [elapsed, error_u , error_r ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method:  mini_batch\n",
            "Epoch:  1\n",
            "WARNING:tensorflow:From /tmp/ipykernel_40987/3727794588.py:52: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_40987/3727794588.py:53: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_40987/3727794588.py:54: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_40987/3727794588.py:54: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_40987/349399739.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_40987/349399739.py:70: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_40987/349399739.py:75: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-29 22:40:46.898359: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-29 22:40:46.920261: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
            "2023-12-29 22:40:46.920860: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8e6b54ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-12-29 22:40:46.920874: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-12-29 22:40:46.921533: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tmp/ipykernel_40987/349399739.py:147: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "mini_batch method is used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It: 0, Loss: 1.219e+04, Loss_bcs: 8.840e-01, Loss_res: 1.219e+04 ,Time: 0.55\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:248: RuntimeWarning: overflow encountered in exp\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:253: RuntimeWarning: overflow encountered in exp\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:254: RuntimeWarning: invalid value encountered in true_divide\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 5.1003e+02\n",
            "Compute NTK...\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Gradients information stored ...\n",
            "It: 100, Loss: 1.177e+06, Loss_bcs: 3.920e-01, Loss_res: 8.190e+03 ,Time: 0.01\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:248: RuntimeWarning: overflow encountered in exp\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:253: RuntimeWarning: overflow encountered in exp\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:254: RuntimeWarning: invalid value encountered in true_divide\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 5.7757e+02\n",
            "Compute NTK...\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Gradients information stored ...\n",
            "It: 200, Loss: 6.649e+05, Loss_bcs: 4.935e-01, Loss_res: 5.428e+03 ,Time: 0.01\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:248: RuntimeWarning: overflow encountered in exp\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:253: RuntimeWarning: overflow encountered in exp\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:254: RuntimeWarning: invalid value encountered in true_divide\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 5.0186e+02\n",
            "Compute NTK...\n",
            "It: 300, Loss: 3.994e+05, Loss_bcs: 1.872e+00, Loss_res: 3.530e+03 ,Time: 0.01\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 2.3968e+02\n",
            "Compute NTK...\n",
            "It: 400, Loss: 2.363e+05, Loss_bcs: 4.615e+00, Loss_res: 2.397e+03 ,Time: 0.01\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 1.1767e+02\n",
            "Compute NTK...\n",
            "It: 500, Loss: 1.417e+05, Loss_bcs: 7.727e+00, Loss_res: 1.773e+03 ,Time: 0.00\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 7.1792e+01\n",
            "Compute NTK...\n",
            "It: 600, Loss: 9.250e+04, Loss_bcs: 1.054e+01, Loss_res: 1.397e+03 ,Time: 0.00\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 5.3419e+01\n",
            "Compute NTK...\n",
            "It: 700, Loss: 6.674e+04, Loss_bcs: 1.312e+01, Loss_res: 1.124e+03 ,Time: 0.01\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 4.2554e+01\n",
            "Compute NTK...\n",
            "It: 800, Loss: 4.953e+04, Loss_bcs: 1.538e+01, Loss_res: 9.170e+02 ,Time: 0.00\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 3.5075e+01\n",
            "Compute NTK...\n",
            "It: 900, Loss: 3.717e+04, Loss_bcs: 1.747e+01, Loss_res: 7.560e+02 ,Time: 0.01\n",
            "update_res: nan\n",
            "update_bcs1: 0.000e+00\n",
            "adaptive_constant_bc: 2.9392e+01\n",
            "Compute NTK...\n",
            "It: 1000, Loss: 2.820e+04, Loss_bcs: 1.934e+01, Loss_res: 6.313e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 4.796e-292\n",
            "adaptive_constant_bc: 2.4945e+01\n",
            "Compute NTK...\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Gradients information stored ...\n",
            "It: 1100, Loss: 2.162e+04, Loss_bcs: 2.093e+01, Loss_res: 5.337e+02 ,Time: 0.04\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/ipykernel_launcher.py:248: RuntimeWarning: overflow encountered in exp\n",
            "update_res: inf\n",
            "update_bcs1: 2.216e-243\n",
            "adaptive_constant_bc: 2.1427e+01\n",
            "Compute NTK...\n",
            "It: 1200, Loss: 1.676e+04, Loss_bcs: 2.226e+01, Loss_res: 4.565e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 4.868e-205\n",
            "adaptive_constant_bc: 1.8603e+01\n",
            "Compute NTK...\n",
            "It: 1300, Loss: 1.315e+04, Loss_bcs: 2.335e+01, Loss_res: 3.947e+02 ,Time: 0.01\n",
            "update_res: inf\n",
            "update_bcs1: 1.633e-174\n",
            "adaptive_constant_bc: 1.6317e+01\n",
            "Compute NTK...\n",
            "It: 1400, Loss: 1.045e+04, Loss_bcs: 2.423e+01, Loss_res: 3.446e+02 ,Time: 0.04\n",
            "update_res: inf\n",
            "update_bcs1: 6.133e-150\n",
            "adaptive_constant_bc: 1.4442e+01\n",
            "Compute NTK...\n",
            "It: 1500, Loss: 8.403e+03, Loss_bcs: 2.496e+01, Loss_res: 3.039e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 5.581e-130\n",
            "adaptive_constant_bc: 1.2884e+01\n",
            "Compute NTK...\n",
            "It: 1600, Loss: 6.842e+03, Loss_bcs: 2.556e+01, Loss_res: 2.703e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 1.226e-113\n",
            "adaptive_constant_bc: 1.1569e+01\n",
            "Compute NTK...\n",
            "It: 1700, Loss: 5.633e+03, Loss_bcs: 2.603e+01, Loss_res: 2.425e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 3.930e-100\n",
            "adaptive_constant_bc: 1.0449e+01\n",
            "Compute NTK...\n",
            "It: 1800, Loss: 4.686e+03, Loss_bcs: 2.641e+01, Loss_res: 2.191e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 7.010e-89\n",
            "adaptive_constant_bc: 9.4866e+00\n",
            "Compute NTK...\n",
            "It: 1900, Loss: 3.935e+03, Loss_bcs: 2.670e+01, Loss_res: 1.994e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 1.988e-79\n",
            "adaptive_constant_bc: 8.6507e+00\n",
            "Compute NTK...\n",
            "It: 2000, Loss: 3.333e+03, Loss_bcs: 2.692e+01, Loss_res: 1.826e+02 ,Time: 0.01\n",
            "update_res: inf\n",
            "update_bcs1: 2.066e-71\n",
            "adaptive_constant_bc: 7.9156e+00\n",
            "Compute NTK...\n",
            "It: 2100, Loss: 2.843e+03, Loss_bcs: 2.708e+01, Loss_res: 1.680e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 1.540e-64\n",
            "adaptive_constant_bc: 7.2606e+00\n",
            "Compute NTK...\n",
            "It: 2200, Loss: 2.438e+03, Loss_bcs: 2.720e+01, Loss_res: 1.553e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 1.422e-58\n",
            "adaptive_constant_bc: 6.6651e+00\n",
            "Compute NTK...\n",
            "It: 2300, Loss: 2.098e+03, Loss_bcs: 2.729e+01, Loss_res: 1.440e+02 ,Time: 0.01\n",
            "update_res: inf\n",
            "update_bcs1: 2.503e-53\n",
            "adaptive_constant_bc: 6.1190e+00\n",
            "Compute NTK...\n",
            "It: 2400, Loss: 1.811e+03, Loss_bcs: 2.736e+01, Loss_res: 1.340e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 1.099e-48\n",
            "adaptive_constant_bc: 5.6289e+00\n",
            "Compute NTK...\n",
            "It: 2500, Loss: 1.572e+03, Loss_bcs: 2.739e+01, Loss_res: 1.253e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 1.302e-44\n",
            "adaptive_constant_bc: 5.2037e+00\n",
            "Compute NTK...\n",
            "It: 2600, Loss: 1.377e+03, Loss_bcs: 2.740e+01, Loss_res: 1.178e+02 ,Time: 0.01\n",
            "update_res: inf\n",
            "update_bcs1: 4.445e-41\n",
            "adaptive_constant_bc: 4.8381e+00\n",
            "Compute NTK...\n",
            "It: 2700, Loss: 1.218e+03, Loss_bcs: 2.738e+01, Loss_res: 1.111e+02 ,Time: 0.00\n",
            "update_res: inf\n",
            "update_bcs1: 5.228e-38\n",
            "adaptive_constant_bc: 4.5195e+00\n",
            "Compute NTK...\n",
            "It: 2800, Loss: 1.085e+03, Loss_bcs: 2.734e+01, Loss_res: 1.052e+02 ,Time: 0.01\n",
            "update_res: inf\n",
            "update_bcs1: 2.615e-35\n",
            "adaptive_constant_bc: 4.2376e+00\n",
            "Compute NTK...\n",
            "It: 2900, Loss: 9.719e+02, Loss_bcs: 2.728e+01, Loss_res: 9.995e+01 ,Time: 0.01\n",
            "update_res: inf\n",
            "update_bcs1: 6.610e-33\n",
            "adaptive_constant_bc: 3.9846e+00\n",
            "Compute NTK...\n",
            "It: 3000, Loss: 8.750e+02, Loss_bcs: 2.721e+01, Loss_res: 9.514e+01 ,Time: 0.01\n",
            "update_res: inf\n",
            "update_bcs1: 9.571e-31\n",
            "adaptive_constant_bc: 3.7556e+00\n",
            "Compute NTK...\n",
            "It: 3100, Loss: 7.909e+02, Loss_bcs: 2.712e+01, Loss_res: 9.075e+01 ,Time: 0.01\n",
            "update_res: inf\n",
            "update_bcs1: 8.704e-29\n",
            "adaptive_constant_bc: 3.5470e+00\n",
            "Compute NTK...\n",
            "It: 3200, Loss: 7.174e+02, Loss_bcs: 2.703e+01, Loss_res: 8.671e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 5.333e-27\n",
            "adaptive_constant_bc: 3.3559e+00\n",
            "Compute NTK...\n",
            "It: 3300, Loss: 6.528e+02, Loss_bcs: 2.692e+01, Loss_res: 8.299e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 2.323e-25\n",
            "adaptive_constant_bc: 3.1806e+00\n",
            "Compute NTK...\n",
            "It: 3400, Loss: 5.957e+02, Loss_bcs: 2.681e+01, Loss_res: 7.953e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 7.513e-24\n",
            "adaptive_constant_bc: 3.0194e+00\n",
            "Compute NTK...\n",
            "It: 3500, Loss: 5.451e+02, Loss_bcs: 2.669e+01, Loss_res: 7.632e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 1.871e-22\n",
            "adaptive_constant_bc: 2.8707e+00\n",
            "Compute NTK...\n",
            "It: 3600, Loss: 5.000e+02, Loss_bcs: 2.657e+01, Loss_res: 7.331e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 3.696e-21\n",
            "adaptive_constant_bc: 2.7332e+00\n",
            "Compute NTK...\n",
            "It: 3700, Loss: 4.597e+02, Loss_bcs: 2.644e+01, Loss_res: 7.050e+01 ,Time: 0.03\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 5.937e-20\n",
            "adaptive_constant_bc: 2.6059e+00\n",
            "Compute NTK...\n",
            "It: 3800, Loss: 4.235e+02, Loss_bcs: 2.630e+01, Loss_res: 6.786e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 7.931e-19\n",
            "adaptive_constant_bc: 2.4880e+00\n",
            "Compute NTK...\n",
            "It: 3900, Loss: 3.910e+02, Loss_bcs: 2.616e+01, Loss_res: 6.537e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 8.982e-18\n",
            "adaptive_constant_bc: 2.3785e+00\n",
            "Compute NTK...\n",
            "It: 4000, Loss: 3.617e+02, Loss_bcs: 2.602e+01, Loss_res: 6.302e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 8.768e-17\n",
            "adaptive_constant_bc: 2.2765e+00\n",
            "Compute NTK...\n",
            "It: 4100, Loss: 3.352e+02, Loss_bcs: 2.588e+01, Loss_res: 6.079e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 7.481e-16\n",
            "adaptive_constant_bc: 2.1814e+00\n",
            "Compute NTK...\n",
            "It: 4200, Loss: 3.112e+02, Loss_bcs: 2.573e+01, Loss_res: 5.868e+01 ,Time: 0.02\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 5.651e-15\n",
            "adaptive_constant_bc: 2.0926e+00\n",
            "Compute NTK...\n",
            "It: 4300, Loss: 2.893e+02, Loss_bcs: 2.558e+01, Loss_res: 5.667e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 3.821e-14\n",
            "adaptive_constant_bc: 2.0095e+00\n",
            "Compute NTK...\n",
            "It: 4400, Loss: 2.694e+02, Loss_bcs: 2.543e+01, Loss_res: 5.475e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 2.336e-13\n",
            "adaptive_constant_bc: 1.9315e+00\n",
            "Compute NTK...\n",
            "It: 4500, Loss: 2.512e+02, Loss_bcs: 2.528e+01, Loss_res: 5.293e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 1.302e-12\n",
            "adaptive_constant_bc: 1.8582e+00\n",
            "Compute NTK...\n",
            "It: 4600, Loss: 2.345e+02, Loss_bcs: 2.512e+01, Loss_res: 5.118e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 6.668e-12\n",
            "adaptive_constant_bc: 1.7892e+00\n",
            "Compute NTK...\n",
            "It: 4700, Loss: 2.192e+02, Loss_bcs: 2.497e+01, Loss_res: 4.950e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 3.158e-11\n",
            "adaptive_constant_bc: 1.7240e+00\n",
            "Compute NTK...\n",
            "It: 4800, Loss: 2.051e+02, Loss_bcs: 2.481e+01, Loss_res: 4.790e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 1.390e-10\n",
            "adaptive_constant_bc: 1.6624e+00\n",
            "Compute NTK...\n",
            "It: 4900, Loss: 1.921e+02, Loss_bcs: 2.466e+01, Loss_res: 4.636e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 5.718e-10\n",
            "adaptive_constant_bc: 1.6042e+00\n",
            "Compute NTK...\n",
            "It: 5000, Loss: 1.801e+02, Loss_bcs: 2.450e+01, Loss_res: 4.488e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 2.208e-09\n",
            "adaptive_constant_bc: 1.5492e+00\n",
            "Compute NTK...\n",
            "It: 5100, Loss: 1.690e+02, Loss_bcs: 2.434e+01, Loss_res: 4.346e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 8.041e-09\n",
            "adaptive_constant_bc: 1.4970e+00\n",
            "Compute NTK...\n",
            "It: 5200, Loss: 1.587e+02, Loss_bcs: 2.418e+01, Loss_res: 4.209e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 2.771e-08\n",
            "adaptive_constant_bc: 1.4476e+00\n",
            "Compute NTK...\n",
            "It: 5300, Loss: 1.492e+02, Loss_bcs: 2.402e+01, Loss_res: 4.077e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 9.068e-08\n",
            "adaptive_constant_bc: 1.4008e+00\n",
            "Compute NTK...\n",
            "It: 5400, Loss: 1.404e+02, Loss_bcs: 2.386e+01, Loss_res: 3.950e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 2.827e-07\n",
            "adaptive_constant_bc: 1.3561e+00\n",
            "Compute NTK...\n",
            "It: 5500, Loss: 1.322e+02, Loss_bcs: 2.371e+01, Loss_res: 3.827e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 8.418e-07\n",
            "adaptive_constant_bc: 1.3136e+00\n",
            "Compute NTK...\n",
            "It: 5600, Loss: 1.246e+02, Loss_bcs: 2.355e+01, Loss_res: 3.708e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 2.400e-06\n",
            "adaptive_constant_bc: 1.2732e+00\n",
            "Compute NTK...\n",
            "It: 5700, Loss: 1.175e+02, Loss_bcs: 2.339e+01, Loss_res: 3.594e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 6.568e-06\n",
            "adaptive_constant_bc: 1.2347e+00\n",
            "Compute NTK...\n",
            "It: 5800, Loss: 1.109e+02, Loss_bcs: 2.323e+01, Loss_res: 3.483e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 1.728e-05\n",
            "adaptive_constant_bc: 1.1980e+00\n",
            "Compute NTK...\n",
            "It: 5900, Loss: 1.047e+02, Loss_bcs: 2.307e+01, Loss_res: 3.376e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 4.378e-05\n",
            "adaptive_constant_bc: 1.1631e+00\n",
            "Compute NTK...\n",
            "It: 6000, Loss: 9.898e+01, Loss_bcs: 2.291e+01, Loss_res: 3.272e+01 ,Time: 0.00\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 1.071e-04\n",
            "adaptive_constant_bc: 1.1299e+00\n",
            "Compute NTK...\n",
            "It: 6100, Loss: 9.361e+01, Loss_bcs: 2.275e+01, Loss_res: 3.172e+01 ,Time: 0.01\n",
            "update_res: 3.000e+00\n",
            "update_bcs1: 2.531e-04\n",
            "adaptive_constant_bc: 1.0981e+00\n",
            "Compute NTK...\n",
            "It: 6200, Loss: 8.858e+01, Loss_bcs: 2.259e+01, Loss_res: 3.075e+01 ,Time: 0.00\n",
            "update_res: 2.999e+00\n",
            "update_bcs1: 5.796e-04\n",
            "adaptive_constant_bc: 1.0677e+00\n",
            "Compute NTK...\n",
            "It: 6300, Loss: 8.387e+01, Loss_bcs: 2.244e+01, Loss_res: 2.981e+01 ,Time: 0.00\n",
            "update_res: 2.999e+00\n",
            "update_bcs1: 1.287e-03\n",
            "adaptive_constant_bc: 1.0387e+00\n",
            "Compute NTK...\n",
            "It: 6400, Loss: 7.947e+01, Loss_bcs: 2.228e+01, Loss_res: 2.889e+01 ,Time: 0.00\n",
            "update_res: 2.997e+00\n",
            "update_bcs1: 2.774e-03\n",
            "adaptive_constant_bc: 1.0110e+00\n",
            "Compute NTK...\n",
            "It: 6500, Loss: 7.534e+01, Loss_bcs: 2.212e+01, Loss_res: 2.801e+01 ,Time: 0.00\n",
            "update_res: 2.994e+00\n",
            "update_bcs1: 5.811e-03\n",
            "adaptive_constant_bc: 9.8459e-01\n",
            "Compute NTK...\n",
            "It: 6600, Loss: 7.147e+01, Loss_bcs: 2.196e+01, Loss_res: 2.715e+01 ,Time: 0.01\n",
            "update_res: 2.988e+00\n",
            "update_bcs1: 1.184e-02\n",
            "adaptive_constant_bc: 9.5934e-01\n",
            "Compute NTK...\n",
            "It: 6700, Loss: 6.784e+01, Loss_bcs: 2.180e+01, Loss_res: 2.632e+01 ,Time: 0.00\n",
            "update_res: 2.977e+00\n",
            "update_bcs1: 2.345e-02\n",
            "adaptive_constant_bc: 9.3528e-01\n",
            "Compute NTK...\n",
            "It: 6800, Loss: 6.444e+01, Loss_bcs: 2.164e+01, Loss_res: 2.551e+01 ,Time: 0.00\n",
            "update_res: 2.955e+00\n",
            "update_bcs1: 4.517e-02\n",
            "adaptive_constant_bc: 9.1241e-01\n",
            "Compute NTK...\n",
            "It: 6900, Loss: 6.126e+01, Loss_bcs: 2.149e+01, Loss_res: 2.472e+01 ,Time: 0.00\n",
            "update_res: 2.916e+00\n",
            "update_bcs1: 8.442e-02\n",
            "adaptive_constant_bc: 8.9047e-01\n",
            "Compute NTK...\n",
            "It: 7000, Loss: 5.826e+01, Loss_bcs: 2.133e+01, Loss_res: 2.396e+01 ,Time: 0.00\n",
            "update_res: 2.847e+00\n",
            "update_bcs1: 1.526e-01\n",
            "adaptive_constant_bc: 8.6940e-01\n",
            "Compute NTK...\n",
            "It: 7100, Loss: 5.543e+01, Loss_bcs: 2.117e+01, Loss_res: 2.322e+01 ,Time: 0.00\n",
            "update_res: 2.735e+00\n",
            "update_bcs1: 2.654e-01\n",
            "adaptive_constant_bc: 8.4923e-01\n",
            "Compute NTK...\n",
            "It: 7200, Loss: 5.277e+01, Loss_bcs: 2.101e+01, Loss_res: 2.250e+01 ,Time: 0.00\n",
            "update_res: 2.560e+00\n",
            "update_bcs1: 4.403e-01\n",
            "adaptive_constant_bc: 8.2982e-01\n",
            "Compute NTK...\n",
            "It: 7300, Loss: 5.026e+01, Loss_bcs: 2.085e+01, Loss_res: 2.180e+01 ,Time: 0.01\n",
            "update_res: 2.310e+00\n",
            "update_bcs1: 6.898e-01\n",
            "adaptive_constant_bc: 8.1116e-01\n",
            "Compute NTK...\n",
            "It: 7400, Loss: 4.789e+01, Loss_bcs: 2.070e+01, Loss_res: 2.112e+01 ,Time: 0.00\n",
            "update_res: 1.989e+00\n",
            "update_bcs1: 1.011e+00\n",
            "adaptive_constant_bc: 7.9327e-01\n",
            "Compute NTK...\n",
            "It: 7500, Loss: 4.565e+01, Loss_bcs: 2.054e+01, Loss_res: 2.046e+01 ,Time: 0.00\n",
            "update_res: 1.624e+00\n",
            "update_bcs1: 1.376e+00\n",
            "adaptive_constant_bc: 7.7614e-01\n",
            "Compute NTK...\n",
            "It: 7600, Loss: 4.354e+01, Loss_bcs: 2.038e+01, Loss_res: 1.982e+01 ,Time: 0.00\n",
            "update_res: 1.257e+00\n",
            "update_bcs1: 1.743e+00\n",
            "adaptive_constant_bc: 7.5963e-01\n",
            "Compute NTK...\n",
            "It: 7700, Loss: 4.155e+01, Loss_bcs: 2.022e+01, Loss_res: 1.919e+01 ,Time: 0.00\n",
            "update_res: 9.289e-01\n",
            "update_bcs1: 2.071e+00\n",
            "adaptive_constant_bc: 7.4375e-01\n",
            "Compute NTK...\n",
            "It: 7800, Loss: 3.966e+01, Loss_bcs: 2.007e+01, Loss_res: 1.859e+01 ,Time: 0.01\n",
            "update_res: 6.636e-01\n",
            "update_bcs1: 2.336e+00\n",
            "adaptive_constant_bc: 7.2848e-01\n",
            "Compute NTK...\n",
            "It: 7900, Loss: 3.788e+01, Loss_bcs: 1.991e+01, Loss_res: 1.800e+01 ,Time: 0.00\n",
            "update_res: 4.641e-01\n",
            "update_bcs1: 2.536e+00\n",
            "adaptive_constant_bc: 7.1375e-01\n",
            "Compute NTK...\n",
            "It: 8000, Loss: 3.619e+01, Loss_bcs: 1.975e+01, Loss_res: 1.743e+01 ,Time: 0.00\n",
            "update_res: 3.212e-01\n",
            "update_bcs1: 2.679e+00\n",
            "adaptive_constant_bc: 6.9949e-01\n",
            "Compute NTK...\n",
            "It: 8100, Loss: 3.458e+01, Loss_bcs: 1.959e+01, Loss_res: 1.687e+01 ,Time: 0.00\n",
            "update_res: 2.219e-01\n",
            "update_bcs1: 2.778e+00\n",
            "adaptive_constant_bc: 6.8576e-01\n",
            "Compute NTK...\n",
            "It: 8200, Loss: 3.306e+01, Loss_bcs: 1.943e+01, Loss_res: 1.633e+01 ,Time: 0.00\n",
            "update_res: 1.538e-01\n",
            "update_bcs1: 2.846e+00\n",
            "adaptive_constant_bc: 6.7258e-01\n",
            "Compute NTK...\n",
            "It: 8300, Loss: 3.162e+01, Loss_bcs: 1.927e+01, Loss_res: 1.580e+01 ,Time: 0.01\n",
            "update_res: 1.074e-01\n",
            "update_bcs1: 2.893e+00\n",
            "adaptive_constant_bc: 6.5985e-01\n",
            "Compute NTK...\n",
            "It: 8400, Loss: 3.026e+01, Loss_bcs: 1.912e+01, Loss_res: 1.529e+01 ,Time: 0.00\n",
            "update_res: 7.572e-02\n",
            "update_bcs1: 2.924e+00\n",
            "adaptive_constant_bc: 6.4749e-01\n",
            "Compute NTK...\n",
            "It: 8500, Loss: 2.896e+01, Loss_bcs: 1.896e+01, Loss_res: 1.479e+01 ,Time: 0.00\n",
            "update_res: 5.399e-02\n",
            "update_bcs1: 2.946e+00\n",
            "adaptive_constant_bc: 6.3550e-01\n",
            "Compute NTK...\n",
            "It: 8600, Loss: 2.773e+01, Loss_bcs: 1.880e+01, Loss_res: 1.431e+01 ,Time: 0.00\n",
            "update_res: 3.896e-02\n",
            "update_bcs1: 2.961e+00\n",
            "adaptive_constant_bc: 6.2387e-01\n",
            "Compute NTK...\n",
            "It: 8700, Loss: 2.655e+01, Loss_bcs: 1.864e+01, Loss_res: 1.384e+01 ,Time: 0.00\n",
            "update_res: 2.847e-02\n",
            "update_bcs1: 2.972e+00\n",
            "adaptive_constant_bc: 6.1261e-01\n",
            "Compute NTK...\n",
            "It: 8800, Loss: 2.544e+01, Loss_bcs: 1.848e+01, Loss_res: 1.338e+01 ,Time: 0.00\n",
            "update_res: 2.106e-02\n",
            "update_bcs1: 2.979e+00\n",
            "adaptive_constant_bc: 6.0168e-01\n",
            "Compute NTK...\n",
            "It: 8900, Loss: 2.437e+01, Loss_bcs: 1.832e+01, Loss_res: 1.294e+01 ,Time: 0.01\n",
            "update_res: 1.578e-02\n",
            "update_bcs1: 2.984e+00\n",
            "adaptive_constant_bc: 5.9110e-01\n",
            "Compute NTK...\n",
            "It: 9000, Loss: 2.336e+01, Loss_bcs: 1.816e+01, Loss_res: 1.251e+01 ,Time: 0.00\n",
            "update_res: 1.197e-02\n",
            "update_bcs1: 2.988e+00\n",
            "adaptive_constant_bc: 5.8087e-01\n",
            "Compute NTK...\n",
            "It: 9100, Loss: 2.240e+01, Loss_bcs: 1.800e+01, Loss_res: 1.209e+01 ,Time: 0.00\n",
            "update_res: 9.191e-03\n",
            "update_bcs1: 2.991e+00\n",
            "adaptive_constant_bc: 5.7091e-01\n",
            "Compute NTK...\n",
            "It: 9200, Loss: 2.148e+01, Loss_bcs: 1.784e+01, Loss_res: 1.169e+01 ,Time: 0.01\n",
            "update_res: 7.144e-03\n",
            "update_bcs1: 2.993e+00\n",
            "adaptive_constant_bc: 5.6123e-01\n",
            "Compute NTK...\n",
            "It: 9300, Loss: 2.061e+01, Loss_bcs: 1.769e+01, Loss_res: 1.129e+01 ,Time: 0.00\n",
            "update_res: 5.619e-03\n",
            "update_bcs1: 2.994e+00\n",
            "adaptive_constant_bc: 5.5184e-01\n",
            "Compute NTK...\n",
            "It: 9400, Loss: 1.978e+01, Loss_bcs: 1.753e+01, Loss_res: 1.091e+01 ,Time: 0.00\n",
            "update_res: 4.471e-03\n",
            "update_bcs1: 2.996e+00\n",
            "adaptive_constant_bc: 5.4274e-01\n",
            "Compute NTK...\n",
            "It: 9500, Loss: 1.899e+01, Loss_bcs: 1.737e+01, Loss_res: 1.054e+01 ,Time: 0.01\n",
            "update_res: 3.598e-03\n",
            "update_bcs1: 2.996e+00\n",
            "adaptive_constant_bc: 5.3392e-01\n",
            "Compute NTK...\n",
            "It: 9600, Loss: 1.823e+01, Loss_bcs: 1.721e+01, Loss_res: 1.018e+01 ,Time: 0.01\n",
            "update_res: 2.929e-03\n",
            "update_bcs1: 2.997e+00\n",
            "adaptive_constant_bc: 5.2536e-01\n",
            "Compute NTK...\n",
            "It: 9700, Loss: 1.751e+01, Loss_bcs: 1.705e+01, Loss_res: 9.827e+00 ,Time: 0.00\n",
            "update_res: 2.409e-03\n",
            "update_bcs1: 2.998e+00\n",
            "adaptive_constant_bc: 5.1709e-01\n",
            "Compute NTK...\n",
            "It: 9800, Loss: 1.682e+01, Loss_bcs: 1.689e+01, Loss_res: 9.487e+00 ,Time: 0.00\n",
            "update_res: 2.004e-03\n",
            "update_bcs1: 2.998e+00\n",
            "adaptive_constant_bc: 5.0912e-01\n",
            "Compute NTK...\n",
            "It: 9900, Loss: 1.617e+01, Loss_bcs: 1.672e+01, Loss_res: 9.157e+00 ,Time: 0.01\n",
            "update_res: 1.683e-03\n",
            "update_bcs1: 2.998e+00\n",
            "adaptive_constant_bc: 5.0146e-01\n",
            "Compute NTK...\n",
            "It: 10000, Loss: 1.555e+01, Loss_bcs: 1.656e+01, Loss_res: 8.837e+00 ,Time: 0.00\n",
            "update_res: 1.429e-03\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.9409e-01\n",
            "Compute NTK...\n",
            "It: 10100, Loss: 1.496e+01, Loss_bcs: 1.640e+01, Loss_res: 8.527e+00 ,Time: 0.00\n",
            "update_res: 1.225e-03\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.8708e-01\n",
            "Compute NTK...\n",
            "It: 10200, Loss: 1.440e+01, Loss_bcs: 1.624e+01, Loss_res: 8.225e+00 ,Time: 0.01\n",
            "update_res: 1.060e-03\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.8038e-01\n",
            "Compute NTK...\n",
            "It: 10300, Loss: 1.387e+01, Loss_bcs: 1.608e+01, Loss_res: 7.933e+00 ,Time: 0.00\n",
            "update_res: 9.257e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.7401e-01\n",
            "Compute NTK...\n",
            "It: 10400, Loss: 1.336e+01, Loss_bcs: 1.592e+01, Loss_res: 7.649e+00 ,Time: 0.00\n",
            "update_res: 8.159e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.6793e-01\n",
            "Compute NTK...\n",
            "It: 10500, Loss: 1.288e+01, Loss_bcs: 1.575e+01, Loss_res: 7.373e+00 ,Time: 0.00\n",
            "update_res: 7.256e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.6220e-01\n",
            "Compute NTK...\n",
            "It: 10600, Loss: 1.243e+01, Loss_bcs: 1.559e+01, Loss_res: 7.105e+00 ,Time: 0.01\n",
            "update_res: 6.509e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.5681e-01\n",
            "Compute NTK...\n",
            "It: 10700, Loss: 1.199e+01, Loss_bcs: 1.543e+01, Loss_res: 6.845e+00 ,Time: 0.01\n",
            "update_res: 5.889e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.5173e-01\n",
            "Compute NTK...\n",
            "It: 10800, Loss: 1.158e+01, Loss_bcs: 1.526e+01, Loss_res: 6.593e+00 ,Time: 0.00\n",
            "update_res: 5.372e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.4692e-01\n",
            "Compute NTK...\n",
            "It: 10900, Loss: 1.119e+01, Loss_bcs: 1.510e+01, Loss_res: 6.348e+00 ,Time: 0.01\n",
            "update_res: 4.941e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.4243e-01\n",
            "Compute NTK...\n",
            "It: 11000, Loss: 1.082e+01, Loss_bcs: 1.493e+01, Loss_res: 6.111e+00 ,Time: 0.00\n",
            "update_res: 4.580e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.3824e-01\n",
            "Compute NTK...\n",
            "It: 11100, Loss: 1.046e+01, Loss_bcs: 1.477e+01, Loss_res: 5.880e+00 ,Time: 0.01\n",
            "update_res: 4.279e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.3431e-01\n",
            "Compute NTK...\n",
            "It: 11200, Loss: 1.012e+01, Loss_bcs: 1.460e+01, Loss_res: 5.656e+00 ,Time: 0.00\n",
            "update_res: 4.029e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.3067e-01\n",
            "Compute NTK...\n",
            "It: 11300, Loss: 9.803e+00, Loss_bcs: 1.443e+01, Loss_res: 5.439e+00 ,Time: 0.00\n",
            "update_res: 3.822e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.2731e-01\n",
            "Compute NTK...\n",
            "It: 11400, Loss: 9.497e+00, Loss_bcs: 1.426e+01, Loss_res: 5.228e+00 ,Time: 0.00\n",
            "update_res: 3.653e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.2423e-01\n",
            "Compute NTK...\n",
            "It: 11500, Loss: 9.206e+00, Loss_bcs: 1.409e+01, Loss_res: 5.023e+00 ,Time: 0.00\n",
            "update_res: 3.517e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.2146e-01\n",
            "Compute NTK...\n",
            "It: 11600, Loss: 8.929e+00, Loss_bcs: 1.392e+01, Loss_res: 4.824e+00 ,Time: 0.00\n",
            "update_res: 3.411e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.1890e-01\n",
            "Compute NTK...\n",
            "It: 11700, Loss: 8.663e+00, Loss_bcs: 1.375e+01, Loss_res: 4.632e+00 ,Time: 0.01\n",
            "update_res: 3.332e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.1657e-01\n",
            "Compute NTK...\n",
            "It: 11800, Loss: 8.410e+00, Loss_bcs: 1.357e+01, Loss_res: 4.445e+00 ,Time: 0.00\n",
            "update_res: 3.277e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.1450e-01\n",
            "Compute NTK...\n",
            "It: 11900, Loss: 8.168e+00, Loss_bcs: 1.340e+01, Loss_res: 4.264e+00 ,Time: 0.01\n",
            "update_res: 3.247e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.1265e-01\n",
            "Compute NTK...\n",
            "It: 12000, Loss: 7.936e+00, Loss_bcs: 1.322e+01, Loss_res: 4.089e+00 ,Time: 0.00\n",
            "update_res: 3.239e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.1103e-01\n",
            "Compute NTK...\n",
            "It: 12100, Loss: 7.714e+00, Loss_bcs: 1.304e+01, Loss_res: 3.919e+00 ,Time: 0.01\n",
            "update_res: 3.254e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0967e-01\n",
            "Compute NTK...\n",
            "It: 12200, Loss: 7.502e+00, Loss_bcs: 1.286e+01, Loss_res: 3.755e+00 ,Time: 0.00\n",
            "update_res: 3.291e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0850e-01\n",
            "Compute NTK...\n",
            "It: 12300, Loss: 7.298e+00, Loss_bcs: 1.268e+01, Loss_res: 3.596e+00 ,Time: 0.01\n",
            "update_res: 3.351e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0749e-01\n",
            "Compute NTK...\n",
            "It: 12400, Loss: 7.102e+00, Loss_bcs: 1.250e+01, Loss_res: 3.442e+00 ,Time: 0.00\n",
            "update_res: 3.436e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0663e-01\n",
            "Compute NTK...\n",
            "It: 12500, Loss: 6.912e+00, Loss_bcs: 1.232e+01, Loss_res: 3.293e+00 ,Time: 0.00\n",
            "update_res: 3.546e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0591e-01\n",
            "Compute NTK...\n",
            "It: 12600, Loss: 6.729e+00, Loss_bcs: 1.213e+01, Loss_res: 3.150e+00 ,Time: 0.00\n",
            "update_res: 3.684e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0541e-01\n",
            "Compute NTK...\n",
            "It: 12700, Loss: 6.552e+00, Loss_bcs: 1.195e+01, Loss_res: 3.011e+00 ,Time: 0.00\n",
            "update_res: 3.853e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0509e-01\n",
            "Compute NTK...\n",
            "It: 12800, Loss: 6.383e+00, Loss_bcs: 1.176e+01, Loss_res: 2.877e+00 ,Time: 0.00\n",
            "update_res: 4.056e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0494e-01\n",
            "Compute NTK...\n",
            "It: 12900, Loss: 6.219e+00, Loss_bcs: 1.157e+01, Loss_res: 2.748e+00 ,Time: 0.01\n",
            "update_res: 4.297e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0500e-01\n",
            "Compute NTK...\n",
            "It: 13000, Loss: 6.061e+00, Loss_bcs: 1.138e+01, Loss_res: 2.624e+00 ,Time: 0.00\n",
            "update_res: 4.581e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0525e-01\n",
            "Compute NTK...\n",
            "It: 13100, Loss: 5.908e+00, Loss_bcs: 1.118e+01, Loss_res: 2.503e+00 ,Time: 0.01\n",
            "update_res: 4.915e-04\n",
            "update_bcs1: 3.000e+00\n",
            "adaptive_constant_bc: 4.0581e-01\n",
            "Compute NTK...\n",
            "It: 13200, Loss: 5.762e+00, Loss_bcs: 1.099e+01, Loss_res: 2.388e+00 ,Time: 0.00\n",
            "update_res: 5.305e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.0664e-01\n",
            "Compute NTK...\n",
            "It: 13300, Loss: 5.622e+00, Loss_bcs: 1.079e+01, Loss_res: 2.276e+00 ,Time: 0.01\n",
            "update_res: 5.762e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.0774e-01\n",
            "Compute NTK...\n",
            "It: 13400, Loss: 5.487e+00, Loss_bcs: 1.059e+01, Loss_res: 2.169e+00 ,Time: 0.01\n",
            "update_res: 6.295e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.0912e-01\n",
            "Compute NTK...\n",
            "It: 13500, Loss: 5.357e+00, Loss_bcs: 1.039e+01, Loss_res: 2.065e+00 ,Time: 0.01\n",
            "update_res: 6.919e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.1083e-01\n",
            "Compute NTK...\n",
            "It: 13600, Loss: 5.232e+00, Loss_bcs: 1.019e+01, Loss_res: 1.965e+00 ,Time: 0.00\n",
            "update_res: 7.648e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.1290e-01\n",
            "Compute NTK...\n",
            "It: 13700, Loss: 5.113e+00, Loss_bcs: 9.984e+00, Loss_res: 1.869e+00 ,Time: 0.00\n",
            "update_res: 8.504e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.1535e-01\n",
            "Compute NTK...\n",
            "It: 13800, Loss: 4.998e+00, Loss_bcs: 9.777e+00, Loss_res: 1.776e+00 ,Time: 0.01\n",
            "update_res: 9.508e-04\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.1824e-01\n",
            "Compute NTK...\n",
            "It: 13900, Loss: 4.889e+00, Loss_bcs: 9.568e+00, Loss_res: 1.687e+00 ,Time: 0.00\n",
            "update_res: 1.069e-03\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.2160e-01\n",
            "Compute NTK...\n",
            "It: 14000, Loss: 4.784e+00, Loss_bcs: 9.356e+00, Loss_res: 1.601e+00 ,Time: 0.00\n",
            "update_res: 1.209e-03\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.2547e-01\n",
            "Compute NTK...\n",
            "It: 14100, Loss: 4.684e+00, Loss_bcs: 9.142e+00, Loss_res: 1.519e+00 ,Time: 0.00\n",
            "update_res: 1.374e-03\n",
            "update_bcs1: 2.999e+00\n",
            "adaptive_constant_bc: 4.2985e-01\n",
            "Compute NTK...\n",
            "It: 14200, Loss: 4.589e+00, Loss_bcs: 8.926e+00, Loss_res: 1.439e+00 ,Time: 0.00\n",
            "update_res: 1.571e-03\n",
            "update_bcs1: 2.998e+00\n",
            "adaptive_constant_bc: 4.3470e-01\n",
            "Compute NTK...\n",
            "It: 14300, Loss: 4.497e+00, Loss_bcs: 8.708e+00, Loss_res: 1.363e+00 ,Time: 0.00\n",
            "update_res: 1.806e-03\n",
            "update_bcs1: 2.998e+00\n",
            "adaptive_constant_bc: 4.4003e-01\n",
            "Compute NTK...\n",
            "It: 14400, Loss: 4.408e+00, Loss_bcs: 8.487e+00, Loss_res: 1.290e+00 ,Time: 0.00\n",
            "update_res: 2.088e-03\n",
            "update_bcs1: 2.998e+00\n",
            "adaptive_constant_bc: 4.4587e-01\n",
            "Compute NTK...\n",
            "It: 14500, Loss: 4.321e+00, Loss_bcs: 8.264e+00, Loss_res: 1.219e+00 ,Time: 0.01\n",
            "update_res: 2.426e-03\n",
            "update_bcs1: 2.998e+00\n",
            "adaptive_constant_bc: 4.5228e-01\n",
            "Compute NTK...\n",
            "It: 14600, Loss: 4.238e+00, Loss_bcs: 8.038e+00, Loss_res: 1.152e+00 ,Time: 0.01\n",
            "update_res: 2.834e-03\n",
            "update_bcs1: 2.997e+00\n",
            "adaptive_constant_bc: 4.5921e-01\n",
            "Compute NTK...\n",
            "It: 14700, Loss: 4.156e+00, Loss_bcs: 7.811e+00, Loss_res: 1.088e+00 ,Time: 0.01\n",
            "update_res: 3.329e-03\n",
            "update_bcs1: 2.997e+00\n",
            "adaptive_constant_bc: 4.6670e-01\n",
            "Compute NTK...\n",
            "It: 14800, Loss: 4.076e+00, Loss_bcs: 7.580e+00, Loss_res: 1.027e+00 ,Time: 0.00\n",
            "update_res: 3.931e-03\n",
            "update_bcs1: 2.996e+00\n",
            "adaptive_constant_bc: 4.7485e-01\n",
            "Compute NTK...\n",
            "It: 14900, Loss: 3.998e+00, Loss_bcs: 7.348e+00, Loss_res: 9.682e-01 ,Time: 0.01\n",
            "update_res: 4.665e-03\n",
            "update_bcs1: 2.995e+00\n",
            "adaptive_constant_bc: 4.8361e-01\n",
            "Compute NTK...\n",
            "It: 15000, Loss: 3.921e+00, Loss_bcs: 7.113e+00, Loss_res: 9.128e-01 ,Time: 0.01\n",
            "update_res: 5.565e-03\n",
            "update_bcs1: 2.994e+00\n",
            "adaptive_constant_bc: 4.9296e-01\n",
            "Compute NTK...\n",
            "It: 15100, Loss: 3.844e+00, Loss_bcs: 6.877e+00, Loss_res: 8.603e-01 ,Time: 0.00\n",
            "update_res: 6.672e-03\n",
            "update_bcs1: 2.993e+00\n",
            "adaptive_constant_bc: 5.0292e-01\n",
            "Compute NTK...\n",
            "It: 15200, Loss: 3.768e+00, Loss_bcs: 6.638e+00, Loss_res: 8.106e-01 ,Time: 0.00\n",
            "update_res: 8.037e-03\n",
            "update_bcs1: 2.992e+00\n",
            "adaptive_constant_bc: 5.1354e-01\n",
            "Compute NTK...\n",
            "It: 15300, Loss: 3.692e+00, Loss_bcs: 6.398e+00, Loss_res: 7.638e-01 ,Time: 0.01\n",
            "update_res: 9.726e-03\n",
            "update_bcs1: 2.990e+00\n",
            "adaptive_constant_bc: 5.2478e-01\n",
            "Compute NTK...\n",
            "It: 15400, Loss: 3.615e+00, Loss_bcs: 6.156e+00, Loss_res: 7.198e-01 ,Time: 0.00\n",
            "update_res: 1.182e-02\n",
            "update_bcs1: 2.988e+00\n",
            "adaptive_constant_bc: 5.3674e-01\n",
            "Compute NTK...\n",
            "It: 15500, Loss: 3.537e+00, Loss_bcs: 5.913e+00, Loss_res: 6.785e-01 ,Time: 0.00\n",
            "update_res: 1.442e-02\n",
            "update_bcs1: 2.986e+00\n",
            "adaptive_constant_bc: 5.4947e-01\n",
            "Compute NTK...\n",
            "It: 15600, Loss: 3.459e+00, Loss_bcs: 5.669e+00, Loss_res: 6.398e-01 ,Time: 0.01\n",
            "update_res: 1.766e-02\n",
            "update_bcs1: 2.982e+00\n",
            "adaptive_constant_bc: 5.6312e-01\n",
            "Compute NTK...\n",
            "It: 15700, Loss: 3.380e+00, Loss_bcs: 5.425e+00, Loss_res: 6.036e-01 ,Time: 0.00\n",
            "update_res: 2.169e-02\n",
            "update_bcs1: 2.978e+00\n",
            "adaptive_constant_bc: 5.7767e-01\n",
            "Compute NTK...\n",
            "It: 15800, Loss: 3.300e+00, Loss_bcs: 5.179e+00, Loss_res: 5.699e-01 ,Time: 0.01\n",
            "update_res: 2.672e-02\n",
            "update_bcs1: 2.973e+00\n",
            "adaptive_constant_bc: 5.9321e-01\n",
            "Compute NTK...\n",
            "It: 15900, Loss: 3.219e+00, Loss_bcs: 4.934e+00, Loss_res: 5.384e-01 ,Time: 0.00\n",
            "update_res: 3.299e-02\n",
            "update_bcs1: 2.967e+00\n",
            "adaptive_constant_bc: 6.0975e-01\n",
            "Compute NTK...\n",
            "It: 16000, Loss: 3.136e+00, Loss_bcs: 4.689e+00, Loss_res: 5.090e-01 ,Time: 0.00\n",
            "update_res: 4.079e-02\n",
            "update_bcs1: 2.959e+00\n",
            "adaptive_constant_bc: 6.2740e-01\n",
            "Compute NTK...\n",
            "It: 16100, Loss: 3.051e+00, Loss_bcs: 4.444e+00, Loss_res: 4.816e-01 ,Time: 0.00\n",
            "update_res: 5.049e-02\n",
            "update_bcs1: 2.950e+00\n",
            "adaptive_constant_bc: 6.4614e-01\n",
            "Compute NTK...\n",
            "It: 16200, Loss: 2.964e+00, Loss_bcs: 4.201e+00, Loss_res: 4.559e-01 ,Time: 0.00\n",
            "update_res: 6.252e-02\n",
            "update_bcs1: 2.937e+00\n",
            "adaptive_constant_bc: 6.6606e-01\n",
            "Compute NTK...\n",
            "It: 16300, Loss: 2.873e+00, Loss_bcs: 3.958e+00, Loss_res: 4.320e-01 ,Time: 0.00\n",
            "update_res: 7.737e-02\n",
            "update_bcs1: 2.923e+00\n",
            "adaptive_constant_bc: 6.8731e-01\n",
            "Compute NTK...\n",
            "It: 16400, Loss: 2.780e+00, Loss_bcs: 3.718e+00, Loss_res: 4.096e-01 ,Time: 0.00\n",
            "update_res: 9.565e-02\n",
            "update_bcs1: 2.904e+00\n",
            "adaptive_constant_bc: 7.1021e-01\n",
            "Compute NTK...\n",
            "It: 16500, Loss: 2.685e+00, Loss_bcs: 3.480e+00, Loss_res: 3.886e-01 ,Time: 0.00\n",
            "update_res: 1.180e-01\n",
            "update_bcs1: 2.882e+00\n",
            "adaptive_constant_bc: 7.3475e-01\n",
            "Compute NTK...\n",
            "It: 16600, Loss: 2.587e+00, Loss_bcs: 3.244e+00, Loss_res: 3.689e-01 ,Time: 0.00\n",
            "update_res: 1.452e-01\n",
            "update_bcs1: 2.855e+00\n",
            "adaptive_constant_bc: 7.6117e-01\n",
            "Compute NTK...\n",
            "It: 16700, Loss: 2.486e+00, Loss_bcs: 3.012e+00, Loss_res: 3.504e-01 ,Time: 0.01\n",
            "update_res: 1.779e-01\n",
            "update_bcs1: 2.822e+00\n",
            "adaptive_constant_bc: 7.8985e-01\n",
            "Compute NTK...\n",
            "It: 16800, Loss: 2.382e+00, Loss_bcs: 2.783e+00, Loss_res: 3.330e-01 ,Time: 0.00\n",
            "update_res: 2.171e-01\n",
            "update_bcs1: 2.783e+00\n",
            "adaptive_constant_bc: 8.2113e-01\n",
            "Compute NTK...\n",
            "It: 16900, Loss: 2.275e+00, Loss_bcs: 2.558e+00, Loss_res: 3.166e-01 ,Time: 0.00\n",
            "update_res: 2.634e-01\n",
            "update_bcs1: 2.737e+00\n",
            "adaptive_constant_bc: 8.5554e-01\n",
            "Compute NTK...\n",
            "It: 17000, Loss: 2.166e+00, Loss_bcs: 2.338e+00, Loss_res: 3.012e-01 ,Time: 0.00\n",
            "update_res: 3.175e-01\n",
            "update_bcs1: 2.682e+00\n",
            "adaptive_constant_bc: 8.9362e-01\n",
            "Compute NTK...\n",
            "It: 17100, Loss: 2.054e+00, Loss_bcs: 2.122e+00, Loss_res: 2.867e-01 ,Time: 0.00\n",
            "update_res: 3.801e-01\n",
            "update_bcs1: 2.620e+00\n",
            "adaptive_constant_bc: 9.3601e-01\n",
            "Compute NTK...\n",
            "It: 17200, Loss: 1.940e+00, Loss_bcs: 1.912e+00, Loss_res: 2.729e-01 ,Time: 0.01\n",
            "update_res: 4.511e-01\n",
            "update_bcs1: 2.549e+00\n",
            "adaptive_constant_bc: 9.8363e-01\n",
            "Compute NTK...\n",
            "It: 17300, Loss: 1.823e+00, Loss_bcs: 1.709e+00, Loss_res: 2.601e-01 ,Time: 0.00\n",
            "update_res: 5.304e-01\n",
            "update_bcs1: 2.470e+00\n",
            "adaptive_constant_bc: 1.0378e+00\n",
            "Compute NTK...\n",
            "It: 17400, Loss: 1.706e+00, Loss_bcs: 1.514e+00, Loss_res: 2.481e-01 ,Time: 0.01\n",
            "update_res: 6.171e-01\n",
            "update_bcs1: 2.383e+00\n",
            "adaptive_constant_bc: 1.1001e+00\n",
            "Compute NTK...\n",
            "It: 17500, Loss: 1.589e+00, Loss_bcs: 1.327e+00, Loss_res: 2.368e-01 ,Time: 0.01\n",
            "update_res: 7.097e-01\n",
            "update_bcs1: 2.290e+00\n",
            "adaptive_constant_bc: 1.1721e+00\n",
            "Compute NTK...\n",
            "It: 17600, Loss: 1.472e+00, Loss_bcs: 1.151e+00, Loss_res: 2.263e-01 ,Time: 0.00\n",
            "update_res: 8.063e-01\n",
            "update_bcs1: 2.194e+00\n",
            "adaptive_constant_bc: 1.2557e+00\n",
            "Compute NTK...\n",
            "It: 17700, Loss: 1.355e+00, Loss_bcs: 9.856e-01, Loss_res: 2.164e-01 ,Time: 0.00\n",
            "update_res: 9.047e-01\n",
            "update_bcs1: 2.095e+00\n",
            "adaptive_constant_bc: 1.3530e+00\n",
            "Compute NTK...\n",
            "It: 17800, Loss: 1.238e+00, Loss_bcs: 8.322e-01, Loss_res: 2.071e-01 ,Time: 0.01\n",
            "update_res: 1.002e+00\n",
            "update_bcs1: 1.998e+00\n",
            "adaptive_constant_bc: 1.4667e+00\n",
            "Compute NTK...\n",
            "It: 17900, Loss: 1.121e+00, Loss_bcs: 6.912e-01, Loss_res: 1.982e-01 ,Time: 0.00\n",
            "update_res: 1.097e+00\n",
            "update_bcs1: 1.903e+00\n",
            "adaptive_constant_bc: 1.6009e+00\n",
            "Compute NTK...\n",
            "It: 18000, Loss: 1.003e+00, Loss_bcs: 5.630e-01, Loss_res: 1.896e-01 ,Time: 0.00\n",
            "update_res: 1.186e+00\n",
            "update_bcs1: 1.814e+00\n",
            "adaptive_constant_bc: 1.7614e+00\n",
            "Compute NTK...\n",
            "It: 18100, Loss: 8.859e-01, Loss_bcs: 4.480e-01, Loss_res: 1.813e-01 ,Time: 0.01\n",
            "update_res: 1.268e+00\n",
            "update_bcs1: 1.732e+00\n",
            "adaptive_constant_bc: 1.9562e+00\n",
            "Compute NTK...\n",
            "It: 18200, Loss: 7.693e-01, Loss_bcs: 3.465e-01, Loss_res: 1.731e-01 ,Time: 0.00\n",
            "update_res: 1.342e+00\n",
            "update_bcs1: 1.658e+00\n",
            "adaptive_constant_bc: 2.1976e+00\n",
            "Compute NTK...\n",
            "It: 18300, Loss: 6.545e-01, Loss_bcs: 2.586e-01, Loss_res: 1.651e-01 ,Time: 0.00\n",
            "update_res: 1.407e+00\n",
            "update_bcs1: 1.593e+00\n",
            "adaptive_constant_bc: 2.5045e+00\n",
            "Compute NTK...\n",
            "It: 18400, Loss: 5.424e-01, Loss_bcs: 1.843e-01, Loss_res: 1.570e-01 ,Time: 0.00\n",
            "update_res: 1.462e+00\n",
            "update_bcs1: 1.538e+00\n",
            "adaptive_constant_bc: 2.9066e+00\n",
            "Compute NTK...\n",
            "It: 18500, Loss: 4.346e-01, Loss_bcs: 1.237e-01, Loss_res: 1.488e-01 ,Time: 0.00\n",
            "update_res: 1.507e+00\n",
            "update_bcs1: 1.493e+00\n",
            "adaptive_constant_bc: 3.4535e+00\n",
            "Compute NTK...\n",
            "It: 18600, Loss: 3.328e-01, Loss_bcs: 7.644e-02, Loss_res: 1.401e-01 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 4.2354e+00\n",
            "Compute NTK...\n",
            "It: 18700, Loss: 2.398e-01, Loss_bcs: 4.201e-02, Loss_res: 1.305e-01 ,Time: 0.00\n",
            "update_res: 1.566e+00\n",
            "update_bcs1: 1.434e+00\n",
            "adaptive_constant_bc: 5.4265e+00\n",
            "Compute NTK...\n",
            "It: 18800, Loss: 1.588e-01, Loss_bcs: 1.934e-02, Loss_res: 1.197e-01 ,Time: 0.01\n",
            "update_res: 1.580e+00\n",
            "update_bcs1: 1.420e+00\n",
            "adaptive_constant_bc: 7.4083e+00\n",
            "Compute NTK...\n",
            "It: 18900, Loss: 9.417e-02, Loss_bcs: 6.692e-03, Loss_res: 1.069e-01 ,Time: 0.01\n",
            "update_res: 1.585e+00\n",
            "update_bcs1: 1.415e+00\n",
            "adaptive_constant_bc: 1.1159e+01\n",
            "Compute NTK...\n",
            "It: 19000, Loss: 4.984e-02, Loss_bcs: 1.419e-03, Loss_res: 9.205e-02 ,Time: 0.00\n",
            "update_res: 1.580e+00\n",
            "update_bcs1: 1.420e+00\n",
            "adaptive_constant_bc: 1.9785e+01\n",
            "Compute NTK...\n",
            "It: 19100, Loss: 2.577e-02, Loss_bcs: 1.306e-04, Loss_res: 7.699e-02 ,Time: 0.00\n",
            "update_res: 1.569e+00\n",
            "update_bcs1: 1.431e+00\n",
            "adaptive_constant_bc: 4.6568e+01\n",
            "Compute NTK...\n",
            "It: 19200, Loss: 1.440e-02, Loss_bcs: 3.982e-06, Loss_res: 6.623e-02 ,Time: 0.00\n",
            "update_res: 1.556e+00\n",
            "update_bcs1: 1.444e+00\n",
            "adaptive_constant_bc: 1.7414e+02\n",
            "Compute NTK...\n",
            "It: 19300, Loss: 8.476e-03, Loss_bcs: 4.740e-08, Loss_res: 6.050e-02 ,Time: 0.01\n",
            "update_res: 1.548e+00\n",
            "update_bcs1: 1.452e+00\n",
            "adaptive_constant_bc: 1.0929e+03\n",
            "Compute NTK...\n",
            "It: 19400, Loss: 5.568e-03, Loss_bcs: 3.018e-10, Loss_res: 5.744e-02 ,Time: 0.00\n",
            "update_res: 1.544e+00\n",
            "update_bcs1: 1.456e+00\n",
            "adaptive_constant_bc: 1.1000e+04\n",
            "Compute NTK...\n",
            "It: 19500, Loss: 4.279e-03, Loss_bcs: 9.780e-11, Loss_res: 5.662e-02 ,Time: 0.01\n",
            "update_res: 1.543e+00\n",
            "update_bcs1: 1.457e+00\n",
            "adaptive_constant_bc: 1.2433e+04\n",
            "Compute NTK...\n",
            "It: 19600, Loss: 3.477e-03, Loss_bcs: 4.145e-13, Loss_res: 5.612e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.8810e+05\n",
            "Compute NTK...\n",
            "It: 19700, Loss: 3.136e-03, Loss_bcs: 2.524e-10, Loss_res: 5.624e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.7164e+03\n",
            "Compute NTK...\n",
            "It: 19800, Loss: 2.989e-03, Loss_bcs: 2.180e-11, Loss_res: 5.619e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.9336e+04\n",
            "Compute NTK...\n",
            "It: 19900, Loss: 2.993e-03, Loss_bcs: 1.089e-14, Loss_res: 5.615e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 9.7509e+05\n",
            "Compute NTK...\n",
            "It: 20000, Loss: 3.869e-02, Loss_bcs: 3.663e-08, Loss_res: 5.613e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 6.6770e+02\n",
            "Compute NTK...\n",
            "It: 20100, Loss: 3.787e-03, Loss_bcs: 1.363e-06, Loss_res: 5.618e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.8194e+02\n",
            "Compute NTK...\n",
            "It: 20200, Loss: 2.978e-03, Loss_bcs: 5.754e-07, Loss_res: 5.609e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.8234e+02\n",
            "Compute NTK...\n",
            "It: 20300, Loss: 2.916e-03, Loss_bcs: 2.423e-07, Loss_res: 5.604e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 4.4122e+02\n",
            "Compute NTK...\n",
            "It: 20400, Loss: 2.875e-03, Loss_bcs: 6.198e-08, Loss_res: 5.600e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 8.9442e+02\n",
            "Compute NTK...\n",
            "It: 20500, Loss: 2.864e-03, Loss_bcs: 5.003e-09, Loss_res: 5.597e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.1997e+03\n",
            "Compute NTK...\n",
            "It: 20600, Loss: 2.864e-03, Loss_bcs: 1.276e-11, Loss_res: 5.595e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 5.5800e+04\n",
            "Compute NTK...\n",
            "It: 20700, Loss: 2.856e-03, Loss_bcs: 2.006e-14, Loss_res: 5.593e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 9.0687e+05\n",
            "Compute NTK...\n",
            "It: 20800, Loss: 2.849e-03, Loss_bcs: 8.118e-15, Loss_res: 5.591e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.0919e+06\n",
            "Compute NTK...\n",
            "It: 20900, Loss: 2.841e-03, Loss_bcs: 1.679e-14, Loss_res: 5.589e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.0084e+06\n",
            "Compute NTK...\n",
            "It: 21000, Loss: 2.833e-03, Loss_bcs: 3.157e-14, Loss_res: 5.587e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.1919e+06\n",
            "Compute NTK...\n",
            "It: 21100, Loss: 3.954e-03, Loss_bcs: 5.137e-10, Loss_res: 5.591e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.0306e+03\n",
            "Compute NTK...\n",
            "It: 21200, Loss: 2.979e-03, Loss_bcs: 3.816e-08, Loss_res: 5.593e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 9.5071e+02\n",
            "Compute NTK...\n",
            "It: 21300, Loss: 2.937e-03, Loss_bcs: 3.115e-08, Loss_res: 5.593e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.0473e+03\n",
            "Compute NTK...\n",
            "It: 21400, Loss: 2.924e-03, Loss_bcs: 2.724e-08, Loss_res: 5.592e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.1233e+03\n",
            "Compute NTK...\n",
            "It: 21500, Loss: 2.913e-03, Loss_bcs: 2.312e-08, Loss_res: 5.591e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.2194e+03\n",
            "Compute NTK...\n",
            "It: 21600, Loss: 2.901e-03, Loss_bcs: 1.905e-08, Loss_res: 5.591e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.3469e+03\n",
            "Compute NTK...\n",
            "It: 21700, Loss: 2.889e-03, Loss_bcs: 1.505e-08, Loss_res: 5.590e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.5169e+03\n",
            "Compute NTK...\n",
            "It: 21800, Loss: 2.877e-03, Loss_bcs: 1.139e-08, Loss_res: 5.589e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.7473e+03\n",
            "Compute NTK...\n",
            "It: 21900, Loss: 2.864e-03, Loss_bcs: 8.123e-09, Loss_res: 5.589e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.0731e+03\n",
            "Compute NTK...\n",
            "It: 22000, Loss: 2.851e-03, Loss_bcs: 5.303e-09, Loss_res: 5.588e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.5814e+03\n",
            "Compute NTK...\n",
            "It: 22100, Loss: 2.837e-03, Loss_bcs: 3.034e-09, Loss_res: 5.587e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.4521e+03\n",
            "Compute NTK...\n",
            "It: 22200, Loss: 2.825e-03, Loss_bcs: 1.391e-09, Loss_res: 5.586e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 5.1837e+03\n",
            "Compute NTK...\n",
            "It: 22300, Loss: 2.812e-03, Loss_bcs: 4.409e-10, Loss_res: 5.585e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 9.5769e+03\n",
            "Compute NTK...\n",
            "It: 22400, Loss: 2.801e-03, Loss_bcs: 5.703e-11, Loss_res: 5.584e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.8332e+04\n",
            "Compute NTK...\n",
            "It: 22500, Loss: 2.793e-03, Loss_bcs: 5.113e-13, Loss_res: 5.584e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.6294e+05\n",
            "Compute NTK...\n",
            "It: 22600, Loss: 2.789e-03, Loss_bcs: 2.576e-14, Loss_res: 5.583e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 7.3409e+05\n",
            "Compute NTK...\n",
            "It: 22700, Loss: 2.787e-03, Loss_bcs: 5.151e-15, Loss_res: 5.583e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.7106e+06\n",
            "Compute NTK...\n",
            "It: 22800, Loss: 2.785e-03, Loss_bcs: 1.259e-14, Loss_res: 5.582e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.7120e+06\n",
            "Compute NTK...\n",
            "It: 22900, Loss: 2.783e-03, Loss_bcs: 1.089e-14, Loss_res: 5.582e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.0062e+06\n",
            "Compute NTK...\n",
            "It: 23000, Loss: 2.780e-03, Loss_bcs: 8.136e-15, Loss_res: 5.581e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.3549e+06\n",
            "Compute NTK...\n",
            "It: 23100, Loss: 2.778e-03, Loss_bcs: 2.576e-15, Loss_res: 5.580e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.4348e+06\n",
            "Compute NTK...\n",
            "It: 23200, Loss: 2.776e-03, Loss_bcs: 3.286e-15, Loss_res: 5.580e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.3318e+06\n",
            "Compute NTK...\n",
            "It: 23300, Loss: 2.773e-03, Loss_bcs: 2.567e-14, Loss_res: 5.579e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.1877e+06\n",
            "Compute NTK...\n",
            "It: 23400, Loss: 2.771e-03, Loss_bcs: 6.768e-15, Loss_res: 5.579e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.5352e+06\n",
            "Compute NTK...\n",
            "It: 23500, Loss: 2.768e-03, Loss_bcs: 5.063e-15, Loss_res: 5.578e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.6789e+06\n",
            "Compute NTK...\n",
            "It: 23600, Loss: 2.765e-03, Loss_bcs: 2.496e-14, Loss_res: 5.577e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 8.8263e+05\n",
            "Compute NTK...\n",
            "It: 23700, Loss: 2.762e-03, Loss_bcs: 2.576e-15, Loss_res: 5.576e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.7439e+06\n",
            "Compute NTK...\n",
            "It: 23800, Loss: 2.759e-03, Loss_bcs: 1.837e-14, Loss_res: 5.576e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 7.6503e+05\n",
            "Compute NTK...\n",
            "It: 23900, Loss: 2.755e-03, Loss_bcs: 2.220e-14, Loss_res: 5.575e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 7.2166e+05\n",
            "Compute NTK...\n",
            "It: 24000, Loss: 2.752e-03, Loss_bcs: 1.457e-15, Loss_res: 5.574e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.4099e+06\n",
            "Compute NTK...\n",
            "It: 24100, Loss: 2.749e-03, Loss_bcs: 1.741e-15, Loss_res: 5.573e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.9812e+06\n",
            "Compute NTK...\n",
            "It: 24200, Loss: 2.746e-03, Loss_bcs: 1.267e-14, Loss_res: 5.572e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 6.8259e+05\n",
            "Compute NTK...\n",
            "It: 24300, Loss: 2.742e-03, Loss_bcs: 5.560e-15, Loss_res: 5.571e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 1.6877e+06\n",
            "Compute NTK...\n",
            "It: 24400, Loss: 2.738e-03, Loss_bcs: 5.560e-15, Loss_res: 5.570e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.1215e+06\n",
            "Compute NTK...\n",
            "It: 24500, Loss: 2.734e-03, Loss_bcs: 1.155e-15, Loss_res: 5.569e-02 ,Time: 0.02\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.9003e+06\n",
            "Compute NTK...\n",
            "It: 24600, Loss: 3.254e+00, Loss_bcs: 1.121e-06, Loss_res: 5.555e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 2.2452e+02\n",
            "Compute NTK...\n",
            "It: 24700, Loss: 5.179e-02, Loss_bcs: 2.108e-04, Loss_res: 7.411e-02 ,Time: 0.00\n",
            "update_res: 1.555e+00\n",
            "update_bcs1: 1.445e+00\n",
            "adaptive_constant_bc: 5.4644e+01\n",
            "Compute NTK...\n",
            "It: 24800, Loss: 3.346e-02, Loss_bcs: 1.919e-04, Loss_res: 7.131e-02 ,Time: 0.00\n",
            "update_res: 1.554e+00\n",
            "update_bcs1: 1.446e+00\n",
            "adaptive_constant_bc: 5.2765e+01\n",
            "Compute NTK...\n",
            "It: 24900, Loss: 3.012e-02, Loss_bcs: 1.798e-04, Loss_res: 6.945e-02 ,Time: 0.00\n",
            "update_res: 1.553e+00\n",
            "update_bcs1: 1.447e+00\n",
            "adaptive_constant_bc: 5.1260e+01\n",
            "Compute NTK...\n",
            "It: 25000, Loss: 2.766e-02, Loss_bcs: 1.691e-04, Loss_res: 6.799e-02 ,Time: 0.00\n",
            "update_res: 1.551e+00\n",
            "update_bcs1: 1.449e+00\n",
            "adaptive_constant_bc: 5.0059e+01\n",
            "Compute NTK...\n",
            "It: 25100, Loss: 2.565e-02, Loss_bcs: 1.594e-04, Loss_res: 6.678e-02 ,Time: 0.00\n",
            "update_res: 1.550e+00\n",
            "update_bcs1: 1.450e+00\n",
            "adaptive_constant_bc: 4.9071e+01\n",
            "Compute NTK...\n",
            "It: 25200, Loss: 2.393e-02, Loss_bcs: 1.503e-04, Loss_res: 6.574e-02 ,Time: 0.01\n",
            "update_res: 1.550e+00\n",
            "update_bcs1: 1.450e+00\n",
            "adaptive_constant_bc: 4.8271e+01\n",
            "Compute NTK...\n",
            "It: 25300, Loss: 2.244e-02, Loss_bcs: 1.419e-04, Loss_res: 6.482e-02 ,Time: 0.01\n",
            "update_res: 1.549e+00\n",
            "update_bcs1: 1.451e+00\n",
            "adaptive_constant_bc: 4.7544e+01\n",
            "Compute NTK...\n",
            "It: 25400, Loss: 2.109e-02, Loss_bcs: 1.339e-04, Loss_res: 6.400e-02 ,Time: 0.00\n",
            "update_res: 1.548e+00\n",
            "update_bcs1: 1.452e+00\n",
            "adaptive_constant_bc: 4.6878e+01\n",
            "Compute NTK...\n",
            "It: 25500, Loss: 1.987e-02, Loss_bcs: 1.264e-04, Loss_res: 6.325e-02 ,Time: 0.01\n",
            "update_res: 1.548e+00\n",
            "update_bcs1: 1.452e+00\n",
            "adaptive_constant_bc: 4.6274e+01\n",
            "Compute NTK...\n",
            "It: 25600, Loss: 1.875e-02, Loss_bcs: 1.193e-04, Loss_res: 6.257e-02 ,Time: 0.01\n",
            "update_res: 1.547e+00\n",
            "update_bcs1: 1.453e+00\n",
            "adaptive_constant_bc: 4.5742e+01\n",
            "Compute NTK...\n",
            "It: 25700, Loss: 1.772e-02, Loss_bcs: 1.126e-04, Loss_res: 6.194e-02 ,Time: 0.00\n",
            "update_res: 1.547e+00\n",
            "update_bcs1: 1.453e+00\n",
            "adaptive_constant_bc: 4.5255e+01\n",
            "Compute NTK...\n",
            "It: 25800, Loss: 1.677e-02, Loss_bcs: 1.061e-04, Loss_res: 6.136e-02 ,Time: 0.00\n",
            "update_res: 1.546e+00\n",
            "update_bcs1: 1.454e+00\n",
            "adaptive_constant_bc: 4.4785e+01\n",
            "Compute NTK...\n",
            "It: 25900, Loss: 1.587e-02, Loss_bcs: 9.990e-05, Loss_res: 6.082e-02 ,Time: 0.00\n",
            "update_res: 1.546e+00\n",
            "update_bcs1: 1.454e+00\n",
            "adaptive_constant_bc: 4.4329e+01\n",
            "Compute NTK...\n",
            "It: 26000, Loss: 1.502e-02, Loss_bcs: 9.395e-05, Loss_res: 6.031e-02 ,Time: 0.00\n",
            "update_res: 1.545e+00\n",
            "update_bcs1: 1.455e+00\n",
            "adaptive_constant_bc: 4.3879e+01\n",
            "Compute NTK...\n",
            "It: 26100, Loss: 1.421e-02, Loss_bcs: 8.827e-05, Loss_res: 5.984e-02 ,Time: 0.01\n",
            "update_res: 1.545e+00\n",
            "update_bcs1: 1.455e+00\n",
            "adaptive_constant_bc: 4.3433e+01\n",
            "Compute NTK...\n",
            "It: 26200, Loss: 1.344e-02, Loss_bcs: 8.281e-05, Loss_res: 5.940e-02 ,Time: 0.00\n",
            "update_res: 1.545e+00\n",
            "update_bcs1: 1.455e+00\n",
            "adaptive_constant_bc: 4.2988e+01\n",
            "Compute NTK...\n",
            "It: 26300, Loss: 1.271e-02, Loss_bcs: 7.760e-05, Loss_res: 5.899e-02 ,Time: 0.00\n",
            "update_res: 1.544e+00\n",
            "update_bcs1: 1.456e+00\n",
            "adaptive_constant_bc: 4.2554e+01\n",
            "Compute NTK...\n",
            "It: 26400, Loss: 1.201e-02, Loss_bcs: 7.263e-05, Loss_res: 5.860e-02 ,Time: 0.01\n",
            "update_res: 1.544e+00\n",
            "update_bcs1: 1.456e+00\n",
            "adaptive_constant_bc: 4.2120e+01\n",
            "Compute NTK...\n",
            "It: 26500, Loss: 1.135e-02, Loss_bcs: 6.789e-05, Loss_res: 5.825e-02 ,Time: 0.01\n",
            "update_res: 1.544e+00\n",
            "update_bcs1: 1.456e+00\n",
            "adaptive_constant_bc: 4.1681e+01\n",
            "Compute NTK...\n",
            "It: 26600, Loss: 1.072e-02, Loss_bcs: 6.341e-05, Loss_res: 5.793e-02 ,Time: 0.01\n",
            "update_res: 1.544e+00\n",
            "update_bcs1: 1.456e+00\n",
            "adaptive_constant_bc: 4.1230e+01\n",
            "Compute NTK...\n",
            "It: 26700, Loss: 1.012e-02, Loss_bcs: 5.914e-05, Loss_res: 5.763e-02 ,Time: 0.00\n",
            "update_res: 1.543e+00\n",
            "update_bcs1: 1.457e+00\n",
            "adaptive_constant_bc: 4.0778e+01\n",
            "Compute NTK...\n",
            "It: 26800, Loss: 9.548e-03, Loss_bcs: 5.506e-05, Loss_res: 5.736e-02 ,Time: 0.00\n",
            "update_res: 1.543e+00\n",
            "update_bcs1: 1.457e+00\n",
            "adaptive_constant_bc: 4.0316e+01\n",
            "Compute NTK...\n",
            "It: 26900, Loss: 8.998e-03, Loss_bcs: 5.118e-05, Loss_res: 5.710e-02 ,Time: 0.00\n",
            "update_res: 1.543e+00\n",
            "update_bcs1: 1.457e+00\n",
            "adaptive_constant_bc: 3.9848e+01\n",
            "Compute NTK...\n",
            "It: 27000, Loss: 8.472e-03, Loss_bcs: 4.747e-05, Loss_res: 5.686e-02 ,Time: 0.00\n",
            "update_res: 1.543e+00\n",
            "update_bcs1: 1.457e+00\n",
            "adaptive_constant_bc: 3.9381e+01\n",
            "Compute NTK...\n",
            "It: 27100, Loss: 7.968e-03, Loss_bcs: 4.393e-05, Loss_res: 5.664e-02 ,Time: 0.00\n",
            "update_res: 1.543e+00\n",
            "update_bcs1: 1.457e+00\n",
            "adaptive_constant_bc: 3.8908e+01\n",
            "Compute NTK...\n",
            "It: 27200, Loss: 7.485e-03, Loss_bcs: 4.056e-05, Loss_res: 5.643e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.8431e+01\n",
            "Compute NTK...\n",
            "It: 27300, Loss: 7.022e-03, Loss_bcs: 3.735e-05, Loss_res: 5.624e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.7940e+01\n",
            "Compute NTK...\n",
            "It: 27400, Loss: 6.578e-03, Loss_bcs: 3.432e-05, Loss_res: 5.606e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.7444e+01\n",
            "Compute NTK...\n",
            "It: 27500, Loss: 6.154e-03, Loss_bcs: 3.146e-05, Loss_res: 5.590e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.6934e+01\n",
            "Compute NTK...\n",
            "It: 27600, Loss: 5.748e-03, Loss_bcs: 2.875e-05, Loss_res: 5.574e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.6412e+01\n",
            "Compute NTK...\n",
            "It: 27700, Loss: 5.359e-03, Loss_bcs: 2.622e-05, Loss_res: 5.560e-02 ,Time: 0.01\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.5859e+01\n",
            "Compute NTK...\n",
            "It: 27800, Loss: 4.989e-03, Loss_bcs: 2.388e-05, Loss_res: 5.547e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.5276e+01\n",
            "Compute NTK...\n",
            "It: 27900, Loss: 4.639e-03, Loss_bcs: 2.175e-05, Loss_res: 5.536e-02 ,Time: 0.00\n",
            "update_res: 1.542e+00\n",
            "update_bcs1: 1.458e+00\n",
            "adaptive_constant_bc: 3.4662e+01\n",
            "Compute NTK...\n",
            "It: 28000, Loss: 4.314e-03, Loss_bcs: 1.991e-05, Loss_res: 5.525e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.4015e+01\n",
            "Compute NTK...\n",
            "It: 28100, Loss: 4.024e-03, Loss_bcs: 1.842e-05, Loss_res: 5.516e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.3376e+01\n",
            "Compute NTK...\n",
            "It: 28200, Loss: 3.778e-03, Loss_bcs: 1.722e-05, Loss_res: 5.509e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.2762e+01\n",
            "Compute NTK...\n",
            "It: 28300, Loss: 3.569e-03, Loss_bcs: 1.620e-05, Loss_res: 5.503e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.2190e+01\n",
            "Compute NTK...\n",
            "It: 28400, Loss: 3.385e-03, Loss_bcs: 1.531e-05, Loss_res: 5.497e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.1673e+01\n",
            "Compute NTK...\n",
            "It: 28500, Loss: 3.223e-03, Loss_bcs: 1.450e-05, Loss_res: 5.492e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.1197e+01\n",
            "Compute NTK...\n",
            "It: 28600, Loss: 3.076e-03, Loss_bcs: 1.374e-05, Loss_res: 5.487e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.0738e+01\n",
            "Compute NTK...\n",
            "It: 28700, Loss: 2.938e-03, Loss_bcs: 1.302e-05, Loss_res: 5.483e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.0302e+01\n",
            "Compute NTK...\n",
            "It: 28800, Loss: 2.807e-03, Loss_bcs: 1.233e-05, Loss_res: 5.479e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.9876e+01\n",
            "Compute NTK...\n",
            "It: 28900, Loss: 2.681e-03, Loss_bcs: 1.167e-05, Loss_res: 5.475e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.9464e+01\n",
            "Compute NTK...\n",
            "It: 29000, Loss: 2.562e-03, Loss_bcs: 1.103e-05, Loss_res: 5.471e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.9057e+01\n",
            "Compute NTK...\n",
            "It: 29100, Loss: 2.446e-03, Loss_bcs: 1.042e-05, Loss_res: 5.467e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.8645e+01\n",
            "Compute NTK...\n",
            "It: 29200, Loss: 2.334e-03, Loss_bcs: 9.827e-06, Loss_res: 5.464e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.8239e+01\n",
            "Compute NTK...\n",
            "It: 29300, Loss: 2.225e-03, Loss_bcs: 9.255e-06, Loss_res: 5.461e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.7835e+01\n",
            "Compute NTK...\n",
            "It: 29400, Loss: 2.119e-03, Loss_bcs: 8.704e-06, Loss_res: 5.458e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.7434e+01\n",
            "Compute NTK...\n",
            "It: 29500, Loss: 2.018e-03, Loss_bcs: 8.176e-06, Loss_res: 5.455e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.7039e+01\n",
            "Compute NTK...\n",
            "It: 29600, Loss: 1.919e-03, Loss_bcs: 7.665e-06, Loss_res: 5.452e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.6660e+01\n",
            "Compute NTK...\n",
            "It: 29700, Loss: 1.825e-03, Loss_bcs: 7.175e-06, Loss_res: 5.450e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.6287e+01\n",
            "Compute NTK...\n",
            "It: 29800, Loss: 1.734e-03, Loss_bcs: 6.705e-06, Loss_res: 5.447e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.5947e+01\n",
            "Compute NTK...\n",
            "It: 29900, Loss: 1.648e-03, Loss_bcs: 6.253e-06, Loss_res: 5.445e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.5668e+01\n",
            "Compute NTK...\n",
            "It: 30000, Loss: 1.568e-03, Loss_bcs: 5.823e-06, Loss_res: 5.443e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.5433e+01\n",
            "Compute NTK...\n",
            "It: 30100, Loss: 1.494e-03, Loss_bcs: 5.412e-06, Loss_res: 5.441e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.5291e+01\n",
            "Compute NTK...\n",
            "It: 30200, Loss: 1.427e-03, Loss_bcs: 5.017e-06, Loss_res: 5.439e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.5241e+01\n",
            "Compute NTK...\n",
            "It: 30300, Loss: 1.365e-03, Loss_bcs: 4.638e-06, Loss_res: 5.438e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.5309e+01\n",
            "Compute NTK...\n",
            "It: 30400, Loss: 1.311e-03, Loss_bcs: 4.275e-06, Loss_res: 5.436e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.5536e+01\n",
            "Compute NTK...\n",
            "It: 30500, Loss: 1.265e-03, Loss_bcs: 3.924e-06, Loss_res: 5.434e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.5869e+01\n",
            "Compute NTK...\n",
            "It: 30600, Loss: 1.223e-03, Loss_bcs: 3.589e-06, Loss_res: 5.433e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.6325e+01\n",
            "Compute NTK...\n",
            "It: 30700, Loss: 1.186e-03, Loss_bcs: 3.265e-06, Loss_res: 5.432e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.6988e+01\n",
            "Compute NTK...\n",
            "It: 30800, Loss: 1.155e-03, Loss_bcs: 2.952e-06, Loss_res: 5.430e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.7832e+01\n",
            "Compute NTK...\n",
            "It: 30900, Loss: 1.128e-03, Loss_bcs: 2.654e-06, Loss_res: 5.429e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.8978e+01\n",
            "Compute NTK...\n",
            "It: 31000, Loss: 1.109e-03, Loss_bcs: 2.365e-06, Loss_res: 5.428e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.0353e+01\n",
            "Compute NTK...\n",
            "It: 31100, Loss: 1.092e-03, Loss_bcs: 2.088e-06, Loss_res: 5.427e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.1995e+01\n",
            "Compute NTK...\n",
            "It: 31200, Loss: 1.076e-03, Loss_bcs: 1.810e-06, Loss_res: 5.426e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.3973e+01\n",
            "Compute NTK...\n",
            "It: 31300, Loss: 1.058e-03, Loss_bcs: 1.514e-06, Loss_res: 5.425e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.6781e+01\n",
            "Compute NTK...\n",
            "It: 31400, Loss: 1.041e-03, Loss_bcs: 1.204e-06, Loss_res: 5.424e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 4.1261e+01\n",
            "Compute NTK...\n",
            "It: 31500, Loss: 1.034e-03, Loss_bcs: 8.866e-07, Loss_res: 5.423e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 4.8897e+01\n",
            "Compute NTK...\n",
            "It: 31600, Loss: 1.043e-03, Loss_bcs: 5.837e-07, Loss_res: 5.423e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 6.3150e+01\n",
            "Compute NTK...\n",
            "It: 31700, Loss: 1.083e-03, Loss_bcs: 3.213e-07, Loss_res: 5.423e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 9.1954e+01\n",
            "Compute NTK...\n",
            "It: 31800, Loss: 1.160e-03, Loss_bcs: 1.323e-07, Loss_res: 5.424e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 1.5631e+02\n",
            "Compute NTK...\n",
            "It: 31900, Loss: 1.256e-03, Loss_bcs: 3.223e-08, Loss_res: 5.424e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.4211e+02\n",
            "Compute NTK...\n",
            "It: 32000, Loss: 1.348e-03, Loss_bcs: 2.095e-09, Loss_res: 5.423e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 1.4010e+03\n",
            "Compute NTK...\n",
            "It: 32100, Loss: 1.406e-03, Loss_bcs: 9.660e-12, Loss_res: 5.421e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.0212e+04\n",
            "Compute NTK...\n",
            "It: 32200, Loss: 1.399e-03, Loss_bcs: 5.819e-14, Loss_res: 5.417e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.6865e+05\n",
            "Compute NTK...\n",
            "It: 32300, Loss: 1.369e-03, Loss_bcs: 6.596e-14, Loss_res: 5.414e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 2.2927e+05\n",
            "Compute NTK...\n",
            "It: 32400, Loss: 1.338e-03, Loss_bcs: 2.908e-14, Loss_res: 5.411e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.0416e+05\n",
            "Compute NTK...\n",
            "It: 32500, Loss: 1.314e-03, Loss_bcs: 7.118e-13, Loss_res: 5.407e-02 ,Time: 0.01\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.4900e+05\n",
            "Compute NTK...\n",
            "It: 32600, Loss: 2.750e-02, Loss_bcs: 7.509e-08, Loss_res: 5.404e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 9.5216e+02\n",
            "Compute NTK...\n",
            "It: 32700, Loss: 1.270e-03, Loss_bcs: 9.208e-10, Loss_res: 5.401e-02 ,Time: 0.00\n",
            "update_res: 1.541e+00\n",
            "update_bcs1: 1.459e+00\n",
            "adaptive_constant_bc: 3.2905e+03\n",
            "Compute NTK...\n",
            "It: 32800, Loss: 1.227e-03, Loss_bcs: 1.413e-12, Loss_res: 5.399e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 4.7634e+04\n",
            "Compute NTK...\n",
            "It: 32900, Loss: 1.221e-03, Loss_bcs: 1.139e-14, Loss_res: 5.397e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.0894e+06\n",
            "Compute NTK...\n",
            "It: 33000, Loss: 1.567e-03, Loss_bcs: 3.213e-10, Loss_res: 5.396e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 4.4690e+03\n",
            "Compute NTK...\n",
            "It: 33100, Loss: 1.219e-03, Loss_bcs: 6.250e-10, Loss_res: 5.396e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 3.2499e+03\n",
            "Compute NTK...\n",
            "It: 33200, Loss: 1.226e-03, Loss_bcs: 3.477e-10, Loss_res: 5.396e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 4.4652e+03\n",
            "Compute NTK...\n",
            "It: 33300, Loss: 1.224e-03, Loss_bcs: 1.668e-10, Loss_res: 5.396e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 6.7403e+03\n",
            "Compute NTK...\n",
            "It: 33400, Loss: 1.223e-03, Loss_bcs: 5.709e-11, Loss_res: 5.396e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.2442e+04\n",
            "Compute NTK...\n",
            "It: 33500, Loss: 1.222e-03, Loss_bcs: 8.306e-12, Loss_res: 5.396e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 3.4472e+04\n",
            "Compute NTK...\n",
            "It: 33600, Loss: 1.221e-03, Loss_bcs: 2.023e-13, Loss_res: 5.395e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 2.1966e+05\n",
            "Compute NTK...\n",
            "It: 33700, Loss: 1.222e-03, Loss_bcs: 2.203e-15, Loss_res: 5.395e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 7.7420e+05\n",
            "Compute NTK...\n",
            "It: 33800, Loss: 1.224e-03, Loss_bcs: 7.105e-15, Loss_res: 5.395e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 8.7570e+05\n",
            "Compute NTK...\n",
            "It: 33900, Loss: 1.225e-03, Loss_bcs: 1.155e-15, Loss_res: 5.395e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.9793e+06\n",
            "Compute NTK...\n",
            "It: 34000, Loss: 1.226e-03, Loss_bcs: 4.903e-15, Loss_res: 5.394e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.8102e+06\n",
            "Compute NTK...\n",
            "It: 34100, Loss: 1.226e-03, Loss_bcs: 4.921e-15, Loss_res: 5.394e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.0513e+06\n",
            "Compute NTK...\n",
            "It: 34200, Loss: 1.228e-03, Loss_bcs: 3.002e-15, Loss_res: 5.394e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 6.0390e+05\n",
            "Compute NTK...\n",
            "It: 34300, Loss: 1.229e-03, Loss_bcs: 3.784e-15, Loss_res: 5.394e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.8106e+06\n",
            "Compute NTK...\n",
            "It: 34400, Loss: 1.230e-03, Loss_bcs: 1.608e-14, Loss_res: 5.393e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 3.8061e+05\n",
            "Compute NTK...\n",
            "It: 34500, Loss: 1.232e-03, Loss_bcs: 8.811e-15, Loss_res: 5.393e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.0590e+06\n",
            "Compute NTK...\n",
            "It: 34600, Loss: 1.234e-03, Loss_bcs: 1.309e-14, Loss_res: 5.393e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 5.5661e+05\n",
            "Compute NTK...\n",
            "It: 34700, Loss: 1.236e-03, Loss_bcs: 5.773e-15, Loss_res: 5.393e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 7.3457e+05\n",
            "Compute NTK...\n",
            "It: 34800, Loss: 1.237e-03, Loss_bcs: 1.794e-15, Loss_res: 5.392e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.0667e+06\n",
            "Compute NTK...\n",
            "It: 34900, Loss: 1.239e-03, Loss_bcs: 8.242e-15, Loss_res: 5.392e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 6.3189e+05\n",
            "Compute NTK...\n",
            "It: 35000, Loss: 1.242e-03, Loss_bcs: 6.839e-15, Loss_res: 5.392e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 9.5830e+05\n",
            "Compute NTK...\n",
            "It: 35100, Loss: 1.245e-03, Loss_bcs: 1.890e-14, Loss_res: 5.391e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 9.7222e+05\n",
            "Compute NTK...\n",
            "It: 35200, Loss: 1.248e-03, Loss_bcs: 9.948e-16, Loss_res: 5.391e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 9.6319e+05\n",
            "Compute NTK...\n",
            "It: 35300, Loss: 1.251e-03, Loss_bcs: 3.553e-15, Loss_res: 5.390e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 1.1144e+06\n",
            "Compute NTK...\n",
            "It: 35400, Loss: 1.254e-03, Loss_bcs: 3.020e-14, Loss_res: 5.390e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 4.4052e+05\n",
            "Compute NTK...\n",
            "It: 35500, Loss: 1.258e-03, Loss_bcs: 1.627e-14, Loss_res: 5.390e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 5.1111e+05\n",
            "Compute NTK...\n",
            "It: 35600, Loss: 1.261e-03, Loss_bcs: 5.684e-15, Loss_res: 5.389e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 3.5513e+05\n",
            "Compute NTK...\n",
            "It: 35700, Loss: 1.264e-03, Loss_bcs: 4.068e-15, Loss_res: 5.389e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 8.6995e+05\n",
            "Compute NTK...\n",
            "It: 35800, Loss: 1.268e-03, Loss_bcs: 7.336e-15, Loss_res: 5.388e-02 ,Time: 0.00\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 8.2288e+05\n",
            "Compute NTK...\n",
            "It: 35900, Loss: 1.271e-03, Loss_bcs: 2.219e-14, Loss_res: 5.388e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 5.0366e+05\n",
            "Compute NTK...\n",
            "It: 36000, Loss: 1.275e-03, Loss_bcs: 1.847e-15, Loss_res: 5.387e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 7.0197e+05\n",
            "Compute NTK...\n",
            "It: 36100, Loss: 1.278e-03, Loss_bcs: 1.648e-14, Loss_res: 5.387e-02 ,Time: 0.01\n",
            "update_res: 1.540e+00\n",
            "update_bcs1: 1.460e+00\n",
            "adaptive_constant_bc: 3.1817e+05\n",
            "Compute NTK...\n"
          ]
        }
      ],
      "source": [
        "# Define computional domain\n",
        "bc1_coords = np.array([[0.0], [0.0]])\n",
        "bc2_coords = np.array([[1.0], [1.0]])\n",
        "dom_coords = np.array([[0.0], [1.0]])\n",
        "\n",
        "# Training data on u(x) -- Dirichlet boundary conditions\n",
        "\n",
        "nn  = 100\n",
        "\n",
        "X_bc1 = dom_coords[0, 0] * np.ones((nn // 2, 1))\n",
        "X_bc2 = dom_coords[1, 0] * np.ones((nn // 2, 1))\n",
        "X_u = np.vstack([X_bc1, X_bc2])\n",
        "Y_u = u(X_u, a)\n",
        "\n",
        "X_r = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "Y_r = u_xx(X_r, a)\n",
        "\n",
        "nn = 1000\n",
        "X_star = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "u_star = u(X_star, a)\n",
        "r_star = u_xx(X_star, a)\n",
        "\n",
        "nIter =40001\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 128\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'M1'\n",
        "layers = [1, 500,500, 1]\n",
        "\n",
        "\n",
        "\n",
        "iterations = 1\n",
        "methods = [ \"mini_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    error_r_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "        gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "        tf.reset_default_graph()\n",
        "        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) as sess:\n",
        "\n",
        "            model = PINN(layers, X_u, Y_u, X_r, Y_r , mode , sess)    \n",
        "\n",
        "            # Train model\n",
        "            start_time = time.time()\n",
        "\n",
        "            if mtd ==\"full_batch\":\n",
        "                print(\"full_batch method is used\")\n",
        "                model.train(nIter  , bcbatch_size , ubatch_size  )\n",
        "            elif mtd ==\"mini_batch\":\n",
        "                print(\"mini_batch method is used\")\n",
        "                model.trainmb(nIter, mbbatch_size)\n",
        "            else:\n",
        "                print(\"unknown method!\")\n",
        "            elapsed = time.time() - start_time\n",
        "\n",
        "            # Predictions\n",
        "            u_pred = model.predict_u(X_star)\n",
        "            r_pred = model.predict_r(X_star)\n",
        "            # Predictions\n",
        "\n",
        " \n",
        "\n",
        "            error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "            error_r = np.linalg.norm(r_star - r_pred, 2) / np.linalg.norm(r_star, 2)\n",
        "\n",
        "            model.print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "            model.print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "            model.print('Relative L2 error_r: {:.2e}'.format(error_r))\n",
        "\n",
        "\n",
        "            model.print('mean value of lambda_bc: {:.2e}'.format(np.average(model.adaptive_constant_bcs_log)))\n",
        "            model.print('first value of lambda_bc: {:.2e}'.format(model.adaptive_constant_bcs_log[0]))\n",
        "            model.print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "            model.print('Relative L2 error_v: {:.2e}'.format(error_r))\n",
        "            \n",
        "            model.save_NN()\n",
        "            model.plot_ntk()\n",
        "            model.plot_grad()\n",
        "            model.plot_lambda()\n",
        "            model.plt_prediction( X_star , u_star , u_pred)\n",
        "            sess.close()  \n",
        "            \n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "        error_r_list.append(error_r)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    print(\"average of error_v_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list ,error_r_list ]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(os.path.join(model.dirname,\"\"+mtd+\"_model\"+mode+\"_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(bcbatch_size)+\"_n\"+str(iterations)+\"_nIter\"+str(nIter)+\".mat\") , result_dict)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "elapsed: 8.47e+01\n",
            "Relative L2 error_u: 9.90e-01\n",
            "Relative L2 error_r: 9.57e-01\n",
            "mean value of lambda_bc: 3.01e+09\n",
            "first value of lambda_bc: 3.22e+02\n",
            "Relative L2 error_u: 9.90e-01\n",
            "Relative L2 error_v: 9.57e-01\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Method:  mini_batch\n",
            "\n",
            "average of time_list: 84.6841676235199\n",
            "average of error_u_list: 0.99012879989674\n",
            "average of error_v_list: 0.9567692789504263\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "error_r = np.linalg.norm(r_star - r_pred, 2) / np.linalg.norm(r_star, 2)\n",
        "\n",
        "model.print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "model.print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "model.print('Relative L2 error_r: {:.2e}'.format(error_r))\n",
        "\n",
        "\n",
        "model.print('mean value of lambda_bc: {:.2e}'.format(np.average(model.adaptive_constant_bcs_log)))\n",
        "model.print('first value of lambda_bc: {:.2e}'.format(model.adaptive_constant_bcs_log[0]))\n",
        "model.print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "model.print('Relative L2 error_v: {:.2e}'.format(error_r))\n",
        "\n",
        "# model.save_NN()\n",
        "model.plot_ntk()\n",
        "model.plot_grad()\n",
        "model.plot_lambda()\n",
        "model.plt_prediction( X_star , u_star , u_pred)\n",
        "sess.close()  \n",
        "\n",
        "time_list.append(elapsed)\n",
        "error_u_list.append(error_u)\n",
        "error_r_list.append(error_r)\n",
        "\n",
        "print(\"\\n\\nMethod: \", mtd)\n",
        "print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "print(\"average of error_v_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "result_dict[mtd] = [time_list ,error_u_list ,error_r_list ]\n",
        "# scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "scipy.io.savemat(os.path.join(model.dirname,\"\"+mtd+\"_model\"+mode+\"_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(bcbatch_size)+\"_n\"+str(iterations)+\"_nIter\"+str(nIter)+\".mat\") , result_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.mean_grad_bcs_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_grad(self):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches([15,8])\n",
        "    ax.semilogy(self.mean_grad_res_list_log, label=r'$\\bar{\\nabla_\\theta \\mathcal{L}_{u_{phy}}}$')\n",
        "    ax.semilogy(self.mean_grad_bcs_list_log, label=r'$\\bar{\\nabla_\\theta \\mathcal{L}_{u_{bc}}}$')\n",
        "\n",
        "    ax.set_xlabel(\"epochs\", fontsize=15)\n",
        "    ax.set_ylabel(\"loss\", fontsize=15)\n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.legend()\n",
        "    path = os.path.join(self.dirname,'grad_history.png')\n",
        "    plt.savefig(path)\n",
        "\n",
        "plot_grad(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define model\n",
        "layers = [1, 512, 1]  \n",
        "# layers = [1, 512, 512, 512, 1]  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "Fw807UNzhu5z",
        "outputId": "929ae89c-3e10-4c56-e349-051441e8ab32"
      },
      "outputs": [],
      "source": [
        "loss_bcs = model.loss_bcs_log\n",
        "loss_res = model.loss_res_log\n",
        "\n",
        "fig = plt.figure(figsize=(6,5))\n",
        "plt.plot(loss_res, label='$\\mathcal{L}_{r}$')\n",
        "plt.plot(loss_bcs, label='$\\mathcal{L}_{b}$')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFLIBq5xjZ3v"
      },
      "source": [
        "**Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To0PDN17cc0v",
        "outputId": "7284b31e-f2fe-41ab-93a9-4c2c91f94cde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "K428lOuXhdc8",
        "outputId": "b1e23055-178c-400c-8972-f3e7987e0892"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EYdfKGLj6h0"
      },
      "source": [
        "**NTK Eigenvalues**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3dByeQjhBYj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "vSn3Q_1IhisN",
        "outputId": "4c713f42-11b2-4de9-8698-085eb54c164d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIS5UH81kOxT"
      },
      "source": [
        "**Change of NTK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF4Q_iZshQ-0"
      },
      "outputs": [],
      "source": [
        "# Change of the NTK\n",
        "NTK_change_list = []\n",
        "K0 = K_list[0]\n",
        "for K in K_list:\n",
        "    diff = np.linalg.norm(K - K0) / np.linalg.norm(K0) \n",
        "    NTK_change_list.append(diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "E-_gPGpCkF4n",
        "outputId": "9893e038-907d-4425-bb6e-8ecdb2ad497d"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6,5))\n",
        "plt.plot(NTK_change_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg0ZGHbAkW6N"
      },
      "source": [
        "\n",
        "**Change of NN Params**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLGv9JUuioVZ"
      },
      "outputs": [],
      "source": [
        "# Change of the weights and biases\n",
        "def compute_weights_diff(weights_1, weights_2):\n",
        "    weights = []\n",
        "    N = len(weights_1)\n",
        "    for k in range(N):\n",
        "        weight = weights_1[k] - weights_2[k]\n",
        "        weights.append(weight)\n",
        "    return weights\n",
        "\n",
        "def compute_weights_norm(weights, biases):\n",
        "    norm = 0\n",
        "    for w in weights:\n",
        "        norm = norm + np.sum(np.square(w))\n",
        "    for b in biases:\n",
        "        norm = norm + np.sum(np.square(b))\n",
        "    norm = np.sqrt(norm)\n",
        "    return norm\n",
        "\n",
        "# Restore the list weights and biases\n",
        "weights_log = model.weights_log\n",
        "biases_log = model.biases_log\n",
        "\n",
        "weights_0 = weights_log[0]\n",
        "biases_0 = biases_log[0]\n",
        "\n",
        "# Norm of the weights at initialization\n",
        "weights_init_norm = compute_weights_norm(weights_0, biases_0)\n",
        "\n",
        "weights_change_list = []\n",
        "\n",
        "N = len(weights_log)\n",
        "for k in range(N):\n",
        "    weights_diff = compute_weights_diff(weights_log[k], weights_log[0])\n",
        "    biases_diff = compute_weights_diff(biases_log[k], biases_log[0])\n",
        "    \n",
        "    weights_diff_norm = compute_weights_norm(weights_diff, biases_diff)\n",
        "    weights_change = weights_diff_norm / weights_init_norm\n",
        "    weights_change_list.append(weights_change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "5NLsAxgzi4KH",
        "outputId": "74d92bf9-0dde-438e-e9b3-a551904f4e2f"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6,5))\n",
        "plt.plot(weights_change_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYbzkhfMjJ8k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PINNsNTK_Poisson.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
