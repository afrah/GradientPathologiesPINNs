Using mode: ntk
neural network: [1, 500, 500, 1]
Bc1 Training data size : 50
Bc2 Training data size : 50
interior Training data size : 100
Activation function: tanh
number of iterations: 40001
starter_learning_rate: 1.0000e-05
Method desciption : gradual learing rate , with  mini-batch batch. 
mean_grad_bcs: 1.4757e-01
mean_grad_res: 1.0063e+02
lam_res: 1.0047e+00
lam_bc: 2.1386e+02
Gradients information stored ...
Gradients information stored ...
mean_grad_bcs: 5.6996e-02
mean_grad_res: 3.1448e+00
lam_res: 1.0010e+00
lam_bc: 1.0085e+03
Gradients information stored ...
mean_grad_bcs: 5.2914e-02
mean_grad_res: 1.8716e+00
lam_res: 1.0010e+00
lam_bc: 1.0016e+03
mean_grad_bcs: 4.0458e-02
mean_grad_res: 1.4056e+00
lam_res: 1.0010e+00
lam_bc: 1.0059e+03
mean_grad_bcs: 2.9253e-02
mean_grad_res: 1.1058e+00
lam_res: 1.0010e+00
lam_bc: 1.0090e+03
mean_grad_bcs: 2.2100e-02
mean_grad_res: 9.7985e-01
lam_res: 1.0010e+00
lam_bc: 1.0011e+03
mean_grad_bcs: 1.7481e-02
mean_grad_res: 7.7588e-01
lam_res: 1.0010e+00
lam_bc: 1.0070e+03
mean_grad_bcs: 1.4008e-02
mean_grad_res: 6.4484e-01
lam_res: 1.0010e+00
lam_bc: 1.0116e+03
mean_grad_bcs: 1.1498e-02
mean_grad_res: 5.4717e-01
lam_res: 1.0010e+00
lam_bc: 1.0156e+03
mean_grad_bcs: 9.6494e-03
mean_grad_res: 4.7144e-01
lam_res: 1.0010e+00
lam_bc: 1.0193e+03
mean_grad_bcs: 8.2608e-03
mean_grad_res: 4.1205e-01
lam_res: 1.0010e+00
lam_bc: 1.0229e+03
mean_grad_bcs: 7.1999e-03
mean_grad_res: 3.6482e-01
lam_res: 1.0010e+00
lam_bc: 1.0263e+03
mean_grad_bcs: 6.3769e-03
mean_grad_res: 3.2812e-01
lam_res: 1.0010e+00
lam_bc: 1.0295e+03
mean_grad_bcs: 5.7266e-03
mean_grad_res: 2.9963e-01
lam_res: 1.0010e+00
lam_bc: 1.0326e+03
mean_grad_bcs: 5.2052e-03
mean_grad_res: 2.7812e-01
lam_res: 1.0010e+00
lam_bc: 1.0357e+03
mean_grad_bcs: 4.7779e-03
mean_grad_res: 2.6166e-01
lam_res: 1.0010e+00
lam_bc: 1.0385e+03
mean_grad_bcs: 4.4212e-03
mean_grad_res: 2.4932e-01
lam_res: 1.0010e+00
lam_bc: 1.0413e+03
mean_grad_bcs: 4.1184e-03
mean_grad_res: 2.3860e-01
lam_res: 1.0010e+00
lam_bc: 1.0440e+03
mean_grad_bcs: 3.8535e-03
mean_grad_res: 2.2906e-01
lam_res: 1.0010e+00
lam_bc: 1.0465e+03
mean_grad_bcs: 3.6194e-03
mean_grad_res: 2.2005e-01
lam_res: 1.0010e+00
lam_bc: 1.0489e+03
mean_grad_bcs: 3.4108e-03
mean_grad_res: 2.1122e-01
lam_res: 1.0010e+00
lam_bc: 1.0512e+03
mean_grad_bcs: 3.2179e-03
mean_grad_res: 2.0233e-01
lam_res: 1.0010e+00
lam_bc: 1.0534e+03
mean_grad_bcs: 3.0451e-03
mean_grad_res: 1.9415e-01
lam_res: 1.0009e+00
lam_bc: 1.0554e+03
mean_grad_bcs: 2.8872e-03
mean_grad_res: 1.8567e-01
lam_res: 1.0009e+00
lam_bc: 1.0574e+03
mean_grad_bcs: 2.7423e-03
mean_grad_res: 1.7866e-01
lam_res: 1.0009e+00
lam_bc: 1.0592e+03
mean_grad_bcs: 2.6055e-03
mean_grad_res: 1.6980e-01
lam_res: 1.0009e+00
lam_bc: 1.0610e+03
mean_grad_bcs: 2.4807e-03
mean_grad_res: 1.6278e-01
lam_res: 1.0009e+00
lam_bc: 1.0626e+03
mean_grad_bcs: 2.3669e-03
mean_grad_res: 1.5498e-01
lam_res: 1.0009e+00
lam_bc: 1.0642e+03
mean_grad_bcs: 2.2583e-03
mean_grad_res: 1.4706e-01
lam_res: 1.0009e+00
lam_bc: 1.0657e+03
mean_grad_bcs: 2.1568e-03
mean_grad_res: 1.3933e-01
lam_res: 1.0009e+00
lam_bc: 1.0672e+03
mean_grad_bcs: 2.0647e-03
mean_grad_res: 1.3293e-01
lam_res: 1.0009e+00
lam_bc: 1.0685e+03
mean_grad_bcs: 1.9775e-03
mean_grad_res: 1.2578e-01
lam_res: 1.0009e+00
lam_bc: 1.0699e+03
mean_grad_bcs: 1.8952e-03
mean_grad_res: 1.1903e-01
lam_res: 1.0009e+00
lam_bc: 1.0711e+03
mean_grad_bcs: 1.8191e-03
mean_grad_res: 1.1275e-01
lam_res: 1.0009e+00
lam_bc: 1.0724e+03
mean_grad_bcs: 1.7471e-03
mean_grad_res: 1.0579e-01
lam_res: 1.0009e+00
lam_bc: 1.0736e+03
mean_grad_bcs: 1.6814e-03
mean_grad_res: 1.0059e-01
lam_res: 1.0009e+00
lam_bc: 1.0747e+03
mean_grad_bcs: 1.6172e-03
mean_grad_res: 9.4486e-02
lam_res: 1.0009e+00
lam_bc: 1.0759e+03
mean_grad_bcs: 1.5580e-03
mean_grad_res: 8.8321e-02
lam_res: 1.0009e+00
lam_bc: 1.0770e+03
mean_grad_bcs: 1.5077e-03
mean_grad_res: 8.4782e-02
lam_res: 1.0009e+00
lam_bc: 1.0781e+03
mean_grad_bcs: 1.4543e-03
mean_grad_res: 7.8778e-02
lam_res: 1.0009e+00
lam_bc: 1.0791e+03
Gradients information stored ...
mean_grad_bcs: 1.4073e-03
mean_grad_res: 7.4371e-02
lam_res: 1.0009e+00
lam_bc: 1.0801e+03
elapsed: 9.39e+03
Relative L2 error_u: 3.85e-03
Relative L2 error_r: 1.13e-03
mean value of lambda_bc: nan
