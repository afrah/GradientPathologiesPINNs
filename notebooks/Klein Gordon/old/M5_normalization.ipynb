{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import griddata\n",
    "# from Klein_Gordon_model_tf import Sampler, Klein_Gordon\n",
    "import timeit\n",
    "import os\n",
    "os.environ[\"KMP_WARNINGS\"] = \"FALSE\" \n",
    "\n",
    "import scipy\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "import scipy\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "import os.path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "def u(x):\n",
    "    \"\"\"\n",
    "    :param x: x = (t, x)\n",
    "    \"\"\"\n",
    "    return x[:, 1:2] * np.cos(5 * np.pi * x[:, 0:1]) + (x[:, 0:1] * x[:, 1:2])**3\n",
    "\n",
    "def u_tt(x):\n",
    "    return - 25 * np.pi**2 * x[:, 1:2] * np.cos(5 * np.pi * x[:, 0:1]) + 6 * x[:,0:1] * x[:,1:2]**3\n",
    "\n",
    "def u_xx(x):\n",
    "    return np.zeros((x.shape[0], 1)) +  6 * x[:,1:2] * x[:,0:1]**3\n",
    "\n",
    "def f(x, alpha, beta, gamma, k):\n",
    "    return u_tt(x) + alpha * u_xx(x) + beta * u(x) + gamma * u(x)**k\n",
    "\n",
    "def operator(u, t, x, alpha, beta, gamma, k,  sigma_t=1.0, sigma_x=1.0):\n",
    "    u_t = tf.gradients(u, t)[0] / sigma_t\n",
    "    u_x = tf.gradients(u, x)[0] / sigma_x\n",
    "    u_tt = tf.gradients(u_t, t)[0]/ sigma_t\n",
    "    u_xx = tf.gradients(u_x, x)[0] / sigma_x\n",
    "    residual = u_tt + alpha * u_xx + beta * u + gamma * u**k\n",
    "    return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################################################################################################\n",
    "class neural_net(object):\n",
    "    def __init__(self, mean , std, layers):\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.num_layers = len(self.layers)\n",
    "        \n",
    "        # if len(inputs) == 0:\n",
    "        #     in_dim = self.layers[0]\n",
    "        #     self.X_mean = np.zeros([1, in_dim])\n",
    "        #     self.X_std = np.ones([1, in_dim])\n",
    "        # else:\n",
    "        # X = np.concatenate(inputs, 1)\n",
    "        self.X_mean = mean # X.mean(0, keepdims=True)\n",
    "        self.X_std = std #X.std(0, keepdims=True)\n",
    "        # print('self.X_mean : ' , self.X_mean)    \n",
    "        # print('self.X_std : ' , self.X_std)    \n",
    "\n",
    "        # if ExistModel== 1:\n",
    "        # self.weights , self.biases , self.gammas = self.load_NN(modelDir)\n",
    "        # else:\n",
    "        self.weights = [] \n",
    "        self.biases = []\n",
    "        # self.gammas = []\n",
    "        \n",
    "        self.weights , self.biases  = self.initialize_NN() #, self.gammas\n",
    "\n",
    "        # for l in range(0,self.num_layers-1):\n",
    "        #     in_dim = self.layers[l]\n",
    "        #     out_dim = self.layers[l+1]\n",
    "        #     W = np.random.normal(size=[in_dim, out_dim])\n",
    "        #     b = np.zeros([1, out_dim])\n",
    "        #     g = np.ones([1, out_dim])\n",
    "        #     # tensorflow variables\n",
    "        #     if ExistModel== 0:\n",
    "        #         self.weights.append(tf.Variable(W, dtype=tf.float32, trainable=True))\n",
    "        #         self.biases.append(tf.Variable(b, dtype=tf.float32, trainable=True))\n",
    "        #         self.gammas.append(tf.Variable(g, dtype=tf.float32, trainable=True))\n",
    "            \n",
    "    def __call__(self, *inputs):\n",
    "                \n",
    "        H =   (tf.concat(inputs, 1) - self.X_mean)/self.X_std\n",
    "    \n",
    "        for l in range( self.num_layers-2):\n",
    "            # print(l)\n",
    "            W = self.weights[l]\n",
    "            b = self.biases[l]\n",
    "            # g = self.gammas[l]\n",
    "            V = W/tf.norm(W, axis = 0, keepdims=True)\n",
    "            H = tf.matmul(H, V)\n",
    "            H = H + b\n",
    "            # H = H*tf.sigmoid(H)\n",
    "            H = tf.tanh(H)\n",
    "\n",
    "        W = self.weights[-1]\n",
    "        b = self.biases[-1]\n",
    "        H = tf.add(tf.matmul(H, W), b)\n",
    "        return H\n",
    "                    # return Y\n",
    "        # H = tf.concat(inputs, 1)\n",
    "        # num_layers = len(self.layers)\n",
    "        # for l in range(0, num_layers - 2):\n",
    "        #     W = self.weights[l]\n",
    "        #     b = self.biases[l]\n",
    "        #     H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        # W = self.weights[-1]\n",
    "        # b = self.biases[-1]\n",
    "        # H = tf.add(tf.matmul(H, W), b)\n",
    "        # return H\n",
    "\n",
    "    \n",
    "    def load_NN(self, modelDir):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        gammas = []\n",
    "\n",
    "        num_layers = len(self.layers)\n",
    "        with open(modelDir, 'rb') as f:\n",
    "            uv_weights, uv_biases , uv_gammas = pickle.load(f)\n",
    "\n",
    "            # Stored model must has the same # of layers\n",
    "            assert num_layers == (len(uv_weights)+1)\n",
    "\n",
    "            for num in range(0, num_layers - 1):\n",
    "                W = tf.Variable(uv_weights[num], dtype=tf.float32)\n",
    "                b = tf.Variable(uv_biases[num],  dtype=tf.float32)\n",
    "                # g = tf.Variable(uv_biases[num],  dtype=tf.float32)\n",
    "\n",
    "                weights.append(W)\n",
    "                biases.append(b)\n",
    "                # gammas.append(g)\n",
    "            print(\" - Load NN parameters successfully...\")\n",
    "        return weights, biases #, gammas\n",
    "    \n",
    "    def initialize_NN(self):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        gammas = []\n",
    "\n",
    "        num_layers = len(self.layers)\n",
    "        for l in range(0, num_layers - 1):\n",
    "            W = self.xavier_init(size=[self.layers[l], self.layers[l + 1]])\n",
    "            b = tf.Variable(tf.zeros([1, self.layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            # g = tf.Variable(tf.ones([1, self.layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "            # gammas.append(g)\n",
    "        return weights, biases #, gammas\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2.0 / (in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim],  stddev=xavier_stddev,  dtype=tf.float32),dtype=tf.float32)\n",
    "#######################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Sampler:\n",
    "    # Initialize the class\n",
    "    def __init__(self, dim, coords, func, name = None):\n",
    "        self.dim = dim\n",
    "        self.coords = coords\n",
    "        self.func = func\n",
    "        self.name = name\n",
    "    def sample(self, N):\n",
    "        x = self.coords[0:1,:] + (self.coords[1:2,:]-self.coords[0:1,:])*np.random.rand(N, self.dim)\n",
    "        y = self.func(x)\n",
    "        return x, y\n",
    "\n",
    "class Klein_Gordon:\n",
    "    # Initialize the class\n",
    "    def __init__(self, layers, operator, ics_sampler, bcs_sampler, res_sampler, alpha, beta, gamma, k, mode, sess):\n",
    "            # mode = Klein_Gordon(layers, operator, ics_sampler, bcs_sampler, res_sampler, alpha, beta, gamma, k, mode, sess)\n",
    "\n",
    "\n",
    "\n",
    "        self.mode = mode\n",
    "        self.layers = layers\n",
    "        self.dirname, logpath = self.make_output_dir()\n",
    "        self.logger = self.get_logger(logpath)     \n",
    "\n",
    "        # Normalization constants\n",
    "        X, _ = res_sampler.sample(np.int32(1e5))\n",
    "        self.mu_X, self.sigma_X = X.mean(0), X.std(0)\n",
    "        self.mu_t, self.sigma_t = self.mu_X[0], self.sigma_X[0]\n",
    "        self.mu_x, self.sigma_x = self.mu_X[1], self.sigma_X[1]\n",
    "\n",
    "        # Samplers\n",
    "        self.operator = operator\n",
    "        self.ics_sampler = ics_sampler\n",
    "        self.bcs_sampler = bcs_sampler\n",
    "        self.res_sampler = res_sampler\n",
    "\n",
    "        # Klein_Gordon constant\n",
    "        self.alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "        self.beta = tf.constant(beta, dtype=tf.float32)\n",
    "        self.gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "        self.k = tf.constant(k, dtype=tf.float32)\n",
    "\n",
    "\n",
    "        # Record stiff ratio\n",
    "        # self.stiff_ratio = stiff_ratio\n",
    "\n",
    "        # Adaptive re-weighting constant\n",
    "        self.rate = 0.9\n",
    "        self.adaptive_constant_ics_val = np.array(1.0)\n",
    "        self.adaptive_constant_bcs_val = np.array(1.0)\n",
    "        self.adaptive_constant_res_val = np.array(1.0)\n",
    "\n",
    "        # Initialize network weights and biases\n",
    "        # self.layers = layers\n",
    "        # self.weights, self.biases = self.initialize_NN(layers)\n",
    "\n",
    "        # if model in ['M3', 'M4']:\n",
    "        #     # Initialize encoder weights and biases\n",
    "        #     self.encoder_weights_1 = self.xavier_init([2, layers[1]])\n",
    "        #     self.encoder_biases_1 = self.xavier_init([1, layers[1]])\n",
    "\n",
    "        #     self.encoder_weights_2 = self.xavier_init([2, layers[1]])\n",
    "        #     self.encoder_biases_2 = self.xavier_init([1, layers[1]])\n",
    "\n",
    "        # Define Tensorflow session\n",
    "        self.sess = sess #tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "\n",
    "        # Define placeholders and computational graph\n",
    "        self.t_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.t_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.u_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.t_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.u_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.t_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.u_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.t_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.adaptive_constant_ics_tf = tf.placeholder(tf.float32, shape=self.adaptive_constant_ics_val.shape)\n",
    "        self.adaptive_constant_bcs_tf = tf.placeholder(tf.float32, shape=self.adaptive_constant_bcs_val.shape)\n",
    "        self.adaptive_constant_res_tf = tf.placeholder(tf.float32, shape=self.adaptive_constant_res_val.shape)\n",
    "\n",
    "        self.net_cuvwp = neural_net(self.mu_X, self.sigma_X ,   layers =self.layers)\n",
    "\n",
    "        # Evaluate predictions\n",
    "        self.u_ics_pred = self.net_cuvwp(self.t_ics_tf, self.x_ics_tf)\n",
    "        self.u_t_ics_pred = tf.reduce_mean( ( tf.square(tf.gradients(self.u_ics_pred , self.t_ics_tf)[0]/self.sigma_t ) )) #self.net_u_t(self.t_ics_tf, self.x_ics_tf)\n",
    "        self.u_bc1_pred = self.net_cuvwp(self.t_bc1_tf, self.x_bc1_tf) \n",
    "        self.u_bc2_pred = self.net_cuvwp(self.t_bc2_tf, self.x_bc2_tf)\n",
    "\n",
    "        self.u_pred = self.net_cuvwp(self.t_u_tf, self.x_u_tf)\n",
    "        self.r_pred = self.net_r(self.t_r_tf, self.x_r_tf)\n",
    "\n",
    "        # Boundary loss and Initial loss\n",
    "        self.loss_ic_u = tf.reduce_mean(tf.square(self.u_ics_tf - self.u_ics_pred))\n",
    "        self.loss_ic_u_t = tf.reduce_mean(tf.square(self.u_t_ics_pred))\n",
    "        self.loss_bc1 = tf.reduce_mean(tf.square(self.u_bc1_pred - self.u_bc1_tf))\n",
    "        self.loss_bc2 = tf.reduce_mean(tf.square(self.u_bc2_pred - self.u_bc2_tf))\n",
    "\n",
    "        self.loss_bcs =  (self.loss_bc1 + self.loss_bc2 + self.loss_ic_u )\n",
    "        self.loss_ics =  ( self.loss_ic_u_t)\n",
    "        self.loss_u = self.loss_bcs + self.loss_ics\n",
    "\n",
    "        # Residual loss\n",
    "        self.loss_res = tf.reduce_mean(tf.square(self.r_pred - self.r_tf))\n",
    "\n",
    "#     daptive_constant_ics_val: 3.803e+05\n",
    "# adaptive_constant_bcs1_val: 1.414e+03\n",
    "\n",
    "        # self.loss = self.adaptive_constant_res_tf * self.loss_res + self.adaptive_constant_bcs_tf * (self.loss_bc1 + self.loss_bc2 + self.loss_ic_u) + self.adaptive_constant_ics_tf * (self.loss_ic_u_t)\n",
    "        self.loss =  1 * self.loss_res + 1000* (self.loss_bc1 + self.loss_bc2 + self.loss_ic_u) + 1 * (self.loss_ic_u_t)\n",
    "\n",
    "        # Define optimizer with learning rate schedule\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        starter_learning_rate = 1e-3\n",
    "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step , 1000, 0.9, staircase=False)\n",
    "        # Passing global_step to minimize() will increment it at each step.\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss, global_step=self.global_step  )\n",
    "\n",
    "\n",
    "        self.loss_tensor_list = [self.loss ,  self.loss_res,  self.loss_bcs , self.loss_ics ] \n",
    "        self.loss_list = [\"total loss\" , \"loss_res\" , \"loss_bcs\", \"loss_ics\"] \n",
    "        \n",
    "        self.epoch_loss = dict.fromkeys(self.loss_list, 0)\n",
    "        self.loss_history = dict((loss, []) for loss in self.loss_list)\n",
    "        # Logger\n",
    "        self.loss_u_log = []\n",
    "        self.loss_r_log = []\n",
    "        # self.saver = tf.train.Saver()\n",
    "\n",
    "        # Generate dicts for gradients storage\n",
    "        self.dict_gradients_res_layers = self.generate_grad_dict()\n",
    "        self.dict_gradients_bcs_layers = self.generate_grad_dict()\n",
    "        self.dict_gradients_ics_layers = self.generate_grad_dict()\n",
    "\n",
    "        # Gradients Storage\n",
    "        self.grad_res = []\n",
    "        self.grad_ics = []\n",
    "        self.grad_bcs = []\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.grad_res.append(tf.gradients(self.loss_res, self.net_cuvwp.weights[i])[0])\n",
    "            self.grad_bcs.append(tf.gradients(self.loss_bcs, self.net_cuvwp.weights[i])[0])\n",
    "            self.grad_ics.append(tf.gradients(self.loss_ics, self.net_cuvwp.weights[i])[0])\n",
    "\n",
    "        # Store the adaptive constant\n",
    "  \n",
    "        self.adaptive_constant_bcs_log = []\n",
    "        self.adaptive_constant_ics_log = []\n",
    "        self.adaptive_constant_res_log = []\n",
    "\n",
    "        self.mean_adaptive_constant_res_log = []\n",
    "        self.mean_adaptive_constant_bcs_log = []\n",
    "        self.mean_adaptive_constant_ics_log = []\n",
    "        # Compute the adaptive constant\n",
    "        \n",
    "        self.std_grad_res_list = []\n",
    "        self.std_grad_bcs_list = []\n",
    "        self.std_grad_ics_list = []\n",
    "\n",
    "        self.mean_grad_res_list = []\n",
    "        self.mean_grad_bcs_list = []\n",
    "        self.mean_grad_ics_list = []\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.std_grad_res_list.append(tf.math.reduce_std(tf.abs(self.grad_res[i]))) \n",
    "            self.std_grad_bcs_list.append(tf.math.reduce_std(tf.abs(self.grad_bcs[i]))) \n",
    "            self.std_grad_ics_list.append(tf.math.reduce_std(tf.abs(self.grad_ics[i]))) \n",
    "\n",
    "            self.mean_grad_res_list.append(tf.reduce_mean(tf.abs(self.grad_res[i])))\n",
    "            self.mean_grad_bcs_list.append(tf.reduce_mean(tf.abs(self.grad_bcs[i])))\n",
    "            self.mean_grad_ics_list.append(tf.reduce_mean(tf.abs(self.grad_ics[i])))\n",
    "        \n",
    "        self.std_grad_res = tf.math.reduce_std(tf.stack(self.std_grad_res_list))\n",
    "        self.std_grad_bcs = tf.math.reduce_std(tf.stack(self.std_grad_bcs_list))\n",
    "        self.std_grad_ics = tf.math.reduce_std(tf.stack(self.std_grad_ics_list))\n",
    "\n",
    "        self.mean_grad_res = tf.reduce_mean(tf.stack(self.mean_grad_res_list))\n",
    "        self.mean_grad_bcs = tf.reduce_mean(tf.stack(self.mean_grad_bcs_list))\n",
    "        self.mean_grad_ics = tf.reduce_mean(tf.stack(self.mean_grad_ics_list))\n",
    "    \n",
    "\n",
    "        self.kurtosis_grad_res_list = []\n",
    "        self.kurtosis_grad_bcs_list = []\n",
    "        self.kurtosis_grad_ics_list = []\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "\n",
    "            self.kurtosis_grad_res_list.append(tf.math.reduce_mean(   tf.math.pow ((( tf.abs(self.grad_res[i]) - self.mean_grad_res) / self.std_grad_res),4)))\n",
    "            self.kurtosis_grad_bcs_list.append(tf.math.reduce_mean(   tf.math.pow ((( tf.abs(self.grad_bcs[i]) - self.mean_grad_bcs) / self.std_grad_bcs),4)))\n",
    "            self.kurtosis_grad_ics_list.append(tf.math.reduce_mean(   tf.math.pow ((( tf.abs(self.grad_ics[i]) - self.mean_grad_ics) / self.std_grad_ics),4)))\n",
    "\n",
    "        self.kurtosis_grad_res = tf.math.reduce_mean(tf.stack(self.kurtosis_grad_res_list))\n",
    "        self.kurtosis_grad_bcs = tf.math.reduce_mean(tf.stack(self.kurtosis_grad_bcs_list))\n",
    "        self.kurtosis_grad_ics = tf.math.reduce_mean(tf.stack(self.kurtosis_grad_ics_list))\n",
    "    \n",
    "        # # Stiff Ratio\n",
    "        # if self.stiff_ratio:\n",
    "        #     self.Hessian, self.Hessian_ics, self.Hessian_bcs, self.Hessian_res = self.get_H_op()\n",
    "        #     self.eigenvalues, _ = tf.linalg.eigh(self.Hessian)\n",
    "        #     self.eigenvalues_ics, _ = tf.linalg.eigh(self.Hessian_ics)\n",
    "        #     self.eigenvalues_bcs, _ = tf.linalg.eigh(self.Hessian_bcs)\n",
    "        #     self.eigenvalues_res, _ = tf.linalg.eigh(self.Hessian_res)\n",
    "\n",
    "        #     self.eigenvalue_log = []\n",
    "        #     self.eigenvalue_ics_log = []\n",
    "        #     self.eigenvalue_bcs_log = []\n",
    "        #     self.eigenvalue_res_log = []\n",
    "\n",
    "        # Initialize Tensorflow variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    # Create dictionary to store gradients\n",
    "    def generate_grad_dict(self, layers):\n",
    "        num = len(layers) - 1\n",
    "        grad_dict = {}\n",
    "        for i in range(num):\n",
    "            grad_dict['layer_{}'.format(i + 1)] = []\n",
    "        return grad_dict\n",
    "\n",
    "    # Save gradients\n",
    "    def save_gradients(self, tf_dict):\n",
    "        num_layers = len(self.layers)\n",
    "        for i in range(num_layers - 1):\n",
    "            grad_ics_value , grad_bcs_value, grad_res_value= self.sess.run([self.grad_ics[i],\n",
    "                                                                            self.grad_bcs[i],\n",
    "                                                                            self.grad_res[i]],\n",
    "                                                                            feed_dict=tf_dict)\n",
    "\n",
    "            # save gradients of loss_res and loss_bcs\n",
    "            self.dict_gradients_ics_layers['layer_' + str(i + 1)].append(grad_ics_value.flatten())\n",
    "            self.dict_gradients_bcs_layers['layer_' + str(i + 1)].append(grad_bcs_value.flatten())\n",
    "            self.dict_gradients_res_layers['layer_' + str(i + 1)].append(grad_res_value.flatten())\n",
    "        return None\n",
    "\n",
    "    # Compute the Hessian\n",
    "    def flatten(self, vectors):\n",
    "        return tf.concat([tf.reshape(v, [-1]) for v in vectors], axis=0)\n",
    "\n",
    "    def get_Hv(self, v):\n",
    "        loss_gradients = self.flatten(tf.gradients(self.loss, self.weights))\n",
    "        vprod = tf.math.multiply(loss_gradients, tf.stop_gradient(v))\n",
    "        Hv_op = self.flatten(tf.gradients(vprod, self.weights))\n",
    "        return Hv_op\n",
    "\n",
    "    def get_Hv_ics(self, v):\n",
    "        loss_gradients = self.flatten(tf.gradients(self.loss_ics, self.weights))\n",
    "        vprod = tf.math.multiply(loss_gradients, tf.stop_gradient(v))\n",
    "        Hv_op = self.flatten(tf.gradients(vprod, self.weights))\n",
    "        return Hv_op\n",
    "\n",
    "    def get_Hv_bcs(self, v):\n",
    "        loss_gradients = self.flatten(tf.gradients(self.loss_bcs, self.weights))\n",
    "        vprod = tf.math.multiply(loss_gradients, tf.stop_gradient(v))\n",
    "        Hv_op = self.flatten(tf.gradients(vprod, self.weights))\n",
    "        return Hv_op\n",
    "\n",
    "    def get_Hv_res(self, v):\n",
    "        loss_gradients = self.flatten(tf.gradients(self.loss_res, self.weights))\n",
    "        vprod = tf.math.multiply(loss_gradients, tf.stop_gradient(v))\n",
    "        Hv_op = self.flatten(tf.gradients(vprod, self.weights))\n",
    "        return Hv_op\n",
    "\n",
    "    def get_H_op(self):\n",
    "        self.P = self.flatten(self.weights).get_shape().as_list()[0]\n",
    "        H = tf.map_fn(self.get_Hv, tf.eye(self.P, self.P), dtype='float32')\n",
    "        H_ics = tf.map_fn(self.get_Hv_ics, tf.eye(self.P, self.P), dtype='float32')\n",
    "        H_bcs = tf.map_fn(self.get_Hv_bcs, tf.eye(self.P, self.P), dtype='float32')\n",
    "        H_res = tf.map_fn(self.get_Hv_res, tf.eye(self.P, self.P), dtype='float32')\n",
    "\n",
    "        return H, H_ics, H_bcs, H_res\n",
    "\n",
    "    # # Xavier initialization\n",
    "    # def xavier_init(self, size):\n",
    "    #     in_dim = size[0]\n",
    "    #     out_dim = size[1]\n",
    "    #     xavier_stddev = 1. / np.sqrt((in_dim + out_dim) / 2.)\n",
    "    #     return tf.Variable(tf.random_normal([in_dim, out_dim], dtype=tf.float32) * xavier_stddev,\n",
    "    #                        dtype=tf.float32)\n",
    "\n",
    "    # # Initialize network weights and biases using Xavier initialization\n",
    "    # def initialize_NN(self, layers):\n",
    "    #     weights = []\n",
    "    #     biases = []\n",
    "    #     num_layers = len(layers)\n",
    "    #     for l in range(0, num_layers - 1):\n",
    "    #         W = self.xavier_init(size=[layers[l], layers[l + 1]])\n",
    "    #         b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
    "    #         weights.append(W)\n",
    "    #         biases.append(b)\n",
    "    #     return weights, biases\n",
    "\n",
    "    # # Evaluates the forward pass\n",
    "    # def forward_pass(self, H):\n",
    "    #     num_layers = len(self.layers)\n",
    "    #     for l in range(0, num_layers - 2):\n",
    "    #         W = self.weights[l]\n",
    "    #         b = self.biases[l]\n",
    "    #         H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "    #     W = self.weights[-1]\n",
    "    #     b = self.biases[-1]\n",
    "    #     H = tf.add(tf.matmul(H, W), b)\n",
    "    #     return H\n",
    "\n",
    "    # if self.model in ['M3', 'M4']:\n",
    "    #     num_layers = len(self.layers)\n",
    "    #     encoder_1 = tf.tanh(tf.add(tf.matmul(H, self.encoder_weights_1), self.encoder_biases_1))\n",
    "    #     encoder_2 = tf.tanh(tf.add(tf.matmul(H, self.encoder_weights_2), self.encoder_biases_2))\n",
    "\n",
    "    #     for l in range(0, num_layers - 2):\n",
    "    #         W = self.weights[l]\n",
    "    #         b = self.biases[l]\n",
    "    #         H = tf.math.multiply(tf.tanh(tf.add(tf.matmul(H, W), b)), encoder_1) + \\\n",
    "    #             tf.math.multiply(1 - tf.tanh(tf.add(tf.matmul(H, W), b)), encoder_2)\n",
    "\n",
    "    #     W = self.weights[-1]\n",
    "    #     b = self.biases[-1]\n",
    "    #     H = tf.add(tf.matmul(H, W), b)\n",
    "    #     return H\n",
    "\n",
    "    # Forward pass for u\n",
    "    # def net_u(self, t, x):\n",
    "    #     u = self.forward_pass(tf.concat([t, x], 1))\n",
    "    #     return u\n",
    "\n",
    "    def net_u_t(self, t, x):\n",
    "        u = self.net_u(t, x)\n",
    "        u_t = tf.gradients(u, t)[0] / self.sigma_t\n",
    "        return u_t\n",
    "\n",
    "    # Forward pass for residual\n",
    "    def net_r(self, t, x):\n",
    "        u = self.net_cuvwp(t, x)\n",
    "        residual = self.operator(u, t, x,  self.alpha, self.beta, self.gamma, self.k, self.sigma_t, self.sigma_x)\n",
    "        return residual\n",
    "\n",
    "    def fetch_minibatch(self, sampler, N):\n",
    "        X, Y = sampler.sample(N)\n",
    "        X = (X - self.mu_X) #/ self.sigma_X\n",
    "        return X, Y\n",
    "\n",
    "    # Trains the model by minimizing the MSE loss\n",
    "################################################################################################################\n",
    "\n",
    "    def train(self, nIter=10000):\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "        batch_size = 500\n",
    "        # Fetch boundary mini-batches\n",
    "        X_ics_batch, u_ics_batch = self.fetch_minibatch(self.ics_sampler, batch_size)\n",
    "        X_bc1_batch, u_bc1_batch = self.fetch_minibatch(self.bcs_sampler[0], batch_size)\n",
    "        X_bc2_batch, u_bc2_batch = self.fetch_minibatch(self.bcs_sampler[1], batch_size)\n",
    "\n",
    "        batch_size = 5000\n",
    "\n",
    "        # Fetch residual mini-batch\n",
    "        X_res_batch, f_res_batch = self.fetch_minibatch(self.res_sampler, batch_size)\n",
    "\n",
    "        # Define a dictionary for associating placeholders with data\n",
    "        tf_dict = {self.t_ics_tf: X_ics_batch[:, 0:1], self.x_ics_tf: X_ics_batch[:, 1:2],\n",
    "                    self.u_ics_tf: u_ics_batch,\n",
    "                    self.t_bc1_tf: X_bc1_batch[:, 0:1], self.x_bc1_tf: X_bc1_batch[:, 1:2],\n",
    "                    self.u_bc1_tf: u_bc1_batch,\n",
    "                    self.t_bc2_tf: X_bc2_batch[:, 0:1], self.x_bc2_tf: X_bc2_batch[:, 1:2],\n",
    "                    self.u_bc2_tf: u_bc2_batch,\n",
    "                    self.t_r_tf: X_res_batch[:, 0:1], self.x_r_tf: X_res_batch[:, 1:2],\n",
    "                    self.r_tf: f_res_batch,\n",
    "                    self.adaptive_constant_ics_tf: self.adaptive_constant_ics_val,\n",
    "                    self.adaptive_constant_bcs_tf: self.adaptive_constant_bcs_val}\n",
    "\n",
    "        # Run the Tensorflow session to minimize the loss\n",
    "\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op, tf_dict)\n",
    "\n",
    "            # Print\n",
    "            if it % 10 == 0:\n",
    "                elapsed = timeit.default_timer() - start_time\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                loss_u_value, loss_r_value = self.sess.run([self.loss_u, self.loss_res], tf_dict)\n",
    "\n",
    "                # Compute and Print adaptive weights during training\n",
    "                # Compute the adaptive constant\n",
    "                adaptive_constant_ics_val, adaptive_constant_bcs_val = self.sess.run( [self.adaptive_constant_ics, self.adaptive_constant_bcs], tf_dict)\n",
    "                # Print adaptive weights during training\n",
    "                self.adaptive_constant_ics_val = adaptive_constant_ics_val * ( 1.0 - self.rate) + self.rate * self.adaptive_constant_ics_val\n",
    "                self.adaptive_constant_bcs_val = adaptive_constant_bcs_val * ( 1.0 - self.rate) + self.rate * self.adaptive_constant_bcs_val\n",
    "\n",
    "                # # Store loss and adaptive weights\n",
    "                # self.loss_u_log.append(loss_u_value)\n",
    "                # self.loss_r_log.append(loss_r_value)\n",
    "\n",
    "                # self.adaptive_constant_ics_log.append(self.adaptive_constant_ics_val)\n",
    "                # self.adaptive_constant_bcs_log.append(self.adaptive_constant_bcs_val)\n",
    "                if it % 1000 == 0:\n",
    "\n",
    "                    print('It: %d, Loss: %.3e, Loss_u: %.3e, Loss_r: %.3e, Time: %.2f' %  (it, loss_value, loss_u_value, loss_r_value, elapsed))\n",
    "                    print(\"constant_ics_val: {:.3f}, constant_bcs_val: {:.3f}\".format(  self.adaptive_constant_ics_val,  self.adaptive_constant_bcs_val))\n",
    "                start_time = timeit.default_timer()\n",
    "\n",
    "            # # Compute the eigenvalues of the Hessian of losses\n",
    "            # if self.stiff_ratio:\n",
    "            #     if it % 1000 == 0:\n",
    "            #         print(\"Eigenvalues information stored ...\")\n",
    "            #         eigenvalues, eigenvalues_ics, eigenvalues_bcs, eigenvalues_res = self.sess.run([self.eigenvalues,\n",
    "            #                                                                                         self.eigenvalues_ics,\n",
    "            #                                                                                         self.eigenvalues_bcs,\n",
    "            #                                                                                         self.eigenvalues_res], tf_dict)\n",
    "            #         self.eigenvalue_log.append(eigenvalues)\n",
    "            #         self.eigenvalue_ics_log.append(eigenvalues_bcs)\n",
    "            #         self.eigenvalue_bcs_log.append(eigenvalues_bcs)\n",
    "            #         self.eigenvalue_res_log.append(eigenvalues_res)\n",
    "\n",
    "            # # Store gradients\n",
    "            # if it % 10000 == 0:\n",
    "            #     self.save_gradients(tf_dict)\n",
    "            #     print(\"Gradients information stored ...\")\n",
    "\n",
    "################################################################################################################\n",
    "                \n",
    "\n",
    "    def lambda_balance(self  , term  ):\n",
    "                histoy_mean =  np.mean(self.loss_history[term])\n",
    "                m = 3 #len(self.loss_list)\n",
    "                num = np.exp( (self.loss_history[term][-1] -2 * self.loss_history[term][-2] +  self.loss_history[term][-3]) / np.mean(self.loss_history[term][-99::]) )#/(self.T * histoy_mean)) np.exp( )\n",
    "                denum = 0 \n",
    "\n",
    "                for  key in self.loss_list:\n",
    "                    denum +=  np.exp(  (self.loss_history[key][-1] -2 * self.loss_history[key][-2] +  self.loss_history[key][-3])  /  np.mean(self.loss_history[key][-99::]) )# /(self.T * histoy_mean))  np.exp(self.loss_history[key][-1] )\n",
    "                return m * (num / denum)\n",
    "    \n",
    "    def trainmb(self, nIter=10000, batch_size=128):\n",
    "        itValues = [1,100,1000,39999]\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "        # Fetch boundary mini-batches\n",
    "        # batch_size = 500\n",
    "        for it in range( nIter):\n",
    "\n",
    "            X_ics_batch, u_ics_batch = self.fetch_minibatch(self.ics_sampler, batch_size)\n",
    "            X_bc1_batch, u_bc1_batch = self.fetch_minibatch(self.bcs_sampler[0], batch_size)\n",
    "            X_bc2_batch, u_bc2_batch = self.fetch_minibatch(self.bcs_sampler[1], batch_size)\n",
    "\n",
    "            # Fetch residual mini-batch\n",
    "            # batch_size = 5000\n",
    "\n",
    "            X_res_batch, f_res_batch = self.fetch_minibatch(self.res_sampler, batch_size)\n",
    "\n",
    "            # Define a dictionary for associating placeholders with data\n",
    "            tf_dict = {self.t_ics_tf: X_ics_batch[:, 0:1], self.x_ics_tf: X_ics_batch[:, 1:2],\n",
    "                       self.u_ics_tf: u_ics_batch,\n",
    "                       self.t_bc1_tf: X_bc1_batch[:, 0:1], self.x_bc1_tf: X_bc1_batch[:, 1:2],\n",
    "                       self.u_bc1_tf: u_bc1_batch,\n",
    "                       self.t_bc2_tf: X_bc2_batch[:, 0:1], self.x_bc2_tf: X_bc2_batch[:, 1:2],\n",
    "                       self.u_bc2_tf: u_bc2_batch,\n",
    "                       self.t_r_tf: X_res_batch[:, 0:1], self.x_r_tf: X_res_batch[:, 1:2],\n",
    "                       self.r_tf: f_res_batch,\n",
    "                       self.adaptive_constant_ics_tf: self.adaptive_constant_ics_val,\n",
    "                       self.adaptive_constant_bcs_tf: self.adaptive_constant_bcs_val,\n",
    "                       self.adaptive_constant_res_tf: self.adaptive_constant_res_val\n",
    "                       }\n",
    "\n",
    "            # Run the Tensorflow session to minimize the loss\n",
    "            _ , batch_losses = self.sess.run( [  self.train_op , self.loss_tensor_list ] ,tf_dict)\n",
    "            self.assign_batch_losses(batch_losses)\n",
    "            for key in self.loss_history:\n",
    "                self.loss_history[key].append(self.epoch_loss[key])\n",
    "\n",
    "            # Print\n",
    "            if it % 100 == 0:\n",
    "                elapsed = timeit.default_timer() - start_time\n",
    "                [loss ,  loss_res,  loss_bcs , loss_ics ]  = batch_losses\n",
    "\n",
    "                self.print('It: %d, Loss: %.3e, loss_bcs: %.3e, loss_ics: %.3e, Loss_r: %.3e, Time: %.2f' %(it, loss, loss_bcs , loss_ics, loss_res, elapsed))\n",
    "\n",
    "                # Compute and Print adaptive weights during training\n",
    "                std_grad_res, std_grad_bcs, std_grad_ics , kurtosis_grad_res, kurtosis_grad_bcs ,kurtosis_grad_ics  = self.sess.run( [self.std_grad_res, self.std_grad_bcs , self.std_grad_ics,  self.mean_grad_res , self.mean_grad_bcs , self.mean_grad_ics  ], tf_dict)\n",
    "                if it == 0:\n",
    "\n",
    "                    self.adaptive_constant_res_val =  np.max([ std_grad_res ,std_grad_ics , std_grad_bcs ]) / std_grad_res  # np.max([ kurtosis_grad_res ,kurtosis_grad_bcs , kurtosis_grad_ics ])\n",
    "                    self.adaptive_constant_ics_val = np.max([ std_grad_res ,std_grad_ics , std_grad_bcs ])  / std_grad_ics\n",
    "                    self.adaptive_constant_bcs_val = np.max([ std_grad_res ,std_grad_ics , std_grad_bcs ])  / std_grad_bcs\n",
    "\n",
    "                self.print('std_grad_res: {:.3e}'.format( std_grad_res))\n",
    "                self.print('std_grad_bcs: {:.3e}'.format( std_grad_bcs))\n",
    "                self.print('std_grad_ics: {:.3e}'.format( std_grad_ics))\n",
    "                \n",
    "                self.print('kurtosis_grad_res: {:.3e}'.format( kurtosis_grad_res))\n",
    "                self.print('kurtosis_grad_bcs: {:.3e}'.format( kurtosis_grad_bcs))\n",
    "                self.print('kurtosis_grad_ics: {:.3e}'.format( kurtosis_grad_ics))\n",
    "                \n",
    "                self.print('adaptive_constant_res_val: {:.3e}'.format( self.adaptive_constant_res_val))\n",
    "                self.print('adaptive_constant_ics_val: {:.3e}'.format( self.adaptive_constant_ics_val))\n",
    "                self.print('adaptive_constant_bcs1_val: {:.3e}'.format( self.adaptive_constant_bcs_val))\n",
    "                \n",
    "                self.adaptive_constant_res_log.append(self.adaptive_constant_res_val)\n",
    "                self.adaptive_constant_bcs_log.append(self.adaptive_constant_bcs_val)\n",
    "                self.adaptive_constant_ics_log.append(self.adaptive_constant_ics_val)\n",
    "\n",
    "                max_grad_res , mean_grad_bcs, mean_grad_ics = self.sess.run( [ self.std_grad_res , self.mean_grad_bcs , self.mean_grad_ics  ], tf_dict)\n",
    "\n",
    "                self.mean_adaptive_constant_res_log.append( max_grad_res)\n",
    "                self.mean_adaptive_constant_bcs_log.append( mean_grad_bcs)\n",
    "                self.mean_adaptive_constant_ics_log.append( mean_grad_ics)\n",
    "\n",
    "            start_time =  timeit.default_timer()\n",
    "            if it in itValues:\n",
    "                    self.plot_layerLoss(tf_dict , it)\n",
    "                    self.print(\"Gradients information stored ...\")\n",
    "\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    # Evaluates predictions at test points\n",
    "    def predict_u(self, X_star):\n",
    "        X_star = (X_star - self.mu_X) #/ self.sigma_X\n",
    "        tf_dict = {self.t_u_tf: X_star[:, 0:1], self.x_u_tf: X_star[:, 1:2]}\n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "        return u_star\n",
    "\n",
    "    def predict_r(self, X_star):\n",
    "        X_star = (X_star - self.mu_X) #/ self.sigma_X\n",
    "        tf_dict = {self.t_r_tf: X_star[:, 0:1], self.x_r_tf: X_star[:, 1:2]}\n",
    "        r_star = self.sess.run(self.r_pred, tf_dict)\n",
    "        return r_star\n",
    "\n",
    "  # ###############################################################################################################################################\n",
    "   # \n",
    "   #  \n",
    "    def plot_layerLoss(self , tf_dict , epoch):\n",
    "        ## Gradients #\n",
    "        num_layers = len(self.layers)\n",
    "        for i in range(num_layers - 1):\n",
    "            grad_res, grad_bc1  , grad_ics  = self.sess.run([ self.grad_res[i],self.grad_bcs[i],self.grad_ics[i]], feed_dict=tf_dict)\n",
    "\n",
    "            # save gradients of loss_r and loss_u\n",
    "            self.dict_gradients_res_layers['layer_' + str(i + 1)].append(grad_res.flatten())\n",
    "            self.dict_gradients_bcs_layers['layer_' + str(i + 1)].append(grad_bc1.flatten())\n",
    "            self.dict_gradients_ics_layers['layer_' + str(i + 1)].append(grad_ics.flatten())\n",
    "\n",
    "        num_hidden_layers = num_layers -1\n",
    "        cnt = 1\n",
    "        fig = plt.figure(4, figsize=(13, 4))\n",
    "        for j in range(num_hidden_layers):\n",
    "            ax = plt.subplot(1, num_hidden_layers, cnt)\n",
    "            ax.set_title('Layer {}'.format(j + 1))\n",
    "            ax.set_yscale('symlog')\n",
    "            gradients_res = self.dict_gradients_res_layers['layer_' + str(j + 1)][-1]\n",
    "            gradients_bc1 = self.dict_gradients_bcs_layers['layer_' + str(j + 1)][-1]\n",
    "            gradients_ics = self.dict_gradients_ics_layers['layer_' + str(j + 1)][-1]\n",
    "\n",
    "            sns.distplot(gradients_res, hist=False,kde_kws={\"shade\": False},norm_hist=True,  label=r'$\\nabla_\\theta \\mathcal{L}_r$')\n",
    "\n",
    "            sns.distplot(gradients_bc1, hist=False,kde_kws={\"shade\": False},norm_hist=True,   label=r'$\\nabla_\\theta \\mathcal{L}_{u_{bc1}}$')\n",
    "            sns.distplot(gradients_ics, hist=False,kde_kws={\"shade\": False},norm_hist=True,   label=r'$\\nabla_\\theta \\mathcal{L}_{u_{ics}}$')\n",
    "\n",
    "            #ax.get_legend().remove()\n",
    "            ax.set_xlim([-1.0, 1.0])\n",
    "            #ax.set_ylim([0, 150])\n",
    "            cnt += 1\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "        fig.legend(handles, labels, loc=\"center\",  bbox_to_anchor=(0.5, -0.03),borderaxespad=0,bbox_transform=fig.transFigure, ncol=3)\n",
    "        text = 'layerLoss_epoch' + str(epoch) +'.png'\n",
    "        plt.savefig(os.path.join(self.dirname,text) , bbox_inches='tight')\n",
    "        plt.close(\"all\" , )\n",
    "    # #########################\n",
    "    # def make_output_dir(self):\n",
    "        \n",
    "    #     if not os.path.exists(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\"):\n",
    "    #         os.mkdir(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\")\n",
    "    #     dirname = os.path.join(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\", datetime.now().strftime(\"%b-%d-%Y_%H-%M-%S-%f_\") + self.mode)\n",
    "    #     os.mkdir(dirname)\n",
    "    #     text = 'output.log'\n",
    "    #     logpath = os.path.join(dirname, text)\n",
    "    #     shutil.copyfile('/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/M2.py', os.path.join(dirname, 'M2.py'))\n",
    "\n",
    "    #     return dirname, logpath\n",
    "    \n",
    "    # # ###########################################################\n",
    "    def make_output_dir(self):\n",
    "        \n",
    "        if not os.path.exists(\"checkpoints\"):\n",
    "            os.mkdir(\"checkpoints\")\n",
    "        dirname = os.path.join(\"checkpoints\", datetime.now().strftime(\"%b-%d-%Y_%H-%M-%S-%f_\") + self.mode)\n",
    "        os.mkdir(dirname)\n",
    "        text = 'output.log'\n",
    "        logpath = os.path.join(dirname, text)\n",
    "        shutil.copyfile('M2.ipynb', os.path.join(dirname, 'M2.ipynb'))\n",
    "        return dirname, logpath\n",
    "    \n",
    "\n",
    "    def get_logger(self, logpath):\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        sh = logging.StreamHandler()\n",
    "        sh.setLevel(logging.DEBUG)        \n",
    "        sh.setFormatter(logging.Formatter('%(message)s'))\n",
    "        fh = logging.FileHandler(logpath)\n",
    "        logger.addHandler(sh)\n",
    "        logger.addHandler(fh)\n",
    "        return logger\n",
    "\n",
    "\n",
    "   \n",
    "    def print(self, *args):\n",
    "        for word in args:\n",
    "            if len(args) == 1:\n",
    "                self.logger.info(word)\n",
    "            elif word != args[-1]:\n",
    "                for handler in self.logger.handlers:\n",
    "                    handler.terminator = \"\"\n",
    "                if type(word) == float or type(word) == np.float64 or type(word) == np.float32: \n",
    "                    self.logger.info(\"%.4e\" % (word))\n",
    "                else:\n",
    "                    self.logger.info(word)\n",
    "            else:\n",
    "                for handler in self.logger.handlers:\n",
    "                    handler.terminator = \"\\n\"\n",
    "                if type(word) == float or type(word) == np.float64 or type(word) == np.float32:\n",
    "                    self.logger.info(\"%.4e\" % (word))\n",
    "                else:\n",
    "                    self.logger.info(word)\n",
    "\n",
    "\n",
    "    def plot_loss_history(self , path):\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches([15,8])\n",
    "        for key in self.loss_history:\n",
    "            self.print(\"Final loss %s: %e\" % (key, self.loss_history[key][-1]))\n",
    "            ax.semilogy(self.loss_history[key], label=key)\n",
    "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
    "        ax.set_ylabel(\"loss\", fontsize=15)\n",
    "        ax.tick_params(labelsize=15)\n",
    "        ax.legend()\n",
    "        plt.savefig(path)\n",
    "        plt.close(\"all\" , )\n",
    "       #######################\n",
    "    def save_NN(self):\n",
    "\n",
    "        uv_weights = self.sess.run(self.net_cuvwp.weights)\n",
    "        uv_biases = self.sess.run(self.net_cuvwp.biases)\n",
    "\n",
    "        with open(os.path.join(self.dirname,'model.pickle'), 'wb') as f:\n",
    "            pickle.dump([uv_weights, uv_biases], f)\n",
    "            self.print(\"Save uv NN parameters successfully in %s ...\" , self.dirname)\n",
    "\n",
    "        # with open(os.path.join(self.dirname,'loss_history_BFS.pickle'), 'wb') as f:\n",
    "        #     pickle.dump(self.loss_rec, f)\n",
    "        with open(os.path.join(self.dirname,'loss_history_BFS.png'), 'wb') as f:\n",
    "            self.plot_loss_history(f)\n",
    "\n",
    "\n",
    "    def assign_batch_losses(self, batch_losses):\n",
    "        for loss_values, key in zip(batch_losses, self.epoch_loss):\n",
    "            self.epoch_loss[key] = loss_values\n",
    "\n",
    "\n",
    "    def generate_grad_dict(self):\n",
    "        num = len(self.layers) - 1\n",
    "        grad_dict = {}\n",
    "        for i in range(num):\n",
    "            grad_dict['layer_{}'.format(i + 1)] = []\n",
    "        return grad_dict\n",
    "    \n",
    "    def assign_batch_losses(self, batch_losses):\n",
    "        for loss_values, key in zip(batch_losses, self.epoch_loss):\n",
    "            self.epoch_loss[key] = loss_values\n",
    "            \n",
    "    def plt_prediction(self , x1 , x2 , X_star , u_star , u_pred , f_star , f_pred):\n",
    "        from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "        ### Plot ###\n",
    "        plt.close(\"all\" , )\n",
    "\n",
    "        # Exact solution & Predicted solution\n",
    "        # Exact soluton\n",
    "        U_star = griddata(X_star, u_star.flatten(), (x1, x2), method='cubic')\n",
    "        F_star = griddata(X_star, f_star.flatten(), (x1, x2), method='cubic')\n",
    "\n",
    "        # Predicted solution\n",
    "        U_pred = griddata(X_star, u_pred.flatten(), (x1, x2), method='cubic')\n",
    "        F_pred = griddata(X_star, f_pred.flatten(), (x1, x2), method='cubic')\n",
    "\n",
    "        titles = ['Exact $u(x)$' , 'Predicted $u(x)$' , 'Absolute error' , 'Exact $f(x)$' , 'Predicted $f(x)$' , 'Absolute error']\n",
    "        data = [U_star , U_pred ,  np.abs(U_star - U_pred) , F_star , F_pred ,  np.abs(F_star - F_pred) ]\n",
    "        \n",
    "\n",
    "        fig_1 = plt.figure(1, figsize=(13, 5))\n",
    "        grid = ImageGrid(fig_1, 111, direction=\"row\", nrows_ncols=(2,3), \n",
    "                        label_mode=\"1\", axes_pad=1.7, share_all=False, \n",
    "                        cbar_mode=\"each\", cbar_location=\"right\", \n",
    "                        cbar_size=\"5%\", cbar_pad=0.0)\n",
    "    # CREATE ARGUMENTS DICT FOR CONTOURPLOTS\n",
    "        minmax_list = []\n",
    "        kwargs_list = []\n",
    "        for d in data:\n",
    "            # if(local):\n",
    "            #     minmax_list.append([np.min(d), np.max(d)])\n",
    "            # else:\n",
    "            minmax_list.append([np.min(d), np.max(d)])\n",
    "\n",
    "            kwargs_list.append(dict(levels=np.linspace(minmax_list[-1][0],minmax_list[-1][1], 60),\n",
    "                cmap=\"coolwarm\", vmin=minmax_list[-1][0], vmax=minmax_list[-1][1]))\n",
    "\n",
    "        for ax, z, kwargs, minmax, title in zip(grid, data, kwargs_list, minmax_list, titles):\n",
    "        #pcf = [ax.tricontourf(x, y, z[0,:], **kwargs)]\n",
    "            #pcfsets.append(pcf)\n",
    "            # if (timeStp == 0):\n",
    "                #  print( z[timeStp,:,:])\n",
    "            pcf = [ax.pcolor(x1, x2, z , cmap='jet')]\n",
    "            cb = ax.cax.colorbar(pcf[0], ticks=np.linspace(minmax[0],minmax[1],7),  format='%.3e')\n",
    "            ax.cax.tick_params(labelsize=14.5)\n",
    "            ax.set_title(title, fontsize=14.5, pad=7)\n",
    "            ax.set_ylabel(\"time\", labelpad=14.5, fontsize=14.5, rotation=\"horizontal\")\n",
    "            ax.set_xlabel(\"x\", fontsize=14.5)\n",
    "            ax.tick_params(labelsize=14.5)\n",
    "            ax.set_xlim(x1.min(), x1.max())\n",
    "            ax.set_ylim(x2.min(), x2.max())\n",
    "            ax.set_aspect(\"equal\")\n",
    "\n",
    "        fig_1.set_size_inches(15, 10, True)\n",
    "        fig_1.subplots_adjust(left=0.7, bottom=0, right=2.2, top=0.5, wspace=None, hspace=None)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.dirname,\"prediction.png\"), dpi=300 , bbox_inches='tight')\n",
    "        plt.close(\"all\" , )\n",
    "\n",
    "\n",
    "    def plot_grad(self ):\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches([15,8])\n",
    "        ax.semilogy(self.adaptive_constant_bcs_log, label=r'$\\bar{\\nabla_\\theta \\mathcal{L}_{u_{bc}}}$')\n",
    "        ax.semilogy(self.adaptive_constant_ics_log, label=r'$\\bar{\\nabla_\\theta \\mathcal{L}_{u_{ic}}}$')\n",
    "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
    "        ax.set_ylabel(\"loss\", fontsize=15)\n",
    "        ax.tick_params(labelsize=15)\n",
    "        ax.legend()\n",
    "        path = os.path.join(self.dirname,'grad_history.png')\n",
    "        plt.savefig(path)\n",
    "        plt.close(\"all\" , )\n",
    "    \n",
    "    def plot_lambda(self ):\n",
    "\n",
    "        fontsize = 17\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches([16,8])\n",
    "        ax.semilogy(self.mean_adaptive_constant_bcs_log, label=r'$\\bar{\\nabla_\\theta {u_{bc}}}$' , color = 'tab:green')\n",
    "        ax.semilogy(self.mean_adaptive_constant_ics_log, label=r'$\\bar{\\nabla_\\theta {u_{ics}}}$' , color = 'tab:blue')\n",
    "        ax.semilogy(self.mean_adaptive_constant_res_log, label=r'$Max{\\nabla_\\theta {u_{phy}}}$' , color = 'tab:red')\n",
    "        ax.set_xlabel(\"epochs\", fontsize=fontsize)\n",
    "        ax.set_ylabel(r'$\\bar{\\nabla_\\theta {u}}$', fontsize=fontsize)\n",
    "        ax.tick_params(labelsize=fontsize)\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(-0.25, 0.5))\n",
    "\n",
    "        ax2 = ax.twinx() \n",
    "\n",
    "        # fig, ax = plt.subplots()\n",
    "        # fig.set_size_inches([15,8])\n",
    "    \n",
    "        ax2.semilogy(self.adaptive_constant_bcs_log, label=r'$\\bar{\\lambda_{bc}}$'  ,  linestyle='dashed' , color = 'tab:green') \n",
    "        ax2.semilogy(self.adaptive_constant_ics_log, label=r'$\\bar{\\lambda_{ics}}$' , linestyle='dashed'  , color = 'tab:blue')\n",
    "        ax2.semilogy(self.adaptive_constant_res_log, label=r'$\\bar{\\lambda_{phy}}$' ,  linestyle='dashed' , color = 'tab:red')\n",
    "        ax2.set_xlabel(\"epochs\", fontsize=fontsize)\n",
    "        ax2.set_ylabel(r'$\\bar{\\lambda}$', fontsize=fontsize)\n",
    "        ax2.tick_params(labelsize=fontsize)\n",
    "        ax2.legend(loc='center right', bbox_to_anchor=(1.2, 0.5))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        path = os.path.join(self.dirname,'lambda_history.png')\n",
    "        plt.savefig(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_method(method , layers, operator, ics_sampler, bcs_sampler, res_sampler, alpha, beta, gamma ,k ,mode , stiff_ratio ,  X_star , u_star , f_star):\n",
    "\n",
    "\n",
    "    model = Klein_Gordon(layers, operator, ics_sampler, bcs_sampler, res_sampler, alpha, beta, gamma, k, mode, stiff_ratio)\n",
    "\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "\n",
    "    if method ==\"full_batch\":\n",
    "        model.train(nIter=40001 )\n",
    "    elif method ==\"mini_batch\":\n",
    "        model.trainmb(nIter=40001, batch_size=128)\n",
    "    else:\n",
    "        print(\"unknown method!\")\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Predictions\n",
    "    u_pred = model.predict_u(X_star)\n",
    "    f_pred = model.predict_r(X_star)\n",
    "\n",
    "    # Relative error\n",
    "    error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "    error_f = np.linalg.norm(f_star - f_pred, 2) / np.linalg.norm(f_star, 2)\n",
    "\n",
    "    print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
    "    print('Relative L2 error_f: {:.2e}'.format(error_f))\n",
    "\n",
    "    return [elapsed, error_u , error_f]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  mini_batch\n",
      "Epoch:  1\n",
      "WARNING:tensorflow:From /tmp/ipykernel_48509/1717239770.py:66: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_48509/1717239770.py:67: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_48509/1717239770.py:68: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_48509/1717239770.py:68: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_48509/52739167.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_48509/182583593.py:114: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:01:28.427017: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 10:01:28.452077: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
      "2024-01-19 10:01:28.452513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e762fc7f90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-19 10:01:28.452528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-01-19 10:01:28.456190: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_48509/52739167.py:125: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_48509/52739167.py:127: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tmp/ipykernel_48509/52739167.py:220: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 9.756e+03, loss_bcs: 1.013e+00, loss_ics: 1.381e-05, Loss_r: 9.550e+03, Time: 6.09\n",
      "std_grad_res: 2.227e+00\n",
      "std_grad_bcs: 1.236e-02\n",
      "std_grad_ics: 2.876e-03\n",
      "kurtosis_grad_res: 2.160e+00\n",
      "kurtosis_grad_bcs: 1.273e-02\n",
      "kurtosis_grad_ics: 2.492e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Gradients information stored ...\n",
      "It: 100, Loss: 5.945e+03, loss_bcs: 5.010e-01, loss_ics: 3.282e-01, Loss_r: 5.821e+03, Time: 0.01\n",
      "std_grad_res: 1.399e+02\n",
      "std_grad_bcs: 6.123e-02\n",
      "std_grad_ics: 4.274e+00\n",
      "kurtosis_grad_res: 7.543e+01\n",
      "kurtosis_grad_bcs: 6.657e-02\n",
      "kurtosis_grad_ics: 1.505e+00\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Gradients information stored ...\n",
      "It: 200, Loss: 4.703e+03, loss_bcs: 1.127e+00, loss_ics: 2.611e-01, Loss_r: 4.455e+03, Time: 0.01\n",
      "std_grad_res: 4.501e+01\n",
      "std_grad_bcs: 2.235e-01\n",
      "std_grad_ics: 4.896e+00\n",
      "kurtosis_grad_res: 5.206e+01\n",
      "kurtosis_grad_bcs: 1.454e-01\n",
      "kurtosis_grad_ics: 1.511e+00\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 300, Loss: 2.413e+03, loss_bcs: 6.352e-01, loss_ics: 1.615e-02, Loss_r: 2.282e+03, Time: 0.09\n",
      "std_grad_res: 1.411e+02\n",
      "std_grad_bcs: 1.822e-01\n",
      "std_grad_ics: 4.052e-01\n",
      "kurtosis_grad_res: 8.365e+01\n",
      "kurtosis_grad_bcs: 1.830e-01\n",
      "kurtosis_grad_ics: 1.259e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 400, Loss: 1.142e+03, loss_bcs: 3.016e-01, loss_ics: 4.939e-03, Loss_r: 1.080e+03, Time: 0.04\n",
      "std_grad_res: 2.339e+02\n",
      "std_grad_bcs: 6.819e-02\n",
      "std_grad_ics: 1.009e+00\n",
      "kurtosis_grad_res: 9.861e+01\n",
      "kurtosis_grad_bcs: 9.009e-02\n",
      "kurtosis_grad_ics: 3.370e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 500, Loss: 4.312e+02, loss_bcs: 1.477e-01, loss_ics: 5.093e-04, Loss_r: 4.010e+02, Time: 0.09\n",
      "std_grad_res: 1.453e+03\n",
      "std_grad_bcs: 9.614e-02\n",
      "std_grad_ics: 2.896e-01\n",
      "kurtosis_grad_res: 5.463e+02\n",
      "kurtosis_grad_bcs: 8.515e-02\n",
      "kurtosis_grad_ics: 1.091e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 600, Loss: 4.363e+02, loss_bcs: 1.546e-01, loss_ics: 5.032e-02, Loss_r: 4.013e+02, Time: 0.01\n",
      "std_grad_res: 1.603e+02\n",
      "std_grad_bcs: 7.900e-02\n",
      "std_grad_ics: 8.016e-01\n",
      "kurtosis_grad_res: 1.088e+02\n",
      "kurtosis_grad_bcs: 8.869e-02\n",
      "kurtosis_grad_ics: 3.290e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 700, Loss: 2.598e+02, loss_bcs: 1.038e-01, loss_ics: 2.137e-02, Loss_r: 2.372e+02, Time: 0.01\n",
      "std_grad_res: 8.259e+02\n",
      "std_grad_bcs: 1.032e-01\n",
      "std_grad_ics: 1.158e-02\n",
      "kurtosis_grad_res: 3.462e+02\n",
      "kurtosis_grad_bcs: 9.267e-02\n",
      "kurtosis_grad_ics: 4.052e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 800, Loss: 3.911e+02, loss_bcs: 1.652e-01, loss_ics: 3.278e-02, Loss_r: 3.551e+02, Time: 0.01\n",
      "std_grad_res: 4.399e+02\n",
      "std_grad_bcs: 9.195e-02\n",
      "std_grad_ics: 7.400e-02\n",
      "kurtosis_grad_res: 1.512e+02\n",
      "kurtosis_grad_bcs: 9.069e-02\n",
      "kurtosis_grad_ics: 4.312e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 900, Loss: 1.692e+02, loss_bcs: 9.396e-02, loss_ics: 5.278e-03, Loss_r: 1.496e+02, Time: 0.01\n",
      "std_grad_res: 9.385e+02\n",
      "std_grad_bcs: 7.260e-02\n",
      "std_grad_ics: 3.102e-02\n",
      "kurtosis_grad_res: 3.558e+02\n",
      "kurtosis_grad_bcs: 6.582e-02\n",
      "kurtosis_grad_ics: 2.004e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1000, Loss: 1.084e+02, loss_bcs: 8.934e-02, loss_ics: 1.689e-02, Loss_r: 8.905e+01, Time: 0.01\n",
      "std_grad_res: 1.085e+03\n",
      "std_grad_bcs: 5.884e-02\n",
      "std_grad_ics: 5.033e-01\n",
      "kurtosis_grad_res: 4.339e+02\n",
      "kurtosis_grad_bcs: 7.160e-02\n",
      "kurtosis_grad_ics: 2.019e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Gradients information stored ...\n",
      "It: 1100, Loss: 1.286e+02, loss_bcs: 6.012e-02, loss_ics: 4.444e-03, Loss_r: 1.161e+02, Time: 0.01\n",
      "std_grad_res: 1.075e+03\n",
      "std_grad_bcs: 1.421e-01\n",
      "std_grad_ics: 2.502e-01\n",
      "kurtosis_grad_res: 4.118e+02\n",
      "kurtosis_grad_bcs: 9.665e-02\n",
      "kurtosis_grad_ics: 8.258e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1200, Loss: 6.443e+01, loss_bcs: 2.428e-02, loss_ics: 8.637e-03, Loss_r: 5.888e+01, Time: 0.01\n",
      "std_grad_res: 7.070e+02\n",
      "std_grad_bcs: 6.588e-02\n",
      "std_grad_ics: 1.925e-01\n",
      "kurtosis_grad_res: 2.976e+02\n",
      "kurtosis_grad_bcs: 4.558e-02\n",
      "kurtosis_grad_ics: 8.359e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1300, Loss: 3.736e+01, loss_bcs: 3.006e-02, loss_ics: 9.034e-03, Loss_r: 3.060e+01, Time: 0.01\n",
      "std_grad_res: 2.376e+02\n",
      "std_grad_bcs: 6.076e-02\n",
      "std_grad_ics: 4.303e-02\n",
      "kurtosis_grad_res: 1.020e+02\n",
      "kurtosis_grad_bcs: 4.608e-02\n",
      "kurtosis_grad_ics: 2.763e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1400, Loss: 2.845e+01, loss_bcs: 3.157e-02, loss_ics: 6.130e-03, Loss_r: 2.159e+01, Time: 0.01\n",
      "std_grad_res: 8.853e+02\n",
      "std_grad_bcs: 4.775e-02\n",
      "std_grad_ics: 1.440e-02\n",
      "kurtosis_grad_res: 3.246e+02\n",
      "kurtosis_grad_bcs: 4.112e-02\n",
      "kurtosis_grad_ics: 7.983e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1500, Loss: 3.836e+01, loss_bcs: 1.639e-02, loss_ics: 3.178e-03, Loss_r: 3.479e+01, Time: 0.02\n",
      "std_grad_res: 4.643e+02\n",
      "std_grad_bcs: 1.827e-02\n",
      "std_grad_ics: 1.725e-01\n",
      "kurtosis_grad_res: 1.567e+02\n",
      "kurtosis_grad_bcs: 2.082e-02\n",
      "kurtosis_grad_ics: 7.260e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1600, Loss: 3.061e+01, loss_bcs: 6.774e-03, loss_ics: 1.083e-02, Loss_r: 2.849e+01, Time: 0.01\n",
      "std_grad_res: 8.274e+02\n",
      "std_grad_bcs: 7.678e-02\n",
      "std_grad_ics: 8.141e-01\n",
      "kurtosis_grad_res: 3.045e+02\n",
      "kurtosis_grad_bcs: 3.825e-02\n",
      "kurtosis_grad_ics: 2.648e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1700, Loss: 1.640e+01, loss_bcs: 9.386e-03, loss_ics: 3.286e-03, Loss_r: 1.426e+01, Time: 0.01\n",
      "std_grad_res: 2.635e+02\n",
      "std_grad_bcs: 8.366e-02\n",
      "std_grad_ics: 6.305e-02\n",
      "kurtosis_grad_res: 1.001e+02\n",
      "kurtosis_grad_bcs: 4.086e-02\n",
      "kurtosis_grad_ics: 2.510e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1800, Loss: 1.621e+01, loss_bcs: 6.146e-03, loss_ics: 4.631e-03, Loss_r: 1.464e+01, Time: 0.01\n",
      "std_grad_res: 1.535e+02\n",
      "std_grad_bcs: 3.702e-02\n",
      "std_grad_ics: 7.415e-02\n",
      "kurtosis_grad_res: 5.547e+01\n",
      "kurtosis_grad_bcs: 1.820e-02\n",
      "kurtosis_grad_ics: 3.535e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 1900, Loss: 3.657e+01, loss_bcs: 1.353e-02, loss_ics: 1.639e-03, Loss_r: 3.369e+01, Time: 0.01\n",
      "std_grad_res: 1.269e+03\n",
      "std_grad_bcs: 1.540e-02\n",
      "std_grad_ics: 7.036e-03\n",
      "kurtosis_grad_res: 4.808e+02\n",
      "kurtosis_grad_bcs: 1.753e-02\n",
      "kurtosis_grad_ics: 4.080e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2000, Loss: 1.132e+01, loss_bcs: 6.715e-03, loss_ics: 1.058e-03, Loss_r: 9.875e+00, Time: 0.01\n",
      "std_grad_res: 3.320e+02\n",
      "std_grad_bcs: 5.814e-02\n",
      "std_grad_ics: 1.065e-02\n",
      "kurtosis_grad_res: 1.313e+02\n",
      "kurtosis_grad_bcs: 2.885e-02\n",
      "kurtosis_grad_ics: 6.545e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2100, Loss: 1.430e+01, loss_bcs: 3.942e-03, loss_ics: 3.767e-03, Loss_r: 1.324e+01, Time: 0.01\n",
      "std_grad_res: 1.683e+02\n",
      "std_grad_bcs: 5.032e-02\n",
      "std_grad_ics: 2.982e-02\n",
      "kurtosis_grad_res: 6.259e+01\n",
      "kurtosis_grad_bcs: 2.398e-02\n",
      "kurtosis_grad_ics: 1.856e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2200, Loss: 1.172e+01, loss_bcs: 1.047e-02, loss_ics: 2.143e-03, Loss_r: 9.435e+00, Time: 0.02\n",
      "std_grad_res: 7.594e+02\n",
      "std_grad_bcs: 1.155e-02\n",
      "std_grad_ics: 2.690e-01\n",
      "kurtosis_grad_res: 2.913e+02\n",
      "kurtosis_grad_bcs: 1.168e-02\n",
      "kurtosis_grad_ics: 1.104e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2300, Loss: 1.897e+01, loss_bcs: 6.482e-03, loss_ics: 1.615e-03, Loss_r: 1.753e+01, Time: 0.01\n",
      "std_grad_res: 4.128e+02\n",
      "std_grad_bcs: 1.644e-02\n",
      "std_grad_ics: 8.086e-02\n",
      "kurtosis_grad_res: 1.582e+02\n",
      "kurtosis_grad_bcs: 1.249e-02\n",
      "kurtosis_grad_ics: 3.472e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2400, Loss: 6.136e+00, loss_bcs: 3.532e-03, loss_ics: 3.725e-03, Loss_r: 5.162e+00, Time: 0.01\n",
      "std_grad_res: 8.268e+02\n",
      "std_grad_bcs: 1.478e-02\n",
      "std_grad_ics: 2.180e-01\n",
      "kurtosis_grad_res: 3.096e+02\n",
      "kurtosis_grad_bcs: 8.991e-03\n",
      "kurtosis_grad_ics: 8.989e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2500, Loss: 7.939e+00, loss_bcs: 4.850e-03, loss_ics: 9.914e-04, Loss_r: 6.881e+00, Time: 0.01\n",
      "std_grad_res: 4.934e+01\n",
      "std_grad_bcs: 2.198e-02\n",
      "std_grad_ics: 3.383e-02\n",
      "kurtosis_grad_res: 1.942e+01\n",
      "kurtosis_grad_bcs: 1.676e-02\n",
      "kurtosis_grad_ics: 1.286e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2600, Loss: 9.620e+00, loss_bcs: 3.853e-03, loss_ics: 6.184e-04, Loss_r: 8.791e+00, Time: 0.05\n",
      "std_grad_res: 3.509e+01\n",
      "std_grad_bcs: 1.423e-02\n",
      "std_grad_ics: 5.778e-03\n",
      "kurtosis_grad_res: 1.901e+01\n",
      "kurtosis_grad_bcs: 1.353e-02\n",
      "kurtosis_grad_ics: 3.290e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2700, Loss: 1.318e+01, loss_bcs: 4.300e-03, loss_ics: 5.756e-04, Loss_r: 1.227e+01, Time: 0.01\n",
      "std_grad_res: 1.966e+02\n",
      "std_grad_bcs: 1.622e-02\n",
      "std_grad_ics: 2.382e-02\n",
      "kurtosis_grad_res: 6.593e+01\n",
      "kurtosis_grad_bcs: 1.337e-02\n",
      "kurtosis_grad_ics: 1.088e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2800, Loss: 5.572e+00, loss_bcs: 3.637e-03, loss_ics: 6.646e-04, Loss_r: 4.785e+00, Time: 0.06\n",
      "std_grad_res: 8.718e+01\n",
      "std_grad_bcs: 3.449e-02\n",
      "std_grad_ics: 1.321e-02\n",
      "kurtosis_grad_res: 4.616e+01\n",
      "kurtosis_grad_bcs: 2.327e-02\n",
      "kurtosis_grad_ics: 8.463e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 2900, Loss: 1.280e+01, loss_bcs: 3.404e-03, loss_ics: 1.056e-03, Loss_r: 1.204e+01, Time: 0.01\n",
      "std_grad_res: 2.216e+02\n",
      "std_grad_bcs: 1.476e-02\n",
      "std_grad_ics: 9.513e-03\n",
      "kurtosis_grad_res: 9.231e+01\n",
      "kurtosis_grad_bcs: 1.101e-02\n",
      "kurtosis_grad_ics: 5.972e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3000, Loss: 6.236e+00, loss_bcs: 3.117e-03, loss_ics: 1.267e-03, Loss_r: 5.513e+00, Time: 0.08\n",
      "std_grad_res: 6.074e+01\n",
      "std_grad_bcs: 2.117e-02\n",
      "std_grad_ics: 5.853e-02\n",
      "kurtosis_grad_res: 2.249e+01\n",
      "kurtosis_grad_bcs: 1.423e-02\n",
      "kurtosis_grad_ics: 2.885e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3100, Loss: 1.382e+01, loss_bcs: 2.195e-03, loss_ics: 4.088e-04, Loss_r: 1.335e+01, Time: 0.01\n",
      "std_grad_res: 2.294e+02\n",
      "std_grad_bcs: 7.211e-03\n",
      "std_grad_ics: 2.729e-02\n",
      "kurtosis_grad_res: 9.057e+01\n",
      "kurtosis_grad_bcs: 9.411e-03\n",
      "kurtosis_grad_ics: 1.217e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3200, Loss: 5.602e+00, loss_bcs: 1.759e-03, loss_ics: 5.047e-05, Loss_r: 5.240e+00, Time: 0.02\n",
      "std_grad_res: 5.415e+01\n",
      "std_grad_bcs: 1.609e-02\n",
      "std_grad_ics: 1.459e-03\n",
      "kurtosis_grad_res: 3.050e+01\n",
      "kurtosis_grad_bcs: 1.272e-02\n",
      "kurtosis_grad_ics: 8.300e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3300, Loss: 6.902e+00, loss_bcs: 2.439e-03, loss_ics: 8.491e-04, Loss_r: 6.346e+00, Time: 0.02\n",
      "std_grad_res: 5.963e+02\n",
      "std_grad_bcs: 9.355e-03\n",
      "std_grad_ics: 1.789e-01\n",
      "kurtosis_grad_res: 2.254e+02\n",
      "kurtosis_grad_bcs: 8.028e-03\n",
      "kurtosis_grad_ics: 7.064e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3400, Loss: 1.479e+01, loss_bcs: 3.892e-03, loss_ics: 2.675e-03, Loss_r: 1.382e+01, Time: 0.01\n",
      "std_grad_res: 7.409e+02\n",
      "std_grad_bcs: 4.826e-03\n",
      "std_grad_ics: 2.426e-02\n",
      "kurtosis_grad_res: 2.911e+02\n",
      "kurtosis_grad_bcs: 9.842e-03\n",
      "kurtosis_grad_ics: 1.242e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3500, Loss: 7.854e+00, loss_bcs: 5.403e-03, loss_ics: 2.580e-04, Loss_r: 6.733e+00, Time: 0.01\n",
      "std_grad_res: 1.108e+02\n",
      "std_grad_bcs: 4.394e-02\n",
      "std_grad_ics: 4.956e-02\n",
      "kurtosis_grad_res: 4.407e+01\n",
      "kurtosis_grad_bcs: 2.099e-02\n",
      "kurtosis_grad_ics: 1.625e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3600, Loss: 6.273e+00, loss_bcs: 1.471e-03, loss_ics: 3.920e-04, Loss_r: 5.946e+00, Time: 0.01\n",
      "std_grad_res: 1.397e+02\n",
      "std_grad_bcs: 7.746e-03\n",
      "std_grad_ics: 2.484e-02\n",
      "kurtosis_grad_res: 5.886e+01\n",
      "kurtosis_grad_bcs: 7.246e-03\n",
      "kurtosis_grad_ics: 9.149e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3700, Loss: 1.472e+01, loss_bcs: 4.961e-03, loss_ics: 2.713e-04, Loss_r: 1.369e+01, Time: 0.01\n",
      "std_grad_res: 2.466e+02\n",
      "std_grad_bcs: 3.290e-02\n",
      "std_grad_ics: 5.238e-03\n",
      "kurtosis_grad_res: 9.994e+01\n",
      "kurtosis_grad_bcs: 1.927e-02\n",
      "kurtosis_grad_ics: 2.487e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3800, Loss: 4.307e+00, loss_bcs: 2.643e-03, loss_ics: 8.112e-04, Loss_r: 3.713e+00, Time: 0.01\n",
      "std_grad_res: 5.956e+01\n",
      "std_grad_bcs: 1.350e-02\n",
      "std_grad_ics: 1.484e-02\n",
      "kurtosis_grad_res: 2.320e+01\n",
      "kurtosis_grad_bcs: 9.095e-03\n",
      "kurtosis_grad_ics: 7.235e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 3900, Loss: 6.298e+00, loss_bcs: 3.372e-03, loss_ics: 1.919e-03, Loss_r: 5.479e+00, Time: 0.01\n",
      "std_grad_res: 4.643e+02\n",
      "std_grad_bcs: 5.371e-03\n",
      "std_grad_ics: 3.545e-01\n",
      "kurtosis_grad_res: 1.883e+02\n",
      "kurtosis_grad_bcs: 7.983e-03\n",
      "kurtosis_grad_ics: 1.492e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4000, Loss: 9.449e+00, loss_bcs: 3.303e-03, loss_ics: 6.654e-04, Loss_r: 8.729e+00, Time: 0.01\n",
      "std_grad_res: 5.187e+02\n",
      "std_grad_bcs: 8.984e-03\n",
      "std_grad_ics: 4.767e-02\n",
      "kurtosis_grad_res: 2.007e+02\n",
      "kurtosis_grad_bcs: 8.554e-03\n",
      "kurtosis_grad_ics: 2.226e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4100, Loss: 1.966e+01, loss_bcs: 2.940e-03, loss_ics: 3.665e-04, Loss_r: 1.904e+01, Time: 0.01\n",
      "std_grad_res: 2.428e+02\n",
      "std_grad_bcs: 6.556e-03\n",
      "std_grad_ics: 8.632e-03\n",
      "kurtosis_grad_res: 8.987e+01\n",
      "kurtosis_grad_bcs: 7.318e-03\n",
      "kurtosis_grad_ics: 4.041e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4200, Loss: 1.409e+03, loss_bcs: 5.334e-01, loss_ics: 4.502e-01, Loss_r: 1.270e+03, Time: 0.06\n",
      "std_grad_res: 1.629e+03\n",
      "std_grad_bcs: 1.383e-01\n",
      "std_grad_ics: 7.333e-01\n",
      "kurtosis_grad_res: 7.178e+02\n",
      "kurtosis_grad_bcs: 1.342e-01\n",
      "kurtosis_grad_ics: 4.280e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4300, Loss: 5.243e+02, loss_bcs: 3.091e-01, loss_ics: 8.888e-02, Loss_r: 4.552e+02, Time: 0.07\n",
      "std_grad_res: 2.317e+02\n",
      "std_grad_bcs: 1.502e-01\n",
      "std_grad_ics: 1.031e+00\n",
      "kurtosis_grad_res: 1.357e+02\n",
      "kurtosis_grad_bcs: 8.976e-02\n",
      "kurtosis_grad_ics: 3.948e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4400, Loss: 2.716e+02, loss_bcs: 1.696e-01, loss_ics: 9.986e-02, Loss_r: 2.302e+02, Time: 0.01\n",
      "std_grad_res: 2.289e+02\n",
      "std_grad_bcs: 8.157e-02\n",
      "std_grad_ics: 1.361e+00\n",
      "kurtosis_grad_res: 8.619e+01\n",
      "kurtosis_grad_bcs: 6.152e-02\n",
      "kurtosis_grad_ics: 4.817e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4500, Loss: 6.566e+01, loss_bcs: 1.159e-01, loss_ics: 1.876e-02, Loss_r: 4.073e+01, Time: 0.01\n",
      "std_grad_res: 2.326e+02\n",
      "std_grad_bcs: 1.054e-01\n",
      "std_grad_ics: 3.742e-01\n",
      "kurtosis_grad_res: 9.543e+01\n",
      "kurtosis_grad_bcs: 4.943e-02\n",
      "kurtosis_grad_ics: 1.283e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4600, Loss: 4.387e+01, loss_bcs: 9.817e-02, loss_ics: 1.797e-02, Loss_r: 2.261e+01, Time: 0.01\n",
      "std_grad_res: 5.754e+01\n",
      "std_grad_bcs: 8.069e-02\n",
      "std_grad_ics: 4.039e-01\n",
      "kurtosis_grad_res: 2.595e+01\n",
      "kurtosis_grad_bcs: 4.080e-02\n",
      "kurtosis_grad_ics: 1.491e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4700, Loss: 5.123e+01, loss_bcs: 7.154e-02, loss_ics: 1.455e-02, Loss_r: 3.564e+01, Time: 0.01\n",
      "std_grad_res: 6.703e+01\n",
      "std_grad_bcs: 5.368e-02\n",
      "std_grad_ics: 3.418e-01\n",
      "kurtosis_grad_res: 3.767e+01\n",
      "kurtosis_grad_bcs: 3.849e-02\n",
      "kurtosis_grad_ics: 1.358e-01\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4800, Loss: 4.588e+01, loss_bcs: 6.877e-02, loss_ics: 1.015e-02, Loss_r: 3.115e+01, Time: 0.06\n",
      "std_grad_res: 1.031e+02\n",
      "std_grad_bcs: 6.319e-02\n",
      "std_grad_ics: 1.941e-01\n",
      "kurtosis_grad_res: 5.243e+01\n",
      "kurtosis_grad_bcs: 2.996e-02\n",
      "kurtosis_grad_ics: 8.347e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 4900, Loss: 2.976e+01, loss_bcs: 4.910e-02, loss_ics: 3.200e-03, Loss_r: 1.952e+01, Time: 0.01\n",
      "std_grad_res: 3.787e+02\n",
      "std_grad_bcs: 4.857e-02\n",
      "std_grad_ics: 1.006e-01\n",
      "kurtosis_grad_res: 1.646e+02\n",
      "kurtosis_grad_bcs: 2.720e-02\n",
      "kurtosis_grad_ics: 4.146e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5000, Loss: 2.713e+01, loss_bcs: 4.738e-02, loss_ics: 7.468e-03, Loss_r: 1.695e+01, Time: 0.01\n",
      "std_grad_res: 7.055e+01\n",
      "std_grad_bcs: 4.214e-02\n",
      "std_grad_ics: 3.159e-02\n",
      "kurtosis_grad_res: 3.299e+01\n",
      "kurtosis_grad_bcs: 2.301e-02\n",
      "kurtosis_grad_ics: 1.552e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5100, Loss: 2.159e+01, loss_bcs: 4.142e-02, loss_ics: 4.329e-03, Loss_r: 1.284e+01, Time: 0.01\n",
      "std_grad_res: 5.063e+02\n",
      "std_grad_bcs: 6.779e-02\n",
      "std_grad_ics: 8.631e-02\n",
      "kurtosis_grad_res: 2.139e+02\n",
      "kurtosis_grad_bcs: 3.649e-02\n",
      "kurtosis_grad_ics: 3.944e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5200, Loss: 2.922e+01, loss_bcs: 3.853e-02, loss_ics: 6.241e-03, Loss_r: 2.093e+01, Time: 0.01\n",
      "std_grad_res: 7.832e+01\n",
      "std_grad_bcs: 2.148e-02\n",
      "std_grad_ics: 4.537e-02\n",
      "kurtosis_grad_res: 3.832e+01\n",
      "kurtosis_grad_bcs: 2.273e-02\n",
      "kurtosis_grad_ics: 2.666e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5300, Loss: 2.240e+01, loss_bcs: 3.116e-02, loss_ics: 5.720e-03, Loss_r: 1.565e+01, Time: 0.01\n",
      "std_grad_res: 7.359e+01\n",
      "std_grad_bcs: 6.158e-02\n",
      "std_grad_ics: 2.215e-02\n",
      "kurtosis_grad_res: 3.638e+01\n",
      "kurtosis_grad_bcs: 3.217e-02\n",
      "kurtosis_grad_ics: 1.212e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5400, Loss: 1.920e+01, loss_bcs: 2.402e-02, loss_ics: 6.388e-03, Loss_r: 1.386e+01, Time: 0.02\n",
      "std_grad_res: 8.454e+01\n",
      "std_grad_bcs: 2.434e-02\n",
      "std_grad_ics: 1.200e-01\n",
      "kurtosis_grad_res: 4.193e+01\n",
      "kurtosis_grad_bcs: 1.837e-02\n",
      "kurtosis_grad_ics: 5.209e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5500, Loss: 1.363e+01, loss_bcs: 1.758e-02, loss_ics: 4.499e-03, Loss_r: 9.732e+00, Time: 0.02\n",
      "std_grad_res: 1.742e+02\n",
      "std_grad_bcs: 3.816e-02\n",
      "std_grad_ics: 1.801e-02\n",
      "kurtosis_grad_res: 7.654e+01\n",
      "kurtosis_grad_bcs: 2.109e-02\n",
      "kurtosis_grad_ics: 1.349e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5600, Loss: 3.160e+01, loss_bcs: 1.488e-02, loss_ics: 3.633e-03, Loss_r: 2.831e+01, Time: 0.11\n",
      "std_grad_res: 4.393e+01\n",
      "std_grad_bcs: 3.949e-02\n",
      "std_grad_ics: 9.731e-02\n",
      "kurtosis_grad_res: 1.882e+01\n",
      "kurtosis_grad_bcs: 1.990e-02\n",
      "kurtosis_grad_ics: 4.119e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5700, Loss: 1.534e+01, loss_bcs: 1.803e-02, loss_ics: 4.039e-03, Loss_r: 1.138e+01, Time: 0.01\n",
      "std_grad_res: 1.221e+02\n",
      "std_grad_bcs: 4.210e-02\n",
      "std_grad_ics: 1.025e-02\n",
      "kurtosis_grad_res: 6.173e+01\n",
      "kurtosis_grad_bcs: 2.441e-02\n",
      "kurtosis_grad_ics: 8.686e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5800, Loss: 9.505e+00, loss_bcs: 1.206e-02, loss_ics: 2.998e-03, Loss_r: 6.838e+00, Time: 0.01\n",
      "std_grad_res: 1.637e+02\n",
      "std_grad_bcs: 2.592e-02\n",
      "std_grad_ics: 3.522e-02\n",
      "kurtosis_grad_res: 7.188e+01\n",
      "kurtosis_grad_bcs: 1.605e-02\n",
      "kurtosis_grad_ics: 1.867e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 5900, Loss: 7.443e+00, loss_bcs: 1.168e-02, loss_ics: 3.094e-03, Loss_r: 4.848e+00, Time: 0.02\n",
      "std_grad_res: 1.173e+02\n",
      "std_grad_bcs: 3.553e-02\n",
      "std_grad_ics: 3.006e-02\n",
      "kurtosis_grad_res: 4.958e+01\n",
      "kurtosis_grad_bcs: 1.981e-02\n",
      "kurtosis_grad_ics: 1.727e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6000, Loss: 1.122e+01, loss_bcs: 9.843e-03, loss_ics: 1.813e-03, Loss_r: 9.090e+00, Time: 0.01\n",
      "std_grad_res: 1.987e+02\n",
      "std_grad_bcs: 4.607e-02\n",
      "std_grad_ics: 6.216e-02\n",
      "kurtosis_grad_res: 8.849e+01\n",
      "kurtosis_grad_bcs: 2.273e-02\n",
      "kurtosis_grad_ics: 2.500e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6100, Loss: 1.138e+01, loss_bcs: 8.153e-03, loss_ics: 1.623e-03, Loss_r: 9.602e+00, Time: 0.01\n",
      "std_grad_res: 2.014e+01\n",
      "std_grad_bcs: 3.049e-02\n",
      "std_grad_ics: 3.518e-02\n",
      "kurtosis_grad_res: 1.134e+01\n",
      "kurtosis_grad_bcs: 1.824e-02\n",
      "kurtosis_grad_ics: 1.545e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6200, Loss: 6.678e+00, loss_bcs: 5.792e-03, loss_ics: 1.384e-03, Loss_r: 5.402e+00, Time: 0.01\n",
      "std_grad_res: 1.077e+02\n",
      "std_grad_bcs: 2.779e-02\n",
      "std_grad_ics: 1.677e-02\n",
      "kurtosis_grad_res: 4.787e+01\n",
      "kurtosis_grad_bcs: 1.616e-02\n",
      "kurtosis_grad_ics: 5.089e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6300, Loss: 6.375e+00, loss_bcs: 7.289e-03, loss_ics: 9.155e-04, Loss_r: 4.825e+00, Time: 0.02\n",
      "std_grad_res: 8.045e+01\n",
      "std_grad_bcs: 2.562e-02\n",
      "std_grad_ics: 2.593e-02\n",
      "kurtosis_grad_res: 3.799e+01\n",
      "kurtosis_grad_bcs: 1.519e-02\n",
      "kurtosis_grad_ics: 1.022e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6400, Loss: 4.277e+00, loss_bcs: 6.037e-03, loss_ics: 1.071e-03, Loss_r: 2.972e+00, Time: 0.01\n",
      "std_grad_res: 1.811e+02\n",
      "std_grad_bcs: 2.570e-02\n",
      "std_grad_ics: 1.596e-02\n",
      "kurtosis_grad_res: 8.000e+01\n",
      "kurtosis_grad_bcs: 1.401e-02\n",
      "kurtosis_grad_ics: 6.591e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6500, Loss: 5.847e+00, loss_bcs: 3.810e-03, loss_ics: 6.946e-04, Loss_r: 5.022e+00, Time: 0.02\n",
      "std_grad_res: 1.208e+02\n",
      "std_grad_bcs: 3.875e-02\n",
      "std_grad_ics: 5.523e-02\n",
      "kurtosis_grad_res: 5.464e+01\n",
      "kurtosis_grad_bcs: 1.900e-02\n",
      "kurtosis_grad_ics: 2.067e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6600, Loss: 9.964e+00, loss_bcs: 5.816e-03, loss_ics: 9.147e-04, Loss_r: 8.715e+00, Time: 0.06\n",
      "std_grad_res: 9.397e+01\n",
      "std_grad_bcs: 3.696e-02\n",
      "std_grad_ics: 5.506e-03\n",
      "kurtosis_grad_res: 4.461e+01\n",
      "kurtosis_grad_bcs: 2.022e-02\n",
      "kurtosis_grad_ics: 4.076e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6700, Loss: 7.231e+00, loss_bcs: 5.077e-03, loss_ics: 5.627e-04, Loss_r: 6.156e+00, Time: 0.02\n",
      "std_grad_res: 2.279e+02\n",
      "std_grad_bcs: 4.156e-02\n",
      "std_grad_ics: 3.096e-02\n",
      "kurtosis_grad_res: 1.009e+02\n",
      "kurtosis_grad_bcs: 2.111e-02\n",
      "kurtosis_grad_ics: 1.057e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6800, Loss: 1.754e+01, loss_bcs: 4.912e-03, loss_ics: 8.843e-04, Loss_r: 1.648e+01, Time: 0.11\n",
      "std_grad_res: 1.029e+03\n",
      "std_grad_bcs: 7.244e-02\n",
      "std_grad_ics: 5.869e-03\n",
      "kurtosis_grad_res: 4.252e+02\n",
      "kurtosis_grad_bcs: 3.328e-02\n",
      "kurtosis_grad_ics: 1.856e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 6900, Loss: 6.467e+00, loss_bcs: 4.106e-03, loss_ics: 5.972e-04, Loss_r: 5.588e+00, Time: 0.01\n",
      "std_grad_res: 4.018e+02\n",
      "std_grad_bcs: 1.005e-02\n",
      "std_grad_ics: 7.325e-03\n",
      "kurtosis_grad_res: 1.679e+02\n",
      "kurtosis_grad_bcs: 1.094e-02\n",
      "kurtosis_grad_ics: 3.202e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7000, Loss: 6.427e+00, loss_bcs: 5.561e-03, loss_ics: 1.201e-03, Loss_r: 5.210e+00, Time: 0.02\n",
      "std_grad_res: 2.302e+02\n",
      "std_grad_bcs: 4.758e-02\n",
      "std_grad_ics: 3.068e-02\n",
      "kurtosis_grad_res: 9.983e+01\n",
      "kurtosis_grad_bcs: 2.345e-02\n",
      "kurtosis_grad_ics: 1.181e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7100, Loss: 1.153e+01, loss_bcs: 6.186e-03, loss_ics: 5.840e-04, Loss_r: 1.022e+01, Time: 0.01\n",
      "std_grad_res: 6.709e+01\n",
      "std_grad_bcs: 4.308e-02\n",
      "std_grad_ics: 9.084e-03\n",
      "kurtosis_grad_res: 3.075e+01\n",
      "kurtosis_grad_bcs: 2.376e-02\n",
      "kurtosis_grad_ics: 3.361e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7200, Loss: 5.027e+00, loss_bcs: 4.815e-03, loss_ics: 7.971e-04, Loss_r: 3.990e+00, Time: 0.01\n",
      "std_grad_res: 3.413e+02\n",
      "std_grad_bcs: 1.708e-02\n",
      "std_grad_ics: 2.801e-02\n",
      "kurtosis_grad_res: 1.394e+02\n",
      "kurtosis_grad_bcs: 1.213e-02\n",
      "kurtosis_grad_ics: 8.766e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7300, Loss: 6.624e+00, loss_bcs: 4.477e-03, loss_ics: 1.334e-03, Loss_r: 5.619e+00, Time: 0.01\n",
      "std_grad_res: 4.001e+02\n",
      "std_grad_bcs: 1.594e-02\n",
      "std_grad_ics: 3.408e-02\n",
      "kurtosis_grad_res: 1.803e+02\n",
      "kurtosis_grad_bcs: 1.121e-02\n",
      "kurtosis_grad_ics: 1.193e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7400, Loss: 6.959e+00, loss_bcs: 3.122e-03, loss_ics: 4.235e-04, Loss_r: 6.292e+00, Time: 0.01\n",
      "std_grad_res: 9.793e+01\n",
      "std_grad_bcs: 2.438e-02\n",
      "std_grad_ics: 1.255e-02\n",
      "kurtosis_grad_res: 4.649e+01\n",
      "kurtosis_grad_bcs: 1.290e-02\n",
      "kurtosis_grad_ics: 4.307e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7500, Loss: 4.015e+00, loss_bcs: 3.336e-03, loss_ics: 9.108e-04, Loss_r: 3.272e+00, Time: 0.01\n",
      "std_grad_res: 7.994e+01\n",
      "std_grad_bcs: 2.908e-02\n",
      "std_grad_ics: 7.377e-02\n",
      "kurtosis_grad_res: 2.909e+01\n",
      "kurtosis_grad_bcs: 1.613e-02\n",
      "kurtosis_grad_ics: 2.623e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7600, Loss: 4.191e+00, loss_bcs: 3.176e-03, loss_ics: 4.091e-04, Loss_r: 3.515e+00, Time: 0.01\n",
      "std_grad_res: 1.868e+01\n",
      "std_grad_bcs: 2.622e-02\n",
      "std_grad_ics: 3.767e-03\n",
      "kurtosis_grad_res: 9.977e+00\n",
      "kurtosis_grad_bcs: 1.448e-02\n",
      "kurtosis_grad_ics: 1.504e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7700, Loss: 1.187e+01, loss_bcs: 2.870e-03, loss_ics: 4.022e-04, Loss_r: 1.126e+01, Time: 0.02\n",
      "std_grad_res: 2.772e+02\n",
      "std_grad_bcs: 3.947e-02\n",
      "std_grad_ics: 3.970e-03\n",
      "kurtosis_grad_res: 1.193e+02\n",
      "kurtosis_grad_bcs: 1.632e-02\n",
      "kurtosis_grad_ics: 2.387e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7800, Loss: 4.564e+00, loss_bcs: 2.825e-03, loss_ics: 3.605e-04, Loss_r: 3.963e+00, Time: 0.07\n",
      "std_grad_res: 5.066e+01\n",
      "std_grad_bcs: 1.885e-02\n",
      "std_grad_ics: 1.070e-02\n",
      "kurtosis_grad_res: 2.629e+01\n",
      "kurtosis_grad_bcs: 1.277e-02\n",
      "kurtosis_grad_ics: 4.192e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 7900, Loss: 4.016e+00, loss_bcs: 2.609e-03, loss_ics: 1.560e-03, Loss_r: 3.377e+00, Time: 0.01\n",
      "std_grad_res: 3.298e+02\n",
      "std_grad_bcs: 6.856e-03\n",
      "std_grad_ics: 1.151e-01\n",
      "kurtosis_grad_res: 1.355e+02\n",
      "kurtosis_grad_bcs: 8.659e-03\n",
      "kurtosis_grad_ics: 4.440e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8000, Loss: 7.033e+00, loss_bcs: 2.533e-03, loss_ics: 2.135e-04, Loss_r: 6.501e+00, Time: 0.05\n",
      "std_grad_res: 3.373e+02\n",
      "std_grad_bcs: 3.301e-03\n",
      "std_grad_ics: 1.235e-02\n",
      "kurtosis_grad_res: 1.512e+02\n",
      "kurtosis_grad_bcs: 4.201e-03\n",
      "kurtosis_grad_ics: 4.270e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8100, Loss: 3.938e+00, loss_bcs: 2.555e-03, loss_ics: 3.928e-04, Loss_r: 3.390e+00, Time: 0.01\n",
      "std_grad_res: 1.567e+02\n",
      "std_grad_bcs: 3.203e-02\n",
      "std_grad_ics: 2.850e-02\n",
      "kurtosis_grad_res: 6.388e+01\n",
      "kurtosis_grad_bcs: 1.615e-02\n",
      "kurtosis_grad_ics: 1.035e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8200, Loss: 6.748e+00, loss_bcs: 2.259e-03, loss_ics: 3.339e-04, Loss_r: 6.264e+00, Time: 0.02\n",
      "std_grad_res: 1.288e+02\n",
      "std_grad_bcs: 3.163e-02\n",
      "std_grad_ics: 1.700e-02\n",
      "kurtosis_grad_res: 6.010e+01\n",
      "kurtosis_grad_bcs: 1.577e-02\n",
      "kurtosis_grad_ics: 5.722e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8300, Loss: 3.295e+00, loss_bcs: 2.104e-03, loss_ics: 2.907e-04, Loss_r: 2.846e+00, Time: 0.01\n",
      "std_grad_res: 7.740e+01\n",
      "std_grad_bcs: 1.956e-02\n",
      "std_grad_ics: 1.393e-02\n",
      "kurtosis_grad_res: 3.221e+01\n",
      "kurtosis_grad_bcs: 1.219e-02\n",
      "kurtosis_grad_ics: 4.641e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8400, Loss: 2.588e+00, loss_bcs: 1.755e-03, loss_ics: 4.003e-04, Loss_r: 2.202e+00, Time: 0.01\n",
      "std_grad_res: 1.245e+01\n",
      "std_grad_bcs: 2.808e-02\n",
      "std_grad_ics: 2.026e-02\n",
      "kurtosis_grad_res: 7.937e+00\n",
      "kurtosis_grad_bcs: 1.394e-02\n",
      "kurtosis_grad_ics: 6.647e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8500, Loss: 2.229e+00, loss_bcs: 2.031e-03, loss_ics: 2.647e-04, Loss_r: 1.797e+00, Time: 0.01\n",
      "std_grad_res: 8.672e+01\n",
      "std_grad_bcs: 2.168e-02\n",
      "std_grad_ics: 1.955e-03\n",
      "kurtosis_grad_res: 4.020e+01\n",
      "kurtosis_grad_bcs: 1.192e-02\n",
      "kurtosis_grad_ics: 1.239e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8600, Loss: 2.709e+00, loss_bcs: 2.712e-03, loss_ics: 5.724e-04, Loss_r: 2.117e+00, Time: 0.07\n",
      "std_grad_res: 5.611e+01\n",
      "std_grad_bcs: 1.984e-02\n",
      "std_grad_ics: 7.028e-02\n",
      "kurtosis_grad_res: 2.929e+01\n",
      "kurtosis_grad_bcs: 9.959e-03\n",
      "kurtosis_grad_ics: 2.412e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8700, Loss: 3.910e+00, loss_bcs: 1.404e-03, loss_ics: 3.557e-04, Loss_r: 3.599e+00, Time: 0.01\n",
      "std_grad_res: 1.396e+02\n",
      "std_grad_bcs: 2.611e-02\n",
      "std_grad_ics: 1.134e-02\n",
      "kurtosis_grad_res: 6.172e+01\n",
      "kurtosis_grad_bcs: 1.311e-02\n",
      "kurtosis_grad_ics: 5.383e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8800, Loss: 5.198e+00, loss_bcs: 1.939e-03, loss_ics: 6.237e-04, Loss_r: 4.759e+00, Time: 0.06\n",
      "std_grad_res: 5.640e+02\n",
      "std_grad_bcs: 6.066e-02\n",
      "std_grad_ics: 2.120e-01\n",
      "kurtosis_grad_res: 2.280e+02\n",
      "kurtosis_grad_bcs: 2.467e-02\n",
      "kurtosis_grad_ics: 7.345e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 8900, Loss: 1.182e+02, loss_bcs: 7.804e-03, loss_ics: 1.105e-03, Loss_r: 1.165e+02, Time: 0.01\n",
      "std_grad_res: 6.720e+02\n",
      "std_grad_bcs: 1.947e-02\n",
      "std_grad_ics: 9.660e-03\n",
      "kurtosis_grad_res: 2.800e+02\n",
      "kurtosis_grad_bcs: 1.672e-02\n",
      "kurtosis_grad_ics: 4.573e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9000, Loss: 1.918e+00, loss_bcs: 2.077e-03, loss_ics: 3.268e-04, Loss_r: 1.472e+00, Time: 0.03\n",
      "std_grad_res: 1.138e+01\n",
      "std_grad_bcs: 1.904e-02\n",
      "std_grad_ics: 4.103e-03\n",
      "kurtosis_grad_res: 7.685e+00\n",
      "kurtosis_grad_bcs: 9.940e-03\n",
      "kurtosis_grad_ics: 2.477e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9100, Loss: 2.616e+00, loss_bcs: 1.324e-03, loss_ics: 2.838e-04, Loss_r: 2.327e+00, Time: 0.01\n",
      "std_grad_res: 2.773e+01\n",
      "std_grad_bcs: 1.700e-02\n",
      "std_grad_ics: 6.037e-03\n",
      "kurtosis_grad_res: 1.332e+01\n",
      "kurtosis_grad_bcs: 1.042e-02\n",
      "kurtosis_grad_ics: 3.065e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9200, Loss: 5.666e+00, loss_bcs: 1.364e-03, loss_ics: 3.488e-04, Loss_r: 5.364e+00, Time: 0.08\n",
      "std_grad_res: 1.497e+01\n",
      "std_grad_bcs: 1.824e-02\n",
      "std_grad_ics: 1.317e-02\n",
      "kurtosis_grad_res: 9.846e+00\n",
      "kurtosis_grad_bcs: 9.204e-03\n",
      "kurtosis_grad_ics: 6.625e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9300, Loss: 4.365e+00, loss_bcs: 1.091e-03, loss_ics: 4.083e-04, Loss_r: 4.114e+00, Time: 0.01\n",
      "std_grad_res: 1.862e+02\n",
      "std_grad_bcs: 1.005e-02\n",
      "std_grad_ics: 7.971e-03\n",
      "kurtosis_grad_res: 7.637e+01\n",
      "kurtosis_grad_bcs: 8.300e-03\n",
      "kurtosis_grad_ics: 4.033e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9400, Loss: 1.652e+00, loss_bcs: 1.169e-03, loss_ics: 5.926e-04, Loss_r: 1.373e+00, Time: 0.06\n",
      "std_grad_res: 1.734e+02\n",
      "std_grad_bcs: 1.351e-02\n",
      "std_grad_ics: 7.916e-03\n",
      "kurtosis_grad_res: 7.518e+01\n",
      "kurtosis_grad_bcs: 7.004e-03\n",
      "kurtosis_grad_ics: 5.286e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9500, Loss: 3.960e+00, loss_bcs: 1.883e-03, loss_ics: 2.609e-04, Loss_r: 3.558e+00, Time: 0.02\n",
      "std_grad_res: 2.565e+01\n",
      "std_grad_bcs: 2.505e-02\n",
      "std_grad_ics: 3.165e-03\n",
      "kurtosis_grad_res: 1.312e+01\n",
      "kurtosis_grad_bcs: 1.318e-02\n",
      "kurtosis_grad_ics: 2.055e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9600, Loss: 1.806e+00, loss_bcs: 1.303e-03, loss_ics: 1.795e-04, Loss_r: 1.528e+00, Time: 0.04\n",
      "std_grad_res: 1.547e+01\n",
      "std_grad_bcs: 1.166e-02\n",
      "std_grad_ics: 1.592e-02\n",
      "kurtosis_grad_res: 7.164e+00\n",
      "kurtosis_grad_bcs: 6.754e-03\n",
      "kurtosis_grad_ics: 5.122e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9700, Loss: 2.201e+00, loss_bcs: 1.599e-03, loss_ics: 1.064e-03, Loss_r: 1.802e+00, Time: 0.01\n",
      "std_grad_res: 4.848e+01\n",
      "std_grad_bcs: 1.798e-02\n",
      "std_grad_ics: 2.009e-02\n",
      "kurtosis_grad_res: 2.272e+01\n",
      "kurtosis_grad_bcs: 8.910e-03\n",
      "kurtosis_grad_ics: 1.042e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9800, Loss: 1.804e+00, loss_bcs: 1.167e-03, loss_ics: 5.197e-04, Loss_r: 1.531e+00, Time: 0.01\n",
      "std_grad_res: 1.664e+01\n",
      "std_grad_bcs: 1.431e-02\n",
      "std_grad_ics: 2.722e-02\n",
      "kurtosis_grad_res: 1.041e+01\n",
      "kurtosis_grad_bcs: 7.239e-03\n",
      "kurtosis_grad_ics: 1.188e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 9900, Loss: 2.877e+00, loss_bcs: 1.232e-03, loss_ics: 3.665e-04, Loss_r: 2.601e+00, Time: 0.02\n",
      "std_grad_res: 5.398e+01\n",
      "std_grad_bcs: 1.015e-02\n",
      "std_grad_ics: 8.731e-03\n",
      "kurtosis_grad_res: 2.444e+01\n",
      "kurtosis_grad_bcs: 7.379e-03\n",
      "kurtosis_grad_ics: 4.806e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10000, Loss: 1.264e+00, loss_bcs: 1.074e-03, loss_ics: 2.790e-04, Loss_r: 1.026e+00, Time: 0.21\n",
      "std_grad_res: 1.984e+02\n",
      "std_grad_bcs: 2.626e-02\n",
      "std_grad_ics: 6.046e-03\n",
      "kurtosis_grad_res: 8.272e+01\n",
      "kurtosis_grad_bcs: 1.128e-02\n",
      "kurtosis_grad_ics: 2.907e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10100, Loss: 2.685e+00, loss_bcs: 1.348e-03, loss_ics: 4.098e-04, Loss_r: 2.382e+00, Time: 0.02\n",
      "std_grad_res: 1.739e+02\n",
      "std_grad_bcs: 9.582e-03\n",
      "std_grad_ics: 2.914e-02\n",
      "kurtosis_grad_res: 8.306e+01\n",
      "kurtosis_grad_bcs: 6.326e-03\n",
      "kurtosis_grad_ics: 9.257e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10200, Loss: 1.542e+00, loss_bcs: 1.010e-03, loss_ics: 4.326e-04, Loss_r: 1.306e+00, Time: 0.01\n",
      "std_grad_res: 6.524e+01\n",
      "std_grad_bcs: 2.325e-02\n",
      "std_grad_ics: 1.098e-02\n",
      "kurtosis_grad_res: 2.579e+01\n",
      "kurtosis_grad_bcs: 1.049e-02\n",
      "kurtosis_grad_ics: 4.927e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10300, Loss: 9.983e+00, loss_bcs: 9.151e-04, loss_ics: 2.528e-03, Loss_r: 9.624e+00, Time: 0.01\n",
      "std_grad_res: 4.437e+02\n",
      "std_grad_bcs: 3.364e-02\n",
      "std_grad_ics: 9.071e-03\n",
      "kurtosis_grad_res: 1.874e+02\n",
      "kurtosis_grad_bcs: 1.605e-02\n",
      "kurtosis_grad_ics: 5.678e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10400, Loss: 2.354e+00, loss_bcs: 1.080e-03, loss_ics: 4.851e-04, Loss_r: 2.100e+00, Time: 0.01\n",
      "std_grad_res: 1.964e+02\n",
      "std_grad_bcs: 4.435e-03\n",
      "std_grad_ics: 1.295e-02\n",
      "kurtosis_grad_res: 8.415e+01\n",
      "kurtosis_grad_bcs: 3.767e-03\n",
      "kurtosis_grad_ics: 6.039e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10500, Loss: 1.621e+00, loss_bcs: 7.574e-04, loss_ics: 1.888e-04, Loss_r: 1.453e+00, Time: 0.01\n",
      "std_grad_res: 8.553e+01\n",
      "std_grad_bcs: 5.599e-03\n",
      "std_grad_ics: 6.182e-03\n",
      "kurtosis_grad_res: 4.140e+01\n",
      "kurtosis_grad_bcs: 5.363e-03\n",
      "kurtosis_grad_ics: 3.135e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10600, Loss: 1.676e+00, loss_bcs: 1.014e-03, loss_ics: 1.601e-04, Loss_r: 1.458e+00, Time: 0.02\n",
      "std_grad_res: 4.672e+01\n",
      "std_grad_bcs: 1.223e-02\n",
      "std_grad_ics: 1.439e-02\n",
      "kurtosis_grad_res: 2.050e+01\n",
      "kurtosis_grad_bcs: 7.654e-03\n",
      "kurtosis_grad_ics: 5.647e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10700, Loss: 1.646e+00, loss_bcs: 6.273e-04, loss_ics: 2.320e-04, Loss_r: 1.503e+00, Time: 0.01\n",
      "std_grad_res: 2.238e+02\n",
      "std_grad_bcs: 4.438e-03\n",
      "std_grad_ics: 6.079e-03\n",
      "kurtosis_grad_res: 9.427e+01\n",
      "kurtosis_grad_bcs: 3.121e-03\n",
      "kurtosis_grad_ics: 3.363e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10800, Loss: 1.753e+00, loss_bcs: 8.225e-04, loss_ics: 1.134e-04, Loss_r: 1.577e+00, Time: 0.01\n",
      "std_grad_res: 1.991e+01\n",
      "std_grad_bcs: 1.299e-02\n",
      "std_grad_ics: 3.576e-03\n",
      "kurtosis_grad_res: 1.339e+01\n",
      "kurtosis_grad_bcs: 6.900e-03\n",
      "kurtosis_grad_ics: 1.966e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 10900, Loss: 2.720e+00, loss_bcs: 1.203e-03, loss_ics: 2.916e-04, Loss_r: 2.455e+00, Time: 0.07\n",
      "std_grad_res: 5.673e+02\n",
      "std_grad_bcs: 1.027e-02\n",
      "std_grad_ics: 2.420e-02\n",
      "kurtosis_grad_res: 2.406e+02\n",
      "kurtosis_grad_bcs: 6.017e-03\n",
      "kurtosis_grad_ics: 1.013e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11000, Loss: 1.149e+00, loss_bcs: 5.472e-04, loss_ics: 5.173e-04, Loss_r: 1.002e+00, Time: 0.01\n",
      "std_grad_res: 1.048e+02\n",
      "std_grad_bcs: 1.660e-02\n",
      "std_grad_ics: 5.729e-03\n",
      "kurtosis_grad_res: 4.265e+01\n",
      "kurtosis_grad_bcs: 7.586e-03\n",
      "kurtosis_grad_ics: 3.864e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11100, Loss: 2.171e+00, loss_bcs: 1.348e-03, loss_ics: 5.390e-04, Loss_r: 1.859e+00, Time: 0.08\n",
      "std_grad_res: 2.688e+01\n",
      "std_grad_bcs: 1.641e-02\n",
      "std_grad_ics: 3.096e-02\n",
      "kurtosis_grad_res: 1.731e+01\n",
      "kurtosis_grad_bcs: 8.281e-03\n",
      "kurtosis_grad_ics: 1.302e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11200, Loss: 1.794e+00, loss_bcs: 1.179e-03, loss_ics: 2.119e-03, Loss_r: 1.409e+00, Time: 0.01\n",
      "std_grad_res: 4.155e+02\n",
      "std_grad_bcs: 5.712e-03\n",
      "std_grad_ics: 2.111e-01\n",
      "kurtosis_grad_res: 1.756e+02\n",
      "kurtosis_grad_bcs: 7.090e-03\n",
      "kurtosis_grad_ics: 8.117e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11300, Loss: 1.184e+00, loss_bcs: 1.094e-03, loss_ics: 1.299e-04, Loss_r: 9.523e-01, Time: 0.02\n",
      "std_grad_res: 4.053e+01\n",
      "std_grad_bcs: 1.838e-02\n",
      "std_grad_ics: 2.632e-03\n",
      "kurtosis_grad_res: 1.707e+01\n",
      "kurtosis_grad_bcs: 9.003e-03\n",
      "kurtosis_grad_ics: 1.235e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11400, Loss: 2.234e+00, loss_bcs: 6.126e-04, loss_ics: 1.433e-04, Loss_r: 2.100e+00, Time: 0.07\n",
      "std_grad_res: 8.135e+01\n",
      "std_grad_bcs: 6.700e-03\n",
      "std_grad_ics: 1.204e-02\n",
      "kurtosis_grad_res: 3.722e+01\n",
      "kurtosis_grad_bcs: 3.623e-03\n",
      "kurtosis_grad_ics: 3.710e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11500, Loss: 4.091e+00, loss_bcs: 8.827e-04, loss_ics: 1.795e-04, Loss_r: 3.899e+00, Time: 0.04\n",
      "std_grad_res: 2.092e+02\n",
      "std_grad_bcs: 1.750e-02\n",
      "std_grad_ics: 1.281e-02\n",
      "kurtosis_grad_res: 9.118e+01\n",
      "kurtosis_grad_bcs: 1.127e-02\n",
      "kurtosis_grad_ics: 6.197e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11600, Loss: 2.545e+00, loss_bcs: 7.776e-04, loss_ics: 1.329e-04, Loss_r: 2.377e+00, Time: 0.24\n",
      "std_grad_res: 1.940e+02\n",
      "std_grad_bcs: 2.185e-02\n",
      "std_grad_ics: 1.917e-02\n",
      "kurtosis_grad_res: 8.489e+01\n",
      "kurtosis_grad_bcs: 1.066e-02\n",
      "kurtosis_grad_ics: 6.269e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11700, Loss: 1.576e+00, loss_bcs: 6.572e-04, loss_ics: 5.127e-04, Loss_r: 1.407e+00, Time: 0.05\n",
      "std_grad_res: 1.202e+01\n",
      "std_grad_bcs: 1.537e-02\n",
      "std_grad_ics: 2.583e-03\n",
      "kurtosis_grad_res: 8.860e+00\n",
      "kurtosis_grad_bcs: 9.160e-03\n",
      "kurtosis_grad_ics: 1.953e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11800, Loss: 1.238e+00, loss_bcs: 6.893e-04, loss_ics: 5.028e-04, Loss_r: 1.063e+00, Time: 0.03\n",
      "std_grad_res: 2.806e+01\n",
      "std_grad_bcs: 1.056e-02\n",
      "std_grad_ics: 3.827e-02\n",
      "kurtosis_grad_res: 1.179e+01\n",
      "kurtosis_grad_bcs: 7.175e-03\n",
      "kurtosis_grad_ics: 1.834e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 11900, Loss: 1.241e+00, loss_bcs: 9.965e-04, loss_ics: 3.203e-04, Loss_r: 1.016e+00, Time: 0.02\n",
      "std_grad_res: 4.707e+01\n",
      "std_grad_bcs: 1.325e-02\n",
      "std_grad_ics: 1.494e-02\n",
      "kurtosis_grad_res: 2.011e+01\n",
      "kurtosis_grad_bcs: 8.911e-03\n",
      "kurtosis_grad_ics: 7.943e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12000, Loss: 9.524e+00, loss_bcs: 1.274e-03, loss_ics: 8.705e-04, Loss_r: 9.205e+00, Time: 0.19\n",
      "std_grad_res: 3.455e+02\n",
      "std_grad_bcs: 2.643e-02\n",
      "std_grad_ics: 1.478e-01\n",
      "kurtosis_grad_res: 1.434e+02\n",
      "kurtosis_grad_bcs: 1.183e-02\n",
      "kurtosis_grad_ics: 4.973e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12100, Loss: 1.652e+00, loss_bcs: 9.320e-04, loss_ics: 3.327e-04, Loss_r: 1.439e+00, Time: 0.21\n",
      "std_grad_res: 7.878e+01\n",
      "std_grad_bcs: 1.904e-02\n",
      "std_grad_ics: 8.047e-03\n",
      "kurtosis_grad_res: 3.561e+01\n",
      "kurtosis_grad_bcs: 1.139e-02\n",
      "kurtosis_grad_ics: 5.081e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12200, Loss: 8.655e-01, loss_bcs: 7.437e-04, loss_ics: 5.719e-04, Loss_r: 6.747e-01, Time: 0.30\n",
      "std_grad_res: 3.838e+01\n",
      "std_grad_bcs: 1.780e-02\n",
      "std_grad_ics: 3.730e-02\n",
      "kurtosis_grad_res: 1.886e+01\n",
      "kurtosis_grad_bcs: 8.701e-03\n",
      "kurtosis_grad_ics: 1.550e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12300, Loss: 1.126e+00, loss_bcs: 8.735e-04, loss_ics: 1.981e-04, Loss_r: 9.345e-01, Time: 0.06\n",
      "std_grad_res: 1.646e+02\n",
      "std_grad_bcs: 2.649e-03\n",
      "std_grad_ics: 3.060e-02\n",
      "kurtosis_grad_res: 6.893e+01\n",
      "kurtosis_grad_bcs: 2.490e-03\n",
      "kurtosis_grad_ics: 1.243e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12400, Loss: 1.730e+00, loss_bcs: 8.463e-04, loss_ics: 9.381e-05, Loss_r: 1.551e+00, Time: 0.18\n",
      "std_grad_res: 1.776e+02\n",
      "std_grad_bcs: 1.753e-02\n",
      "std_grad_ics: 1.519e-02\n",
      "kurtosis_grad_res: 8.000e+01\n",
      "kurtosis_grad_bcs: 1.749e-02\n",
      "kurtosis_grad_ics: 5.028e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12500, Loss: 8.580e-01, loss_bcs: 4.977e-04, loss_ics: 2.580e-04, Loss_r: 7.389e-01, Time: 0.02\n",
      "std_grad_res: 7.050e+01\n",
      "std_grad_bcs: 1.297e-02\n",
      "std_grad_ics: 7.226e-03\n",
      "kurtosis_grad_res: 3.167e+01\n",
      "kurtosis_grad_bcs: 6.780e-03\n",
      "kurtosis_grad_ics: 4.476e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12600, Loss: 7.885e-01, loss_bcs: 6.062e-04, loss_ics: 2.904e-04, Loss_r: 6.450e-01, Time: 0.11\n",
      "std_grad_res: 6.222e+01\n",
      "std_grad_bcs: 1.579e-02\n",
      "std_grad_ics: 1.227e-02\n",
      "kurtosis_grad_res: 2.708e+01\n",
      "kurtosis_grad_bcs: 7.362e-03\n",
      "kurtosis_grad_ics: 5.903e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12700, Loss: 2.709e+00, loss_bcs: 6.506e-04, loss_ics: 4.595e-04, Loss_r: 2.544e+00, Time: 0.01\n",
      "std_grad_res: 2.610e+02\n",
      "std_grad_bcs: 1.715e-02\n",
      "std_grad_ics: 3.408e-02\n",
      "kurtosis_grad_res: 1.124e+02\n",
      "kurtosis_grad_bcs: 8.972e-03\n",
      "kurtosis_grad_ics: 1.477e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12800, Loss: 6.962e-01, loss_bcs: 7.796e-04, loss_ics: 1.590e-04, Loss_r: 5.262e-01, Time: 0.42\n",
      "std_grad_res: 4.364e+01\n",
      "std_grad_bcs: 9.901e-03\n",
      "std_grad_ics: 2.961e-03\n",
      "kurtosis_grad_res: 1.661e+01\n",
      "kurtosis_grad_bcs: 6.522e-03\n",
      "kurtosis_grad_ics: 2.189e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 12900, Loss: 3.458e+00, loss_bcs: 3.634e-04, loss_ics: 7.654e-04, Loss_r: 3.332e+00, Time: 0.02\n",
      "std_grad_res: 1.681e+01\n",
      "std_grad_bcs: 1.174e-02\n",
      "std_grad_ics: 4.741e-03\n",
      "kurtosis_grad_res: 1.057e+01\n",
      "kurtosis_grad_bcs: 5.476e-03\n",
      "kurtosis_grad_ics: 2.721e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13000, Loss: 9.530e-01, loss_bcs: 5.715e-04, loss_ics: 7.036e-05, Loss_r: 8.315e-01, Time: 0.03\n",
      "std_grad_res: 7.728e+01\n",
      "std_grad_bcs: 1.013e-02\n",
      "std_grad_ics: 8.807e-04\n",
      "kurtosis_grad_res: 3.019e+01\n",
      "kurtosis_grad_bcs: 6.258e-03\n",
      "kurtosis_grad_ics: 5.775e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13100, Loss: 9.018e-01, loss_bcs: 6.568e-04, loss_ics: 1.107e-04, Loss_r: 7.602e-01, Time: 0.08\n",
      "std_grad_res: 1.461e+01\n",
      "std_grad_bcs: 1.362e-02\n",
      "std_grad_ics: 3.225e-03\n",
      "kurtosis_grad_res: 6.347e+00\n",
      "kurtosis_grad_bcs: 7.064e-03\n",
      "kurtosis_grad_ics: 1.265e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13200, Loss: 3.901e+00, loss_bcs: 3.446e-04, loss_ics: 7.471e-04, Loss_r: 3.780e+00, Time: 0.10\n",
      "std_grad_res: 1.642e+02\n",
      "std_grad_bcs: 2.083e-02\n",
      "std_grad_ics: 1.202e-02\n",
      "kurtosis_grad_res: 7.133e+01\n",
      "kurtosis_grad_bcs: 9.937e-03\n",
      "kurtosis_grad_ics: 5.553e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13300, Loss: 3.139e+00, loss_bcs: 6.866e-04, loss_ics: 2.069e-04, Loss_r: 2.985e+00, Time: 0.08\n",
      "std_grad_res: 4.058e+01\n",
      "std_grad_bcs: 8.211e-03\n",
      "std_grad_ics: 1.966e-03\n",
      "kurtosis_grad_res: 2.010e+01\n",
      "kurtosis_grad_bcs: 5.901e-03\n",
      "kurtosis_grad_ics: 1.383e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13400, Loss: 4.455e+00, loss_bcs: 8.102e-04, loss_ics: 5.222e-04, Loss_r: 4.255e+00, Time: 0.02\n",
      "std_grad_res: 1.445e+02\n",
      "std_grad_bcs: 1.842e-03\n",
      "std_grad_ics: 8.925e-02\n",
      "kurtosis_grad_res: 5.735e+01\n",
      "kurtosis_grad_bcs: 1.762e-03\n",
      "kurtosis_grad_ics: 3.517e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13500, Loss: 9.749e-01, loss_bcs: 8.440e-04, loss_ics: 1.005e-04, Loss_r: 7.957e-01, Time: 0.04\n",
      "std_grad_res: 6.957e+01\n",
      "std_grad_bcs: 8.545e-03\n",
      "std_grad_ics: 2.473e-03\n",
      "kurtosis_grad_res: 3.030e+01\n",
      "kurtosis_grad_bcs: 6.270e-03\n",
      "kurtosis_grad_ics: 1.007e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13600, Loss: 2.663e+00, loss_bcs: 8.466e-04, loss_ics: 3.251e-04, Loss_r: 2.468e+00, Time: 0.06\n",
      "std_grad_res: 5.778e+01\n",
      "std_grad_bcs: 1.248e-02\n",
      "std_grad_ics: 3.719e-03\n",
      "kurtosis_grad_res: 2.921e+01\n",
      "kurtosis_grad_bcs: 7.079e-03\n",
      "kurtosis_grad_ics: 2.356e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13700, Loss: 1.358e+00, loss_bcs: 5.820e-04, loss_ics: 1.026e-04, Loss_r: 1.232e+00, Time: 0.05\n",
      "std_grad_res: 4.166e+01\n",
      "std_grad_bcs: 1.042e-02\n",
      "std_grad_ics: 5.553e-02\n",
      "kurtosis_grad_res: 1.694e+01\n",
      "kurtosis_grad_bcs: 7.693e-03\n",
      "kurtosis_grad_ics: 2.183e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13800, Loss: 1.006e+00, loss_bcs: 6.237e-04, loss_ics: 1.855e-04, Loss_r: 8.657e-01, Time: 0.03\n",
      "std_grad_res: 7.532e+01\n",
      "std_grad_bcs: 4.971e-03\n",
      "std_grad_ics: 1.451e-02\n",
      "kurtosis_grad_res: 3.133e+01\n",
      "kurtosis_grad_bcs: 2.951e-03\n",
      "kurtosis_grad_ics: 6.408e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 13900, Loss: 7.639e-01, loss_bcs: 5.393e-04, loss_ics: 1.022e-04, Loss_r: 6.469e-01, Time: 0.17\n",
      "std_grad_res: 1.603e+01\n",
      "std_grad_bcs: 8.192e-03\n",
      "std_grad_ics: 2.260e-03\n",
      "kurtosis_grad_res: 6.815e+00\n",
      "kurtosis_grad_bcs: 4.014e-03\n",
      "kurtosis_grad_ics: 1.119e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14000, Loss: 8.225e-01, loss_bcs: 4.795e-04, loss_ics: 1.957e-04, Loss_r: 7.113e-01, Time: 0.08\n",
      "std_grad_res: 1.482e+02\n",
      "std_grad_bcs: 3.767e-03\n",
      "std_grad_ics: 1.609e-02\n",
      "kurtosis_grad_res: 6.009e+01\n",
      "kurtosis_grad_bcs: 2.318e-03\n",
      "kurtosis_grad_ics: 7.200e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14100, Loss: 1.488e+00, loss_bcs: 7.577e-04, loss_ics: 5.263e-04, Loss_r: 1.297e+00, Time: 0.02\n",
      "std_grad_res: 1.448e+01\n",
      "std_grad_bcs: 1.711e-02\n",
      "std_grad_ics: 1.224e-02\n",
      "kurtosis_grad_res: 7.594e+00\n",
      "kurtosis_grad_bcs: 8.234e-03\n",
      "kurtosis_grad_ics: 6.885e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14200, Loss: 8.226e-01, loss_bcs: 5.118e-04, loss_ics: 7.566e-05, Loss_r: 7.129e-01, Time: 0.14\n",
      "std_grad_res: 4.491e+01\n",
      "std_grad_bcs: 8.059e-03\n",
      "std_grad_ics: 1.822e-03\n",
      "kurtosis_grad_res: 1.828e+01\n",
      "kurtosis_grad_bcs: 5.239e-03\n",
      "kurtosis_grad_ics: 1.199e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14300, Loss: 6.662e+00, loss_bcs: 1.433e-03, loss_ics: 1.104e-04, Loss_r: 6.362e+00, Time: 0.02\n",
      "std_grad_res: 2.507e+02\n",
      "std_grad_bcs: 3.391e-02\n",
      "std_grad_ics: 1.366e-03\n",
      "kurtosis_grad_res: 1.109e+02\n",
      "kurtosis_grad_bcs: 1.421e-02\n",
      "kurtosis_grad_ics: 1.099e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14400, Loss: 1.596e+00, loss_bcs: 6.726e-04, loss_ics: 5.279e-04, Loss_r: 1.423e+00, Time: 0.02\n",
      "std_grad_res: 8.242e+01\n",
      "std_grad_bcs: 1.393e-02\n",
      "std_grad_ics: 1.429e-02\n",
      "kurtosis_grad_res: 4.164e+01\n",
      "kurtosis_grad_bcs: 8.152e-03\n",
      "kurtosis_grad_ics: 6.872e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14500, Loss: 1.185e+00, loss_bcs: 6.024e-04, loss_ics: 8.244e-04, Loss_r: 1.006e+00, Time: 0.03\n",
      "std_grad_res: 4.847e+01\n",
      "std_grad_bcs: 9.429e-03\n",
      "std_grad_ics: 1.957e-02\n",
      "kurtosis_grad_res: 2.061e+01\n",
      "kurtosis_grad_bcs: 4.812e-03\n",
      "kurtosis_grad_ics: 8.296e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14600, Loss: 1.650e+00, loss_bcs: 5.895e-04, loss_ics: 7.786e-04, Loss_r: 1.476e+00, Time: 0.06\n",
      "std_grad_res: 6.827e+01\n",
      "std_grad_bcs: 6.529e-03\n",
      "std_grad_ics: 5.749e-02\n",
      "kurtosis_grad_res: 3.027e+01\n",
      "kurtosis_grad_bcs: 3.705e-03\n",
      "kurtosis_grad_ics: 2.471e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14700, Loss: 8.118e-01, loss_bcs: 4.864e-04, loss_ics: 6.719e-05, Loss_r: 7.080e-01, Time: 0.16\n",
      "std_grad_res: 3.498e+01\n",
      "std_grad_bcs: 1.240e-02\n",
      "std_grad_ics: 3.524e-03\n",
      "kurtosis_grad_res: 1.768e+01\n",
      "kurtosis_grad_bcs: 7.655e-03\n",
      "kurtosis_grad_ics: 1.321e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14800, Loss: 8.433e-01, loss_bcs: 5.068e-04, loss_ics: 2.080e-04, Loss_r: 7.257e-01, Time: 0.08\n",
      "std_grad_res: 1.857e+01\n",
      "std_grad_bcs: 1.277e-02\n",
      "std_grad_ics: 2.120e-03\n",
      "kurtosis_grad_res: 8.676e+00\n",
      "kurtosis_grad_bcs: 7.770e-03\n",
      "kurtosis_grad_ics: 1.454e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 14900, Loss: 1.508e+00, loss_bcs: 6.992e-04, loss_ics: 6.085e-04, Loss_r: 1.324e+00, Time: 0.24\n",
      "std_grad_res: 1.733e+02\n",
      "std_grad_bcs: 4.738e-03\n",
      "std_grad_ics: 8.700e-02\n",
      "kurtosis_grad_res: 7.209e+01\n",
      "kurtosis_grad_bcs: 6.505e-03\n",
      "kurtosis_grad_ics: 3.501e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15000, Loss: 7.261e-01, loss_bcs: 5.111e-04, loss_ics: 7.982e-05, Loss_r: 6.164e-01, Time: 0.13\n",
      "std_grad_res: 1.021e+02\n",
      "std_grad_bcs: 6.232e-03\n",
      "std_grad_ics: 1.387e-02\n",
      "kurtosis_grad_res: 4.397e+01\n",
      "kurtosis_grad_bcs: 3.167e-03\n",
      "kurtosis_grad_ics: 6.090e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15100, Loss: 1.516e+00, loss_bcs: 5.078e-04, loss_ics: 1.184e-04, Loss_r: 1.404e+00, Time: 0.16\n",
      "std_grad_res: 4.710e+01\n",
      "std_grad_bcs: 7.846e-03\n",
      "std_grad_ics: 1.504e-02\n",
      "kurtosis_grad_res: 2.403e+01\n",
      "kurtosis_grad_bcs: 4.227e-03\n",
      "kurtosis_grad_ics: 4.969e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15200, Loss: 7.965e-01, loss_bcs: 7.104e-04, loss_ics: 7.704e-04, Loss_r: 5.991e-01, Time: 0.06\n",
      "std_grad_res: 5.998e+01\n",
      "std_grad_bcs: 1.383e-02\n",
      "std_grad_ics: 3.307e-03\n",
      "kurtosis_grad_res: 2.381e+01\n",
      "kurtosis_grad_bcs: 6.681e-03\n",
      "kurtosis_grad_ics: 2.593e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15300, Loss: 6.706e-01, loss_bcs: 5.199e-04, loss_ics: 1.570e-04, Loss_r: 5.538e-01, Time: 0.02\n",
      "std_grad_res: 5.790e+01\n",
      "std_grad_bcs: 1.256e-02\n",
      "std_grad_ics: 1.617e-03\n",
      "kurtosis_grad_res: 2.677e+01\n",
      "kurtosis_grad_bcs: 6.110e-03\n",
      "kurtosis_grad_ics: 1.159e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15400, Loss: 8.494e-01, loss_bcs: 5.215e-04, loss_ics: 1.266e-04, Loss_r: 7.343e-01, Time: 0.09\n",
      "std_grad_res: 6.548e+01\n",
      "std_grad_bcs: 7.558e-03\n",
      "std_grad_ics: 3.268e-02\n",
      "kurtosis_grad_res: 2.793e+01\n",
      "kurtosis_grad_bcs: 3.688e-03\n",
      "kurtosis_grad_ics: 1.391e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15500, Loss: 4.609e-01, loss_bcs: 5.038e-04, loss_ics: 6.085e-05, Loss_r: 3.539e-01, Time: 0.06\n",
      "std_grad_res: 6.368e+01\n",
      "std_grad_bcs: 1.610e-02\n",
      "std_grad_ics: 1.489e-02\n",
      "kurtosis_grad_res: 2.790e+01\n",
      "kurtosis_grad_bcs: 7.607e-03\n",
      "kurtosis_grad_ics: 4.930e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15600, Loss: 7.138e-01, loss_bcs: 6.644e-04, loss_ics: 9.626e-05, Loss_r: 5.717e-01, Time: 0.02\n",
      "std_grad_res: 3.936e+01\n",
      "std_grad_bcs: 6.623e-03\n",
      "std_grad_ics: 1.842e-03\n",
      "kurtosis_grad_res: 1.646e+01\n",
      "kurtosis_grad_bcs: 5.899e-03\n",
      "kurtosis_grad_ics: 1.420e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15700, Loss: 1.004e+00, loss_bcs: 4.457e-04, loss_ics: 2.361e-04, Loss_r: 8.969e-01, Time: 0.12\n",
      "std_grad_res: 8.572e+00\n",
      "std_grad_bcs: 1.008e-02\n",
      "std_grad_ics: 1.920e-02\n",
      "kurtosis_grad_res: 5.883e+00\n",
      "kurtosis_grad_bcs: 5.921e-03\n",
      "kurtosis_grad_ics: 7.798e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15800, Loss: 3.814e+00, loss_bcs: 7.309e-04, loss_ics: 9.066e-05, Loss_r: 3.658e+00, Time: 0.02\n",
      "std_grad_res: 2.566e+01\n",
      "std_grad_bcs: 1.075e-02\n",
      "std_grad_ics: 2.957e-03\n",
      "kurtosis_grad_res: 1.408e+01\n",
      "kurtosis_grad_bcs: 9.478e-03\n",
      "kurtosis_grad_ics: 1.585e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 15900, Loss: 9.170e-01, loss_bcs: 4.083e-04, loss_ics: 5.599e-04, Loss_r: 7.955e-01, Time: 0.04\n",
      "std_grad_res: 9.352e+01\n",
      "std_grad_bcs: 3.120e-03\n",
      "std_grad_ics: 1.350e-02\n",
      "kurtosis_grad_res: 3.632e+01\n",
      "kurtosis_grad_bcs: 2.862e-03\n",
      "kurtosis_grad_ics: 6.452e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16000, Loss: 6.838e-01, loss_bcs: 4.025e-04, loss_ics: 9.344e-05, Loss_r: 5.953e-01, Time: 0.05\n",
      "std_grad_res: 1.507e+01\n",
      "std_grad_bcs: 1.243e-02\n",
      "std_grad_ics: 1.143e-03\n",
      "kurtosis_grad_res: 6.540e+00\n",
      "kurtosis_grad_bcs: 5.604e-03\n",
      "kurtosis_grad_ics: 9.195e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16100, Loss: 1.649e+00, loss_bcs: 2.906e-04, loss_ics: 1.757e-04, Loss_r: 1.577e+00, Time: 0.02\n",
      "std_grad_res: 1.820e+02\n",
      "std_grad_bcs: 1.495e-02\n",
      "std_grad_ics: 2.085e-02\n",
      "kurtosis_grad_res: 7.938e+01\n",
      "kurtosis_grad_bcs: 7.278e-03\n",
      "kurtosis_grad_ics: 8.880e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16200, Loss: 1.351e+00, loss_bcs: 7.477e-04, loss_ics: 5.658e-05, Loss_r: 1.195e+00, Time: 0.03\n",
      "std_grad_res: 2.378e+01\n",
      "std_grad_bcs: 1.393e-02\n",
      "std_grad_ics: 2.728e-03\n",
      "kurtosis_grad_res: 1.108e+01\n",
      "kurtosis_grad_bcs: 7.707e-03\n",
      "kurtosis_grad_ics: 1.725e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16300, Loss: 8.386e-01, loss_bcs: 3.140e-04, loss_ics: 2.140e-04, Loss_r: 7.600e-01, Time: 0.02\n",
      "std_grad_res: 1.095e+02\n",
      "std_grad_bcs: 1.341e-02\n",
      "std_grad_ics: 2.147e-03\n",
      "kurtosis_grad_res: 4.724e+01\n",
      "kurtosis_grad_bcs: 6.689e-03\n",
      "kurtosis_grad_ics: 1.361e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16400, Loss: 3.314e+00, loss_bcs: 6.916e-04, loss_ics: 1.282e-04, Loss_r: 3.165e+00, Time: 0.03\n",
      "std_grad_res: 8.238e+01\n",
      "std_grad_bcs: 6.652e-03\n",
      "std_grad_ics: 5.081e-03\n",
      "kurtosis_grad_res: 3.669e+01\n",
      "kurtosis_grad_bcs: 5.531e-03\n",
      "kurtosis_grad_ics: 2.950e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16500, Loss: 5.144e-01, loss_bcs: 3.953e-04, loss_ics: 1.047e-04, Loss_r: 4.266e-01, Time: 0.15\n",
      "std_grad_res: 7.212e+01\n",
      "std_grad_bcs: 1.672e-02\n",
      "std_grad_ics: 1.204e-03\n",
      "kurtosis_grad_res: 3.168e+01\n",
      "kurtosis_grad_bcs: 8.039e-03\n",
      "kurtosis_grad_ics: 9.543e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16600, Loss: 7.163e-01, loss_bcs: 4.457e-04, loss_ics: 8.921e-05, Loss_r: 6.192e-01, Time: 0.34\n",
      "std_grad_res: 5.788e+01\n",
      "std_grad_bcs: 5.421e-03\n",
      "std_grad_ics: 1.035e-03\n",
      "kurtosis_grad_res: 2.394e+01\n",
      "kurtosis_grad_bcs: 4.266e-03\n",
      "kurtosis_grad_ics: 6.296e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16700, Loss: 9.155e-01, loss_bcs: 4.951e-04, loss_ics: 3.905e-05, Loss_r: 8.118e-01, Time: 0.23\n",
      "std_grad_res: 3.630e+01\n",
      "std_grad_bcs: 8.919e-03\n",
      "std_grad_ics: 9.748e-03\n",
      "kurtosis_grad_res: 1.668e+01\n",
      "kurtosis_grad_bcs: 6.558e-03\n",
      "kurtosis_grad_ics: 4.145e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16800, Loss: 8.304e-01, loss_bcs: 4.839e-04, loss_ics: 4.249e-05, Loss_r: 7.287e-01, Time: 0.09\n",
      "std_grad_res: 4.595e+01\n",
      "std_grad_bcs: 8.702e-03\n",
      "std_grad_ics: 3.706e-03\n",
      "kurtosis_grad_res: 2.333e+01\n",
      "kurtosis_grad_bcs: 5.876e-03\n",
      "kurtosis_grad_ics: 1.138e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 16900, Loss: 6.187e-01, loss_bcs: 4.093e-04, loss_ics: 6.860e-05, Loss_r: 5.305e-01, Time: 0.08\n",
      "std_grad_res: 1.362e+01\n",
      "std_grad_bcs: 7.831e-03\n",
      "std_grad_ics: 1.409e-02\n",
      "kurtosis_grad_res: 6.044e+00\n",
      "kurtosis_grad_bcs: 5.424e-03\n",
      "kurtosis_grad_ics: 6.072e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17000, Loss: 6.167e-01, loss_bcs: 5.393e-04, loss_ics: 1.194e-04, Loss_r: 4.985e-01, Time: 0.01\n",
      "std_grad_res: 2.767e+01\n",
      "std_grad_bcs: 7.191e-03\n",
      "std_grad_ics: 1.865e-02\n",
      "kurtosis_grad_res: 1.186e+01\n",
      "kurtosis_grad_bcs: 7.334e-03\n",
      "kurtosis_grad_ics: 8.067e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17100, Loss: 1.346e+00, loss_bcs: 4.446e-04, loss_ics: 7.438e-05, Loss_r: 1.251e+00, Time: 0.14\n",
      "std_grad_res: 6.720e+01\n",
      "std_grad_bcs: 1.023e-02\n",
      "std_grad_ics: 3.931e-03\n",
      "kurtosis_grad_res: 3.083e+01\n",
      "kurtosis_grad_bcs: 8.361e-03\n",
      "kurtosis_grad_ics: 1.555e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17200, Loss: 1.384e+00, loss_bcs: 4.677e-04, loss_ics: 4.682e-05, Loss_r: 1.285e+00, Time: 0.02\n",
      "std_grad_res: 7.854e+01\n",
      "std_grad_bcs: 1.368e-02\n",
      "std_grad_ics: 3.626e-03\n",
      "kurtosis_grad_res: 3.237e+01\n",
      "kurtosis_grad_bcs: 5.609e-03\n",
      "kurtosis_grad_ics: 1.373e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17300, Loss: 5.651e-01, loss_bcs: 3.723e-04, loss_ics: 5.604e-05, Loss_r: 4.853e-01, Time: 0.11\n",
      "std_grad_res: 1.018e+02\n",
      "std_grad_bcs: 1.722e-02\n",
      "std_grad_ics: 8.730e-03\n",
      "kurtosis_grad_res: 4.266e+01\n",
      "kurtosis_grad_bcs: 8.004e-03\n",
      "kurtosis_grad_ics: 2.726e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17400, Loss: 5.320e-01, loss_bcs: 4.798e-04, loss_ics: 1.696e-04, Loss_r: 4.225e-01, Time: 0.02\n",
      "std_grad_res: 9.950e+01\n",
      "std_grad_bcs: 4.208e-03\n",
      "std_grad_ics: 5.687e-03\n",
      "kurtosis_grad_res: 4.429e+01\n",
      "kurtosis_grad_bcs: 2.716e-03\n",
      "kurtosis_grad_ics: 2.780e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17500, Loss: 7.618e-01, loss_bcs: 3.959e-04, loss_ics: 1.314e-04, Loss_r: 6.721e-01, Time: 0.09\n",
      "std_grad_res: 6.188e+01\n",
      "std_grad_bcs: 1.057e-02\n",
      "std_grad_ics: 2.003e-03\n",
      "kurtosis_grad_res: 2.645e+01\n",
      "kurtosis_grad_bcs: 5.833e-03\n",
      "kurtosis_grad_ics: 1.398e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17600, Loss: 6.290e-01, loss_bcs: 4.102e-04, loss_ics: 2.422e-04, Loss_r: 5.288e-01, Time: 0.03\n",
      "std_grad_res: 8.913e+00\n",
      "std_grad_bcs: 1.164e-02\n",
      "std_grad_ics: 9.812e-03\n",
      "kurtosis_grad_res: 4.939e+00\n",
      "kurtosis_grad_bcs: 4.938e-03\n",
      "kurtosis_grad_ics: 4.621e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17700, Loss: 5.504e-01, loss_bcs: 5.348e-04, loss_ics: 1.908e-04, Loss_r: 4.283e-01, Time: 0.22\n",
      "std_grad_res: 5.224e+01\n",
      "std_grad_bcs: 4.362e-03\n",
      "std_grad_ics: 3.469e-02\n",
      "kurtosis_grad_res: 2.263e+01\n",
      "kurtosis_grad_bcs: 4.542e-03\n",
      "kurtosis_grad_ics: 1.488e-02\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17800, Loss: 1.423e+00, loss_bcs: 4.559e-04, loss_ics: 1.027e-04, Loss_r: 1.323e+00, Time: 0.22\n",
      "std_grad_res: 4.491e+01\n",
      "std_grad_bcs: 1.232e-02\n",
      "std_grad_ics: 5.078e-03\n",
      "kurtosis_grad_res: 1.631e+01\n",
      "kurtosis_grad_bcs: 7.420e-03\n",
      "kurtosis_grad_ics: 1.640e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 17900, Loss: 6.770e-01, loss_bcs: 3.203e-04, loss_ics: 1.448e-04, Loss_r: 6.018e-01, Time: 0.01\n",
      "std_grad_res: 2.445e+01\n",
      "std_grad_bcs: 8.111e-03\n",
      "std_grad_ics: 9.436e-03\n",
      "kurtosis_grad_res: 1.079e+01\n",
      "kurtosis_grad_bcs: 3.982e-03\n",
      "kurtosis_grad_ics: 4.356e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18000, Loss: 1.177e+00, loss_bcs: 4.264e-04, loss_ics: 4.087e-05, Loss_r: 1.087e+00, Time: 0.09\n",
      "std_grad_res: 6.117e+01\n",
      "std_grad_bcs: 1.230e-02\n",
      "std_grad_ics: 3.143e-03\n",
      "kurtosis_grad_res: 2.635e+01\n",
      "kurtosis_grad_bcs: 5.581e-03\n",
      "kurtosis_grad_ics: 1.220e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18100, Loss: 6.891e-01, loss_bcs: 3.817e-04, loss_ics: 8.227e-05, Loss_r: 6.056e-01, Time: 0.13\n",
      "std_grad_res: 1.934e+01\n",
      "std_grad_bcs: 7.838e-03\n",
      "std_grad_ics: 5.625e-03\n",
      "kurtosis_grad_res: 1.063e+01\n",
      "kurtosis_grad_bcs: 5.510e-03\n",
      "kurtosis_grad_ics: 1.765e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18200, Loss: 1.765e+00, loss_bcs: 3.330e-04, loss_ics: 5.053e-05, Loss_r: 1.694e+00, Time: 0.06\n",
      "std_grad_res: 6.432e+01\n",
      "std_grad_bcs: 3.317e-03\n",
      "std_grad_ics: 5.561e-04\n",
      "kurtosis_grad_res: 2.525e+01\n",
      "kurtosis_grad_bcs: 2.065e-03\n",
      "kurtosis_grad_ics: 2.709e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18300, Loss: 1.019e+00, loss_bcs: 4.882e-04, loss_ics: 4.253e-05, Loss_r: 9.168e-01, Time: 0.05\n",
      "std_grad_res: 7.640e+01\n",
      "std_grad_bcs: 4.402e-03\n",
      "std_grad_ics: 6.395e-03\n",
      "kurtosis_grad_res: 3.226e+01\n",
      "kurtosis_grad_bcs: 3.970e-03\n",
      "kurtosis_grad_ics: 2.780e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18400, Loss: 2.288e+00, loss_bcs: 4.088e-04, loss_ics: 2.077e-04, Loss_r: 2.190e+00, Time: 0.13\n",
      "std_grad_res: 9.946e+01\n",
      "std_grad_bcs: 2.561e-03\n",
      "std_grad_ics: 4.495e-03\n",
      "kurtosis_grad_res: 4.519e+01\n",
      "kurtosis_grad_bcs: 4.466e-03\n",
      "kurtosis_grad_ics: 2.520e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18500, Loss: 4.720e-01, loss_bcs: 5.023e-04, loss_ics: 4.154e-05, Loss_r: 3.666e-01, Time: 0.12\n",
      "std_grad_res: 8.425e+01\n",
      "std_grad_bcs: 1.119e-02\n",
      "std_grad_ics: 2.300e-03\n",
      "kurtosis_grad_res: 3.710e+01\n",
      "kurtosis_grad_bcs: 7.830e-03\n",
      "kurtosis_grad_ics: 8.034e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18600, Loss: 4.127e-01, loss_bcs: 3.141e-04, loss_ics: 9.889e-05, Loss_r: 3.418e-01, Time: 0.07\n",
      "std_grad_res: 3.302e+01\n",
      "std_grad_bcs: 1.031e-02\n",
      "std_grad_ics: 3.787e-03\n",
      "kurtosis_grad_res: 1.536e+01\n",
      "kurtosis_grad_bcs: 4.456e-03\n",
      "kurtosis_grad_ics: 1.384e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18700, Loss: 4.244e-01, loss_bcs: 4.477e-04, loss_ics: 4.287e-05, Loss_r: 3.301e-01, Time: 0.06\n",
      "std_grad_res: 6.762e+00\n",
      "std_grad_bcs: 7.921e-03\n",
      "std_grad_ics: 5.399e-03\n",
      "kurtosis_grad_res: 4.429e+00\n",
      "kurtosis_grad_bcs: 4.696e-03\n",
      "kurtosis_grad_ics: 2.560e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18800, Loss: 6.429e-01, loss_bcs: 3.926e-04, loss_ics: 6.418e-05, Loss_r: 5.584e-01, Time: 0.05\n",
      "std_grad_res: 6.221e+01\n",
      "std_grad_bcs: 4.361e-03\n",
      "std_grad_ics: 1.391e-03\n",
      "kurtosis_grad_res: 2.784e+01\n",
      "kurtosis_grad_bcs: 3.570e-03\n",
      "kurtosis_grad_ics: 1.068e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 18900, Loss: 4.313e-01, loss_bcs: 3.382e-04, loss_ics: 3.406e-05, Loss_r: 3.599e-01, Time: 0.04\n",
      "std_grad_res: 3.543e+01\n",
      "std_grad_bcs: 4.227e-03\n",
      "std_grad_ics: 2.611e-03\n",
      "kurtosis_grad_res: 1.702e+01\n",
      "kurtosis_grad_bcs: 3.435e-03\n",
      "kurtosis_grad_ics: 8.494e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19000, Loss: 4.449e-01, loss_bcs: 3.923e-04, loss_ics: 4.234e-05, Loss_r: 3.619e-01, Time: 0.23\n",
      "std_grad_res: 7.542e+01\n",
      "std_grad_bcs: 4.631e-03\n",
      "std_grad_ics: 1.036e-03\n",
      "kurtosis_grad_res: 3.395e+01\n",
      "kurtosis_grad_bcs: 4.286e-03\n",
      "kurtosis_grad_ics: 7.689e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19100, Loss: 5.172e-01, loss_bcs: 4.260e-04, loss_ics: 2.969e-04, Loss_r: 4.101e-01, Time: 0.22\n",
      "std_grad_res: 1.007e+02\n",
      "std_grad_bcs: 2.859e-03\n",
      "std_grad_ics: 1.446e-02\n",
      "kurtosis_grad_res: 4.366e+01\n",
      "kurtosis_grad_bcs: 1.899e-03\n",
      "kurtosis_grad_ics: 6.760e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19200, Loss: 6.918e-01, loss_bcs: 4.059e-04, loss_ics: 5.492e-05, Loss_r: 6.052e-01, Time: 0.05\n",
      "std_grad_res: 2.739e+00\n",
      "std_grad_bcs: 6.182e-03\n",
      "std_grad_ics: 2.784e-03\n",
      "kurtosis_grad_res: 1.893e+00\n",
      "kurtosis_grad_bcs: 4.022e-03\n",
      "kurtosis_grad_ics: 1.135e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19300, Loss: 9.432e-01, loss_bcs: 2.875e-04, loss_ics: 2.049e-05, Loss_r: 8.831e-01, Time: 0.02\n",
      "std_grad_res: 1.226e+01\n",
      "std_grad_bcs: 6.497e-03\n",
      "std_grad_ics: 1.199e-03\n",
      "kurtosis_grad_res: 6.531e+00\n",
      "kurtosis_grad_bcs: 3.102e-03\n",
      "kurtosis_grad_ics: 6.205e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19400, Loss: 5.554e-01, loss_bcs: 4.024e-04, loss_ics: 3.276e-05, Loss_r: 4.711e-01, Time: 0.10\n",
      "std_grad_res: 7.779e+01\n",
      "std_grad_bcs: 1.568e-02\n",
      "std_grad_ics: 1.623e-03\n",
      "kurtosis_grad_res: 3.372e+01\n",
      "kurtosis_grad_bcs: 7.214e-03\n",
      "kurtosis_grad_ics: 9.869e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19500, Loss: 1.384e+00, loss_bcs: 5.631e-04, loss_ics: 1.072e-04, Loss_r: 1.262e+00, Time: 0.20\n",
      "std_grad_res: 8.831e+01\n",
      "std_grad_bcs: 1.393e-02\n",
      "std_grad_ics: 1.304e-02\n",
      "kurtosis_grad_res: 3.979e+01\n",
      "kurtosis_grad_bcs: 6.372e-03\n",
      "kurtosis_grad_ics: 5.935e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19600, Loss: 6.659e-01, loss_bcs: 2.401e-04, loss_ics: 5.037e-05, Loss_r: 6.135e-01, Time: 0.03\n",
      "std_grad_res: 1.026e+02\n",
      "std_grad_bcs: 3.188e-03\n",
      "std_grad_ics: 2.947e-03\n",
      "kurtosis_grad_res: 4.495e+01\n",
      "kurtosis_grad_bcs: 2.253e-03\n",
      "kurtosis_grad_ics: 1.194e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19700, Loss: 4.971e-01, loss_bcs: 4.289e-04, loss_ics: 4.703e-05, Loss_r: 4.063e-01, Time: 0.01\n",
      "std_grad_res: 1.288e+01\n",
      "std_grad_bcs: 1.109e-02\n",
      "std_grad_ics: 7.612e-04\n",
      "kurtosis_grad_res: 5.427e+00\n",
      "kurtosis_grad_bcs: 7.391e-03\n",
      "kurtosis_grad_ics: 5.338e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19800, Loss: 4.356e-01, loss_bcs: 2.446e-04, loss_ics: 5.832e-05, Loss_r: 3.817e-01, Time: 0.25\n",
      "std_grad_res: 3.247e+01\n",
      "std_grad_bcs: 1.098e-02\n",
      "std_grad_ics: 3.000e-03\n",
      "kurtosis_grad_res: 1.319e+01\n",
      "kurtosis_grad_bcs: 5.610e-03\n",
      "kurtosis_grad_ics: 1.233e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 19900, Loss: 8.025e-01, loss_bcs: 1.911e-04, loss_ics: 1.274e-04, Loss_r: 7.548e-01, Time: 0.17\n",
      "std_grad_res: 3.965e+01\n",
      "std_grad_bcs: 1.164e-02\n",
      "std_grad_ics: 8.809e-04\n",
      "kurtosis_grad_res: 1.695e+01\n",
      "kurtosis_grad_bcs: 5.008e-03\n",
      "kurtosis_grad_ics: 7.033e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20000, Loss: 6.475e-01, loss_bcs: 4.274e-04, loss_ics: 6.417e-05, Loss_r: 5.559e-01, Time: 0.02\n",
      "std_grad_res: 9.942e+01\n",
      "std_grad_bcs: 3.277e-03\n",
      "std_grad_ics: 4.358e-03\n",
      "kurtosis_grad_res: 4.438e+01\n",
      "kurtosis_grad_bcs: 2.737e-03\n",
      "kurtosis_grad_ics: 1.394e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20100, Loss: 3.462e-01, loss_bcs: 2.708e-04, loss_ics: 2.532e-05, Loss_r: 2.892e-01, Time: 0.05\n",
      "std_grad_res: 8.529e+01\n",
      "std_grad_bcs: 3.983e-03\n",
      "std_grad_ics: 3.029e-03\n",
      "kurtosis_grad_res: 3.529e+01\n",
      "kurtosis_grad_bcs: 2.069e-03\n",
      "kurtosis_grad_ics: 1.321e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20200, Loss: 4.070e-01, loss_bcs: 4.288e-04, loss_ics: 7.699e-05, Loss_r: 3.142e-01, Time: 0.14\n",
      "std_grad_res: 1.669e+02\n",
      "std_grad_bcs: 1.148e-03\n",
      "std_grad_ics: 1.075e-02\n",
      "kurtosis_grad_res: 7.037e+01\n",
      "kurtosis_grad_bcs: 1.547e-03\n",
      "kurtosis_grad_ics: 4.831e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20300, Loss: 4.442e-01, loss_bcs: 3.539e-04, loss_ics: 1.016e-04, Loss_r: 3.651e-01, Time: 0.01\n",
      "std_grad_res: 3.287e+01\n",
      "std_grad_bcs: 9.549e-03\n",
      "std_grad_ics: 6.610e-03\n",
      "kurtosis_grad_res: 1.542e+01\n",
      "kurtosis_grad_bcs: 4.682e-03\n",
      "kurtosis_grad_ics: 3.404e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20400, Loss: 5.303e-01, loss_bcs: 3.557e-04, loss_ics: 2.506e-05, Loss_r: 4.559e-01, Time: 0.19\n",
      "std_grad_res: 2.099e+01\n",
      "std_grad_bcs: 5.647e-03\n",
      "std_grad_ics: 3.723e-03\n",
      "kurtosis_grad_res: 1.017e+01\n",
      "kurtosis_grad_bcs: 3.634e-03\n",
      "kurtosis_grad_ics: 1.171e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20500, Loss: 3.332e-01, loss_bcs: 2.702e-04, loss_ics: 2.666e-05, Loss_r: 2.762e-01, Time: 0.20\n",
      "std_grad_res: 8.576e+00\n",
      "std_grad_bcs: 5.553e-03\n",
      "std_grad_ics: 2.976e-03\n",
      "kurtosis_grad_res: 4.848e+00\n",
      "kurtosis_grad_bcs: 3.085e-03\n",
      "kurtosis_grad_ics: 9.730e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20600, Loss: 4.519e-01, loss_bcs: 2.990e-04, loss_ics: 3.685e-05, Loss_r: 3.884e-01, Time: 0.05\n",
      "std_grad_res: 4.694e+01\n",
      "std_grad_bcs: 1.199e-02\n",
      "std_grad_ics: 1.446e-03\n",
      "kurtosis_grad_res: 2.014e+01\n",
      "kurtosis_grad_bcs: 6.009e-03\n",
      "kurtosis_grad_ics: 7.186e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20700, Loss: 3.393e+00, loss_bcs: 5.196e-04, loss_ics: 2.829e-05, Loss_r: 3.285e+00, Time: 0.10\n",
      "std_grad_res: 7.578e+01\n",
      "std_grad_bcs: 3.608e-03\n",
      "std_grad_ics: 5.030e-04\n",
      "kurtosis_grad_res: 3.005e+01\n",
      "kurtosis_grad_bcs: 4.834e-03\n",
      "kurtosis_grad_ics: 4.142e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20800, Loss: 4.370e-01, loss_bcs: 4.486e-04, loss_ics: 4.858e-05, Loss_r: 3.422e-01, Time: 0.29\n",
      "std_grad_res: 8.732e+00\n",
      "std_grad_bcs: 7.594e-03\n",
      "std_grad_ics: 1.730e-03\n",
      "kurtosis_grad_res: 6.431e+00\n",
      "kurtosis_grad_bcs: 4.313e-03\n",
      "kurtosis_grad_ics: 1.150e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 20900, Loss: 4.544e-01, loss_bcs: 4.356e-04, loss_ics: 3.679e-05, Loss_r: 3.629e-01, Time: 0.03\n",
      "std_grad_res: 2.050e+01\n",
      "std_grad_bcs: 7.927e-03\n",
      "std_grad_ics: 1.314e-03\n",
      "kurtosis_grad_res: 1.105e+01\n",
      "kurtosis_grad_bcs: 4.377e-03\n",
      "kurtosis_grad_ics: 9.605e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21000, Loss: 3.607e-01, loss_bcs: 3.015e-04, loss_ics: 3.241e-05, Loss_r: 2.969e-01, Time: 0.04\n",
      "std_grad_res: 9.284e+00\n",
      "std_grad_bcs: 7.874e-03\n",
      "std_grad_ics: 9.982e-04\n",
      "kurtosis_grad_res: 4.485e+00\n",
      "kurtosis_grad_bcs: 3.515e-03\n",
      "kurtosis_grad_ics: 6.764e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21100, Loss: 3.501e-01, loss_bcs: 3.925e-04, loss_ics: 1.593e-05, Loss_r: 2.689e-01, Time: 0.12\n",
      "std_grad_res: 3.601e+01\n",
      "std_grad_bcs: 5.982e-03\n",
      "std_grad_ics: 3.230e-04\n",
      "kurtosis_grad_res: 1.541e+01\n",
      "kurtosis_grad_bcs: 3.946e-03\n",
      "kurtosis_grad_ics: 2.618e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21200, Loss: 6.964e-01, loss_bcs: 1.950e-04, loss_ics: 8.268e-05, Loss_r: 6.509e-01, Time: 0.15\n",
      "std_grad_res: 2.073e+01\n",
      "std_grad_bcs: 5.067e-03\n",
      "std_grad_ics: 2.917e-03\n",
      "kurtosis_grad_res: 9.571e+00\n",
      "kurtosis_grad_bcs: 2.767e-03\n",
      "kurtosis_grad_ics: 1.599e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21300, Loss: 8.567e-01, loss_bcs: 4.010e-04, loss_ics: 4.166e-05, Loss_r: 7.720e-01, Time: 0.10\n",
      "std_grad_res: 1.991e+02\n",
      "std_grad_bcs: 9.412e-04\n",
      "std_grad_ics: 2.095e-03\n",
      "kurtosis_grad_res: 8.476e+01\n",
      "kurtosis_grad_bcs: 1.035e-03\n",
      "kurtosis_grad_ics: 1.160e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21400, Loss: 5.616e-01, loss_bcs: 2.994e-04, loss_ics: 3.372e-05, Loss_r: 4.982e-01, Time: 0.20\n",
      "std_grad_res: 1.285e+02\n",
      "std_grad_bcs: 1.392e-02\n",
      "std_grad_ics: 4.935e-04\n",
      "kurtosis_grad_res: 5.612e+01\n",
      "kurtosis_grad_bcs: 5.926e-03\n",
      "kurtosis_grad_ics: 3.876e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21500, Loss: 2.995e-01, loss_bcs: 2.920e-04, loss_ics: 2.437e-05, Loss_r: 2.382e-01, Time: 0.06\n",
      "std_grad_res: 1.745e+01\n",
      "std_grad_bcs: 7.566e-03\n",
      "std_grad_ics: 6.864e-04\n",
      "kurtosis_grad_res: 8.407e+00\n",
      "kurtosis_grad_bcs: 3.548e-03\n",
      "kurtosis_grad_ics: 5.455e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21600, Loss: 6.527e-01, loss_bcs: 2.957e-04, loss_ics: 3.648e-05, Loss_r: 5.898e-01, Time: 0.31\n",
      "std_grad_res: 2.513e+01\n",
      "std_grad_bcs: 7.147e-03\n",
      "std_grad_ics: 1.868e-03\n",
      "kurtosis_grad_res: 1.054e+01\n",
      "kurtosis_grad_bcs: 3.494e-03\n",
      "kurtosis_grad_ics: 7.796e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21700, Loss: 1.227e+00, loss_bcs: 4.240e-04, loss_ics: 3.586e-05, Loss_r: 1.138e+00, Time: 0.31\n",
      "std_grad_res: 7.409e+01\n",
      "std_grad_bcs: 1.081e-02\n",
      "std_grad_ics: 2.923e-03\n",
      "kurtosis_grad_res: 3.231e+01\n",
      "kurtosis_grad_bcs: 5.680e-03\n",
      "kurtosis_grad_ics: 9.315e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21800, Loss: 4.138e-01, loss_bcs: 3.720e-04, loss_ics: 8.531e-05, Loss_r: 3.320e-01, Time: 0.19\n",
      "std_grad_res: 2.334e+01\n",
      "std_grad_bcs: 7.799e-03\n",
      "std_grad_ics: 9.698e-04\n",
      "kurtosis_grad_res: 1.034e+01\n",
      "kurtosis_grad_bcs: 5.055e-03\n",
      "kurtosis_grad_ics: 6.389e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 21900, Loss: 2.487e-01, loss_bcs: 2.754e-04, loss_ics: 2.680e-05, Loss_r: 1.907e-01, Time: 0.33\n",
      "std_grad_res: 4.004e+01\n",
      "std_grad_bcs: 4.935e-03\n",
      "std_grad_ics: 8.467e-04\n",
      "kurtosis_grad_res: 1.768e+01\n",
      "kurtosis_grad_bcs: 3.577e-03\n",
      "kurtosis_grad_ics: 5.245e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22000, Loss: 4.990e-01, loss_bcs: 3.006e-04, loss_ics: 4.620e-05, Loss_r: 4.345e-01, Time: 0.23\n",
      "std_grad_res: 5.183e+01\n",
      "std_grad_bcs: 7.523e-03\n",
      "std_grad_ics: 5.086e-04\n",
      "kurtosis_grad_res: 2.442e+01\n",
      "kurtosis_grad_bcs: 5.383e-03\n",
      "kurtosis_grad_ics: 3.753e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22100, Loss: 5.662e-01, loss_bcs: 3.191e-04, loss_ics: 3.136e-05, Loss_r: 4.989e-01, Time: 0.27\n",
      "std_grad_res: 8.293e+01\n",
      "std_grad_bcs: 1.979e-03\n",
      "std_grad_ics: 9.082e-03\n",
      "kurtosis_grad_res: 3.593e+01\n",
      "kurtosis_grad_bcs: 2.836e-03\n",
      "kurtosis_grad_ics: 3.827e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22200, Loss: 2.659e-01, loss_bcs: 2.311e-04, loss_ics: 4.053e-05, Loss_r: 2.160e-01, Time: 0.02\n",
      "std_grad_res: 3.906e+01\n",
      "std_grad_bcs: 3.546e-03\n",
      "std_grad_ics: 6.867e-04\n",
      "kurtosis_grad_res: 1.841e+01\n",
      "kurtosis_grad_bcs: 3.951e-03\n",
      "kurtosis_grad_ics: 5.398e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22300, Loss: 3.330e-01, loss_bcs: 3.072e-04, loss_ics: 1.505e-05, Loss_r: 2.693e-01, Time: 0.14\n",
      "std_grad_res: 6.469e+00\n",
      "std_grad_bcs: 9.450e-03\n",
      "std_grad_ics: 3.489e-04\n",
      "kurtosis_grad_res: 3.193e+00\n",
      "kurtosis_grad_bcs: 5.250e-03\n",
      "kurtosis_grad_ics: 2.768e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22400, Loss: 1.342e+00, loss_bcs: 4.030e-04, loss_ics: 1.301e-04, Loss_r: 1.251e+00, Time: 0.02\n",
      "std_grad_res: 1.805e+02\n",
      "std_grad_bcs: 8.427e-04\n",
      "std_grad_ics: 5.517e-04\n",
      "kurtosis_grad_res: 7.768e+01\n",
      "kurtosis_grad_bcs: 1.195e-03\n",
      "kurtosis_grad_ics: 2.721e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22500, Loss: 6.514e-01, loss_bcs: 2.477e-04, loss_ics: 3.628e-05, Loss_r: 5.983e-01, Time: 0.06\n",
      "std_grad_res: 8.077e+01\n",
      "std_grad_bcs: 1.031e-02\n",
      "std_grad_ics: 4.115e-03\n",
      "kurtosis_grad_res: 3.606e+01\n",
      "kurtosis_grad_bcs: 5.785e-03\n",
      "kurtosis_grad_ics: 1.307e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22600, Loss: 1.384e+00, loss_bcs: 4.166e-04, loss_ics: 2.482e-05, Loss_r: 1.297e+00, Time: 0.19\n",
      "std_grad_res: 1.555e+01\n",
      "std_grad_bcs: 7.956e-03\n",
      "std_grad_ics: 2.112e-03\n",
      "kurtosis_grad_res: 9.219e+00\n",
      "kurtosis_grad_bcs: 4.320e-03\n",
      "kurtosis_grad_ics: 1.132e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22700, Loss: 2.445e-01, loss_bcs: 2.041e-04, loss_ics: 3.324e-05, Loss_r: 2.005e-01, Time: 0.10\n",
      "std_grad_res: 2.133e+01\n",
      "std_grad_bcs: 4.809e-03\n",
      "std_grad_ics: 5.098e-04\n",
      "kurtosis_grad_res: 9.398e+00\n",
      "kurtosis_grad_bcs: 2.422e-03\n",
      "kurtosis_grad_ics: 3.669e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22800, Loss: 5.948e-01, loss_bcs: 2.502e-04, loss_ics: 6.585e-05, Loss_r: 5.392e-01, Time: 0.02\n",
      "std_grad_res: 3.584e+01\n",
      "std_grad_bcs: 7.292e-03\n",
      "std_grad_ics: 3.643e-04\n",
      "kurtosis_grad_res: 1.618e+01\n",
      "kurtosis_grad_bcs: 4.809e-03\n",
      "kurtosis_grad_ics: 2.158e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 22900, Loss: 4.578e-01, loss_bcs: 2.653e-04, loss_ics: 9.154e-05, Loss_r: 3.974e-01, Time: 0.11\n",
      "std_grad_res: 1.931e+01\n",
      "std_grad_bcs: 6.349e-03\n",
      "std_grad_ics: 2.133e-03\n",
      "kurtosis_grad_res: 8.011e+00\n",
      "kurtosis_grad_bcs: 4.862e-03\n",
      "kurtosis_grad_ics: 1.316e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23000, Loss: 3.923e-01, loss_bcs: 2.308e-04, loss_ics: 9.266e-06, Loss_r: 3.446e-01, Time: 0.05\n",
      "std_grad_res: 2.226e+01\n",
      "std_grad_bcs: 9.651e-03\n",
      "std_grad_ics: 1.489e-03\n",
      "kurtosis_grad_res: 9.970e+00\n",
      "kurtosis_grad_bcs: 5.676e-03\n",
      "kurtosis_grad_ics: 4.722e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23100, Loss: 3.860e-01, loss_bcs: 2.549e-04, loss_ics: 2.410e-05, Loss_r: 3.324e-01, Time: 0.02\n",
      "std_grad_res: 2.041e+01\n",
      "std_grad_bcs: 8.389e-03\n",
      "std_grad_ics: 7.380e-04\n",
      "kurtosis_grad_res: 8.942e+00\n",
      "kurtosis_grad_bcs: 3.835e-03\n",
      "kurtosis_grad_ics: 5.677e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23200, Loss: 6.366e-01, loss_bcs: 3.139e-04, loss_ics: 3.859e-05, Loss_r: 5.699e-01, Time: 0.08\n",
      "std_grad_res: 1.018e+02\n",
      "std_grad_bcs: 5.705e-03\n",
      "std_grad_ics: 9.974e-04\n",
      "kurtosis_grad_res: 4.483e+01\n",
      "kurtosis_grad_bcs: 2.612e-03\n",
      "kurtosis_grad_ics: 7.845e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23300, Loss: 1.427e+00, loss_bcs: 1.745e-04, loss_ics: 3.206e-05, Loss_r: 1.389e+00, Time: 0.09\n",
      "std_grad_res: 1.174e+01\n",
      "std_grad_bcs: 7.744e-03\n",
      "std_grad_ics: 6.304e-04\n",
      "kurtosis_grad_res: 5.707e+00\n",
      "kurtosis_grad_bcs: 4.245e-03\n",
      "kurtosis_grad_ics: 4.505e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23400, Loss: 3.606e-01, loss_bcs: 2.445e-04, loss_ics: 4.717e-05, Loss_r: 3.074e-01, Time: 0.02\n",
      "std_grad_res: 2.747e+01\n",
      "std_grad_bcs: 8.964e-03\n",
      "std_grad_ics: 1.711e-03\n",
      "kurtosis_grad_res: 1.231e+01\n",
      "kurtosis_grad_bcs: 4.746e-03\n",
      "kurtosis_grad_ics: 1.166e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23500, Loss: 4.744e-01, loss_bcs: 2.707e-04, loss_ics: 2.477e-05, Loss_r: 4.175e-01, Time: 0.02\n",
      "std_grad_res: 4.000e+01\n",
      "std_grad_bcs: 1.230e-02\n",
      "std_grad_ics: 3.076e-03\n",
      "kurtosis_grad_res: 1.817e+01\n",
      "kurtosis_grad_bcs: 5.758e-03\n",
      "kurtosis_grad_ics: 9.777e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23600, Loss: 3.679e-01, loss_bcs: 2.479e-04, loss_ics: 1.690e-05, Loss_r: 3.161e-01, Time: 0.02\n",
      "std_grad_res: 1.455e+01\n",
      "std_grad_bcs: 5.112e-03\n",
      "std_grad_ics: 4.565e-03\n",
      "kurtosis_grad_res: 7.784e+00\n",
      "kurtosis_grad_bcs: 2.627e-03\n",
      "kurtosis_grad_ics: 1.495e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23700, Loss: 4.616e-01, loss_bcs: 2.874e-04, loss_ics: 5.213e-05, Loss_r: 3.993e-01, Time: 0.03\n",
      "std_grad_res: 2.591e+01\n",
      "std_grad_bcs: 3.861e-03\n",
      "std_grad_ics: 5.855e-04\n",
      "kurtosis_grad_res: 1.153e+01\n",
      "kurtosis_grad_bcs: 2.582e-03\n",
      "kurtosis_grad_ics: 3.885e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23800, Loss: 4.312e-01, loss_bcs: 2.646e-04, loss_ics: 2.887e-05, Loss_r: 3.752e-01, Time: 0.02\n",
      "std_grad_res: 4.648e+01\n",
      "std_grad_bcs: 8.123e-03\n",
      "std_grad_ics: 8.447e-03\n",
      "kurtosis_grad_res: 1.990e+01\n",
      "kurtosis_grad_bcs: 3.383e-03\n",
      "kurtosis_grad_ics: 2.764e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 23900, Loss: 3.791e-01, loss_bcs: 2.468e-04, loss_ics: 2.482e-05, Loss_r: 3.271e-01, Time: 0.07\n",
      "std_grad_res: 2.311e+01\n",
      "std_grad_bcs: 4.893e-03\n",
      "std_grad_ics: 1.612e-03\n",
      "kurtosis_grad_res: 1.120e+01\n",
      "kurtosis_grad_bcs: 2.304e-03\n",
      "kurtosis_grad_ics: 5.881e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24000, Loss: 3.384e-01, loss_bcs: 2.671e-04, loss_ics: 3.450e-05, Loss_r: 2.816e-01, Time: 0.03\n",
      "std_grad_res: 5.093e+01\n",
      "std_grad_bcs: 1.045e-02\n",
      "std_grad_ics: 6.735e-04\n",
      "kurtosis_grad_res: 2.169e+01\n",
      "kurtosis_grad_bcs: 5.635e-03\n",
      "kurtosis_grad_ics: 4.752e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24100, Loss: 4.445e-01, loss_bcs: 2.764e-04, loss_ics: 1.447e-05, Loss_r: 3.871e-01, Time: 0.03\n",
      "std_grad_res: 1.144e+01\n",
      "std_grad_bcs: 7.263e-03\n",
      "std_grad_ics: 3.955e-03\n",
      "kurtosis_grad_res: 6.738e+00\n",
      "kurtosis_grad_bcs: 4.221e-03\n",
      "kurtosis_grad_ics: 1.317e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24200, Loss: 5.319e-01, loss_bcs: 2.697e-04, loss_ics: 2.597e-05, Loss_r: 4.751e-01, Time: 0.02\n",
      "std_grad_res: 9.095e+00\n",
      "std_grad_bcs: 6.300e-03\n",
      "std_grad_ics: 1.387e-03\n",
      "kurtosis_grad_res: 4.791e+00\n",
      "kurtosis_grad_bcs: 3.427e-03\n",
      "kurtosis_grad_ics: 9.180e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24300, Loss: 4.179e-01, loss_bcs: 2.724e-04, loss_ics: 4.410e-05, Loss_r: 3.593e-01, Time: 0.04\n",
      "std_grad_res: 4.564e+01\n",
      "std_grad_bcs: 3.493e-03\n",
      "std_grad_ics: 6.157e-04\n",
      "kurtosis_grad_res: 1.871e+01\n",
      "kurtosis_grad_bcs: 2.410e-03\n",
      "kurtosis_grad_ics: 4.118e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24400, Loss: 4.822e-01, loss_bcs: 2.573e-04, loss_ics: 6.059e-05, Loss_r: 4.255e-01, Time: 0.02\n",
      "std_grad_res: 4.119e+01\n",
      "std_grad_bcs: 7.666e-03\n",
      "std_grad_ics: 4.516e-03\n",
      "kurtosis_grad_res: 1.952e+01\n",
      "kurtosis_grad_bcs: 3.654e-03\n",
      "kurtosis_grad_ics: 2.336e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24500, Loss: 3.490e-01, loss_bcs: 2.584e-04, loss_ics: 1.298e-05, Loss_r: 2.954e-01, Time: 0.07\n",
      "std_grad_res: 3.451e+01\n",
      "std_grad_bcs: 1.120e-02\n",
      "std_grad_ics: 2.906e-03\n",
      "kurtosis_grad_res: 1.453e+01\n",
      "kurtosis_grad_bcs: 5.518e-03\n",
      "kurtosis_grad_ics: 9.137e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24600, Loss: 6.518e-01, loss_bcs: 2.141e-04, loss_ics: 1.989e-05, Loss_r: 6.067e-01, Time: 0.02\n",
      "std_grad_res: 3.850e+01\n",
      "std_grad_bcs: 7.096e-03\n",
      "std_grad_ics: 6.505e-04\n",
      "kurtosis_grad_res: 1.721e+01\n",
      "kurtosis_grad_bcs: 3.979e-03\n",
      "kurtosis_grad_ics: 3.664e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24700, Loss: 6.625e-01, loss_bcs: 3.739e-04, loss_ics: 2.070e-05, Loss_r: 5.847e-01, Time: 0.09\n",
      "std_grad_res: 8.154e+01\n",
      "std_grad_bcs: 4.118e-03\n",
      "std_grad_ics: 6.914e-04\n",
      "kurtosis_grad_res: 3.876e+01\n",
      "kurtosis_grad_bcs: 3.335e-03\n",
      "kurtosis_grad_ics: 2.501e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24800, Loss: 6.806e-01, loss_bcs: 2.756e-04, loss_ics: 4.566e-05, Loss_r: 6.213e-01, Time: 0.03\n",
      "std_grad_res: 4.994e+01\n",
      "std_grad_bcs: 4.268e-03\n",
      "std_grad_ics: 3.623e-03\n",
      "kurtosis_grad_res: 2.214e+01\n",
      "kurtosis_grad_bcs: 2.624e-03\n",
      "kurtosis_grad_ics: 1.515e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 24900, Loss: 6.862e-01, loss_bcs: 2.778e-04, loss_ics: 1.667e-05, Loss_r: 6.283e-01, Time: 0.02\n",
      "std_grad_res: 1.938e+01\n",
      "std_grad_bcs: 8.977e-03\n",
      "std_grad_ics: 1.811e-03\n",
      "kurtosis_grad_res: 1.048e+01\n",
      "kurtosis_grad_bcs: 3.751e-03\n",
      "kurtosis_grad_ics: 6.176e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25000, Loss: 7.266e-01, loss_bcs: 3.409e-04, loss_ics: 2.432e-05, Loss_r: 6.553e-01, Time: 0.02\n",
      "std_grad_res: 4.061e+01\n",
      "std_grad_bcs: 9.406e-03\n",
      "std_grad_ics: 8.707e-04\n",
      "kurtosis_grad_res: 1.689e+01\n",
      "kurtosis_grad_bcs: 4.506e-03\n",
      "kurtosis_grad_ics: 4.298e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25100, Loss: 4.481e-01, loss_bcs: 2.785e-04, loss_ics: 4.843e-05, Loss_r: 3.879e-01, Time: 0.11\n",
      "std_grad_res: 3.769e+01\n",
      "std_grad_bcs: 4.951e-03\n",
      "std_grad_ics: 1.744e-03\n",
      "kurtosis_grad_res: 1.467e+01\n",
      "kurtosis_grad_bcs: 2.387e-03\n",
      "kurtosis_grad_ics: 1.099e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25200, Loss: 3.218e-01, loss_bcs: 2.523e-04, loss_ics: 2.799e-05, Loss_r: 2.684e-01, Time: 0.03\n",
      "std_grad_res: 1.018e+00\n",
      "std_grad_bcs: 8.141e-03\n",
      "std_grad_ics: 1.841e-03\n",
      "kurtosis_grad_res: 1.203e+00\n",
      "kurtosis_grad_bcs: 3.661e-03\n",
      "kurtosis_grad_ics: 6.727e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25300, Loss: 3.542e-01, loss_bcs: 2.393e-04, loss_ics: 8.309e-06, Loss_r: 3.048e-01, Time: 0.02\n",
      "std_grad_res: 2.806e+01\n",
      "std_grad_bcs: 6.787e-03\n",
      "std_grad_ics: 4.983e-04\n",
      "kurtosis_grad_res: 1.435e+01\n",
      "kurtosis_grad_bcs: 3.633e-03\n",
      "kurtosis_grad_ics: 2.306e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25400, Loss: 3.248e-01, loss_bcs: 2.460e-04, loss_ics: 9.262e-06, Loss_r: 2.740e-01, Time: 0.02\n",
      "std_grad_res: 3.762e+01\n",
      "std_grad_bcs: 4.515e-03\n",
      "std_grad_ics: 2.004e-03\n",
      "kurtosis_grad_res: 1.529e+01\n",
      "kurtosis_grad_bcs: 2.348e-03\n",
      "kurtosis_grad_ics: 9.200e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25500, Loss: 4.804e-01, loss_bcs: 2.135e-04, loss_ics: 2.934e-05, Loss_r: 4.349e-01, Time: 0.03\n",
      "std_grad_res: 7.109e+01\n",
      "std_grad_bcs: 2.146e-03\n",
      "std_grad_ics: 8.976e-04\n",
      "kurtosis_grad_res: 3.100e+01\n",
      "kurtosis_grad_bcs: 1.201e-03\n",
      "kurtosis_grad_ics: 7.076e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25600, Loss: 3.823e-01, loss_bcs: 2.386e-04, loss_ics: 2.107e-05, Loss_r: 3.321e-01, Time: 0.09\n",
      "std_grad_res: 6.170e+01\n",
      "std_grad_bcs: 3.311e-03\n",
      "std_grad_ics: 9.455e-04\n",
      "kurtosis_grad_res: 2.439e+01\n",
      "kurtosis_grad_bcs: 2.217e-03\n",
      "kurtosis_grad_ics: 5.972e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25700, Loss: 3.379e-01, loss_bcs: 1.836e-04, loss_ics: 1.861e-05, Loss_r: 2.991e-01, Time: 0.02\n",
      "std_grad_res: 4.351e+01\n",
      "std_grad_bcs: 4.850e-03\n",
      "std_grad_ics: 6.090e-03\n",
      "kurtosis_grad_res: 2.084e+01\n",
      "kurtosis_grad_bcs: 2.604e-03\n",
      "kurtosis_grad_ics: 1.987e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25800, Loss: 4.484e-01, loss_bcs: 2.187e-04, loss_ics: 1.375e-05, Loss_r: 4.028e-01, Time: 0.02\n",
      "std_grad_res: 1.238e+01\n",
      "std_grad_bcs: 6.884e-03\n",
      "std_grad_ics: 9.480e-04\n",
      "kurtosis_grad_res: 6.702e+00\n",
      "kurtosis_grad_bcs: 4.356e-03\n",
      "kurtosis_grad_ics: 3.736e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 25900, Loss: 2.651e-01, loss_bcs: 2.987e-04, loss_ics: 3.117e-05, Loss_r: 2.021e-01, Time: 0.06\n",
      "std_grad_res: 4.705e+01\n",
      "std_grad_bcs: 2.690e-03\n",
      "std_grad_ics: 1.221e-03\n",
      "kurtosis_grad_res: 2.035e+01\n",
      "kurtosis_grad_bcs: 1.677e-03\n",
      "kurtosis_grad_ics: 7.448e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26000, Loss: 2.929e-01, loss_bcs: 2.316e-04, loss_ics: 3.164e-05, Loss_r: 2.435e-01, Time: 0.03\n",
      "std_grad_res: 1.551e+01\n",
      "std_grad_bcs: 8.487e-03\n",
      "std_grad_ics: 3.901e-03\n",
      "kurtosis_grad_res: 6.608e+00\n",
      "kurtosis_grad_bcs: 4.267e-03\n",
      "kurtosis_grad_ics: 1.258e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26100, Loss: 8.345e-01, loss_bcs: 2.543e-04, loss_ics: 6.910e-05, Loss_r: 7.778e-01, Time: 0.11\n",
      "std_grad_res: 2.146e+01\n",
      "std_grad_bcs: 4.827e-03\n",
      "std_grad_ics: 2.754e-03\n",
      "kurtosis_grad_res: 9.969e+00\n",
      "kurtosis_grad_bcs: 2.248e-03\n",
      "kurtosis_grad_ics: 1.324e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26200, Loss: 4.913e-01, loss_bcs: 1.648e-04, loss_ics: 1.609e-05, Loss_r: 4.566e-01, Time: 0.02\n",
      "std_grad_res: 1.829e+01\n",
      "std_grad_bcs: 6.935e-03\n",
      "std_grad_ics: 4.079e-04\n",
      "kurtosis_grad_res: 7.535e+00\n",
      "kurtosis_grad_bcs: 3.495e-03\n",
      "kurtosis_grad_ics: 2.834e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26300, Loss: 3.789e-01, loss_bcs: 2.316e-04, loss_ics: 2.032e-05, Loss_r: 3.302e-01, Time: 0.02\n",
      "std_grad_res: 7.397e+00\n",
      "std_grad_bcs: 6.388e-03\n",
      "std_grad_ics: 4.632e-04\n",
      "kurtosis_grad_res: 4.286e+00\n",
      "kurtosis_grad_bcs: 3.255e-03\n",
      "kurtosis_grad_ics: 3.125e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26400, Loss: 1.966e-01, loss_bcs: 2.792e-04, loss_ics: 9.297e-06, Loss_r: 1.390e-01, Time: 0.07\n",
      "std_grad_res: 5.930e+00\n",
      "std_grad_bcs: 5.251e-03\n",
      "std_grad_ics: 2.173e-04\n",
      "kurtosis_grad_res: 2.953e+00\n",
      "kurtosis_grad_bcs: 2.974e-03\n",
      "kurtosis_grad_ics: 1.563e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26500, Loss: 4.738e-01, loss_bcs: 3.140e-04, loss_ics: 1.624e-05, Loss_r: 4.086e-01, Time: 0.03\n",
      "std_grad_res: 9.499e+00\n",
      "std_grad_bcs: 7.707e-03\n",
      "std_grad_ics: 1.834e-03\n",
      "kurtosis_grad_res: 6.026e+00\n",
      "kurtosis_grad_bcs: 4.042e-03\n",
      "kurtosis_grad_ics: 6.015e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26600, Loss: 2.481e-01, loss_bcs: 2.342e-04, loss_ics: 1.369e-05, Loss_r: 1.993e-01, Time: 0.02\n",
      "std_grad_res: 1.178e+01\n",
      "std_grad_bcs: 4.036e-03\n",
      "std_grad_ics: 4.136e-04\n",
      "kurtosis_grad_res: 4.699e+00\n",
      "kurtosis_grad_bcs: 2.647e-03\n",
      "kurtosis_grad_ics: 2.399e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26700, Loss: 5.164e-01, loss_bcs: 2.653e-04, loss_ics: 1.061e-05, Loss_r: 4.615e-01, Time: 0.02\n",
      "std_grad_res: 1.235e+01\n",
      "std_grad_bcs: 7.747e-03\n",
      "std_grad_ics: 2.490e-04\n",
      "kurtosis_grad_res: 6.942e+00\n",
      "kurtosis_grad_bcs: 4.380e-03\n",
      "kurtosis_grad_ics: 1.788e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26800, Loss: 2.963e-01, loss_bcs: 2.420e-04, loss_ics: 1.907e-05, Loss_r: 2.456e-01, Time: 0.08\n",
      "std_grad_res: 9.987e+00\n",
      "std_grad_bcs: 6.062e-03\n",
      "std_grad_ics: 1.621e-03\n",
      "kurtosis_grad_res: 4.817e+00\n",
      "kurtosis_grad_bcs: 3.520e-03\n",
      "kurtosis_grad_ics: 8.415e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 26900, Loss: 5.990e-01, loss_bcs: 3.005e-04, loss_ics: 2.267e-05, Loss_r: 5.361e-01, Time: 0.03\n",
      "std_grad_res: 8.451e+01\n",
      "std_grad_bcs: 1.784e-03\n",
      "std_grad_ics: 4.458e-04\n",
      "kurtosis_grad_res: 3.852e+01\n",
      "kurtosis_grad_bcs: 1.754e-03\n",
      "kurtosis_grad_ics: 3.542e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27000, Loss: 2.882e-01, loss_bcs: 2.165e-04, loss_ics: 1.224e-05, Loss_r: 2.431e-01, Time: 0.11\n",
      "std_grad_res: 1.001e+02\n",
      "std_grad_bcs: 1.676e-03\n",
      "std_grad_ics: 5.407e-04\n",
      "kurtosis_grad_res: 4.319e+01\n",
      "kurtosis_grad_bcs: 1.353e-03\n",
      "kurtosis_grad_ics: 3.567e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27100, Loss: 2.390e-01, loss_bcs: 2.044e-04, loss_ics: 1.319e-05, Loss_r: 1.963e-01, Time: 0.02\n",
      "std_grad_res: 4.118e+01\n",
      "std_grad_bcs: 2.334e-03\n",
      "std_grad_ics: 1.988e-04\n",
      "kurtosis_grad_res: 1.847e+01\n",
      "kurtosis_grad_bcs: 2.710e-03\n",
      "kurtosis_grad_ics: 1.408e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27200, Loss: 2.550e-01, loss_bcs: 2.809e-04, loss_ics: 7.906e-06, Loss_r: 1.971e-01, Time: 0.02\n",
      "std_grad_res: 6.271e+00\n",
      "std_grad_bcs: 6.096e-03\n",
      "std_grad_ics: 5.360e-04\n",
      "kurtosis_grad_res: 4.105e+00\n",
      "kurtosis_grad_bcs: 3.217e-03\n",
      "kurtosis_grad_ics: 3.577e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27300, Loss: 2.589e-01, loss_bcs: 2.943e-04, loss_ics: 8.248e-06, Loss_r: 1.982e-01, Time: 0.04\n",
      "std_grad_res: 3.263e+01\n",
      "std_grad_bcs: 7.257e-03\n",
      "std_grad_ics: 6.452e-04\n",
      "kurtosis_grad_res: 1.359e+01\n",
      "kurtosis_grad_bcs: 3.794e-03\n",
      "kurtosis_grad_ics: 2.352e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27400, Loss: 5.599e-01, loss_bcs: 2.767e-04, loss_ics: 1.786e-05, Loss_r: 5.022e-01, Time: 0.02\n",
      "std_grad_res: 5.976e+01\n",
      "std_grad_bcs: 1.980e-03\n",
      "std_grad_ics: 6.614e-03\n",
      "kurtosis_grad_res: 2.401e+01\n",
      "kurtosis_grad_bcs: 2.780e-03\n",
      "kurtosis_grad_ics: 2.761e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27500, Loss: 2.338e-01, loss_bcs: 1.769e-04, loss_ics: 5.962e-06, Loss_r: 1.973e-01, Time: 0.03\n",
      "std_grad_res: 1.976e+01\n",
      "std_grad_bcs: 6.045e-03\n",
      "std_grad_ics: 2.473e-04\n",
      "kurtosis_grad_res: 9.204e+00\n",
      "kurtosis_grad_bcs: 3.122e-03\n",
      "kurtosis_grad_ics: 1.358e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27600, Loss: 4.716e-01, loss_bcs: 2.279e-04, loss_ics: 9.562e-06, Loss_r: 4.245e-01, Time: 0.08\n",
      "std_grad_res: 4.915e+01\n",
      "std_grad_bcs: 3.976e-03\n",
      "std_grad_ics: 4.188e-04\n",
      "kurtosis_grad_res: 2.222e+01\n",
      "kurtosis_grad_bcs: 1.902e-03\n",
      "kurtosis_grad_ics: 1.963e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27700, Loss: 2.725e-01, loss_bcs: 2.952e-04, loss_ics: 1.812e-05, Loss_r: 2.110e-01, Time: 0.02\n",
      "std_grad_res: 3.309e+00\n",
      "std_grad_bcs: 5.702e-03\n",
      "std_grad_ics: 3.577e-04\n",
      "kurtosis_grad_res: 2.084e+00\n",
      "kurtosis_grad_bcs: 2.653e-03\n",
      "kurtosis_grad_ics: 2.452e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27800, Loss: 7.240e-01, loss_bcs: 3.115e-04, loss_ics: 1.736e-05, Loss_r: 6.592e-01, Time: 0.08\n",
      "std_grad_res: 4.892e+01\n",
      "std_grad_bcs: 9.095e-03\n",
      "std_grad_ics: 3.108e-03\n",
      "kurtosis_grad_res: 2.159e+01\n",
      "kurtosis_grad_bcs: 4.590e-03\n",
      "kurtosis_grad_ics: 9.814e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 27900, Loss: 3.406e-01, loss_bcs: 1.951e-04, loss_ics: 2.192e-05, Loss_r: 2.993e-01, Time: 0.03\n",
      "std_grad_res: 5.378e+01\n",
      "std_grad_bcs: 8.603e-03\n",
      "std_grad_ics: 3.826e-04\n",
      "kurtosis_grad_res: 2.338e+01\n",
      "kurtosis_grad_bcs: 4.579e-03\n",
      "kurtosis_grad_ics: 2.791e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28000, Loss: 2.005e-01, loss_bcs: 2.355e-04, loss_ics: 1.653e-05, Loss_r: 1.513e-01, Time: 0.02\n",
      "std_grad_res: 1.612e+01\n",
      "std_grad_bcs: 5.376e-03\n",
      "std_grad_ics: 3.646e-04\n",
      "kurtosis_grad_res: 6.361e+00\n",
      "kurtosis_grad_bcs: 3.404e-03\n",
      "kurtosis_grad_ics: 2.528e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28100, Loss: 5.789e-01, loss_bcs: 1.816e-04, loss_ics: 1.871e-05, Loss_r: 5.405e-01, Time: 0.07\n",
      "std_grad_res: 2.625e+01\n",
      "std_grad_bcs: 2.475e-03\n",
      "std_grad_ics: 4.291e-04\n",
      "kurtosis_grad_res: 1.147e+01\n",
      "kurtosis_grad_bcs: 1.529e-03\n",
      "kurtosis_grad_ics: 3.005e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28200, Loss: 2.462e-01, loss_bcs: 1.628e-04, loss_ics: 1.029e-05, Loss_r: 2.122e-01, Time: 0.02\n",
      "std_grad_res: 1.646e+01\n",
      "std_grad_bcs: 5.434e-03\n",
      "std_grad_ics: 1.857e-03\n",
      "kurtosis_grad_res: 7.540e+00\n",
      "kurtosis_grad_bcs: 2.946e-03\n",
      "kurtosis_grad_ics: 5.941e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28300, Loss: 3.355e-01, loss_bcs: 2.317e-04, loss_ics: 8.314e-06, Loss_r: 2.876e-01, Time: 0.08\n",
      "std_grad_res: 3.986e+01\n",
      "std_grad_bcs: 8.043e-03\n",
      "std_grad_ics: 1.379e-03\n",
      "kurtosis_grad_res: 1.679e+01\n",
      "kurtosis_grad_bcs: 4.533e-03\n",
      "kurtosis_grad_ics: 4.259e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28400, Loss: 2.575e-01, loss_bcs: 2.217e-04, loss_ics: 7.794e-06, Loss_r: 2.117e-01, Time: 0.02\n",
      "std_grad_res: 1.271e+01\n",
      "std_grad_bcs: 8.116e-03\n",
      "std_grad_ics: 1.472e-03\n",
      "kurtosis_grad_res: 6.350e+00\n",
      "kurtosis_grad_bcs: 3.762e-03\n",
      "kurtosis_grad_ics: 4.622e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28500, Loss: 2.290e-01, loss_bcs: 2.000e-04, loss_ics: 8.814e-06, Loss_r: 1.876e-01, Time: 0.02\n",
      "std_grad_res: 1.091e+01\n",
      "std_grad_bcs: 5.515e-03\n",
      "std_grad_ics: 6.134e-04\n",
      "kurtosis_grad_res: 5.020e+00\n",
      "kurtosis_grad_bcs: 2.806e-03\n",
      "kurtosis_grad_ics: 2.540e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28600, Loss: 3.211e-01, loss_bcs: 1.654e-04, loss_ics: 2.066e-05, Loss_r: 2.859e-01, Time: 0.02\n",
      "std_grad_res: 2.020e+01\n",
      "std_grad_bcs: 6.009e-03\n",
      "std_grad_ics: 2.979e-03\n",
      "kurtosis_grad_res: 1.026e+01\n",
      "kurtosis_grad_bcs: 3.915e-03\n",
      "kurtosis_grad_ics: 1.407e-03\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28700, Loss: 2.282e-01, loss_bcs: 2.243e-04, loss_ics: 5.476e-06, Loss_r: 1.820e-01, Time: 0.16\n",
      "std_grad_res: 1.397e+01\n",
      "std_grad_bcs: 3.239e-03\n",
      "std_grad_ics: 8.745e-04\n",
      "kurtosis_grad_res: 5.994e+00\n",
      "kurtosis_grad_bcs: 1.673e-03\n",
      "kurtosis_grad_ics: 2.749e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28800, Loss: 2.758e-01, loss_bcs: 2.570e-04, loss_ics: 1.173e-05, Loss_r: 2.225e-01, Time: 0.03\n",
      "std_grad_res: 1.064e+01\n",
      "std_grad_bcs: 6.144e-03\n",
      "std_grad_ics: 2.338e-04\n",
      "kurtosis_grad_res: 4.341e+00\n",
      "kurtosis_grad_bcs: 3.145e-03\n",
      "kurtosis_grad_ics: 1.599e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 28900, Loss: 2.374e-01, loss_bcs: 2.217e-04, loss_ics: 1.345e-05, Loss_r: 1.912e-01, Time: 0.02\n",
      "std_grad_res: 1.877e+01\n",
      "std_grad_bcs: 7.273e-03\n",
      "std_grad_ics: 6.239e-04\n",
      "kurtosis_grad_res: 8.359e+00\n",
      "kurtosis_grad_bcs: 3.173e-03\n",
      "kurtosis_grad_ics: 3.418e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29000, Loss: 2.943e-01, loss_bcs: 2.580e-04, loss_ics: 7.310e-06, Loss_r: 2.411e-01, Time: 0.02\n",
      "std_grad_res: 1.901e+01\n",
      "std_grad_bcs: 5.810e-03\n",
      "std_grad_ics: 3.138e-04\n",
      "kurtosis_grad_res: 7.846e+00\n",
      "kurtosis_grad_bcs: 3.269e-03\n",
      "kurtosis_grad_ics: 1.598e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29100, Loss: 2.378e-01, loss_bcs: 2.285e-04, loss_ics: 8.625e-06, Loss_r: 1.905e-01, Time: 0.03\n",
      "std_grad_res: 6.808e+01\n",
      "std_grad_bcs: 9.556e-03\n",
      "std_grad_ics: 7.831e-04\n",
      "kurtosis_grad_res: 2.832e+01\n",
      "kurtosis_grad_bcs: 5.026e-03\n",
      "kurtosis_grad_ics: 3.038e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29200, Loss: 3.134e-01, loss_bcs: 1.815e-04, loss_ics: 9.010e-06, Loss_r: 2.757e-01, Time: 0.06\n",
      "std_grad_res: 4.590e+01\n",
      "std_grad_bcs: 2.157e-03\n",
      "std_grad_ics: 5.482e-04\n",
      "kurtosis_grad_res: 1.919e+01\n",
      "kurtosis_grad_bcs: 1.897e-03\n",
      "kurtosis_grad_ics: 2.311e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29300, Loss: 2.665e-01, loss_bcs: 2.025e-04, loss_ics: 1.184e-05, Loss_r: 2.243e-01, Time: 0.03\n",
      "std_grad_res: 9.486e+00\n",
      "std_grad_bcs: 6.940e-03\n",
      "std_grad_ics: 2.531e-04\n",
      "kurtosis_grad_res: 3.627e+00\n",
      "kurtosis_grad_bcs: 3.435e-03\n",
      "kurtosis_grad_ics: 1.765e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29400, Loss: 1.030e+00, loss_bcs: 1.858e-04, loss_ics: 9.890e-06, Loss_r: 9.915e-01, Time: 0.04\n",
      "std_grad_res: 1.194e+02\n",
      "std_grad_bcs: 2.468e-03\n",
      "std_grad_ics: 3.355e-04\n",
      "kurtosis_grad_res: 5.362e+01\n",
      "kurtosis_grad_bcs: 2.101e-03\n",
      "kurtosis_grad_ics: 2.101e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29500, Loss: 3.612e-01, loss_bcs: 1.812e-04, loss_ics: 1.171e-05, Loss_r: 3.234e-01, Time: 0.13\n",
      "std_grad_res: 3.105e+00\n",
      "std_grad_bcs: 3.268e-03\n",
      "std_grad_ics: 6.520e-04\n",
      "kurtosis_grad_res: 1.613e+00\n",
      "kurtosis_grad_bcs: 2.655e-03\n",
      "kurtosis_grad_ics: 4.234e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29600, Loss: 5.600e-01, loss_bcs: 2.351e-04, loss_ics: 1.009e-05, Loss_r: 5.113e-01, Time: 0.02\n",
      "std_grad_res: 2.764e+01\n",
      "std_grad_bcs: 4.444e-03\n",
      "std_grad_ics: 6.457e-04\n",
      "kurtosis_grad_res: 1.196e+01\n",
      "kurtosis_grad_bcs: 2.673e-03\n",
      "kurtosis_grad_ics: 2.750e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29700, Loss: 2.884e-01, loss_bcs: 1.931e-04, loss_ics: 4.742e-05, Loss_r: 2.457e-01, Time: 0.12\n",
      "std_grad_res: 4.735e+01\n",
      "std_grad_bcs: 1.083e-02\n",
      "std_grad_ics: 5.874e-04\n",
      "kurtosis_grad_res: 2.164e+01\n",
      "kurtosis_grad_bcs: 4.963e-03\n",
      "kurtosis_grad_ics: 4.156e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29800, Loss: 4.733e-01, loss_bcs: 1.504e-04, loss_ics: 1.249e-05, Loss_r: 4.417e-01, Time: 0.02\n",
      "std_grad_res: 1.044e+01\n",
      "std_grad_bcs: 6.225e-03\n",
      "std_grad_ics: 2.992e-03\n",
      "kurtosis_grad_res: 5.028e+00\n",
      "kurtosis_grad_bcs: 2.834e-03\n",
      "kurtosis_grad_ics: 9.470e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 29900, Loss: 2.253e-01, loss_bcs: 2.146e-04, loss_ics: 1.310e-05, Loss_r: 1.806e-01, Time: 0.02\n",
      "std_grad_res: 6.756e+00\n",
      "std_grad_bcs: 4.346e-03\n",
      "std_grad_ics: 8.658e-04\n",
      "kurtosis_grad_res: 2.694e+00\n",
      "kurtosis_grad_bcs: 2.692e-03\n",
      "kurtosis_grad_ics: 3.518e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30000, Loss: 2.172e-01, loss_bcs: 2.672e-04, loss_ics: 1.080e-05, Loss_r: 1.619e-01, Time: 0.02\n",
      "std_grad_res: 1.897e+01\n",
      "std_grad_bcs: 4.884e-03\n",
      "std_grad_ics: 3.396e-04\n",
      "kurtosis_grad_res: 8.528e+00\n",
      "kurtosis_grad_bcs: 2.914e-03\n",
      "kurtosis_grad_ics: 2.245e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30100, Loss: 1.916e-01, loss_bcs: 1.817e-04, loss_ics: 1.722e-05, Loss_r: 1.533e-01, Time: 0.02\n",
      "std_grad_res: 7.941e+00\n",
      "std_grad_bcs: 5.914e-03\n",
      "std_grad_ics: 3.989e-04\n",
      "kurtosis_grad_res: 3.745e+00\n",
      "kurtosis_grad_bcs: 3.066e-03\n",
      "kurtosis_grad_ics: 3.068e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30200, Loss: 2.465e-01, loss_bcs: 2.234e-04, loss_ics: 1.161e-05, Loss_r: 2.001e-01, Time: 0.02\n",
      "std_grad_res: 5.086e+00\n",
      "std_grad_bcs: 6.773e-03\n",
      "std_grad_ics: 1.718e-04\n",
      "kurtosis_grad_res: 2.365e+00\n",
      "kurtosis_grad_bcs: 3.934e-03\n",
      "kurtosis_grad_ics: 1.272e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30300, Loss: 5.508e-01, loss_bcs: 2.200e-04, loss_ics: 9.370e-06, Loss_r: 5.052e-01, Time: 0.10\n",
      "std_grad_res: 9.994e+00\n",
      "std_grad_bcs: 7.055e-03\n",
      "std_grad_ics: 2.878e-04\n",
      "kurtosis_grad_res: 4.898e+00\n",
      "kurtosis_grad_bcs: 3.695e-03\n",
      "kurtosis_grad_ics: 2.297e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30400, Loss: 4.059e-01, loss_bcs: 2.527e-04, loss_ics: 7.408e-06, Loss_r: 3.538e-01, Time: 0.02\n",
      "std_grad_res: 4.636e+00\n",
      "std_grad_bcs: 6.389e-03\n",
      "std_grad_ics: 9.066e-04\n",
      "kurtosis_grad_res: 2.561e+00\n",
      "kurtosis_grad_bcs: 3.420e-03\n",
      "kurtosis_grad_ics: 2.831e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30500, Loss: 2.359e-01, loss_bcs: 2.159e-04, loss_ics: 1.211e-05, Loss_r: 1.910e-01, Time: 0.03\n",
      "std_grad_res: 2.009e+01\n",
      "std_grad_bcs: 4.126e-03\n",
      "std_grad_ics: 9.172e-04\n",
      "kurtosis_grad_res: 8.930e+00\n",
      "kurtosis_grad_bcs: 2.306e-03\n",
      "kurtosis_grad_ics: 5.170e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30600, Loss: 4.516e-01, loss_bcs: 1.728e-04, loss_ics: 4.215e-06, Loss_r: 4.160e-01, Time: 0.08\n",
      "std_grad_res: 1.211e+02\n",
      "std_grad_bcs: 2.635e-03\n",
      "std_grad_ics: 2.904e-04\n",
      "kurtosis_grad_res: 5.317e+01\n",
      "kurtosis_grad_bcs: 1.363e-03\n",
      "kurtosis_grad_ics: 1.623e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30700, Loss: 2.415e-01, loss_bcs: 1.725e-04, loss_ics: 1.726e-05, Loss_r: 2.051e-01, Time: 0.02\n",
      "std_grad_res: 2.570e+01\n",
      "std_grad_bcs: 7.888e-03\n",
      "std_grad_ics: 9.622e-04\n",
      "kurtosis_grad_res: 1.135e+01\n",
      "kurtosis_grad_bcs: 4.253e-03\n",
      "kurtosis_grad_ics: 4.018e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30800, Loss: 2.131e-01, loss_bcs: 1.996e-04, loss_ics: 9.382e-06, Loss_r: 1.718e-01, Time: 0.02\n",
      "std_grad_res: 1.119e+01\n",
      "std_grad_bcs: 4.025e-03\n",
      "std_grad_ics: 3.243e-04\n",
      "kurtosis_grad_res: 4.651e+00\n",
      "kurtosis_grad_bcs: 2.262e-03\n",
      "kurtosis_grad_ics: 2.635e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 30900, Loss: 1.817e-01, loss_bcs: 2.044e-04, loss_ics: 9.148e-06, Loss_r: 1.393e-01, Time: 0.02\n",
      "std_grad_res: 1.922e+01\n",
      "std_grad_bcs: 3.986e-03\n",
      "std_grad_ics: 3.794e-04\n",
      "kurtosis_grad_res: 8.575e+00\n",
      "kurtosis_grad_bcs: 2.035e-03\n",
      "kurtosis_grad_ics: 2.818e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31000, Loss: 2.697e-01, loss_bcs: 2.197e-04, loss_ics: 1.381e-05, Loss_r: 2.239e-01, Time: 0.03\n",
      "std_grad_res: 4.104e+00\n",
      "std_grad_bcs: 7.344e-03\n",
      "std_grad_ics: 7.866e-04\n",
      "kurtosis_grad_res: 2.376e+00\n",
      "kurtosis_grad_bcs: 3.810e-03\n",
      "kurtosis_grad_ics: 5.024e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31100, Loss: 1.833e-01, loss_bcs: 1.782e-04, loss_ics: 6.156e-06, Loss_r: 1.465e-01, Time: 0.02\n",
      "std_grad_res: 1.103e+01\n",
      "std_grad_bcs: 5.638e-03\n",
      "std_grad_ics: 1.136e-03\n",
      "kurtosis_grad_res: 5.651e+00\n",
      "kurtosis_grad_bcs: 2.656e-03\n",
      "kurtosis_grad_ics: 3.647e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31200, Loss: 1.966e-01, loss_bcs: 2.080e-04, loss_ics: 1.402e-05, Loss_r: 1.532e-01, Time: 0.03\n",
      "std_grad_res: 4.215e+00\n",
      "std_grad_bcs: 5.828e-03\n",
      "std_grad_ics: 4.430e-04\n",
      "kurtosis_grad_res: 2.879e+00\n",
      "kurtosis_grad_bcs: 3.022e-03\n",
      "kurtosis_grad_ics: 3.429e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31300, Loss: 2.491e-01, loss_bcs: 1.725e-04, loss_ics: 5.976e-06, Loss_r: 2.135e-01, Time: 0.03\n",
      "std_grad_res: 2.548e+01\n",
      "std_grad_bcs: 5.539e-03\n",
      "std_grad_ics: 1.844e-03\n",
      "kurtosis_grad_res: 9.691e+00\n",
      "kurtosis_grad_bcs: 2.554e-03\n",
      "kurtosis_grad_ics: 5.753e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31400, Loss: 1.911e-01, loss_bcs: 1.358e-04, loss_ics: 7.644e-06, Loss_r: 1.628e-01, Time: 0.10\n",
      "std_grad_res: 2.998e+01\n",
      "std_grad_bcs: 4.092e-03\n",
      "std_grad_ics: 1.178e-03\n",
      "kurtosis_grad_res: 1.257e+01\n",
      "kurtosis_grad_bcs: 1.940e-03\n",
      "kurtosis_grad_ics: 5.690e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31500, Loss: 1.955e-01, loss_bcs: 2.253e-04, loss_ics: 9.705e-06, Loss_r: 1.488e-01, Time: 0.10\n",
      "std_grad_res: 1.768e+01\n",
      "std_grad_bcs: 5.435e-03\n",
      "std_grad_ics: 6.521e-04\n",
      "kurtosis_grad_res: 7.379e+00\n",
      "kurtosis_grad_bcs: 2.999e-03\n",
      "kurtosis_grad_ics: 4.090e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31600, Loss: 4.011e-01, loss_bcs: 2.105e-04, loss_ics: 5.980e-06, Loss_r: 3.578e-01, Time: 0.02\n",
      "std_grad_res: 1.213e+01\n",
      "std_grad_bcs: 4.933e-03\n",
      "std_grad_ics: 1.243e-03\n",
      "kurtosis_grad_res: 5.691e+00\n",
      "kurtosis_grad_bcs: 3.008e-03\n",
      "kurtosis_grad_ics: 3.863e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31700, Loss: 3.183e-01, loss_bcs: 2.334e-04, loss_ics: 9.927e-06, Loss_r: 2.700e-01, Time: 0.13\n",
      "std_grad_res: 2.269e+01\n",
      "std_grad_bcs: 8.230e-03\n",
      "std_grad_ics: 5.285e-04\n",
      "kurtosis_grad_res: 1.082e+01\n",
      "kurtosis_grad_bcs: 3.931e-03\n",
      "kurtosis_grad_ics: 3.369e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31800, Loss: 3.574e-01, loss_bcs: 2.231e-04, loss_ics: 1.000e-05, Loss_r: 3.112e-01, Time: 0.02\n",
      "std_grad_res: 1.754e+01\n",
      "std_grad_bcs: 5.801e-03\n",
      "std_grad_ics: 1.154e-03\n",
      "kurtosis_grad_res: 8.504e+00\n",
      "kurtosis_grad_bcs: 3.217e-03\n",
      "kurtosis_grad_ics: 3.957e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 31900, Loss: 2.996e-01, loss_bcs: 2.459e-04, loss_ics: 9.150e-06, Loss_r: 2.488e-01, Time: 0.03\n",
      "std_grad_res: 2.163e+00\n",
      "std_grad_bcs: 6.599e-03\n",
      "std_grad_ics: 1.029e-03\n",
      "kurtosis_grad_res: 1.539e+00\n",
      "kurtosis_grad_bcs: 3.672e-03\n",
      "kurtosis_grad_ics: 3.387e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32000, Loss: 2.423e-01, loss_bcs: 1.858e-04, loss_ics: 1.048e-05, Loss_r: 2.037e-01, Time: 0.03\n",
      "std_grad_res: 2.667e+01\n",
      "std_grad_bcs: 4.807e-03\n",
      "std_grad_ics: 6.806e-04\n",
      "kurtosis_grad_res: 1.262e+01\n",
      "kurtosis_grad_bcs: 2.344e-03\n",
      "kurtosis_grad_ics: 3.045e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32100, Loss: 2.131e-01, loss_bcs: 2.095e-04, loss_ics: 5.469e-06, Loss_r: 1.700e-01, Time: 0.11\n",
      "std_grad_res: 7.653e+00\n",
      "std_grad_bcs: 5.896e-03\n",
      "std_grad_ics: 1.723e-04\n",
      "kurtosis_grad_res: 3.880e+00\n",
      "kurtosis_grad_bcs: 4.033e-03\n",
      "kurtosis_grad_ics: 1.119e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32200, Loss: 2.748e-01, loss_bcs: 2.457e-04, loss_ics: 8.222e-06, Loss_r: 2.241e-01, Time: 0.02\n",
      "std_grad_res: 3.257e+01\n",
      "std_grad_bcs: 4.699e-03\n",
      "std_grad_ics: 6.212e-04\n",
      "kurtosis_grad_res: 1.450e+01\n",
      "kurtosis_grad_bcs: 2.647e-03\n",
      "kurtosis_grad_ics: 3.971e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32300, Loss: 4.809e-01, loss_bcs: 2.437e-04, loss_ics: 5.028e-06, Loss_r: 4.309e-01, Time: 0.03\n",
      "std_grad_res: 2.947e+01\n",
      "std_grad_bcs: 9.398e-03\n",
      "std_grad_ics: 2.280e-03\n",
      "kurtosis_grad_res: 1.250e+01\n",
      "kurtosis_grad_bcs: 4.532e-03\n",
      "kurtosis_grad_ics: 7.484e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32400, Loss: 2.429e-01, loss_bcs: 2.216e-04, loss_ics: 1.710e-05, Loss_r: 1.966e-01, Time: 0.02\n",
      "std_grad_res: 2.295e+01\n",
      "std_grad_bcs: 5.843e-03\n",
      "std_grad_ics: 2.553e-04\n",
      "kurtosis_grad_res: 1.040e+01\n",
      "kurtosis_grad_bcs: 3.019e-03\n",
      "kurtosis_grad_ics: 1.823e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32500, Loss: 2.194e-01, loss_bcs: 1.962e-04, loss_ics: 8.085e-06, Loss_r: 1.788e-01, Time: 0.10\n",
      "std_grad_res: 1.934e+01\n",
      "std_grad_bcs: 3.845e-03\n",
      "std_grad_ics: 1.758e-03\n",
      "kurtosis_grad_res: 8.463e+00\n",
      "kurtosis_grad_bcs: 2.239e-03\n",
      "kurtosis_grad_ics: 5.542e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32600, Loss: 3.312e-01, loss_bcs: 1.915e-04, loss_ics: 8.430e-06, Loss_r: 2.916e-01, Time: 0.02\n",
      "std_grad_res: 1.754e+01\n",
      "std_grad_bcs: 5.930e-03\n",
      "std_grad_ics: 2.212e-04\n",
      "kurtosis_grad_res: 7.470e+00\n",
      "kurtosis_grad_bcs: 2.718e-03\n",
      "kurtosis_grad_ics: 1.605e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32700, Loss: 3.929e-01, loss_bcs: 1.814e-04, loss_ics: 9.819e-06, Loss_r: 3.552e-01, Time: 0.07\n",
      "std_grad_res: 3.398e+01\n",
      "std_grad_bcs: 5.752e-03\n",
      "std_grad_ics: 7.616e-04\n",
      "kurtosis_grad_res: 1.262e+01\n",
      "kurtosis_grad_bcs: 2.819e-03\n",
      "kurtosis_grad_ics: 3.166e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32800, Loss: 2.361e-01, loss_bcs: 1.769e-04, loss_ics: 5.161e-06, Loss_r: 1.996e-01, Time: 0.10\n",
      "std_grad_res: 1.605e+01\n",
      "std_grad_bcs: 5.433e-03\n",
      "std_grad_ics: 4.646e-04\n",
      "kurtosis_grad_res: 7.489e+00\n",
      "kurtosis_grad_bcs: 2.958e-03\n",
      "kurtosis_grad_ics: 1.902e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 32900, Loss: 3.224e-01, loss_bcs: 1.591e-04, loss_ics: 6.165e-06, Loss_r: 2.895e-01, Time: 0.02\n",
      "std_grad_res: 1.251e+01\n",
      "std_grad_bcs: 4.229e-03\n",
      "std_grad_ics: 2.138e-03\n",
      "kurtosis_grad_res: 6.695e+00\n",
      "kurtosis_grad_bcs: 2.227e-03\n",
      "kurtosis_grad_ics: 6.718e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33000, Loss: 2.974e-01, loss_bcs: 1.568e-04, loss_ics: 5.740e-06, Loss_r: 2.650e-01, Time: 0.03\n",
      "std_grad_res: 3.572e+01\n",
      "std_grad_bcs: 8.006e-03\n",
      "std_grad_ics: 5.998e-04\n",
      "kurtosis_grad_res: 1.579e+01\n",
      "kurtosis_grad_bcs: 4.246e-03\n",
      "kurtosis_grad_ics: 2.146e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33100, Loss: 5.373e-01, loss_bcs: 1.987e-04, loss_ics: 1.180e-05, Loss_r: 4.959e-01, Time: 0.03\n",
      "std_grad_res: 2.081e+01\n",
      "std_grad_bcs: 4.758e-03\n",
      "std_grad_ics: 2.935e-04\n",
      "kurtosis_grad_res: 8.441e+00\n",
      "kurtosis_grad_bcs: 2.507e-03\n",
      "kurtosis_grad_ics: 1.871e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33200, Loss: 3.127e-01, loss_bcs: 2.344e-04, loss_ics: 1.153e-05, Loss_r: 2.641e-01, Time: 0.14\n",
      "std_grad_res: 2.813e+01\n",
      "std_grad_bcs: 6.719e-03\n",
      "std_grad_ics: 6.976e-04\n",
      "kurtosis_grad_res: 1.285e+01\n",
      "kurtosis_grad_bcs: 3.445e-03\n",
      "kurtosis_grad_ics: 4.315e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33300, Loss: 2.378e-01, loss_bcs: 2.026e-04, loss_ics: 7.376e-06, Loss_r: 1.959e-01, Time: 0.02\n",
      "std_grad_res: 2.478e+01\n",
      "std_grad_bcs: 2.807e-03\n",
      "std_grad_ics: 6.418e-04\n",
      "kurtosis_grad_res: 1.080e+01\n",
      "kurtosis_grad_bcs: 1.579e-03\n",
      "kurtosis_grad_ics: 2.366e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33400, Loss: 3.309e-01, loss_bcs: 1.762e-04, loss_ics: 6.771e-06, Loss_r: 2.944e-01, Time: 0.08\n",
      "std_grad_res: 2.615e+01\n",
      "std_grad_bcs: 5.079e-03\n",
      "std_grad_ics: 9.447e-04\n",
      "kurtosis_grad_res: 1.249e+01\n",
      "kurtosis_grad_bcs: 3.490e-03\n",
      "kurtosis_grad_ics: 3.094e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33500, Loss: 2.760e-01, loss_bcs: 2.397e-04, loss_ics: 1.087e-05, Loss_r: 2.263e-01, Time: 0.07\n",
      "std_grad_res: 5.634e+00\n",
      "std_grad_bcs: 5.953e-03\n",
      "std_grad_ics: 1.127e-03\n",
      "kurtosis_grad_res: 2.320e+00\n",
      "kurtosis_grad_bcs: 3.365e-03\n",
      "kurtosis_grad_ics: 3.932e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33600, Loss: 2.443e-01, loss_bcs: 1.866e-04, loss_ics: 1.120e-05, Loss_r: 2.055e-01, Time: 0.03\n",
      "std_grad_res: 1.448e+01\n",
      "std_grad_bcs: 4.668e-03\n",
      "std_grad_ics: 4.838e-04\n",
      "kurtosis_grad_res: 6.325e+00\n",
      "kurtosis_grad_bcs: 3.084e-03\n",
      "kurtosis_grad_ics: 2.745e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33700, Loss: 2.383e-01, loss_bcs: 1.811e-04, loss_ics: 6.555e-06, Loss_r: 2.008e-01, Time: 0.08\n",
      "std_grad_res: 1.982e+01\n",
      "std_grad_bcs: 6.147e-03\n",
      "std_grad_ics: 2.933e-04\n",
      "kurtosis_grad_res: 1.016e+01\n",
      "kurtosis_grad_bcs: 3.035e-03\n",
      "kurtosis_grad_ics: 2.254e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33800, Loss: 1.914e-01, loss_bcs: 1.202e-04, loss_ics: 8.418e-06, Loss_r: 1.663e-01, Time: 0.02\n",
      "std_grad_res: 2.660e+01\n",
      "std_grad_bcs: 3.815e-03\n",
      "std_grad_ics: 2.901e-04\n",
      "kurtosis_grad_res: 1.101e+01\n",
      "kurtosis_grad_bcs: 2.402e-03\n",
      "kurtosis_grad_ics: 1.718e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 33900, Loss: 2.501e-01, loss_bcs: 2.194e-04, loss_ics: 1.175e-05, Loss_r: 2.045e-01, Time: 0.02\n",
      "std_grad_res: 3.021e+00\n",
      "std_grad_bcs: 3.832e-03\n",
      "std_grad_ics: 1.384e-03\n",
      "kurtosis_grad_res: 2.086e+00\n",
      "kurtosis_grad_bcs: 2.194e-03\n",
      "kurtosis_grad_ics: 6.984e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34000, Loss: 2.001e-01, loss_bcs: 2.034e-04, loss_ics: 7.162e-06, Loss_r: 1.581e-01, Time: 0.02\n",
      "std_grad_res: 2.100e+01\n",
      "std_grad_bcs: 4.408e-03\n",
      "std_grad_ics: 7.659e-04\n",
      "kurtosis_grad_res: 8.493e+00\n",
      "kurtosis_grad_bcs: 2.508e-03\n",
      "kurtosis_grad_ics: 2.915e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34100, Loss: 2.734e-01, loss_bcs: 2.509e-04, loss_ics: 5.671e-06, Loss_r: 2.218e-01, Time: 0.03\n",
      "std_grad_res: 3.633e+01\n",
      "std_grad_bcs: 8.443e-03\n",
      "std_grad_ics: 1.106e-03\n",
      "kurtosis_grad_res: 1.653e+01\n",
      "kurtosis_grad_bcs: 3.752e-03\n",
      "kurtosis_grad_ics: 3.534e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34200, Loss: 4.947e-01, loss_bcs: 1.468e-04, loss_ics: 9.572e-06, Loss_r: 4.641e-01, Time: 0.14\n",
      "std_grad_res: 5.918e+00\n",
      "std_grad_bcs: 5.107e-03\n",
      "std_grad_ics: 2.064e-04\n",
      "kurtosis_grad_res: 2.709e+00\n",
      "kurtosis_grad_bcs: 2.268e-03\n",
      "kurtosis_grad_ics: 1.532e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34300, Loss: 3.065e-01, loss_bcs: 1.711e-04, loss_ics: 5.155e-06, Loss_r: 2.712e-01, Time: 0.15\n",
      "std_grad_res: 1.443e+01\n",
      "std_grad_bcs: 5.797e-03\n",
      "std_grad_ics: 3.052e-04\n",
      "kurtosis_grad_res: 6.689e+00\n",
      "kurtosis_grad_bcs: 2.967e-03\n",
      "kurtosis_grad_ics: 1.509e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34400, Loss: 2.150e-01, loss_bcs: 1.478e-04, loss_ics: 7.971e-06, Loss_r: 1.842e-01, Time: 0.06\n",
      "std_grad_res: 7.034e+00\n",
      "std_grad_bcs: 3.528e-03\n",
      "std_grad_ics: 4.459e-04\n",
      "kurtosis_grad_res: 3.376e+00\n",
      "kurtosis_grad_bcs: 2.114e-03\n",
      "kurtosis_grad_ics: 2.168e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34500, Loss: 2.656e-01, loss_bcs: 1.799e-04, loss_ics: 8.717e-06, Loss_r: 2.283e-01, Time: 0.21\n",
      "std_grad_res: 9.002e+00\n",
      "std_grad_bcs: 4.621e-03\n",
      "std_grad_ics: 1.127e-03\n",
      "kurtosis_grad_res: 4.580e+00\n",
      "kurtosis_grad_bcs: 2.466e-03\n",
      "kurtosis_grad_ics: 3.802e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34600, Loss: 2.282e-01, loss_bcs: 1.773e-04, loss_ics: 9.591e-06, Loss_r: 1.914e-01, Time: 0.38\n",
      "std_grad_res: 1.043e+01\n",
      "std_grad_bcs: 5.060e-03\n",
      "std_grad_ics: 9.442e-04\n",
      "kurtosis_grad_res: 4.184e+00\n",
      "kurtosis_grad_bcs: 2.290e-03\n",
      "kurtosis_grad_ics: 4.880e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34700, Loss: 5.645e-01, loss_bcs: 1.906e-04, loss_ics: 6.809e-06, Loss_r: 5.251e-01, Time: 0.18\n",
      "std_grad_res: 2.037e+01\n",
      "std_grad_bcs: 5.056e-03\n",
      "std_grad_ics: 7.309e-04\n",
      "kurtosis_grad_res: 1.024e+01\n",
      "kurtosis_grad_bcs: 2.946e-03\n",
      "kurtosis_grad_ics: 2.827e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34800, Loss: 3.015e-01, loss_bcs: 2.225e-04, loss_ics: 9.656e-06, Loss_r: 2.554e-01, Time: 0.36\n",
      "std_grad_res: 4.006e+01\n",
      "std_grad_bcs: 3.032e-03\n",
      "std_grad_ics: 9.117e-04\n",
      "kurtosis_grad_res: 1.643e+01\n",
      "kurtosis_grad_bcs: 1.823e-03\n",
      "kurtosis_grad_ics: 3.419e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 34900, Loss: 1.950e-01, loss_bcs: 1.747e-04, loss_ics: 5.748e-06, Loss_r: 1.589e-01, Time: 0.12\n",
      "std_grad_res: 5.219e+01\n",
      "std_grad_bcs: 3.100e-03\n",
      "std_grad_ics: 4.815e-04\n",
      "kurtosis_grad_res: 2.241e+01\n",
      "kurtosis_grad_bcs: 1.945e-03\n",
      "kurtosis_grad_ics: 2.891e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35000, Loss: 1.687e-01, loss_bcs: 1.619e-04, loss_ics: 7.302e-06, Loss_r: 1.352e-01, Time: 0.33\n",
      "std_grad_res: 3.100e+01\n",
      "std_grad_bcs: 4.508e-03\n",
      "std_grad_ics: 1.378e-04\n",
      "kurtosis_grad_res: 1.413e+01\n",
      "kurtosis_grad_bcs: 2.274e-03\n",
      "kurtosis_grad_ics: 1.055e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35100, Loss: 2.199e-01, loss_bcs: 1.939e-04, loss_ics: 9.786e-06, Loss_r: 1.797e-01, Time: 0.35\n",
      "std_grad_res: 2.029e+01\n",
      "std_grad_bcs: 6.850e-03\n",
      "std_grad_ics: 2.499e-04\n",
      "kurtosis_grad_res: 7.676e+00\n",
      "kurtosis_grad_bcs: 3.121e-03\n",
      "kurtosis_grad_ics: 1.819e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35200, Loss: 1.676e-01, loss_bcs: 1.625e-04, loss_ics: 5.175e-06, Loss_r: 1.341e-01, Time: 0.36\n",
      "std_grad_res: 1.326e+01\n",
      "std_grad_bcs: 4.470e-03\n",
      "std_grad_ics: 3.465e-04\n",
      "kurtosis_grad_res: 5.842e+00\n",
      "kurtosis_grad_bcs: 2.179e-03\n",
      "kurtosis_grad_ics: 1.553e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35300, Loss: 1.794e-01, loss_bcs: 1.981e-04, loss_ics: 5.976e-06, Loss_r: 1.385e-01, Time: 0.47\n",
      "std_grad_res: 3.980e+01\n",
      "std_grad_bcs: 4.003e-03\n",
      "std_grad_ics: 6.973e-04\n",
      "kurtosis_grad_res: 1.752e+01\n",
      "kurtosis_grad_bcs: 1.909e-03\n",
      "kurtosis_grad_ics: 3.915e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35400, Loss: 2.496e-01, loss_bcs: 1.870e-04, loss_ics: 6.479e-06, Loss_r: 2.110e-01, Time: 0.08\n",
      "std_grad_res: 1.681e+01\n",
      "std_grad_bcs: 6.568e-03\n",
      "std_grad_ics: 4.461e-04\n",
      "kurtosis_grad_res: 7.706e+00\n",
      "kurtosis_grad_bcs: 2.969e-03\n",
      "kurtosis_grad_ics: 2.007e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35500, Loss: 1.968e-01, loss_bcs: 2.092e-04, loss_ics: 9.080e-06, Loss_r: 1.535e-01, Time: 0.23\n",
      "std_grad_res: 6.280e+00\n",
      "std_grad_bcs: 4.895e-03\n",
      "std_grad_ics: 1.138e-03\n",
      "kurtosis_grad_res: 3.417e+00\n",
      "kurtosis_grad_bcs: 2.734e-03\n",
      "kurtosis_grad_ics: 3.986e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35600, Loss: 2.568e-01, loss_bcs: 2.008e-04, loss_ics: 8.711e-06, Loss_r: 2.152e-01, Time: 0.32\n",
      "std_grad_res: 1.287e+01\n",
      "std_grad_bcs: 6.097e-03\n",
      "std_grad_ics: 2.135e-04\n",
      "kurtosis_grad_res: 5.043e+00\n",
      "kurtosis_grad_bcs: 3.109e-03\n",
      "kurtosis_grad_ics: 1.617e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35700, Loss: 1.727e-01, loss_bcs: 1.950e-04, loss_ics: 4.500e-06, Loss_r: 1.326e-01, Time: 0.04\n",
      "std_grad_res: 1.565e+01\n",
      "std_grad_bcs: 2.776e-03\n",
      "std_grad_ics: 3.399e-04\n",
      "kurtosis_grad_res: 6.677e+00\n",
      "kurtosis_grad_bcs: 1.643e-03\n",
      "kurtosis_grad_ics: 2.100e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35800, Loss: 2.512e-01, loss_bcs: 1.852e-04, loss_ics: 5.521e-06, Loss_r: 2.130e-01, Time: 0.10\n",
      "std_grad_res: 1.447e+01\n",
      "std_grad_bcs: 4.534e-03\n",
      "std_grad_ics: 4.978e-04\n",
      "kurtosis_grad_res: 6.931e+00\n",
      "kurtosis_grad_bcs: 2.425e-03\n",
      "kurtosis_grad_ics: 1.917e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 35900, Loss: 1.968e-01, loss_bcs: 1.489e-04, loss_ics: 6.456e-06, Loss_r: 1.659e-01, Time: 0.16\n",
      "std_grad_res: 1.085e+01\n",
      "std_grad_bcs: 3.695e-03\n",
      "std_grad_ics: 2.229e-04\n",
      "kurtosis_grad_res: 4.678e+00\n",
      "kurtosis_grad_bcs: 2.470e-03\n",
      "kurtosis_grad_ics: 1.362e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36000, Loss: 2.358e-01, loss_bcs: 1.578e-04, loss_ics: 6.075e-06, Loss_r: 2.032e-01, Time: 0.31\n",
      "std_grad_res: 1.175e+01\n",
      "std_grad_bcs: 4.005e-03\n",
      "std_grad_ics: 5.316e-04\n",
      "kurtosis_grad_res: 5.773e+00\n",
      "kurtosis_grad_bcs: 2.668e-03\n",
      "kurtosis_grad_ics: 2.187e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36100, Loss: 1.897e-01, loss_bcs: 1.979e-04, loss_ics: 2.918e-06, Loss_r: 1.491e-01, Time: 0.17\n",
      "std_grad_res: 1.119e+01\n",
      "std_grad_bcs: 4.831e-03\n",
      "std_grad_ics: 1.843e-04\n",
      "kurtosis_grad_res: 4.821e+00\n",
      "kurtosis_grad_bcs: 2.532e-03\n",
      "kurtosis_grad_ics: 8.517e-05\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36200, Loss: 2.281e-01, loss_bcs: 2.492e-04, loss_ics: 6.204e-06, Loss_r: 1.768e-01, Time: 0.23\n",
      "std_grad_res: 1.132e+01\n",
      "std_grad_bcs: 5.595e-03\n",
      "std_grad_ics: 3.633e-04\n",
      "kurtosis_grad_res: 5.808e+00\n",
      "kurtosis_grad_bcs: 2.889e-03\n",
      "kurtosis_grad_ics: 1.703e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36300, Loss: 2.585e-01, loss_bcs: 1.742e-04, loss_ics: 8.716e-06, Loss_r: 2.224e-01, Time: 0.34\n",
      "std_grad_res: 2.295e+00\n",
      "std_grad_bcs: 5.563e-03\n",
      "std_grad_ics: 9.761e-04\n",
      "kurtosis_grad_res: 1.335e+00\n",
      "kurtosis_grad_bcs: 2.713e-03\n",
      "kurtosis_grad_ics: 3.713e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36400, Loss: 2.329e-01, loss_bcs: 1.691e-04, loss_ics: 8.553e-06, Loss_r: 1.977e-01, Time: 0.43\n",
      "std_grad_res: 8.092e+00\n",
      "std_grad_bcs: 4.114e-03\n",
      "std_grad_ics: 2.146e-04\n",
      "kurtosis_grad_res: 3.826e+00\n",
      "kurtosis_grad_bcs: 2.712e-03\n",
      "kurtosis_grad_ics: 1.519e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36500, Loss: 3.142e-01, loss_bcs: 2.135e-04, loss_ics: 4.481e-06, Loss_r: 2.704e-01, Time: 0.18\n",
      "std_grad_res: 4.250e+00\n",
      "std_grad_bcs: 3.626e-03\n",
      "std_grad_ics: 7.213e-04\n",
      "kurtosis_grad_res: 2.140e+00\n",
      "kurtosis_grad_bcs: 2.317e-03\n",
      "kurtosis_grad_ics: 2.359e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36600, Loss: 1.806e-01, loss_bcs: 1.940e-04, loss_ics: 4.275e-06, Loss_r: 1.407e-01, Time: 0.12\n",
      "std_grad_res: 1.539e+01\n",
      "std_grad_bcs: 4.467e-03\n",
      "std_grad_ics: 8.427e-04\n",
      "kurtosis_grad_res: 7.460e+00\n",
      "kurtosis_grad_bcs: 2.852e-03\n",
      "kurtosis_grad_ics: 2.678e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36700, Loss: 2.391e-01, loss_bcs: 1.933e-04, loss_ics: 9.040e-06, Loss_r: 1.990e-01, Time: 0.38\n",
      "std_grad_res: 3.352e+01\n",
      "std_grad_bcs: 7.791e-03\n",
      "std_grad_ics: 1.992e-04\n",
      "kurtosis_grad_res: 1.440e+01\n",
      "kurtosis_grad_bcs: 3.623e-03\n",
      "kurtosis_grad_ics: 1.375e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36800, Loss: 1.594e-01, loss_bcs: 1.915e-04, loss_ics: 8.962e-06, Loss_r: 1.197e-01, Time: 0.09\n",
      "std_grad_res: 1.954e+00\n",
      "std_grad_bcs: 4.788e-03\n",
      "std_grad_ics: 6.040e-04\n",
      "kurtosis_grad_res: 1.537e+00\n",
      "kurtosis_grad_bcs: 2.437e-03\n",
      "kurtosis_grad_ics: 2.796e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 36900, Loss: 1.870e-01, loss_bcs: 2.726e-04, loss_ics: 7.845e-06, Loss_r: 1.308e-01, Time: 0.23\n",
      "std_grad_res: 1.131e+01\n",
      "std_grad_bcs: 5.586e-03\n",
      "std_grad_ics: 2.700e-04\n",
      "kurtosis_grad_res: 4.976e+00\n",
      "kurtosis_grad_bcs: 3.016e-03\n",
      "kurtosis_grad_ics: 1.886e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37000, Loss: 2.095e-01, loss_bcs: 2.148e-04, loss_ics: 1.354e-05, Loss_r: 1.647e-01, Time: 0.13\n",
      "std_grad_res: 6.350e+00\n",
      "std_grad_bcs: 4.074e-03\n",
      "std_grad_ics: 4.746e-04\n",
      "kurtosis_grad_res: 2.939e+00\n",
      "kurtosis_grad_bcs: 1.994e-03\n",
      "kurtosis_grad_ics: 2.557e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37100, Loss: 1.849e-01, loss_bcs: 1.613e-04, loss_ics: 4.259e-06, Loss_r: 1.517e-01, Time: 0.11\n",
      "std_grad_res: 4.016e+00\n",
      "std_grad_bcs: 4.690e-03\n",
      "std_grad_ics: 6.653e-04\n",
      "kurtosis_grad_res: 2.030e+00\n",
      "kurtosis_grad_bcs: 2.223e-03\n",
      "kurtosis_grad_ics: 2.247e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37200, Loss: 1.775e-01, loss_bcs: 1.403e-04, loss_ics: 6.446e-06, Loss_r: 1.484e-01, Time: 0.44\n",
      "std_grad_res: 3.365e+00\n",
      "std_grad_bcs: 7.194e-03\n",
      "std_grad_ics: 6.442e-04\n",
      "kurtosis_grad_res: 1.529e+00\n",
      "kurtosis_grad_bcs: 4.042e-03\n",
      "kurtosis_grad_ics: 2.394e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37300, Loss: 1.762e-01, loss_bcs: 1.526e-04, loss_ics: 6.796e-06, Loss_r: 1.445e-01, Time: 0.03\n",
      "std_grad_res: 1.677e+00\n",
      "std_grad_bcs: 6.305e-03\n",
      "std_grad_ics: 3.650e-04\n",
      "kurtosis_grad_res: 1.235e+00\n",
      "kurtosis_grad_bcs: 3.020e-03\n",
      "kurtosis_grad_ics: 1.902e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37400, Loss: 2.094e-01, loss_bcs: 1.686e-04, loss_ics: 3.763e-06, Loss_r: 1.748e-01, Time: 0.38\n",
      "std_grad_res: 3.436e+00\n",
      "std_grad_bcs: 5.051e-03\n",
      "std_grad_ics: 2.347e-04\n",
      "kurtosis_grad_res: 1.625e+00\n",
      "kurtosis_grad_bcs: 2.427e-03\n",
      "kurtosis_grad_ics: 1.125e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37500, Loss: 2.068e-01, loss_bcs: 1.945e-04, loss_ics: 6.843e-06, Loss_r: 1.666e-01, Time: 0.22\n",
      "std_grad_res: 8.649e+00\n",
      "std_grad_bcs: 4.967e-03\n",
      "std_grad_ics: 4.245e-04\n",
      "kurtosis_grad_res: 4.365e+00\n",
      "kurtosis_grad_bcs: 2.611e-03\n",
      "kurtosis_grad_ics: 1.926e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37600, Loss: 2.149e-01, loss_bcs: 2.097e-04, loss_ics: 9.013e-06, Loss_r: 1.715e-01, Time: 0.27\n",
      "std_grad_res: 1.373e+01\n",
      "std_grad_bcs: 6.562e-03\n",
      "std_grad_ics: 1.570e-03\n",
      "kurtosis_grad_res: 6.524e+00\n",
      "kurtosis_grad_bcs: 3.177e-03\n",
      "kurtosis_grad_ics: 5.081e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37700, Loss: 1.704e-01, loss_bcs: 2.180e-04, loss_ics: 4.778e-06, Loss_r: 1.256e-01, Time: 0.11\n",
      "std_grad_res: 4.689e+00\n",
      "std_grad_bcs: 4.825e-03\n",
      "std_grad_ics: 4.917e-04\n",
      "kurtosis_grad_res: 2.266e+00\n",
      "kurtosis_grad_bcs: 2.314e-03\n",
      "kurtosis_grad_ics: 1.894e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37800, Loss: 2.650e-01, loss_bcs: 1.573e-04, loss_ics: 7.747e-06, Loss_r: 2.324e-01, Time: 0.09\n",
      "std_grad_res: 1.987e+01\n",
      "std_grad_bcs: 3.775e-03\n",
      "std_grad_ics: 2.053e-04\n",
      "kurtosis_grad_res: 7.972e+00\n",
      "kurtosis_grad_bcs: 2.172e-03\n",
      "kurtosis_grad_ics: 1.421e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 37900, Loss: 2.483e-01, loss_bcs: 1.750e-04, loss_ics: 5.624e-06, Loss_r: 2.122e-01, Time: 0.38\n",
      "std_grad_res: 5.311e+00\n",
      "std_grad_bcs: 5.007e-03\n",
      "std_grad_ics: 1.585e-04\n",
      "kurtosis_grad_res: 2.642e+00\n",
      "kurtosis_grad_bcs: 2.736e-03\n",
      "kurtosis_grad_ics: 1.081e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 38000, Loss: 2.389e-01, loss_bcs: 1.723e-04, loss_ics: 6.307e-06, Loss_r: 2.033e-01, Time: 0.08\n",
      "std_grad_res: 2.419e+01\n",
      "std_grad_bcs: 5.337e-03\n",
      "std_grad_ics: 4.163e-04\n",
      "kurtosis_grad_res: 9.705e+00\n",
      "kurtosis_grad_bcs: 2.555e-03\n",
      "kurtosis_grad_ics: 1.933e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 38100, Loss: 2.003e-01, loss_bcs: 1.947e-04, loss_ics: 4.308e-06, Loss_r: 1.603e-01, Time: 0.28\n",
      "std_grad_res: 1.586e+01\n",
      "std_grad_bcs: 3.258e-03\n",
      "std_grad_ics: 2.149e-04\n",
      "kurtosis_grad_res: 6.595e+00\n",
      "kurtosis_grad_bcs: 2.225e-03\n",
      "kurtosis_grad_ics: 1.200e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 38200, Loss: 2.480e-01, loss_bcs: 2.429e-04, loss_ics: 4.668e-06, Loss_r: 1.981e-01, Time: 0.13\n",
      "std_grad_res: 1.124e+01\n",
      "std_grad_bcs: 4.661e-03\n",
      "std_grad_ics: 7.059e-04\n",
      "kurtosis_grad_res: 5.021e+00\n",
      "kurtosis_grad_bcs: 2.300e-03\n",
      "kurtosis_grad_ics: 2.317e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 38300, Loss: 2.132e-01, loss_bcs: 2.172e-04, loss_ics: 8.293e-06, Loss_r: 1.682e-01, Time: 0.15\n",
      "std_grad_res: 2.023e+01\n",
      "std_grad_bcs: 4.478e-03\n",
      "std_grad_ics: 2.079e-04\n",
      "kurtosis_grad_res: 8.389e+00\n",
      "kurtosis_grad_bcs: 2.366e-03\n",
      "kurtosis_grad_ics: 1.545e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 38400, Loss: 1.599e-01, loss_bcs: 2.038e-04, loss_ics: 6.256e-06, Loss_r: 1.178e-01, Time: 0.12\n",
      "std_grad_res: 9.779e-01\n",
      "std_grad_bcs: 5.467e-03\n",
      "std_grad_ics: 5.575e-04\n",
      "kurtosis_grad_res: 8.247e-01\n",
      "kurtosis_grad_bcs: 2.540e-03\n",
      "kurtosis_grad_ics: 3.228e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 38500, Loss: 2.049e-01, loss_bcs: 1.739e-04, loss_ics: 5.329e-06, Loss_r: 1.691e-01, Time: 0.07\n",
      "std_grad_res: 2.995e+01\n",
      "std_grad_bcs: 6.032e-03\n",
      "std_grad_ics: 8.324e-04\n",
      "kurtosis_grad_res: 1.216e+01\n",
      "kurtosis_grad_bcs: 3.651e-03\n",
      "kurtosis_grad_ics: 2.879e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n",
      "It: 38600, Loss: 2.089e-01, loss_bcs: 1.718e-04, loss_ics: 5.252e-06, Loss_r: 1.735e-01, Time: 0.33\n",
      "std_grad_res: 7.628e+00\n",
      "std_grad_bcs: 4.433e-03\n",
      "std_grad_ics: 4.343e-04\n",
      "kurtosis_grad_res: 3.392e+00\n",
      "kurtosis_grad_bcs: 2.392e-03\n",
      "kurtosis_grad_ics: 1.874e-04\n",
      "adaptive_constant_res_val: 1.000e+00\n",
      "adaptive_constant_ics_val: 7.746e+02\n",
      "adaptive_constant_bcs1_val: 1.802e+02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48509/1717239770.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnIter\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmtd\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"mini_batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainmb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnIter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown method!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48509/52739167.py\u001b[0m in \u001b[0;36mtrainmb\u001b[0;34m(self, nIter, batch_size)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;31m# Run the Tensorflow session to minimize the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_tensor_list\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtf_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_batch_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters of equations\n",
    "alpha = -1.0\n",
    "beta = 0.0\n",
    "gamma = 1.0\n",
    "k = 3\n",
    "# Domain boundaries\n",
    "ics_coords = np.array([[0.0, 0.0], [0.0, 1.0]])\n",
    "bc1_coords = np.array([[0.0, 0.0], [1.0, 0.0]])\n",
    "bc2_coords = np.array([[0.0, 1.0], [1.0, 1.0]])\n",
    "dom_coords = np.array([[0.0, 0.0], [1.0, 1.0]])\n",
    "\n",
    "\n",
    "# Define model\n",
    "layers = [2, 50, 50, 50, 50, 50, 1]\n",
    "mode = 'M2'          # Method: 'M1', 'M2', 'M3', 'M4'\n",
    "stiff_ratio = False  # Log the eigenvalues of Hessian of losses\n",
    "\n",
    "\n",
    "\n",
    "nIter =40001\n",
    "bcbatch_size = 500\n",
    "ubatch_size = 5000\n",
    "mbbatch_size = 128\n",
    "\n",
    "# Test data\n",
    "nn = 100\n",
    "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
    "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
    "t, x = np.meshgrid(t, x)\n",
    "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
    "\n",
    "# Exact solution\n",
    "u_star = u(X_star)\n",
    "f_star = f(X_star, alpha, beta, gamma, k)\n",
    "\n",
    "\n",
    "iterations = 1\n",
    "methods = [\"mini_batch\" ]\n",
    "\n",
    "result_dict =  dict((mtd, []) for mtd in methods)\n",
    "\n",
    "for mtd in methods:\n",
    "    print(\"Method: \", mtd)\n",
    "    time_list = []\n",
    "    error_u_list = []\n",
    "    error_f_list = []\n",
    "    \n",
    "    for index in range(iterations):\n",
    "\n",
    "        print(\"Epoch: \", str(index+1))\n",
    "\n",
    "        # Create initial conditions samplers\n",
    "        ics_sampler = Sampler(2, ics_coords, lambda x: u(x), name='Initial Condition 1')\n",
    "\n",
    "        # Create boundary conditions samplers\n",
    "        bc1 = Sampler(2, bc1_coords, lambda x: u(x), name='Dirichlet BC1')\n",
    "        bc2 = Sampler(2, bc2_coords, lambda x: u(x), name='Dirichlet BC2')\n",
    "        bcs_sampler = [bc1, bc2]\n",
    "\n",
    "        # Create residual sampler\n",
    "        res_sampler = Sampler(2, dom_coords, lambda x: f(x, alpha, beta, gamma, k), name='Forcing')\n",
    "        bcs_sampler = [bc1, bc2]\n",
    "\n",
    "        # [elapsed, error_u , error_f] = test_method(mtd , layers, operator, ics_sampler, bcs_sampler, res_sampler, alpha, beta, gamma ,k ,mode , stiff_ratio ,  X_star , u_star , f_star)\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) \n",
    "\n",
    "        model = Klein_Gordon(layers, operator, ics_sampler, bcs_sampler, res_sampler, alpha, beta, gamma, k, mode, sess)\n",
    "\n",
    "        # Train model\n",
    "        start_time = time.time()\n",
    "\n",
    "        if mtd ==\"full_batch\":\n",
    "            model.train(nIter=nIter )\n",
    "        elif mtd ==\"mini_batch\":\n",
    "            model.trainmb(nIter=nIter, batch_size=128)\n",
    "        else:\n",
    "            print(\"unknown method!\")\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        # Predictions\n",
    "        \n",
    "        # Predictions\n",
    "        u_pred = model.predict_u(X_star)\n",
    "        f_pred = model.predict_r(X_star)\n",
    "        # Relative error\n",
    "        error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "        error_f = np.linalg.norm(f_star - f_pred, 2) / np.linalg.norm(f_star, 2)\n",
    "\n",
    "        model.print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
    "        model.print('Relative L2 error_f: {:.2e}'.format(error_f))\n",
    "        \n",
    "        model.print(\"average lambda_bc\" , np.average(model.adaptive_constant_bcs_log))\n",
    "        model.print(\"average lambda_bc\" , np.average(model.adaptive_constant_ics_log))\n",
    "        model.print(\"average lambda_res\" , str(1.0))\n",
    "        # sess.close()  \n",
    "\n",
    "        model.plot_grad()\n",
    "        model.save_NN()\n",
    "        model.plt_prediction( t , x , X_star , u_star , u_pred , f_star , f_pred)\n",
    "\n",
    "        time_list.append(elapsed)\n",
    "        error_u_list.append(error_u)\n",
    "        error_f_list.append(error_f)\n",
    "\n",
    "    # print(\"\\n\\nMethod: \", mtd)\n",
    "    model.print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
    "    model.print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
    "    model.print(\"average of error_f_list:\" , sum(error_f_list) / len(error_f_list) )\n",
    "\n",
    "    result_dict[mtd] = [time_list ,error_u_list ,  error_f_list]\n",
    "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
    "\n",
    "    scipy.io.savemat(os.path.join(model.dirname,\"\"+mtd+\"_Helmholtz_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_exp\"+str(bcbatch_size)+\"nIter\"+str(nIter)+\".mat\") , result_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Evaluates predictions at test points\n",
    "def predict_u(self, X_star):\n",
    "    # X_star = (X_star - self.mu_X) #/ self.sigma_X\n",
    "    tf_dict = {self.t_u_tf: X_star[:, 0:1], self.x_u_tf: X_star[:, 1:2]}\n",
    "    u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "    return u_star\n",
    "\n",
    "def predict_r(self, X_star):\n",
    "    # X_star = (X_star - self.mu_X) #/ self.sigma_X\n",
    "    tf_dict = {self.t_r_tf: X_star[:, 0:1], self.x_r_tf: X_star[:, 1:2]}\n",
    "    r_star = self.sess.run(self.r_pred, tf_dict)\n",
    "    return r_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average lambda_bc1.8017e+02\n",
      "average lambda_bc7.7456e+02\n",
      "average lambda_res1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative L2 error_u: 3.03e-02\n",
      "Relative L2 error_f: 5.34e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Save uv NN parameters successfully in %s ...checkpoints/Jan-19-2024_10-01-28-456403_M2\n",
      "Final loss total loss: 3.245130e-01\n",
      "Final loss loss_res: 2.843705e-01\n",
      "Final loss loss_bcs: 1.949944e-04\n",
      "Final loss loss_ics: 4.943251e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "average of time_list: 3390.9109629392624\n",
      "average of error_u_list: 0.03027757883603121\n",
      "average of error_f_list: 0.005342073232619589\n"
     ]
    }
   ],
   "source": [
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Predictions\n",
    "u_pred =predict_u( model , X_star)\n",
    "f_pred = predict_r( model , X_star)\n",
    "\n",
    "# Relative error\n",
    "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "error_f = np.linalg.norm(f_star - f_pred, 2) / np.linalg.norm(f_star, 2)\n",
    "\n",
    "print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
    "print('Relative L2 error_f: {:.2e}'.format(error_f))\n",
    "\n",
    "model.print(\"average lambda_bc\" , np.average(model.adaptive_constant_bcs_log))\n",
    "model.print(\"average lambda_bc\" , np.average(model.adaptive_constant_ics_log))\n",
    "model.print(\"average lambda_res\" , str(1.0))\n",
    "# sess.close()  \n",
    "\n",
    "model.plot_grad()\n",
    "model.save_NN()\n",
    "model.plt_prediction( t , x , X_star , u_star , u_pred , f_star , f_pred)\n",
    "\n",
    "time_list.append(elapsed)\n",
    "error_u_list.append(error_u)\n",
    "error_f_list.append(error_f)\n",
    "\n",
    "# print(\"\\n\\nMethod: \", mtd)\n",
    "print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
    "print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
    "print(\"average of error_f_list:\" , sum(error_f_list) / len(error_f_list) )\n",
    "\n",
    "result_dict[mtd] = [time_list ,error_u_list ,  error_f_list]\n",
    "# scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
    "\n",
    "scipy.io.savemat(os.path.join(model.dirname,\"\"+mtd+\"_Helmholtz_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_exp\"+str(bcbatch_size)+\"nIter\"+str(nIter)+\".mat\") , result_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twoPhase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
