{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_WARNINGS\"] = \"FALSE\" \n",
    "\n",
    "\n",
    "import scipy\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "import sys\n",
    "\n",
    "import scipy\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "import os.path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "class Sampler:\n",
    "    # Initialize the class\n",
    "    def __init__(self, dim, coords, func, name=None):\n",
    "        self.dim = dim\n",
    "        self.coords = coords\n",
    "        self.func = func\n",
    "        self.name = name\n",
    "\n",
    "    def sample(self, N):\n",
    "        x = self.coords[0:1, :] + (self.coords[1:2, :] - self.coords[0:1, :]) * np.random.rand(N, self.dim)\n",
    "        y = self.func(x)\n",
    "        return x, y\n",
    "    \n",
    "\n",
    "######################################################################################################\n",
    "def u(x, a_1, a_2):\n",
    "    return np.sin(a_1 * np.pi * x[:, 0:1]) * np.sin(a_2 * np.pi * x[:, 1:2])\n",
    "\n",
    "def u_xx(x, a_1, a_2):\n",
    "    return - (a_1 * np.pi) ** 2 * np.sin(a_1 * np.pi * x[:, 0:1]) * np.sin(a_2 * np.pi * x[:, 1:2])\n",
    "\n",
    "def u_yy(x, a_1, a_2):\n",
    "    return - (a_2 * np.pi) ** 2 * np.sin(a_1 * np.pi * x[:, 0:1]) * np.sin(a_2 * np.pi * x[:, 1:2])\n",
    "\n",
    "# Forcing\n",
    "def f(x, a_1, a_2, lam):\n",
    "    return u_xx(x, a_1, a_2) + u_yy(x, a_1, a_2) + lam * u(x, a_1, a_2)\n",
    "\n",
    "def operator(u, x1, x2, lam, sigma_x1=1.0, sigma_x2=1.0):\n",
    "    u_x1 = tf.gradients(u, x1)[0] / sigma_x1\n",
    "    u_x2 = tf.gradients(u, x2)[0] / sigma_x2\n",
    "    u_xx1 = tf.gradients(u_x1, x1)[0] / sigma_x1\n",
    "    u_xx2 = tf.gradients(u_x2, x2)[0] / sigma_x2\n",
    "    residual = u_xx1 + u_xx2 + lam * u\n",
    "    return residual\n",
    "#######################################################################################################\n",
    "\n",
    "class Helmholtz2D:\n",
    "    def __init__(self, layers, operator, ics_sampler, bcs_sampler, res_sampler, lam, mode, sess):\n",
    "        # Normalization constants\n",
    "\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        self.dirname, logpath = self.make_output_dir()\n",
    "        self.logger = self.get_logger(logpath)     \n",
    "\n",
    "        X, _ = res_sampler.sample(np.int32(1e5))\n",
    "        self.mu_X, self.sigma_X = X.mean(0), X.std(0)\n",
    "        self.mu_x1, self.sigma_x1 = self.mu_X[0], self.sigma_X[0]\n",
    "        self.mu_x2, self.sigma_x2 = self.mu_X[1], self.sigma_X[1]\n",
    "\n",
    "        # Samplers\n",
    "        self.operator = operator\n",
    "        self.ics_sampler = ics_sampler\n",
    "        self.bcs_sampler = bcs_sampler\n",
    "        self.res_sampler = res_sampler\n",
    "\n",
    "        # Helmoholtz constant\n",
    "        self.lam = tf.constant(lam, dtype=tf.float32)\n",
    "\n",
    "        # Mode\n",
    "        self.model = mode\n",
    "\n",
    "        # Record stiff ratio\n",
    "        # self.stiff_ratio = stiff_ratio\n",
    "\n",
    "        # Adaptive constant\n",
    "        self.beta = 0.9\n",
    "        self.adaptive_bcs_val = np.array(1.0)\n",
    "        self.adaptive_res_val = np.array(1.0)\n",
    "\n",
    "        # Initialize network weights and biases\n",
    "        self.layers = layers\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "\n",
    "        # if mode in ['M3', 'M4']:\n",
    "        #     # Initialize encoder weights and biases\n",
    "        #     self.encoder_weights_1 = self.xavier_init([2, layers[1]])\n",
    "        #     self.encoder_biases_1 = self.xavier_init([1, layers[1]])\n",
    "\n",
    "        #     self.encoder_weights_2 = self.xavier_init([2, layers[1]])\n",
    "        #     self.encoder_biases_2 = self.xavier_init([1, layers[1]])\n",
    "\n",
    "        # Define Tensorflow session\n",
    "        self.sess = sess #tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "\n",
    "        # Define placeholders and computational graph\n",
    "        self.x1_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x2_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.x1_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x2_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.u_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.x1_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x2_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.u_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.x1_bc3_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x2_bc3_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.u_bc3_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.x1_bc4_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x2_bc4_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.u_bc4_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        self.x1_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.x2_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.r_tf    = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "        # Define placeholder for adaptive constant\n",
    "        self.adaptive_bcs_tf = tf.placeholder(tf.float32, shape=self.adaptive_bcs_val.shape)\n",
    "        self.adaptive_res_tf = tf.placeholder(tf.float32, shape=self.adaptive_res_val.shape)\n",
    "\n",
    "        # Evaluate predictions\n",
    "        self.u_bc1_pred = self.net_u(self.x1_bc1_tf, self.x2_bc1_tf)\n",
    "        self.u_bc2_pred = self.net_u(self.x1_bc2_tf, self.x2_bc2_tf)\n",
    "        self.u_bc3_pred = self.net_u(self.x1_bc3_tf, self.x2_bc3_tf)\n",
    "        self.u_bc4_pred = self.net_u(self.x1_bc4_tf, self.x2_bc4_tf)\n",
    "\n",
    "        self.u_pred = self.net_u(self.x1_u_tf, self.x2_u_tf)\n",
    "        self.r_pred = self.net_r(self.x1_r_tf, self.x2_r_tf)\n",
    "\n",
    "        # Boundary loss\n",
    "        self.loss_bc1 = tf.reduce_mean(tf.square(self.u_bc1_tf - self.u_bc1_pred))\n",
    "        self.loss_bc2 = tf.reduce_mean(tf.square(self.u_bc2_tf - self.u_bc2_pred))\n",
    "        self.loss_bc3 = tf.reduce_mean(tf.square(self.u_bc3_tf - self.u_bc3_pred))\n",
    "        self.loss_bc4 = tf.reduce_mean(tf.square(self.u_bc4_tf - self.u_bc4_pred))\n",
    "        self.loss_bcs =  (self.loss_bc1 + self.loss_bc2 + self.loss_bc3 + self.loss_bc4)\n",
    "\n",
    "        # Residual loss\n",
    "        self.loss_res = tf.reduce_mean(tf.square(self.r_tf - self.r_pred))\n",
    "\n",
    "        # Total loss\n",
    "        self.loss = self.adaptive_res_tf * self.loss_res + self.adaptive_bcs_tf * self.loss_bcs\n",
    "\n",
    "        # Define optimizer with learning rate schedule\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        starter_learning_rate = 1e-3\n",
    "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step, 1000, 0.9, staircase=False)\n",
    "        # Passing global_step to minimize() will increment it at each step.\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss, global_step=self.global_step)\n",
    "\n",
    "        self.loss_tensor_list = [self.loss ,  self.loss_res,  self.loss_bc1 , self.loss_bc2 , self.loss_bc3, self.loss_bc4] \n",
    "        self.loss_list = [\"total loss\" , \"loss_res\" , \"loss_bc1\", \"loss_bc2\", \"loss_bc3\", \"loss_bc4\"] \n",
    "\n",
    "        self.epoch_loss = dict.fromkeys(self.loss_list, 0)\n",
    "        self.loss_history = dict((loss, []) for loss in self.loss_list)\n",
    "        # Logger\n",
    "        self.loss_bcs_log = []\n",
    "        self.loss_res_log = []\n",
    "        # self.saver = tf.train.Saver()\n",
    "        self.first_grad_res = 0\n",
    "        self.first_grad_bcs = 0\n",
    "        \n",
    "        # Generate dicts for gradients storage\n",
    "        self.dict_gradients_res_layers = self.generate_grad_dict()\n",
    "        self.dict_gradients_bcs_layers = self.generate_grad_dict()\n",
    "\n",
    "        # Gradients Storage\n",
    "        self.grad_res = []\n",
    "        self.grad_bcs = []\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.grad_res.append(tf.gradients(self.loss_res, self.weights[i])[0])\n",
    "            self.grad_bcs.append(tf.gradients(self.loss_bcs, self.weights[i])[0])\n",
    "\n",
    "        # Compute and store the adaptive constant\n",
    "        self.adpative_bcs_log = []\n",
    "        self.adpative_res_log = []\n",
    "\n",
    "        self.std_grad_res_list = []\n",
    "        self.std_grad_bcs_list = []\n",
    "        self.mean_grad_res_list = []\n",
    "        self.mean_grad_bcs_list = []\n",
    "        \n",
    "        self.mean_grad_res_log = []\n",
    "        self.mean_grad_bcs_log = []\n",
    "    \n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.std_grad_res_list.append(tf.math.reduce_std(self.grad_res[i])) \n",
    "            self.std_grad_bcs_list.append(tf.math.reduce_std(self.grad_bcs[i])) \n",
    "            self.mean_grad_res_list.append(tf.math.reduce_mean(self.grad_res[i]))\n",
    "            self.mean_grad_bcs_list.append(tf.math.reduce_mean(self.grad_bcs[i]))\n",
    "        \n",
    "        self.std_grad_res = tf.math.reduce_std(tf.stack(self.std_grad_res_list))\n",
    "        self.std_grad_bcs = tf.math.reduce_std(tf.stack(self.std_grad_bcs_list))\n",
    "        self.mean_grad_res = tf.math.reduce_mean(tf.stack(self.mean_grad_res_list))\n",
    "        self.mean_grad_bcs = tf.math.reduce_mean(tf.stack(self.mean_grad_bcs_list))\n",
    "\n",
    "        self.kurtosis_grad_res_list = []\n",
    "        self.kurtosis_grad_bcs_list = []\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "\n",
    "            self.kurtosis_grad_res_list.append(tf.math.reduce_mean(   tf.math.pow (((self.grad_res[i] - self.mean_grad_res) / self.std_grad_res),4)))\n",
    "            self.kurtosis_grad_bcs_list.append(tf.math.reduce_mean(   tf.math.pow (((self.grad_bcs[i] - self.mean_grad_bcs) / self.std_grad_bcs),4)))\n",
    "\n",
    "        self.kurtosis_grad_res = tf.math.reduce_mean(tf.stack(self.kurtosis_grad_res_list))\n",
    "        self.kurtosis_grad_bcs = tf.math.reduce_mean(tf.stack(self.kurtosis_grad_bcs_list))\n",
    "    \n",
    "        # # Stiff Ratio\n",
    "        # if self.stiff_ratio:\n",
    "        #     self.Hessian, self.Hessian_bcs, self.Hessian_res = self.get_H_op()\n",
    "        #     self.eigenvalues, _ = tf.linalg.eigh(self.Hessian)\n",
    "        #     self.eigenvalues_bcs, _ = tf.linalg.eigh(self.Hessian_bcs)\n",
    "        #     self.eigenvalues_res, _ = tf.linalg.eigh(self.Hessian_res)\n",
    "\n",
    "        #     self.eigenvalue_log = []\n",
    "        #     self.eigenvalue_bcs_log = []\n",
    "        #     self.eigenvalue_res_log = []\n",
    "\n",
    "        # Initialize Tensorflow variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "     # Create dictionary to store gradients\n",
    "    def generate_grad_dict(self, layers):\n",
    "        num = len(layers) - 1\n",
    "        grad_dict = {}\n",
    "        for i in range(num):\n",
    "            grad_dict['layer_{}'.format(i + 1)] = []\n",
    "        return grad_dict\n",
    "\n",
    "    # Save gradients\n",
    "    def save_gradients(self, tf_dict):\n",
    "        num_layers = len(self.layers)\n",
    "        for i in range(num_layers - 1):\n",
    "            grad_res_value, grad_bcs_value = self.sess.run([self.grad_res[i], self.grad_bcs[i]], feed_dict=tf_dict)\n",
    "\n",
    "            # save gradients of loss_res and loss_bcs\n",
    "            self.dict_gradients_res_layers['layer_' + str(i + 1)].append(grad_res_value.flatten())\n",
    "            self.dict_gradients_bcs_layers['layer_' + str(i + 1)].append(grad_bcs_value.flatten())\n",
    "        return None\n",
    "\n",
    "    # Compute the Hessian\n",
    "    def flatten(self, vectors):\n",
    "        return tf.concat([tf.reshape(v, [-1]) for v in vectors], axis=0)\n",
    "\n",
    "    def get_Hv(self, v):\n",
    "        loss_gradients = self.flatten(tf.gradients(self.loss, self.weights))\n",
    "        vprod = tf.math.multiply(loss_gradients, tf.stop_gradient(v))\n",
    "        Hv_op = self.flatten(tf.gradients(vprod, self.weights))\n",
    "        return Hv_op\n",
    "\n",
    "    def get_Hv_res(self, v):\n",
    "        loss_gradients = self.flatten(tf.gradients(self.loss_res,   self.weights))\n",
    "        vprod = tf.math.multiply(loss_gradients, tf.stop_gradient(v))\n",
    "        Hv_op = self.flatten(tf.gradients(vprod,  self.weights))\n",
    "        return Hv_op\n",
    "\n",
    "    def get_Hv_bcs(self, v):\n",
    "        loss_gradients = self.flatten(tf.gradients(self.loss_bcs, self.weights))\n",
    "        vprod = tf.math.multiply(loss_gradients, tf.stop_gradient(v))\n",
    "        Hv_op = self.flatten(tf.gradients(vprod, self.weights))\n",
    "        return Hv_op\n",
    "\n",
    "    def get_H_op(self):\n",
    "        self.P = self.flatten(self.weights).get_shape().as_list()[0]\n",
    "        H = tf.map_fn(self.get_Hv, tf.eye(self.P, self.P), dtype='float32')\n",
    "        H_bcs = tf.map_fn(self.get_Hv_bcs, tf.eye(self.P, self.P),  dtype='float32')\n",
    "        H_res = tf.map_fn(self.get_Hv_res, tf.eye(self.P, self.P),  dtype='float32')\n",
    "\n",
    "        return H, H_bcs, H_res\n",
    "\n",
    "    # Xavier initialization\n",
    "    def xavier_init(self,size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = 1. / np.sqrt((in_dim + out_dim) / 2.)\n",
    "        return tf.Variable(tf.random_normal([in_dim, out_dim], dtype=tf.float32) * xavier_stddev, dtype=tf.float32)\n",
    "\n",
    "    # Initialize network weights and biases using Xavier initialization\n",
    "    def initialize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0, num_layers - 1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l + 1]])\n",
    "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "\n",
    "    # Evaluates the forward pass\n",
    "    def forward_pass(self, H):\n",
    "        num_layers = len(self.layers)\n",
    "        for l in range(0, num_layers - 2):\n",
    "            W = self.weights[l]\n",
    "            b = self.biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = self.weights[-1]\n",
    "        b = self.biases[-1]\n",
    "        H = tf.add(tf.matmul(H, W), b)\n",
    "        return H\n",
    "\n",
    "    # Forward pass for u\n",
    "    def net_u(self, x1, x2):\n",
    "        u = self.forward_pass(tf.concat([x1, x2], 1))\n",
    "        return u\n",
    "\n",
    "    # Forward pass for residual\n",
    "    def net_r(self, x1, x2):\n",
    "        u = self.net_u(x1, x2)\n",
    "        residual = self.operator(u, x1, x2,  self.lam, self.sigma_x1,  self.sigma_x2)\n",
    "        return residual\n",
    "\n",
    "    # Feed minibatch\n",
    "    def fetch_minibatch(self, sampler, N):\n",
    "        X, Y = sampler.sample(N)\n",
    "        X = (X - self.mu_X) / self.sigma_X\n",
    "        return X, Y\n",
    "\n",
    "  # Trains the model by minimizing the MSE loss\n",
    "    def trainmb(self, nIter=10000, batch_size=128):\n",
    "        itValues = [1,100,1000,39999]\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "        for it in range(nIter):\n",
    "            # Fetch boundary mini-batches\n",
    "            X_bc1_batch, u_bc1_batch = self.fetch_minibatch(self.bcs_sampler[0], batch_size)\n",
    "            X_bc2_batch, u_bc2_batch = self.fetch_minibatch(self.bcs_sampler[1], batch_size)\n",
    "            X_bc3_batch, u_bc3_batch = self.fetch_minibatch(self.bcs_sampler[2], batch_size)\n",
    "            X_bc4_batch, u_bc4_batch = self.fetch_minibatch(self.bcs_sampler[3], batch_size)\n",
    "\n",
    "            # Fetch residual mini-batch\n",
    "            X_res_batch, f_res_batch = self.fetch_minibatch(self.res_sampler, batch_size)\n",
    "\n",
    "            # Define a dictionary for associating placeholders with data\n",
    "            tf_dict = {self.x1_bc1_tf: X_bc1_batch[:, 0:1], self.x2_bc1_tf: X_bc1_batch[:, 1:2],\n",
    "                       self.u_bc1_tf: u_bc1_batch,\n",
    "                       self.x1_bc2_tf: X_bc2_batch[:, 0:1], self.x2_bc2_tf: X_bc2_batch[:, 1:2],\n",
    "                       self.u_bc2_tf: u_bc2_batch,\n",
    "                       self.x1_bc3_tf: X_bc3_batch[:, 0:1], self.x2_bc3_tf: X_bc3_batch[:, 1:2],\n",
    "                       self.u_bc3_tf: u_bc3_batch,\n",
    "                       self.x1_bc4_tf: X_bc4_batch[:, 0:1], self.x2_bc4_tf: X_bc4_batch[:, 1:2],\n",
    "                       self.u_bc4_tf: u_bc4_batch,\n",
    "                       self.x1_r_tf: X_res_batch[:, 0:1], self.x2_r_tf: X_res_batch[:, 1:2], \n",
    "                       self.r_tf: f_res_batch,\n",
    "                       self.adaptive_bcs_tf:  self.adaptive_bcs_val,\n",
    "                       self.adaptive_res_tf:  self.adaptive_res_val\n",
    "\n",
    "                       }\n",
    "\n",
    "            # Run the Tensorflow session to minimize the loss\n",
    "            _ , batch_losses = self.sess.run( [  self.train_op , self.loss_tensor_list ] ,tf_dict)\n",
    "            self.assign_batch_losses(batch_losses)\n",
    "            for key in self.loss_history:\n",
    "                self.loss_history[key].append(self.epoch_loss[key])\n",
    "\n",
    "            # Compute the eigenvalues of the Hessian of losses\n",
    "            # Print\n",
    "            if it % 100 == 0:\n",
    "                elapsed = timeit.default_timer() - start_time\n",
    "                loss ,  loss_bcs, loss_res = self.sess.run([self.loss, self.loss_bcs, self.loss_res] , tf_dict)\n",
    "\n",
    " \n",
    "                self.print('It: %d, Loss: %.3e, Loss_bcs: %.3e, Loss_res: %.3e,Time: %.2f' % (it, loss, loss_bcs, loss_res, elapsed))\n",
    "\n",
    "                [std_grad_bcs , std_grad_res ,  kurtosis_grad_bcs  ,  kurtosis_grad_res ]= self.sess.run( [self.std_grad_bcs , self.std_grad_res , self.kurtosis_grad_bcs , self.kurtosis_grad_res  ], tf_dict)\n",
    "                if it  == 0:\n",
    "                   # Print adaptive weights during training\n",
    "                    self.adaptive_bcs_val =   np.max(kurtosis_grad_bcs , kurtosis_grad_res) / std_grad_bcs \n",
    "                    self.adaptive_res_val =   np.max(kurtosis_grad_bcs , kurtosis_grad_res) / std_grad_res  \n",
    "                    \n",
    "                   \n",
    "                self.print(' kurtosis_grad_res: ', kurtosis_grad_res)\n",
    "                self.print(' kurtosis_grad_bcs: ', kurtosis_grad_bcs)\n",
    "                self.print('std_grad_bcs: %f' % std_grad_bcs)\n",
    "                self.print('std_grad_res: %f' % std_grad_res)\n",
    "\n",
    "\n",
    "                self.print('adaptive_bcs_val: ',self.adaptive_bcs_val)\n",
    "                self.print('adaptive_res_val: ', self.adaptive_res_val)\n",
    "                \n",
    " \n",
    "                self.adpative_bcs_log.append(self.adaptive_bcs_val)\n",
    "                self.adpative_res_log.append(self.adaptive_res_val)\n",
    "\n",
    "\n",
    "                self.mean_grad_res_log.append(std_grad_res)\n",
    "                self.mean_grad_bcs_log.append(std_grad_bcs)\n",
    "\n",
    "  \n",
    "            start_time = timeit.default_timer()\n",
    "\n",
    "            if it in itValues:\n",
    "                    self.plot_layerLoss(tf_dict , it)\n",
    "                    self.print(\"Gradients information stored ...\")\n",
    "\n",
    "            sys.stdout.flush()\n",
    " \n",
    "    # Evaluates predictions at test points\n",
    "    def predict_u(self, X_star):\n",
    "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
    "        tf_dict = {self.x1_u_tf: X_star[:, 0:1], self.x2_u_tf: X_star[:, 1:2]}\n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "        return u_star\n",
    "\n",
    "    def predict_r(self, X_star):\n",
    "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
    "        tf_dict = {self.x1_r_tf: X_star[:, 0:1], self.x2_r_tf: X_star[:, 1:2]}\n",
    "        r_star = self.sess.run(self.r_pred, tf_dict)\n",
    "        return r_star\n",
    "\n",
    "\n",
    "\n",
    "  # ###############################################################################################################################################\n",
    "   # \n",
    "   #  \n",
    "    def plot_layerLoss(self , tf_dict , epoch):\n",
    "        ## Gradients #\n",
    "        num_layers = len(self.layers)\n",
    "        for i in range(num_layers - 1):\n",
    "            grad_res, grad_bc1    = self.sess.run([ self.grad_res[i],self.grad_bcs[i]], feed_dict=tf_dict)\n",
    "\n",
    "            # save gradients of loss_r and loss_u\n",
    "            self.dict_gradients_res_layers['layer_' + str(i + 1)].append(grad_res.flatten())\n",
    "            self.dict_gradients_bcs_layers['layer_' + str(i + 1)].append(grad_bc1.flatten())\n",
    "\n",
    "        num_hidden_layers = num_layers -1\n",
    "        cnt = 1\n",
    "        fig = plt.figure(4, figsize=(13, 4))\n",
    "        for j in range(num_hidden_layers):\n",
    "            ax = plt.subplot(1, num_hidden_layers, cnt)\n",
    "            ax.set_title('Layer {}'.format(j + 1))\n",
    "            ax.set_yscale('symlog')\n",
    "            gradients_res = self.dict_gradients_res_layers['layer_' + str(j + 1)][-1]\n",
    "            gradients_bc1 = self.dict_gradients_bcs_layers['layer_' + str(j + 1)][-1]\n",
    "\n",
    "            sns.distplot(gradients_res, hist=False,kde_kws={\"shade\": False},norm_hist=True,  label=r'$\\nabla_\\theta \\mathcal{L}_r$')\n",
    "\n",
    "            sns.distplot(gradients_bc1, hist=False,kde_kws={\"shade\": False},norm_hist=True,   label=r'$\\nabla_\\theta \\mathcal{L}_{u_{bc1}}$')\n",
    "\n",
    "            #ax.get_legend().remove()\n",
    "            ax.set_xlim([-1.0, 1.0])\n",
    "            #ax.set_ylim([0, 150])\n",
    "            cnt += 1\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "        fig.legend(handles, labels, loc=\"center\",  bbox_to_anchor=(0.5, -0.03),borderaxespad=0,bbox_transform=fig.transFigure, ncol=2)\n",
    "        text = 'layerLoss_epoch' + str(epoch) +'.png'\n",
    "        plt.savefig(os.path.join(self.dirname,text) , bbox_inches='tight')\n",
    "        plt.close(\"all\")\n",
    "    # #########################\n",
    "    # def make_output_dir(self):\n",
    "        \n",
    "    #     if not os.path.exists(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\"):\n",
    "    #         os.mkdir(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\")\n",
    "    #     dirname = os.path.join(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\", datetime.now().strftime(\"%b-%d-%Y_%H-%M-%S-%f_\") + self.mode)\n",
    "    #     os.mkdir(dirname)\n",
    "    #     text = 'output.log'\n",
    "    #     logpath = os.path.join(dirname, text)\n",
    "    #     shutil.copyfile('/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/M2.py', os.path.join(dirname, 'M2.py'))\n",
    "\n",
    "    #     return dirname, logpath\n",
    "    \n",
    "    # # ###########################################################\n",
    "    def make_output_dir(self):\n",
    "        \n",
    "        if not os.path.exists(\"checkpoints\"):\n",
    "            os.mkdir(\"checkpoints\")\n",
    "        dirname = os.path.join(\"checkpoints\", datetime.now().strftime(\"%b-%d-%Y_%H-%M-%S-%f_\") + self.mode)\n",
    "        os.mkdir(dirname)\n",
    "        text = 'output.log'\n",
    "        logpath = os.path.join(dirname, text)\n",
    "        # shutil.copyfile('M2.ipynb', os.path.join(dirname, 'M2.ipynb'))\n",
    "        return dirname, logpath\n",
    "    \n",
    "\n",
    "    def get_logger(self, logpath):\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        sh = logging.StreamHandler()\n",
    "        sh.setLevel(logging.DEBUG)        \n",
    "        sh.setFormatter(logging.Formatter('%(message)s'))\n",
    "        fh = logging.FileHandler(logpath)\n",
    "        logger.addHandler(sh)\n",
    "        logger.addHandler(fh)\n",
    "        return logger\n",
    "\n",
    "\n",
    "   \n",
    "    def print(self, *args):\n",
    "        for word in args:\n",
    "            if len(args) == 1:\n",
    "                self.logger.info(word)\n",
    "            elif word != args[-1]:\n",
    "                for handler in self.logger.handlers:\n",
    "                    handler.terminator = \"\"\n",
    "                if type(word) == float or type(word) == np.float64 or type(word) == np.float32: \n",
    "                    self.logger.info(\"%.4e\" % (word))\n",
    "                else:\n",
    "                    self.logger.info(word)\n",
    "            else:\n",
    "                for handler in self.logger.handlers:\n",
    "                    handler.terminator = \"\\n\"\n",
    "                if type(word) == float or type(word) == np.float64 or type(word) == np.float32:\n",
    "                    self.logger.info(\"%.4e\" % (word))\n",
    "                else:\n",
    "                    self.logger.info(word)\n",
    "\n",
    "\n",
    "    def plot_loss_history(self , path):\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches([15,8])\n",
    "        for key in self.loss_history:\n",
    "            self.print(\"Final loss %s: %e\" % (key, self.loss_history[key][-1]))\n",
    "            ax.semilogy(self.loss_history[key], label=key)\n",
    "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
    "        ax.set_ylabel(\"loss\", fontsize=15)\n",
    "        ax.tick_params(labelsize=15)\n",
    "        ax.legend()\n",
    "        plt.savefig(path)\n",
    "        plt.close(\"all\" , )\n",
    "       #######################\n",
    "    def save_NN(self):\n",
    "\n",
    "        uv_weights = self.sess.run(self.weights)\n",
    "        uv_biases = self.sess.run(self.biases)\n",
    "\n",
    "        with open(os.path.join(self.dirname,'model.pickle'), 'wb') as f:\n",
    "            pickle.dump([uv_weights, uv_biases], f)\n",
    "            self.print(\"Save uv NN parameters successfully in %s ...\" , self.dirname)\n",
    "\n",
    "        # with open(os.path.join(self.dirname,'loss_history_BFS.pickle'), 'wb') as f:\n",
    "        #     pickle.dump(self.loss_rec, f)\n",
    "        with open(os.path.join(self.dirname,'loss_history_BFS.png'), 'wb') as f:\n",
    "            self.plot_loss_history(f)\n",
    "\n",
    "\n",
    "    def assign_batch_losses(self, batch_losses):\n",
    "        for loss_values, key in zip(batch_losses, self.epoch_loss):\n",
    "            self.epoch_loss[key] = loss_values\n",
    "\n",
    "\n",
    "    def generate_grad_dict(self):\n",
    "        num = len(self.layers) - 1\n",
    "        grad_dict = {}\n",
    "        for i in range(num):\n",
    "            grad_dict['layer_{}'.format(i + 1)] = []\n",
    "        return grad_dict\n",
    "    \n",
    "    def assign_batch_losses(self, batch_losses):\n",
    "        for loss_values, key in zip(batch_losses, self.epoch_loss):\n",
    "            self.epoch_loss[key] = loss_values\n",
    "            \n",
    "    def plt_prediction(self , x1 , x2 , X_star , u_star , u_pred , f_star , f_pred):\n",
    "        from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "        ### Plot ###\n",
    "\n",
    "        # Exact solution & Predicted solution\n",
    "        # Exact soluton\n",
    "        U_star = griddata(X_star, u_star.flatten(), (x1, x2), method='cubic')\n",
    "        F_star = griddata(X_star, f_star.flatten(), (x1, x2), method='cubic')\n",
    "\n",
    "        # Predicted solution\n",
    "        U_pred = griddata(X_star, u_pred.flatten(), (x1, x2), method='cubic')\n",
    "        F_pred = griddata(X_star, f_pred.flatten(), (x1, x2), method='cubic')\n",
    "\n",
    "        titles = ['Exact $u(x)$' , 'Predicted $u(x)$' , 'Absolute error' , 'Exact $f(x)$' , 'Predicted $f(x)$' , 'Absolute error']\n",
    "        data = [U_star , U_pred ,  np.abs(U_star - U_pred) , F_star , F_pred ,  np.abs(F_star - F_pred) ]\n",
    "        \n",
    "\n",
    "        fig_1 = plt.figure(1, figsize=(13, 5))\n",
    "        grid = ImageGrid(fig_1, 111, direction=\"row\", nrows_ncols=(2,3), \n",
    "                        label_mode=\"1\", axes_pad=1.7, share_all=False, \n",
    "                        cbar_mode=\"each\", cbar_location=\"right\", \n",
    "                        cbar_size=\"5%\", cbar_pad=0.0)\n",
    "    # CREATE ARGUMENTS DICT FOR CONTOURPLOTS\n",
    "        minmax_list = []\n",
    "        kwargs_list = []\n",
    "        for d in data:\n",
    "            # if(local):\n",
    "            #     minmax_list.append([np.min(d), np.max(d)])\n",
    "            # else:\n",
    "            minmax_list.append([np.min(d), np.max(d)])\n",
    "\n",
    "            kwargs_list.append(dict(levels=np.linspace(minmax_list[-1][0],minmax_list[-1][1], 60),\n",
    "                cmap=\"coolwarm\", vmin=minmax_list[-1][0], vmax=minmax_list[-1][1]))\n",
    "\n",
    "        for ax, z, kwargs, minmax, title in zip(grid, data, kwargs_list, minmax_list, titles):\n",
    "        #pcf = [ax.tricontourf(x, y, z[0,:], **kwargs)]\n",
    "            #pcfsets.append(pcf)\n",
    "            # if (timeStp == 0):\n",
    "                #  print( z[timeStp,:,:])\n",
    "            pcf = [ax.pcolor(x1, x2, z , cmap='jet')]\n",
    "            cb = ax.cax.colorbar(pcf[0], ticks=np.linspace(minmax[0],minmax[1],7),  format='%.3e')\n",
    "            ax.cax.tick_params(labelsize=14.5)\n",
    "            ax.set_title(title, fontsize=14.5, pad=7)\n",
    "            ax.set_ylabel(\"y\", labelpad=14.5, fontsize=14.5, rotation=\"horizontal\")\n",
    "            ax.set_xlabel(\"x\", fontsize=14.5)\n",
    "            ax.tick_params(labelsize=14.5)\n",
    "            ax.set_xlim(x1.min(), x1.max())\n",
    "            ax.set_ylim(x2.min(), x2.max())\n",
    "            ax.set_aspect(\"equal\")\n",
    "\n",
    "        fig_1.set_size_inches(15, 10, True)\n",
    "        fig_1.subplots_adjust(left=0.7, bottom=0, right=2.2, top=0.5, wspace=None, hspace=None)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.dirname,\"prediction.png\"), dpi=300 , bbox_inches='tight')\n",
    "        plt.close(\"all\" , )\n",
    "\n",
    "\n",
    "    def plot_grad(self ):\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches([15,8])\n",
    "        ax.semilogy(self.adpative_bcs_log, label=r'$\\bar{\\nabla_\\theta \\mathcal{L}_{u_{bc}}}$')\n",
    "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
    "        ax.set_ylabel(\"loss\", fontsize=15)\n",
    "        ax.tick_params(labelsize=15)\n",
    "        ax.legend()\n",
    "        path = os.path.join(self.dirname,'grad_history.png')\n",
    "        plt.savefig(path)\n",
    "        plt.close(\"all\" , )\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "    def plot_lambda(self ):\n",
    "\n",
    "        fontsize = 17\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches([16,8])\n",
    "        ax.semilogy(self.mean_grad_res_log, label=r'$\\bar{\\nabla_\\theta {u_{res}}}$' , color = 'tab:green')\n",
    "        ax.semilogy(self.mean_grad_bcs_log, label=r'$\\bar{\\nabla_\\theta {u_{bc}}}$' , color = 'tab:blue')\n",
    "        ax.set_xlabel(\"epochs\", fontsize=fontsize)\n",
    "        ax.set_ylabel(r'$\\bar{\\nabla_\\theta {u}}$', fontsize=fontsize)\n",
    "        ax.tick_params(labelsize=fontsize)\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(-0.25, 0.5))\n",
    "\n",
    "        ax2 = ax.twinx() \n",
    "\n",
    "        # fig, ax = plt.subplots()\n",
    "        # fig.set_size_inches([15,8])\n",
    "    \n",
    "        ax2.semilogy(self.adpative_bcs_log, label=r'$\\bar{\\lambda_{bc}}$'  ,  linestyle='dashed' , color = 'tab:green') \n",
    "        ax2.semilogy(self.adpative_res_log, label=r'$\\bar{\\lambda_{res}}$'  ,  linestyle='dashed' , color = 'tab:blue') \n",
    "\n",
    "        ax2.set_xlabel(\"epochs\", fontsize=fontsize)\n",
    "        ax2.set_ylabel(r'$\\bar{\\lambda}$', fontsize=fontsize)\n",
    "        ax2.tick_params(labelsize=fontsize)\n",
    "        ax2.legend(loc='center right', bbox_to_anchor=(1.2, 0.5))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        path = os.path.join(self.dirname,'lambda_history.png')\n",
    "        plt.savefig(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_method(mtd , layers, operator, ics_sampler, bcs_sampler , res_sampler ,lam , mode , stiff_ratio , X_star ,u_star , f_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size)\n",
    "\n",
    "def test_method(method , layers, operator, ics_sampler, bcs_sampler, res_sampler, lam ,mode , stiff_ratio ,  X_star , u_star , f_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size):\n",
    "\n",
    "\n",
    "    model = Helmholtz2D(layers, operator, ics_sampler, bcs_sampler, res_sampler, lam, mode, stiff_ratio)\n",
    "\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "\n",
    "    if method ==\"full_batch\":\n",
    "        model.train(nIter  ,bcbatch_size , ubatch_size )\n",
    "    elif method ==\"mini_batch\":\n",
    "        model.trainmb(nIter, batch_size=mbbatch_size)\n",
    "    else:\n",
    "        print(\"unknown method!\")\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "\n",
    "    # Predictions\n",
    "    u_pred = model.predict_u(X_star)\n",
    "    f_pred = model.predict_r(X_star)\n",
    "\n",
    "    # Relative error\n",
    "    error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "    error_f = np.linalg.norm(f_star - f_pred, 2) / np.linalg.norm(f_star, 2)\n",
    "\n",
    "    print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
    "    print('Relative L2 error_f: {:.2e}'.format(error_f))\n",
    "\n",
    "    return [elapsed, error_u , error_f ,  model]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  mini_batch\n",
      "Epoch:  1\n",
      "WARNING:tensorflow:From /tmp/ipykernel_116381/3928250666.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_116381/3928250666.py:83: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_116381/3928250666.py:84: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_116381/3928250666.py:84: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_116381/1051282895.py:304: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_116381/1051282895.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:09:25.494633: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-17 12:09:25.517825: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
      "2024-01-17 12:09:25.518498: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562c4f0b7e40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-17 12:09:25.518517: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-01-17 12:09:25.520814: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_116381/1051282895.py:174: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_116381/1051282895.py:176: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_116381/1051282895.py:247: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 6.271e+03, Loss_bcs: 7.102e-01, Loss_res: 6.270e+03,Time: 1.52\n",
      " kurtosis_grad_res: 8.7689e+01\n",
      " kurtosis_grad_bcs: 1.4995e+02\n",
      "std_grad_bcs: 0.227718\n",
      "std_grad_res: 0.588397\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Gradients information stored ...\n",
      "It: 100, Loss: 1.287e+06, Loss_bcs: 2.681e-01, Loss_res: 8.638e+03,Time: 0.01\n",
      " kurtosis_grad_res: 2.7465e+02\n",
      " kurtosis_grad_bcs: 1.1109e+02\n",
      "std_grad_bcs: 0.080522\n",
      "std_grad_res: 5.855366\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Gradients information stored ...\n",
      "It: 200, Loss: 1.082e+06, Loss_bcs: 1.937e+00, Loss_res: 7.255e+03,Time: 0.01\n",
      " kurtosis_grad_res: 4.6847e+01\n",
      " kurtosis_grad_bcs: 7.0687e+01\n",
      "std_grad_bcs: 0.215793\n",
      "std_grad_res: 9.803514\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 300, Loss: 9.338e+05, Loss_bcs: 4.237e+00, Loss_res: 6.247e+03,Time: 0.01\n",
      " kurtosis_grad_res: 7.0141e+01\n",
      " kurtosis_grad_bcs: 5.9449e+01\n",
      "std_grad_bcs: 0.390201\n",
      "std_grad_res: 16.848454\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 400, Loss: 9.685e+05, Loss_bcs: 7.824e+00, Loss_res: 6.464e+03,Time: 0.01\n",
      " kurtosis_grad_res: 6.2107e+01\n",
      " kurtosis_grad_bcs: 4.0372e+01\n",
      "std_grad_bcs: 0.673689\n",
      "std_grad_res: 13.007174\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 500, Loss: 7.870e+05, Loss_bcs: 9.241e+00, Loss_res: 5.240e+03,Time: 0.01\n",
      " kurtosis_grad_res: 6.3298e+01\n",
      " kurtosis_grad_bcs: 4.9703e+01\n",
      "std_grad_bcs: 0.660326\n",
      "std_grad_res: 89.725540\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 600, Loss: 5.401e+05, Loss_bcs: 5.356e+00, Loss_res: 3.601e+03,Time: 0.01\n",
      " kurtosis_grad_res: 5.8114e+01\n",
      " kurtosis_grad_bcs: 5.0372e+01\n",
      "std_grad_bcs: 0.630858\n",
      "std_grad_res: 107.772675\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 700, Loss: 1.415e+05, Loss_bcs: 7.418e+00, Loss_res: 9.165e+02,Time: 0.02\n",
      " kurtosis_grad_res: 5.0656e+01\n",
      " kurtosis_grad_bcs: 4.0281e+01\n",
      "std_grad_bcs: 1.000602\n",
      "std_grad_res: 82.629028\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 800, Loss: 3.608e+04, Loss_bcs: 7.919e+00, Loss_res: 2.071e+02,Time: 0.01\n",
      " kurtosis_grad_res: 6.1901e+01\n",
      " kurtosis_grad_bcs: 6.0057e+01\n",
      "std_grad_bcs: 0.654193\n",
      "std_grad_res: 31.463316\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 900, Loss: 3.341e+04, Loss_bcs: 7.238e+00, Loss_res: 1.922e+02,Time: 0.01\n",
      " kurtosis_grad_res: 3.8419e+01\n",
      " kurtosis_grad_bcs: 7.1611e+01\n",
      "std_grad_bcs: 0.528841\n",
      "std_grad_res: 88.791290\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1000, Loss: 1.779e+04, Loss_bcs: 6.812e+00, Loss_res: 8.928e+01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9181e+01\n",
      " kurtosis_grad_bcs: 6.6094e+01\n",
      "std_grad_bcs: 0.559743\n",
      "std_grad_res: 78.408211\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Gradients information stored ...\n",
      "It: 1100, Loss: 1.684e+04, Loss_bcs: 5.831e+00, Loss_res: 8.723e+01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4544e+01\n",
      " kurtosis_grad_bcs: 5.9675e+01\n",
      "std_grad_bcs: 0.646649\n",
      "std_grad_res: 35.802586\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1200, Loss: 1.073e+04, Loss_bcs: 4.470e+00, Loss_res: 5.225e+01,Time: 0.01\n",
      " kurtosis_grad_res: 3.6548e+01\n",
      " kurtosis_grad_bcs: 7.0411e+01\n",
      "std_grad_bcs: 0.618974\n",
      "std_grad_res: 91.606712\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1300, Loss: 8.858e+03, Loss_bcs: 3.927e+00, Loss_res: 4.209e+01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1698e+01\n",
      " kurtosis_grad_bcs: 7.2397e+01\n",
      "std_grad_bcs: 0.637569\n",
      "std_grad_res: 55.683353\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1400, Loss: 7.147e+03, Loss_bcs: 3.460e+00, Loss_res: 3.267e+01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9880e+01\n",
      " kurtosis_grad_bcs: 7.0002e+01\n",
      "std_grad_bcs: 0.613840\n",
      "std_grad_res: 66.582726\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1500, Loss: 6.195e+03, Loss_bcs: 2.819e+00, Loss_res: 2.911e+01,Time: 0.00\n",
      " kurtosis_grad_res: 4.2267e+01\n",
      " kurtosis_grad_bcs: 7.4259e+01\n",
      "std_grad_bcs: 0.624744\n",
      "std_grad_res: 17.713757\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1600, Loss: 6.694e+03, Loss_bcs: 2.389e+00, Loss_res: 3.436e+01,Time: 0.01\n",
      " kurtosis_grad_res: 5.5523e+01\n",
      " kurtosis_grad_bcs: 6.6183e+01\n",
      "std_grad_bcs: 0.605998\n",
      "std_grad_res: 108.146362\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1700, Loss: 5.080e+03, Loss_bcs: 1.963e+00, Loss_res: 2.541e+01,Time: 0.01\n",
      " kurtosis_grad_res: 3.8459e+01\n",
      " kurtosis_grad_bcs: 6.7690e+01\n",
      "std_grad_bcs: 0.537900\n",
      "std_grad_res: 43.955025\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1800, Loss: 4.909e+03, Loss_bcs: 1.947e+00, Loss_res: 2.434e+01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1692e+01\n",
      " kurtosis_grad_bcs: 6.5101e+01\n",
      "std_grad_bcs: 0.515145\n",
      "std_grad_res: 40.737309\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 1900, Loss: 4.243e+03, Loss_bcs: 1.460e+00, Loss_res: 2.202e+01,Time: 0.00\n",
      " kurtosis_grad_res: 3.2759e+01\n",
      " kurtosis_grad_bcs: 6.4746e+01\n",
      "std_grad_bcs: 0.488295\n",
      "std_grad_res: 56.043640\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2000, Loss: 4.574e+03, Loss_bcs: 1.294e+00, Loss_res: 2.498e+01,Time: 0.01\n",
      " kurtosis_grad_res: 5.0220e+01\n",
      " kurtosis_grad_bcs: 6.8619e+01\n",
      "std_grad_bcs: 0.428255\n",
      "std_grad_res: 90.386940\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2100, Loss: 3.961e+03, Loss_bcs: 1.141e+00, Loss_res: 2.154e+01,Time: 0.00\n",
      " kurtosis_grad_res: 3.4320e+01\n",
      " kurtosis_grad_bcs: 6.3358e+01\n",
      "std_grad_bcs: 0.423931\n",
      "std_grad_res: 49.225201\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2200, Loss: 3.210e+03, Loss_bcs: 1.040e+00, Loss_res: 1.694e+01,Time: 0.01\n",
      " kurtosis_grad_res: 2.8648e+01\n",
      " kurtosis_grad_bcs: 5.2540e+01\n",
      "std_grad_bcs: 0.453197\n",
      "std_grad_res: 34.572849\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2300, Loss: 2.483e+03, Loss_bcs: 8.441e-01, Loss_res: 1.293e+01,Time: 0.01\n",
      " kurtosis_grad_res: 3.8807e+01\n",
      " kurtosis_grad_bcs: 5.2605e+01\n",
      "std_grad_bcs: 0.388679\n",
      "std_grad_res: 17.761612\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2400, Loss: 2.728e+03, Loss_bcs: 7.784e-01, Loss_res: 1.486e+01,Time: 0.01\n",
      " kurtosis_grad_res: 3.7585e+01\n",
      " kurtosis_grad_bcs: 5.9362e+01\n",
      "std_grad_bcs: 0.347746\n",
      "std_grad_res: 38.606865\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2500, Loss: 2.017e+03, Loss_bcs: 5.900e-01, Loss_res: 1.093e+01,Time: 0.01\n",
      " kurtosis_grad_res: 4.4486e+01\n",
      " kurtosis_grad_bcs: 4.8795e+01\n",
      "std_grad_bcs: 0.295693\n",
      "std_grad_res: 8.734031\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2600, Loss: 2.026e+03, Loss_bcs: 6.429e-01, Loss_res: 1.075e+01,Time: 0.00\n",
      " kurtosis_grad_res: 2.4496e+01\n",
      " kurtosis_grad_bcs: 5.4611e+01\n",
      "std_grad_bcs: 0.363170\n",
      "std_grad_res: 27.587847\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2700, Loss: 1.468e+03, Loss_bcs: 5.235e-01, Loss_res: 7.537e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.2543e+01\n",
      " kurtosis_grad_bcs: 4.8670e+01\n",
      "std_grad_bcs: 0.270046\n",
      "std_grad_res: 26.271769\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2800, Loss: 2.256e+03, Loss_bcs: 5.623e-01, Loss_res: 1.266e+01,Time: 0.01\n",
      " kurtosis_grad_res: 5.1102e+01\n",
      " kurtosis_grad_bcs: 5.4641e+01\n",
      "std_grad_bcs: 0.335923\n",
      "std_grad_res: 79.184029\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 2900, Loss: 1.591e+03, Loss_bcs: 3.964e-01, Loss_res: 8.926e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.0615e+01\n",
      " kurtosis_grad_bcs: 4.6800e+01\n",
      "std_grad_bcs: 0.258659\n",
      "std_grad_res: 32.088253\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3000, Loss: 1.855e+03, Loss_bcs: 3.934e-01, Loss_res: 1.071e+01,Time: 0.01\n",
      " kurtosis_grad_res: 2.3101e+01\n",
      " kurtosis_grad_bcs: 4.3323e+01\n",
      "std_grad_bcs: 0.270826\n",
      "std_grad_res: 38.007675\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3100, Loss: 1.403e+03, Loss_bcs: 3.375e-01, Loss_res: 7.922e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.4302e+01\n",
      " kurtosis_grad_bcs: 4.1980e+01\n",
      "std_grad_bcs: 0.199151\n",
      "std_grad_res: 21.361464\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3200, Loss: 1.630e+03, Loss_bcs: 3.442e-01, Loss_res: 9.414e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.5701e+01\n",
      " kurtosis_grad_bcs: 4.4354e+01\n",
      "std_grad_bcs: 0.241117\n",
      "std_grad_res: 39.582821\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3300, Loss: 1.095e+03, Loss_bcs: 3.365e-01, Loss_res: 5.860e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.8213e+01\n",
      " kurtosis_grad_bcs: 4.0613e+01\n",
      "std_grad_bcs: 0.185733\n",
      "std_grad_res: 25.620342\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3400, Loss: 1.649e+03, Loss_bcs: 3.078e-01, Loss_res: 9.703e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.0169e+01\n",
      " kurtosis_grad_bcs: 5.0434e+01\n",
      "std_grad_bcs: 0.198489\n",
      "std_grad_res: 70.033745\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3500, Loss: 8.830e+02, Loss_bcs: 2.628e-01, Loss_res: 4.763e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.2246e+01\n",
      " kurtosis_grad_bcs: 6.0402e+01\n",
      "std_grad_bcs: 0.175267\n",
      "std_grad_res: 14.691855\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3600, Loss: 1.298e+03, Loss_bcs: 2.468e-01, Loss_res: 7.620e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.3452e+01\n",
      " kurtosis_grad_bcs: 3.2477e+01\n",
      "std_grad_bcs: 0.162353\n",
      "std_grad_res: 42.639740\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3700, Loss: 1.336e+03, Loss_bcs: 2.792e-01, Loss_res: 7.731e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.5627e+01\n",
      " kurtosis_grad_bcs: 3.5301e+01\n",
      "std_grad_bcs: 0.172706\n",
      "std_grad_res: 39.708576\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3800, Loss: 8.384e+02, Loss_bcs: 2.351e-01, Loss_res: 4.587e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.5337e+01\n",
      " kurtosis_grad_bcs: 4.5252e+01\n",
      "std_grad_bcs: 0.198211\n",
      "std_grad_res: 11.752834\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 3900, Loss: 1.126e+03, Loss_bcs: 2.392e-01, Loss_res: 6.500e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.6990e+01\n",
      " kurtosis_grad_bcs: 5.8836e+01\n",
      "std_grad_bcs: 0.186374\n",
      "std_grad_res: 23.042955\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4000, Loss: 9.066e+02, Loss_bcs: 2.380e-01, Loss_res: 5.032e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.2879e+01\n",
      " kurtosis_grad_bcs: 3.6857e+01\n",
      "std_grad_bcs: 0.171231\n",
      "std_grad_res: 16.746817\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4100, Loss: 9.238e+02, Loss_bcs: 2.410e-01, Loss_res: 5.134e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.9366e+01\n",
      " kurtosis_grad_bcs: 4.4384e+01\n",
      "std_grad_bcs: 0.155880\n",
      "std_grad_res: 26.751492\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4200, Loss: 6.794e+02, Loss_bcs: 2.413e-01, Loss_res: 3.492e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.7896e+01\n",
      " kurtosis_grad_bcs: 4.1362e+01\n",
      "std_grad_bcs: 0.149529\n",
      "std_grad_res: 20.612280\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4300, Loss: 8.722e+02, Loss_bcs: 2.376e-01, Loss_res: 4.802e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.2876e+01\n",
      " kurtosis_grad_bcs: 5.0146e+01\n",
      "std_grad_bcs: 0.158123\n",
      "std_grad_res: 29.305964\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4400, Loss: 7.120e+02, Loss_bcs: 2.211e-01, Loss_res: 3.801e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.0516e+01\n",
      " kurtosis_grad_bcs: 4.5438e+01\n",
      "std_grad_bcs: 0.138082\n",
      "std_grad_res: 24.190401\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4500, Loss: 7.537e+02, Loss_bcs: 2.343e-01, Loss_res: 4.022e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.6939e+01\n",
      " kurtosis_grad_bcs: 6.0483e+01\n",
      "std_grad_bcs: 0.168633\n",
      "std_grad_res: 16.097914\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4600, Loss: 7.337e+02, Loss_bcs: 2.206e-01, Loss_res: 3.948e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.9698e+01\n",
      " kurtosis_grad_bcs: 4.3121e+01\n",
      "std_grad_bcs: 0.115477\n",
      "std_grad_res: 15.301822\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4700, Loss: 7.436e+02, Loss_bcs: 2.203e-01, Loss_res: 4.016e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.2258e+01\n",
      " kurtosis_grad_bcs: 3.3594e+01\n",
      "std_grad_bcs: 0.123961\n",
      "std_grad_res: 22.290936\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4800, Loss: 7.188e+02, Loss_bcs: 2.154e-01, Loss_res: 3.872e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.5560e+01\n",
      " kurtosis_grad_bcs: 3.4690e+01\n",
      "std_grad_bcs: 0.141648\n",
      "std_grad_res: 30.743086\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 4900, Loss: 5.412e+02, Loss_bcs: 2.076e-01, Loss_res: 2.715e+00,Time: 0.00\n",
      " kurtosis_grad_res: 4.0827e+01\n",
      " kurtosis_grad_bcs: 4.6559e+01\n",
      "std_grad_bcs: 0.105562\n",
      "std_grad_res: 11.476185\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5000, Loss: 6.863e+02, Loss_bcs: 2.083e-01, Loss_res: 3.684e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.9770e+01\n",
      " kurtosis_grad_bcs: 3.1047e+01\n",
      "std_grad_bcs: 0.112508\n",
      "std_grad_res: 22.394127\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5100, Loss: 7.846e+02, Loss_bcs: 2.002e-01, Loss_res: 4.380e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.4176e+01\n",
      " kurtosis_grad_bcs: 5.7848e+01\n",
      "std_grad_bcs: 0.103998\n",
      "std_grad_res: 25.472023\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5200, Loss: 6.929e+02, Loss_bcs: 1.873e-01, Loss_res: 3.822e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.4488e+01\n",
      " kurtosis_grad_bcs: 5.4676e+01\n",
      "std_grad_bcs: 0.097255\n",
      "std_grad_res: 28.825203\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5300, Loss: 6.388e+02, Loss_bcs: 1.890e-01, Loss_res: 3.451e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.3275e+01\n",
      " kurtosis_grad_bcs: 4.2054e+01\n",
      "std_grad_bcs: 0.103661\n",
      "std_grad_res: 23.818527\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5400, Loss: 5.700e+02, Loss_bcs: 1.750e-01, Loss_res: 3.051e+00,Time: 0.02\n",
      " kurtosis_grad_res: 2.5580e+01\n",
      " kurtosis_grad_bcs: 4.2877e+01\n",
      "std_grad_bcs: 0.117157\n",
      "std_grad_res: 21.408356\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5500, Loss: 5.650e+02, Loss_bcs: 1.669e-01, Loss_res: 3.054e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.9270e+01\n",
      " kurtosis_grad_bcs: 3.9477e+01\n",
      "std_grad_bcs: 0.077108\n",
      "std_grad_res: 24.203545\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5600, Loss: 6.972e+02, Loss_bcs: 1.825e-01, Loss_res: 3.872e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.0903e+01\n",
      " kurtosis_grad_bcs: 3.3979e+01\n",
      "std_grad_bcs: 0.130950\n",
      "std_grad_res: 44.004604\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5700, Loss: 7.505e+02, Loss_bcs: 1.814e-01, Loss_res: 4.234e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.3695e+01\n",
      " kurtosis_grad_bcs: 4.3951e+01\n",
      "std_grad_bcs: 0.096299\n",
      "std_grad_res: 33.753353\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5800, Loss: 5.389e+02, Loss_bcs: 1.725e-01, Loss_res: 2.854e+00,Time: 0.01\n",
      " kurtosis_grad_res: 1.8303e+01\n",
      " kurtosis_grad_bcs: 3.8622e+01\n",
      "std_grad_bcs: 0.100583\n",
      "std_grad_res: 24.166424\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 5900, Loss: 7.550e+02, Loss_bcs: 1.678e-01, Loss_res: 4.325e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.2298e+01\n",
      " kurtosis_grad_bcs: 4.3322e+01\n",
      "std_grad_bcs: 0.083711\n",
      "std_grad_res: 51.470753\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6000, Loss: 5.609e+02, Loss_bcs: 1.760e-01, Loss_res: 2.986e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.7351e+01\n",
      " kurtosis_grad_bcs: 3.3787e+01\n",
      "std_grad_bcs: 0.105325\n",
      "std_grad_res: 22.889050\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6100, Loss: 6.537e+02, Loss_bcs: 1.665e-01, Loss_res: 3.651e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.6424e+01\n",
      " kurtosis_grad_bcs: 3.6262e+01\n",
      "std_grad_bcs: 0.063851\n",
      "std_grad_res: 24.093998\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6200, Loss: 5.852e+02, Loss_bcs: 1.513e-01, Loss_res: 3.258e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.5281e+01\n",
      " kurtosis_grad_bcs: 5.8712e+01\n",
      "std_grad_bcs: 0.077655\n",
      "std_grad_res: 20.346216\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6300, Loss: 5.311e+02, Loss_bcs: 1.657e-01, Loss_res: 2.832e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.5940e+01\n",
      " kurtosis_grad_bcs: 3.3705e+01\n",
      "std_grad_bcs: 0.107169\n",
      "std_grad_res: 28.445274\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6400, Loss: 4.842e+02, Loss_bcs: 1.625e-01, Loss_res: 2.531e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.4717e+01\n",
      " kurtosis_grad_bcs: 3.5518e+01\n",
      "std_grad_bcs: 0.093649\n",
      "std_grad_res: 27.282837\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6500, Loss: 6.099e+02, Loss_bcs: 1.387e-01, Loss_res: 3.480e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.4631e+01\n",
      " kurtosis_grad_bcs: 5.3300e+01\n",
      "std_grad_bcs: 0.089035\n",
      "std_grad_res: 40.415264\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6600, Loss: 3.743e+02, Loss_bcs: 1.489e-01, Loss_res: 1.854e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.7359e+01\n",
      " kurtosis_grad_bcs: 4.2464e+01\n",
      "std_grad_bcs: 0.080374\n",
      "std_grad_res: 10.827251\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6700, Loss: 8.822e+02, Loss_bcs: 1.563e-01, Loss_res: 5.229e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.3938e+01\n",
      " kurtosis_grad_bcs: 4.1808e+01\n",
      "std_grad_bcs: 0.093956\n",
      "std_grad_res: 45.082527\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6800, Loss: 6.023e+02, Loss_bcs: 1.434e-01, Loss_res: 3.408e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.1678e+01\n",
      " kurtosis_grad_bcs: 3.4507e+01\n",
      "std_grad_bcs: 0.077963\n",
      "std_grad_res: 42.816223\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 6900, Loss: 4.174e+02, Loss_bcs: 1.459e-01, Loss_res: 2.156e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.4705e+01\n",
      " kurtosis_grad_bcs: 3.7124e+01\n",
      "std_grad_bcs: 0.082656\n",
      "std_grad_res: 16.217381\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7000, Loss: 6.312e+02, Loss_bcs: 1.466e-01, Loss_res: 3.587e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.5080e+01\n",
      " kurtosis_grad_bcs: 5.7980e+01\n",
      "std_grad_bcs: 0.086786\n",
      "std_grad_res: 32.769047\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7100, Loss: 7.267e+02, Loss_bcs: 1.483e-01, Loss_res: 4.221e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.5654e+01\n",
      " kurtosis_grad_bcs: 3.2531e+01\n",
      "std_grad_bcs: 0.085603\n",
      "std_grad_res: 26.407066\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7200, Loss: 3.452e+02, Loss_bcs: 1.223e-01, Loss_res: 1.776e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.0281e+01\n",
      " kurtosis_grad_bcs: 3.7179e+01\n",
      "std_grad_bcs: 0.067049\n",
      "std_grad_res: 8.038868\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7300, Loss: 5.109e+02, Loss_bcs: 1.307e-01, Loss_res: 2.851e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.8509e+01\n",
      " kurtosis_grad_bcs: 5.8266e+01\n",
      "std_grad_bcs: 0.076572\n",
      "std_grad_res: 8.032775\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7400, Loss: 3.282e+02, Loss_bcs: 1.229e-01, Loss_res: 1.659e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.7535e+01\n",
      " kurtosis_grad_bcs: 4.3376e+01\n",
      "std_grad_bcs: 0.092348\n",
      "std_grad_res: 7.832150\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7500, Loss: 5.135e+02, Loss_bcs: 1.344e-01, Loss_res: 2.852e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.3880e+01\n",
      " kurtosis_grad_bcs: 5.2501e+01\n",
      "std_grad_bcs: 0.080289\n",
      "std_grad_res: 13.391704\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7600, Loss: 4.002e+02, Loss_bcs: 1.321e-01, Loss_res: 2.101e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.5845e+01\n",
      " kurtosis_grad_bcs: 4.7726e+01\n",
      "std_grad_bcs: 0.083095\n",
      "std_grad_res: 16.170580\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7700, Loss: 4.828e+02, Loss_bcs: 1.160e-01, Loss_res: 2.727e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.6074e+01\n",
      " kurtosis_grad_bcs: 6.6031e+01\n",
      "std_grad_bcs: 0.079862\n",
      "std_grad_res: 15.640754\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7800, Loss: 4.379e+02, Loss_bcs: 1.366e-01, Loss_res: 2.335e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.9333e+01\n",
      " kurtosis_grad_bcs: 2.6961e+01\n",
      "std_grad_bcs: 0.075198\n",
      "std_grad_res: 15.766657\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 7900, Loss: 3.562e+02, Loss_bcs: 1.206e-01, Loss_res: 1.858e+00,Time: 0.02\n",
      " kurtosis_grad_res: 2.6533e+01\n",
      " kurtosis_grad_bcs: 2.9564e+01\n",
      "std_grad_bcs: 0.077963\n",
      "std_grad_res: 23.382198\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8000, Loss: 3.357e+02, Loss_bcs: 1.132e-01, Loss_res: 1.753e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.8721e+01\n",
      " kurtosis_grad_bcs: 2.8707e+01\n",
      "std_grad_bcs: 0.069926\n",
      "std_grad_res: 11.166366\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8100, Loss: 4.409e+02, Loss_bcs: 1.397e-01, Loss_res: 2.342e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.6936e+01\n",
      " kurtosis_grad_bcs: 3.8934e+01\n",
      "std_grad_bcs: 0.073355\n",
      "std_grad_res: 17.406374\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8200, Loss: 2.834e+02, Loss_bcs: 1.210e-01, Loss_res: 1.367e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.0513e+01\n",
      " kurtosis_grad_bcs: 4.5235e+01\n",
      "std_grad_bcs: 0.063219\n",
      "std_grad_res: 13.416369\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8300, Loss: 4.343e+02, Loss_bcs: 1.165e-01, Loss_res: 2.400e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.1566e+01\n",
      " kurtosis_grad_bcs: 3.0487e+01\n",
      "std_grad_bcs: 0.063167\n",
      "std_grad_res: 21.793983\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8400, Loss: 2.712e+02, Loss_bcs: 1.201e-01, Loss_res: 1.289e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.9672e+01\n",
      " kurtosis_grad_bcs: 3.2966e+01\n",
      "std_grad_bcs: 0.061206\n",
      "std_grad_res: 9.067374\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8500, Loss: 3.907e+02, Loss_bcs: 1.158e-01, Loss_res: 2.110e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.6612e+01\n",
      " kurtosis_grad_bcs: 3.0399e+01\n",
      "std_grad_bcs: 0.054017\n",
      "std_grad_res: 14.596691\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8600, Loss: 5.176e+02, Loss_bcs: 1.036e-01, Loss_res: 3.015e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.3145e+01\n",
      " kurtosis_grad_bcs: 3.1019e+01\n",
      "std_grad_bcs: 0.052543\n",
      "std_grad_res: 37.007465\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8700, Loss: 3.391e+02, Loss_bcs: 1.041e-01, Loss_res: 1.815e+00,Time: 0.02\n",
      " kurtosis_grad_res: 2.6396e+01\n",
      " kurtosis_grad_bcs: 4.4477e+01\n",
      "std_grad_bcs: 0.059896\n",
      "std_grad_res: 12.668818\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8800, Loss: 5.106e+02, Loss_bcs: 1.070e-01, Loss_res: 2.953e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.1018e+01\n",
      " kurtosis_grad_bcs: 2.9249e+01\n",
      "std_grad_bcs: 0.059139\n",
      "std_grad_res: 41.693703\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 8900, Loss: 3.035e+02, Loss_bcs: 1.023e-01, Loss_res: 1.585e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.8613e+01\n",
      " kurtosis_grad_bcs: 5.4854e+01\n",
      "std_grad_bcs: 0.057036\n",
      "std_grad_res: 12.925283\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9000, Loss: 3.133e+02, Loss_bcs: 1.111e-01, Loss_res: 1.611e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.6483e+01\n",
      " kurtosis_grad_bcs: 3.4249e+01\n",
      "std_grad_bcs: 0.077400\n",
      "std_grad_res: 19.026020\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9100, Loss: 3.577e+02, Loss_bcs: 1.113e-01, Loss_res: 1.908e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.8631e+01\n",
      " kurtosis_grad_bcs: 4.6853e+01\n",
      "std_grad_bcs: 0.067079\n",
      "std_grad_res: 11.737139\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9200, Loss: 4.094e+02, Loss_bcs: 1.265e-01, Loss_res: 2.188e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.4131e+01\n",
      " kurtosis_grad_bcs: 3.6565e+01\n",
      "std_grad_bcs: 0.078901\n",
      "std_grad_res: 22.985231\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9300, Loss: 3.134e+02, Loss_bcs: 1.083e-01, Loss_res: 1.624e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.2890e+01\n",
      " kurtosis_grad_bcs: 3.2609e+01\n",
      "std_grad_bcs: 0.048430\n",
      "std_grad_res: 16.594652\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9400, Loss: 2.762e+02, Loss_bcs: 1.099e-01, Loss_res: 1.368e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.1163e+01\n",
      " kurtosis_grad_bcs: 5.5208e+01\n",
      "std_grad_bcs: 0.054070\n",
      "std_grad_res: 5.578922\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9500, Loss: 3.741e+02, Loss_bcs: 1.133e-01, Loss_res: 2.010e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.2046e+01\n",
      " kurtosis_grad_bcs: 3.8353e+01\n",
      "std_grad_bcs: 0.068614\n",
      "std_grad_res: 12.902500\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9600, Loss: 3.851e+02, Loss_bcs: 9.019e-02, Loss_res: 2.186e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.0476e+01\n",
      " kurtosis_grad_bcs: 4.0008e+01\n",
      "std_grad_bcs: 0.058627\n",
      "std_grad_res: 18.257851\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9700, Loss: 3.058e+02, Loss_bcs: 8.854e-02, Loss_res: 1.661e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.7224e+01\n",
      " kurtosis_grad_bcs: 4.2884e+01\n",
      "std_grad_bcs: 0.064000\n",
      "std_grad_res: 11.611902\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9800, Loss: 3.132e+02, Loss_bcs: 1.129e-01, Loss_res: 1.603e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.6168e+01\n",
      " kurtosis_grad_bcs: 4.2004e+01\n",
      "std_grad_bcs: 0.044497\n",
      "std_grad_res: 12.724954\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 9900, Loss: 3.319e+02, Loss_bcs: 9.622e-02, Loss_res: 1.802e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.1977e+01\n",
      " kurtosis_grad_bcs: 2.8433e+01\n",
      "std_grad_bcs: 0.057662\n",
      "std_grad_res: 13.434958\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10000, Loss: 3.016e+02, Loss_bcs: 9.692e-02, Loss_res: 1.595e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.3101e+01\n",
      " kurtosis_grad_bcs: 2.9586e+01\n",
      "std_grad_bcs: 0.045947\n",
      "std_grad_res: 12.266188\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10100, Loss: 3.157e+02, Loss_bcs: 9.335e-02, Loss_res: 1.706e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.3272e+01\n",
      " kurtosis_grad_bcs: 6.3132e+01\n",
      "std_grad_bcs: 0.067393\n",
      "std_grad_res: 11.542929\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10200, Loss: 2.831e+02, Loss_bcs: 8.781e-02, Loss_res: 1.512e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.5424e+01\n",
      " kurtosis_grad_bcs: 4.1578e+01\n",
      "std_grad_bcs: 0.067846\n",
      "std_grad_res: 11.792820\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10300, Loss: 2.299e+02, Loss_bcs: 9.202e-02, Loss_res: 1.136e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.7320e+01\n",
      " kurtosis_grad_bcs: 3.8650e+01\n",
      "std_grad_bcs: 0.035161\n",
      "std_grad_res: 9.475950\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10400, Loss: 3.636e+02, Loss_bcs: 8.816e-02, Loss_res: 2.050e+00,Time: 0.00\n",
      " kurtosis_grad_res: 4.1006e+01\n",
      " kurtosis_grad_bcs: 4.1142e+01\n",
      "std_grad_bcs: 0.067763\n",
      "std_grad_res: 31.714787\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10500, Loss: 4.788e+02, Loss_bcs: 9.052e-02, Loss_res: 2.813e+00,Time: 0.00\n",
      " kurtosis_grad_res: 4.7860e+01\n",
      " kurtosis_grad_bcs: 5.6581e+01\n",
      "std_grad_bcs: 0.066589\n",
      "std_grad_res: 26.912310\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10600, Loss: 2.563e+02, Loss_bcs: 1.017e-01, Loss_res: 1.271e+00,Time: 0.00\n",
      " kurtosis_grad_res: 4.8357e+01\n",
      " kurtosis_grad_bcs: 3.2064e+01\n",
      "std_grad_bcs: 0.050735\n",
      "std_grad_res: 20.666332\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10700, Loss: 2.745e+02, Loss_bcs: 1.044e-01, Loss_res: 1.380e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.9490e+01\n",
      " kurtosis_grad_bcs: 5.9744e+01\n",
      "std_grad_bcs: 0.069323\n",
      "std_grad_res: 19.685087\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10800, Loss: 3.364e+02, Loss_bcs: 1.016e-01, Loss_res: 1.809e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.2204e+01\n",
      " kurtosis_grad_bcs: 6.8951e+01\n",
      "std_grad_bcs: 0.081807\n",
      "std_grad_res: 20.211052\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 10900, Loss: 2.674e+02, Loss_bcs: 8.807e-02, Loss_res: 1.405e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.1536e+01\n",
      " kurtosis_grad_bcs: 5.3555e+01\n",
      "std_grad_bcs: 0.055821\n",
      "std_grad_res: 14.947914\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11000, Loss: 3.454e+02, Loss_bcs: 8.204e-02, Loss_res: 1.955e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.4948e+01\n",
      " kurtosis_grad_bcs: 3.2490e+01\n",
      "std_grad_bcs: 0.060429\n",
      "std_grad_res: 15.853822\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11100, Loss: 3.101e+02, Loss_bcs: 8.837e-02, Loss_res: 1.690e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.9060e+01\n",
      " kurtosis_grad_bcs: 3.9877e+01\n",
      "std_grad_bcs: 0.062140\n",
      "std_grad_res: 24.391024\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11200, Loss: 2.770e+02, Loss_bcs: 8.457e-02, Loss_res: 1.485e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.2765e+01\n",
      " kurtosis_grad_bcs: 2.9420e+01\n",
      "std_grad_bcs: 0.056203\n",
      "std_grad_res: 10.937781\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11300, Loss: 2.452e+02, Loss_bcs: 9.681e-02, Loss_res: 1.218e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.4301e+01\n",
      " kurtosis_grad_bcs: 4.0032e+01\n",
      "std_grad_bcs: 0.038724\n",
      "std_grad_res: 12.869385\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11400, Loss: 2.158e+02, Loss_bcs: 8.482e-02, Loss_res: 1.073e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.8610e+01\n",
      " kurtosis_grad_bcs: 3.3456e+01\n",
      "std_grad_bcs: 0.043461\n",
      "std_grad_res: 17.351120\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11500, Loss: 3.348e+02, Loss_bcs: 9.346e-02, Loss_res: 1.834e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.4405e+01\n",
      " kurtosis_grad_bcs: 3.3996e+01\n",
      "std_grad_bcs: 0.052340\n",
      "std_grad_res: 30.491737\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11600, Loss: 3.387e+02, Loss_bcs: 8.080e-02, Loss_res: 1.916e+00,Time: 0.00\n",
      " kurtosis_grad_res: 5.2884e+01\n",
      " kurtosis_grad_bcs: 3.4618e+01\n",
      "std_grad_bcs: 0.043758\n",
      "std_grad_res: 22.584690\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11700, Loss: 2.011e+02, Loss_bcs: 8.627e-02, Loss_res: 9.679e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7073e+01\n",
      " kurtosis_grad_bcs: 3.7317e+01\n",
      "std_grad_bcs: 0.051741\n",
      "std_grad_res: 9.260351\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11800, Loss: 2.276e+02, Loss_bcs: 8.583e-02, Loss_res: 1.148e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.1046e+01\n",
      " kurtosis_grad_bcs: 4.5950e+01\n",
      "std_grad_bcs: 0.054287\n",
      "std_grad_res: 9.508745\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 11900, Loss: 2.737e+02, Loss_bcs: 8.734e-02, Loss_res: 1.451e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.2993e+01\n",
      " kurtosis_grad_bcs: 5.7471e+01\n",
      "std_grad_bcs: 0.054226\n",
      "std_grad_res: 17.843357\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12000, Loss: 2.386e+02, Loss_bcs: 1.011e-01, Loss_res: 1.154e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.7569e+01\n",
      " kurtosis_grad_bcs: 4.9133e+01\n",
      "std_grad_bcs: 0.052654\n",
      "std_grad_res: 11.244503\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12100, Loss: 1.726e+02, Loss_bcs: 8.056e-02, Loss_res: 8.025e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.7154e+01\n",
      " kurtosis_grad_bcs: 3.2658e+01\n",
      "std_grad_bcs: 0.049339\n",
      "std_grad_res: 6.870998\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12200, Loss: 3.816e+02, Loss_bcs: 8.244e-02, Loss_res: 2.196e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.3712e+01\n",
      " kurtosis_grad_bcs: 3.0304e+01\n",
      "std_grad_bcs: 0.049252\n",
      "std_grad_res: 13.395321\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12300, Loss: 2.364e+02, Loss_bcs: 7.765e-02, Loss_res: 1.243e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.1596e+01\n",
      " kurtosis_grad_bcs: 3.5909e+01\n",
      "std_grad_bcs: 0.042373\n",
      "std_grad_res: 10.797532\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12400, Loss: 2.537e+02, Loss_bcs: 9.021e-02, Loss_res: 1.304e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.7615e+01\n",
      " kurtosis_grad_bcs: 5.5914e+01\n",
      "std_grad_bcs: 0.053980\n",
      "std_grad_res: 18.329792\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12500, Loss: 2.127e+02, Loss_bcs: 8.114e-02, Loss_res: 1.069e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.5909e+01\n",
      " kurtosis_grad_bcs: 3.9486e+01\n",
      "std_grad_bcs: 0.045892\n",
      "std_grad_res: 8.719362\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12600, Loss: 3.040e+02, Loss_bcs: 7.186e-02, Loss_res: 1.722e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.3987e+01\n",
      " kurtosis_grad_bcs: 3.0934e+01\n",
      "std_grad_bcs: 0.050050\n",
      "std_grad_res: 17.585377\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12700, Loss: 3.399e+02, Loss_bcs: 7.561e-02, Loss_res: 1.946e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.2337e+01\n",
      " kurtosis_grad_bcs: 3.5017e+01\n",
      "std_grad_bcs: 0.048529\n",
      "std_grad_res: 31.253271\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12800, Loss: 2.364e+02, Loss_bcs: 8.858e-02, Loss_res: 1.195e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.3693e+01\n",
      " kurtosis_grad_bcs: 4.3358e+01\n",
      "std_grad_bcs: 0.059374\n",
      "std_grad_res: 14.490659\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 12900, Loss: 1.838e+02, Loss_bcs: 7.821e-02, Loss_res: 8.874e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7214e+01\n",
      " kurtosis_grad_bcs: 3.0383e+01\n",
      "std_grad_bcs: 0.032254\n",
      "std_grad_res: 10.821144\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13000, Loss: 3.214e+02, Loss_bcs: 7.401e-02, Loss_res: 1.830e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.8693e+01\n",
      " kurtosis_grad_bcs: 7.3882e+01\n",
      "std_grad_bcs: 0.066187\n",
      "std_grad_res: 17.465395\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13100, Loss: 1.810e+02, Loss_bcs: 7.731e-02, Loss_res: 8.726e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.4021e+01\n",
      " kurtosis_grad_bcs: 4.4139e+01\n",
      "std_grad_bcs: 0.056889\n",
      "std_grad_res: 8.028494\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13200, Loss: 1.996e+02, Loss_bcs: 8.450e-02, Loss_res: 9.659e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.8778e+01\n",
      " kurtosis_grad_bcs: 3.8608e+01\n",
      "std_grad_bcs: 0.054104\n",
      "std_grad_res: 12.120019\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13300, Loss: 1.845e+02, Loss_bcs: 7.331e-02, Loss_res: 9.142e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.7392e+01\n",
      " kurtosis_grad_bcs: 3.5807e+01\n",
      "std_grad_bcs: 0.051909\n",
      "std_grad_res: 8.144730\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13400, Loss: 2.282e+02, Loss_bcs: 6.937e-02, Loss_res: 1.225e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.0115e+01\n",
      " kurtosis_grad_bcs: 3.8051e+01\n",
      "std_grad_bcs: 0.046715\n",
      "std_grad_res: 13.989180\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13500, Loss: 1.470e+02, Loss_bcs: 7.518e-02, Loss_res: 6.539e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.5598e+01\n",
      " kurtosis_grad_bcs: 3.3586e+01\n",
      "std_grad_bcs: 0.034144\n",
      "std_grad_res: 5.382864\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13600, Loss: 2.047e+02, Loss_bcs: 8.256e-02, Loss_res: 1.009e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.8856e+01\n",
      " kurtosis_grad_bcs: 3.6190e+01\n",
      "std_grad_bcs: 0.042721\n",
      "std_grad_res: 8.979828\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13700, Loss: 2.536e+02, Loss_bcs: 7.330e-02, Loss_res: 1.377e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.4107e+01\n",
      " kurtosis_grad_bcs: 4.7916e+01\n",
      "std_grad_bcs: 0.030917\n",
      "std_grad_res: 18.809515\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13800, Loss: 1.713e+02, Loss_bcs: 6.793e-02, Loss_res: 8.496e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9414e+01\n",
      " kurtosis_grad_bcs: 3.0367e+01\n",
      "std_grad_bcs: 0.051573\n",
      "std_grad_res: 14.423616\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 13900, Loss: 2.558e+02, Loss_bcs: 6.920e-02, Loss_res: 1.410e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.7642e+01\n",
      " kurtosis_grad_bcs: 5.8780e+01\n",
      "std_grad_bcs: 0.043041\n",
      "std_grad_res: 17.822170\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14000, Loss: 2.120e+02, Loss_bcs: 6.441e-02, Loss_res: 1.138e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.0102e+01\n",
      " kurtosis_grad_bcs: 5.4263e+01\n",
      "std_grad_bcs: 0.056654\n",
      "std_grad_res: 7.850726\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14100, Loss: 2.001e+02, Loss_bcs: 7.197e-02, Loss_res: 1.025e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.2089e+01\n",
      " kurtosis_grad_bcs: 6.4839e+01\n",
      "std_grad_bcs: 0.044830\n",
      "std_grad_res: 26.345724\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14200, Loss: 2.170e+02, Loss_bcs: 6.923e-02, Loss_res: 1.150e+00,Time: 0.00\n",
      " kurtosis_grad_res: 4.7534e+01\n",
      " kurtosis_grad_bcs: 4.2787e+01\n",
      "std_grad_bcs: 0.050870\n",
      "std_grad_res: 12.167532\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14300, Loss: 1.951e+02, Loss_bcs: 7.499e-02, Loss_res: 9.776e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.2570e+01\n",
      " kurtosis_grad_bcs: 4.3823e+01\n",
      "std_grad_bcs: 0.066357\n",
      "std_grad_res: 15.149295\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14400, Loss: 2.024e+02, Loss_bcs: 7.671e-02, Loss_res: 1.019e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.6915e+01\n",
      " kurtosis_grad_bcs: 4.8691e+01\n",
      "std_grad_bcs: 0.050828\n",
      "std_grad_res: 9.835561\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14500, Loss: 2.704e+02, Loss_bcs: 6.124e-02, Loss_res: 1.543e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.1200e+01\n",
      " kurtosis_grad_bcs: 3.0752e+01\n",
      "std_grad_bcs: 0.039735\n",
      "std_grad_res: 12.148984\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14600, Loss: 1.669e+02, Loss_bcs: 6.905e-02, Loss_res: 8.148e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.6342e+01\n",
      " kurtosis_grad_bcs: 4.0121e+01\n",
      "std_grad_bcs: 0.033904\n",
      "std_grad_res: 10.365592\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14700, Loss: 2.739e+02, Loss_bcs: 6.874e-02, Loss_res: 1.534e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.4172e+01\n",
      " kurtosis_grad_bcs: 4.9818e+01\n",
      "std_grad_bcs: 0.043468\n",
      "std_grad_res: 16.441267\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14800, Loss: 1.879e+02, Loss_bcs: 6.957e-02, Loss_res: 9.536e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.3757e+01\n",
      " kurtosis_grad_bcs: 3.1432e+01\n",
      "std_grad_bcs: 0.048141\n",
      "std_grad_res: 15.308858\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 14900, Loss: 1.609e+02, Loss_bcs: 7.201e-02, Loss_res: 7.616e-01,Time: 0.00\n",
      " kurtosis_grad_res: 7.4198e+01\n",
      " kurtosis_grad_bcs: 3.0726e+01\n",
      "std_grad_bcs: 0.039297\n",
      "std_grad_res: 5.761457\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15000, Loss: 1.699e+02, Loss_bcs: 6.521e-02, Loss_res: 8.516e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.3686e+01\n",
      " kurtosis_grad_bcs: 3.1875e+01\n",
      "std_grad_bcs: 0.043055\n",
      "std_grad_res: 11.122075\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15100, Loss: 2.291e+02, Loss_bcs: 7.899e-02, Loss_res: 1.188e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.6980e+01\n",
      " kurtosis_grad_bcs: 4.2401e+01\n",
      "std_grad_bcs: 0.037235\n",
      "std_grad_res: 18.756239\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15200, Loss: 2.164e+02, Loss_bcs: 5.716e-02, Loss_res: 1.199e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.3941e+01\n",
      " kurtosis_grad_bcs: 5.6005e+01\n",
      "std_grad_bcs: 0.041095\n",
      "std_grad_res: 14.565021\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15300, Loss: 1.628e+02, Loss_bcs: 6.507e-02, Loss_res: 8.050e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.7841e+01\n",
      " kurtosis_grad_bcs: 2.8563e+01\n",
      "std_grad_bcs: 0.043105\n",
      "std_grad_res: 12.437708\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15400, Loss: 1.908e+02, Loss_bcs: 6.850e-02, Loss_res: 9.778e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9810e+01\n",
      " kurtosis_grad_bcs: 3.3614e+01\n",
      "std_grad_bcs: 0.043493\n",
      "std_grad_res: 13.990845\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15500, Loss: 2.060e+02, Loss_bcs: 6.992e-02, Loss_res: 1.073e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.2425e+01\n",
      " kurtosis_grad_bcs: 4.9142e+01\n",
      "std_grad_bcs: 0.040004\n",
      "std_grad_res: 17.944218\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15600, Loss: 1.775e+02, Loss_bcs: 6.090e-02, Loss_res: 9.219e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.1151e+01\n",
      " kurtosis_grad_bcs: 3.1814e+01\n",
      "std_grad_bcs: 0.038415\n",
      "std_grad_res: 16.840712\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15700, Loss: 1.705e+02, Loss_bcs: 6.494e-02, Loss_res: 8.569e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.3186e+01\n",
      " kurtosis_grad_bcs: 3.8404e+01\n",
      "std_grad_bcs: 0.039784\n",
      "std_grad_res: 8.314445\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15800, Loss: 1.726e+02, Loss_bcs: 6.407e-02, Loss_res: 8.748e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9194e+01\n",
      " kurtosis_grad_bcs: 5.8675e+01\n",
      "std_grad_bcs: 0.055840\n",
      "std_grad_res: 15.312185\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 15900, Loss: 1.542e+02, Loss_bcs: 5.918e-02, Loss_res: 7.731e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5595e+01\n",
      " kurtosis_grad_bcs: 5.7232e+01\n",
      "std_grad_bcs: 0.051634\n",
      "std_grad_res: 8.490123\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16000, Loss: 1.917e+02, Loss_bcs: 6.230e-02, Loss_res: 1.011e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.2642e+01\n",
      " kurtosis_grad_bcs: 3.8460e+01\n",
      "std_grad_bcs: 0.046348\n",
      "std_grad_res: 15.768146\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16100, Loss: 1.770e+02, Loss_bcs: 6.649e-02, Loss_res: 8.936e-01,Time: 0.01\n",
      " kurtosis_grad_res: 1.9993e+01\n",
      " kurtosis_grad_bcs: 3.2106e+01\n",
      "std_grad_bcs: 0.042323\n",
      "std_grad_res: 12.208696\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16200, Loss: 2.279e+02, Loss_bcs: 6.387e-02, Loss_res: 1.247e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.1520e+01\n",
      " kurtosis_grad_bcs: 3.7523e+01\n",
      "std_grad_bcs: 0.050422\n",
      "std_grad_res: 12.558819\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16300, Loss: 2.513e+02, Loss_bcs: 7.523e-02, Loss_res: 1.354e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.5405e+01\n",
      " kurtosis_grad_bcs: 4.4220e+01\n",
      "std_grad_bcs: 0.041456\n",
      "std_grad_res: 10.527103\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16400, Loss: 2.403e+02, Loss_bcs: 7.676e-02, Loss_res: 1.273e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.3257e+01\n",
      " kurtosis_grad_bcs: 4.8083e+01\n",
      "std_grad_bcs: 0.046076\n",
      "std_grad_res: 9.252601\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16500, Loss: 1.736e+02, Loss_bcs: 6.269e-02, Loss_res: 8.876e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.0210e+01\n",
      " kurtosis_grad_bcs: 2.8331e+01\n",
      "std_grad_bcs: 0.047821\n",
      "std_grad_res: 5.776543\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16600, Loss: 2.183e+02, Loss_bcs: 6.095e-02, Loss_res: 1.196e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.2086e+01\n",
      " kurtosis_grad_bcs: 3.5491e+01\n",
      "std_grad_bcs: 0.040375\n",
      "std_grad_res: 14.335570\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16700, Loss: 1.986e+02, Loss_bcs: 5.898e-02, Loss_res: 1.072e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.7260e+01\n",
      " kurtosis_grad_bcs: 6.5260e+01\n",
      "std_grad_bcs: 0.052622\n",
      "std_grad_res: 17.352249\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16800, Loss: 1.805e+02, Loss_bcs: 5.990e-02, Loss_res: 9.462e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.9206e+01\n",
      " kurtosis_grad_bcs: 4.7914e+01\n",
      "std_grad_bcs: 0.045310\n",
      "std_grad_res: 14.824174\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 16900, Loss: 1.499e+02, Loss_bcs: 6.629e-02, Loss_res: 7.131e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9688e+01\n",
      " kurtosis_grad_bcs: 5.8564e+01\n",
      "std_grad_bcs: 0.042991\n",
      "std_grad_res: 11.478648\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17000, Loss: 1.681e+02, Loss_bcs: 5.481e-02, Loss_res: 8.858e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.5472e+01\n",
      " kurtosis_grad_bcs: 3.9941e+01\n",
      "std_grad_bcs: 0.056785\n",
      "std_grad_res: 9.918998\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17100, Loss: 1.509e+02, Loss_bcs: 7.124e-02, Loss_res: 6.979e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.1073e+01\n",
      " kurtosis_grad_bcs: 4.5269e+01\n",
      "std_grad_bcs: 0.043106\n",
      "std_grad_res: 9.807931\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17200, Loss: 1.384e+02, Loss_bcs: 6.590e-02, Loss_res: 6.378e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4774e+01\n",
      " kurtosis_grad_bcs: 5.2101e+01\n",
      "std_grad_bcs: 0.044754\n",
      "std_grad_res: 9.905338\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17300, Loss: 1.619e+02, Loss_bcs: 6.177e-02, Loss_res: 8.134e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1581e+01\n",
      " kurtosis_grad_bcs: 6.7855e+01\n",
      "std_grad_bcs: 0.065354\n",
      "std_grad_res: 10.440310\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17400, Loss: 1.337e+02, Loss_bcs: 6.086e-02, Loss_res: 6.283e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.4800e+01\n",
      " kurtosis_grad_bcs: 4.0260e+01\n",
      "std_grad_bcs: 0.052640\n",
      "std_grad_res: 10.174175\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17500, Loss: 1.440e+02, Loss_bcs: 6.139e-02, Loss_res: 6.951e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4233e+01\n",
      " kurtosis_grad_bcs: 3.3468e+01\n",
      "std_grad_bcs: 0.040848\n",
      "std_grad_res: 5.479340\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17600, Loss: 1.268e+02, Loss_bcs: 6.055e-02, Loss_res: 5.834e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.3520e+01\n",
      " kurtosis_grad_bcs: 3.6081e+01\n",
      "std_grad_bcs: 0.040523\n",
      "std_grad_res: 8.759226\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17700, Loss: 2.171e+02, Loss_bcs: 4.867e-02, Loss_res: 1.242e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.1388e+01\n",
      " kurtosis_grad_bcs: 3.7068e+01\n",
      "std_grad_bcs: 0.044921\n",
      "std_grad_res: 12.855462\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17800, Loss: 2.390e+02, Loss_bcs: 6.353e-02, Loss_res: 1.323e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.6931e+01\n",
      " kurtosis_grad_bcs: 6.0576e+01\n",
      "std_grad_bcs: 0.047807\n",
      "std_grad_res: 29.389788\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 17900, Loss: 1.360e+02, Loss_bcs: 5.702e-02, Loss_res: 6.604e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.2743e+01\n",
      " kurtosis_grad_bcs: 3.8142e+01\n",
      "std_grad_bcs: 0.034140\n",
      "std_grad_res: 10.121525\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18000, Loss: 1.313e+02, Loss_bcs: 5.774e-02, Loss_res: 6.261e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.1909e+01\n",
      " kurtosis_grad_bcs: 4.2309e+01\n",
      "std_grad_bcs: 0.037260\n",
      "std_grad_res: 8.288929\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18100, Loss: 2.135e+02, Loss_bcs: 6.276e-02, Loss_res: 1.155e+00,Time: 0.02\n",
      " kurtosis_grad_res: 3.1147e+01\n",
      " kurtosis_grad_bcs: 4.9362e+01\n",
      "std_grad_bcs: 0.026641\n",
      "std_grad_res: 7.956233\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18200, Loss: 1.304e+02, Loss_bcs: 5.648e-02, Loss_res: 6.255e-01,Time: 0.01\n",
      " kurtosis_grad_res: 7.0710e+01\n",
      " kurtosis_grad_bcs: 3.0728e+01\n",
      "std_grad_bcs: 0.042378\n",
      "std_grad_res: 3.385572\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18300, Loss: 1.215e+02, Loss_bcs: 6.621e-02, Loss_res: 5.225e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9034e+01\n",
      " kurtosis_grad_bcs: 4.8878e+01\n",
      "std_grad_bcs: 0.029683\n",
      "std_grad_res: 7.573905\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18400, Loss: 1.578e+02, Loss_bcs: 5.119e-02, Loss_res: 8.327e-01,Time: 0.00\n",
      " kurtosis_grad_res: 2.2706e+01\n",
      " kurtosis_grad_bcs: 3.7766e+01\n",
      "std_grad_bcs: 0.043492\n",
      "std_grad_res: 18.609123\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18500, Loss: 2.347e+02, Loss_bcs: 6.127e-02, Loss_res: 1.304e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.0535e+01\n",
      " kurtosis_grad_bcs: 5.0514e+01\n",
      "std_grad_bcs: 0.038487\n",
      "std_grad_res: 20.201210\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18600, Loss: 1.811e+02, Loss_bcs: 5.634e-02, Loss_res: 9.662e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1445e+01\n",
      " kurtosis_grad_bcs: 4.1238e+01\n",
      "std_grad_bcs: 0.037644\n",
      "std_grad_res: 9.866513\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18700, Loss: 1.512e+02, Loss_bcs: 5.529e-02, Loss_res: 7.705e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1197e+01\n",
      " kurtosis_grad_bcs: 4.0195e+01\n",
      "std_grad_bcs: 0.039810\n",
      "std_grad_res: 10.194058\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18800, Loss: 1.545e+02, Loss_bcs: 6.341e-02, Loss_res: 7.564e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7766e+01\n",
      " kurtosis_grad_bcs: 6.1703e+01\n",
      "std_grad_bcs: 0.032588\n",
      "std_grad_res: 12.765304\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 18900, Loss: 1.269e+02, Loss_bcs: 5.030e-02, Loss_res: 6.295e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.3812e+01\n",
      " kurtosis_grad_bcs: 4.3649e+01\n",
      "std_grad_bcs: 0.059911\n",
      "std_grad_res: 9.569095\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19000, Loss: 1.252e+02, Loss_bcs: 5.176e-02, Loss_res: 6.113e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1106e+01\n",
      " kurtosis_grad_bcs: 4.0891e+01\n",
      "std_grad_bcs: 0.027898\n",
      "std_grad_res: 10.019500\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19100, Loss: 1.814e+02, Loss_bcs: 5.704e-02, Loss_res: 9.655e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.2653e+01\n",
      " kurtosis_grad_bcs: 4.6786e+01\n",
      "std_grad_bcs: 0.053128\n",
      "std_grad_res: 13.644649\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19200, Loss: 1.625e+02, Loss_bcs: 5.586e-02, Loss_res: 8.435e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7211e+01\n",
      " kurtosis_grad_bcs: 5.4962e+01\n",
      "std_grad_bcs: 0.036265\n",
      "std_grad_res: 9.612326\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19300, Loss: 3.248e+02, Loss_bcs: 5.332e-02, Loss_res: 1.944e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.0836e+01\n",
      " kurtosis_grad_bcs: 5.6661e+01\n",
      "std_grad_bcs: 0.042999\n",
      "std_grad_res: 22.782158\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19400, Loss: 1.945e+02, Loss_bcs: 5.986e-02, Loss_res: 1.040e+00,Time: 0.00\n",
      " kurtosis_grad_res: 4.6909e+01\n",
      " kurtosis_grad_bcs: 3.6009e+01\n",
      "std_grad_bcs: 0.034912\n",
      "std_grad_res: 11.668205\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19500, Loss: 1.685e+02, Loss_bcs: 5.907e-02, Loss_res: 8.699e-01,Time: 0.00\n",
      " kurtosis_grad_res: 2.0510e+01\n",
      " kurtosis_grad_bcs: 4.5803e+01\n",
      "std_grad_bcs: 0.033176\n",
      "std_grad_res: 9.588294\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19600, Loss: 1.346e+02, Loss_bcs: 5.627e-02, Loss_res: 6.544e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.5405e+01\n",
      " kurtosis_grad_bcs: 5.2689e+01\n",
      "std_grad_bcs: 0.032115\n",
      "std_grad_res: 7.268920\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19700, Loss: 2.514e+02, Loss_bcs: 5.474e-02, Loss_res: 1.445e+00,Time: 0.00\n",
      " kurtosis_grad_res: 2.8982e+01\n",
      " kurtosis_grad_bcs: 3.1824e+01\n",
      "std_grad_bcs: 0.036179\n",
      "std_grad_res: 10.772243\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19800, Loss: 1.286e+02, Loss_bcs: 4.920e-02, Loss_res: 6.454e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.0818e+01\n",
      " kurtosis_grad_bcs: 5.4170e+01\n",
      "std_grad_bcs: 0.034614\n",
      "std_grad_res: 10.862123\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 19900, Loss: 1.341e+02, Loss_bcs: 5.087e-02, Loss_res: 6.752e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4073e+01\n",
      " kurtosis_grad_bcs: 4.3242e+01\n",
      "std_grad_bcs: 0.040300\n",
      "std_grad_res: 13.288347\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20000, Loss: 1.291e+02, Loss_bcs: 5.983e-02, Loss_res: 6.021e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.5534e+01\n",
      " kurtosis_grad_bcs: 4.7304e+01\n",
      "std_grad_bcs: 0.047239\n",
      "std_grad_res: 6.007592\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20100, Loss: 1.898e+02, Loss_bcs: 5.147e-02, Loss_res: 1.046e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.2027e+01\n",
      " kurtosis_grad_bcs: 3.9776e+01\n",
      "std_grad_bcs: 0.048285\n",
      "std_grad_res: 10.044118\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20200, Loss: 1.714e+02, Loss_bcs: 5.160e-02, Loss_res: 9.220e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.5567e+01\n",
      " kurtosis_grad_bcs: 4.6007e+01\n",
      "std_grad_bcs: 0.024599\n",
      "std_grad_res: 7.593006\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20300, Loss: 1.357e+02, Loss_bcs: 4.729e-02, Loss_res: 7.019e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.1070e+01\n",
      " kurtosis_grad_bcs: 5.1350e+01\n",
      "std_grad_bcs: 0.045520\n",
      "std_grad_res: 9.747893\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20400, Loss: 1.921e+02, Loss_bcs: 6.146e-02, Loss_res: 1.018e+00,Time: 0.00\n",
      " kurtosis_grad_res: 4.4481e+01\n",
      " kurtosis_grad_bcs: 6.3530e+01\n",
      "std_grad_bcs: 0.059119\n",
      "std_grad_res: 3.871047\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20500, Loss: 1.686e+02, Loss_bcs: 6.352e-02, Loss_res: 8.506e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.0298e+01\n",
      " kurtosis_grad_bcs: 4.1543e+01\n",
      "std_grad_bcs: 0.045990\n",
      "std_grad_res: 13.816122\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20600, Loss: 1.430e+02, Loss_bcs: 4.970e-02, Loss_res: 7.402e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.2145e+01\n",
      " kurtosis_grad_bcs: 2.8743e+01\n",
      "std_grad_bcs: 0.035530\n",
      "std_grad_res: 3.383482\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20700, Loss: 1.166e+02, Loss_bcs: 5.098e-02, Loss_res: 5.568e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5512e+01\n",
      " kurtosis_grad_bcs: 3.5452e+01\n",
      "std_grad_bcs: 0.036522\n",
      "std_grad_res: 8.918797\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20800, Loss: 1.675e+02, Loss_bcs: 5.406e-02, Loss_res: 8.852e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.4644e+01\n",
      " kurtosis_grad_bcs: 5.6995e+01\n",
      "std_grad_bcs: 0.030956\n",
      "std_grad_res: 9.104840\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 20900, Loss: 1.609e+02, Loss_bcs: 4.278e-02, Loss_res: 8.907e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5574e+01\n",
      " kurtosis_grad_bcs: 4.1178e+01\n",
      "std_grad_bcs: 0.048364\n",
      "std_grad_res: 8.675613\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21000, Loss: 1.152e+02, Loss_bcs: 4.850e-02, Loss_res: 5.588e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.6988e+01\n",
      " kurtosis_grad_bcs: 3.3540e+01\n",
      "std_grad_bcs: 0.037407\n",
      "std_grad_res: 7.289505\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21100, Loss: 1.511e+02, Loss_bcs: 4.622e-02, Loss_res: 8.097e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.9661e+01\n",
      " kurtosis_grad_bcs: 5.6900e+01\n",
      "std_grad_bcs: 0.045112\n",
      "std_grad_res: 4.580267\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21200, Loss: 1.491e+02, Loss_bcs: 6.306e-02, Loss_res: 7.216e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.6739e+01\n",
      " kurtosis_grad_bcs: 4.9265e+01\n",
      "std_grad_bcs: 0.034515\n",
      "std_grad_res: 9.911621\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21300, Loss: 1.214e+02, Loss_bcs: 4.505e-02, Loss_res: 6.154e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5807e+01\n",
      " kurtosis_grad_bcs: 5.9673e+01\n",
      "std_grad_bcs: 0.039271\n",
      "std_grad_res: 8.682718\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21400, Loss: 1.562e+02, Loss_bcs: 4.858e-02, Loss_res: 8.337e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.6513e+01\n",
      " kurtosis_grad_bcs: 4.0699e+01\n",
      "std_grad_bcs: 0.039787\n",
      "std_grad_res: 9.673953\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21500, Loss: 2.028e+02, Loss_bcs: 4.971e-02, Loss_res: 1.141e+00,Time: 0.01\n",
      " kurtosis_grad_res: 6.9591e+01\n",
      " kurtosis_grad_bcs: 4.9394e+01\n",
      "std_grad_bcs: 0.038789\n",
      "std_grad_res: 11.612401\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21600, Loss: 1.606e+02, Loss_bcs: 5.600e-02, Loss_res: 8.305e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.0588e+01\n",
      " kurtosis_grad_bcs: 5.5697e+01\n",
      "std_grad_bcs: 0.039449\n",
      "std_grad_res: 11.553026\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21700, Loss: 1.348e+02, Loss_bcs: 5.108e-02, Loss_res: 6.785e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9320e+01\n",
      " kurtosis_grad_bcs: 5.7069e+01\n",
      "std_grad_bcs: 0.043358\n",
      "std_grad_res: 7.407491\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21800, Loss: 1.442e+02, Loss_bcs: 5.262e-02, Loss_res: 7.349e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.5734e+01\n",
      " kurtosis_grad_bcs: 3.9405e+01\n",
      "std_grad_bcs: 0.040384\n",
      "std_grad_res: 9.226122\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 21900, Loss: 1.095e+02, Loss_bcs: 5.220e-02, Loss_res: 5.044e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.3755e+01\n",
      " kurtosis_grad_bcs: 5.4104e+01\n",
      "std_grad_bcs: 0.044146\n",
      "std_grad_res: 3.823188\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22000, Loss: 1.437e+02, Loss_bcs: 6.061e-02, Loss_res: 6.966e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.0559e+01\n",
      " kurtosis_grad_bcs: 4.7007e+01\n",
      "std_grad_bcs: 0.037917\n",
      "std_grad_res: 6.383655\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22100, Loss: 1.249e+02, Loss_bcs: 5.823e-02, Loss_res: 5.805e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.8436e+01\n",
      " kurtosis_grad_bcs: 4.8585e+01\n",
      "std_grad_bcs: 0.025992\n",
      "std_grad_res: 7.676623\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22200, Loss: 1.278e+02, Loss_bcs: 5.018e-02, Loss_res: 6.356e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.3212e+01\n",
      " kurtosis_grad_bcs: 3.2570e+01\n",
      "std_grad_bcs: 0.029935\n",
      "std_grad_res: 6.089767\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22300, Loss: 1.399e+02, Loss_bcs: 5.269e-02, Loss_res: 7.061e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.0930e+01\n",
      " kurtosis_grad_bcs: 4.7305e+01\n",
      "std_grad_bcs: 0.027733\n",
      "std_grad_res: 6.922360\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22400, Loss: 1.652e+02, Loss_bcs: 5.855e-02, Loss_res: 8.500e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.7931e+01\n",
      " kurtosis_grad_bcs: 5.3511e+01\n",
      "std_grad_bcs: 0.044821\n",
      "std_grad_res: 6.615346\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22500, Loss: 1.048e+02, Loss_bcs: 4.380e-02, Loss_res: 5.097e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1111e+01\n",
      " kurtosis_grad_bcs: 3.6121e+01\n",
      "std_grad_bcs: 0.047362\n",
      "std_grad_res: 6.092896\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22600, Loss: 2.226e+02, Loss_bcs: 5.124e-02, Loss_res: 1.267e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.4355e+01\n",
      " kurtosis_grad_bcs: 4.7189e+01\n",
      "std_grad_bcs: 0.037737\n",
      "std_grad_res: 16.960951\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22700, Loss: 1.788e+02, Loss_bcs: 5.815e-02, Loss_res: 9.425e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.5406e+01\n",
      " kurtosis_grad_bcs: 3.4424e+01\n",
      "std_grad_bcs: 0.027279\n",
      "std_grad_res: 8.417674\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22800, Loss: 1.319e+02, Loss_bcs: 5.352e-02, Loss_res: 6.483e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.5882e+01\n",
      " kurtosis_grad_bcs: 3.3703e+01\n",
      "std_grad_bcs: 0.035089\n",
      "std_grad_res: 10.634437\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 22900, Loss: 1.227e+02, Loss_bcs: 4.662e-02, Loss_res: 6.173e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1343e+01\n",
      " kurtosis_grad_bcs: 4.2934e+01\n",
      "std_grad_bcs: 0.029161\n",
      "std_grad_res: 11.397199\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23000, Loss: 1.063e+02, Loss_bcs: 5.123e-02, Loss_res: 4.872e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1135e+01\n",
      " kurtosis_grad_bcs: 6.1396e+01\n",
      "std_grad_bcs: 0.043252\n",
      "std_grad_res: 13.870244\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23100, Loss: 1.582e+02, Loss_bcs: 5.230e-02, Loss_res: 8.304e-01,Time: 0.00\n",
      " kurtosis_grad_res: 4.8205e+01\n",
      " kurtosis_grad_bcs: 5.4489e+01\n",
      "std_grad_bcs: 0.043943\n",
      "std_grad_res: 8.721813\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23200, Loss: 2.129e+02, Loss_bcs: 5.398e-02, Loss_res: 1.190e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.7096e+01\n",
      " kurtosis_grad_bcs: 5.5852e+01\n",
      "std_grad_bcs: 0.043716\n",
      "std_grad_res: 12.741166\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23300, Loss: 2.681e+02, Loss_bcs: 5.514e-02, Loss_res: 1.555e+00,Time: 0.00\n",
      " kurtosis_grad_res: 3.7386e+01\n",
      " kurtosis_grad_bcs: 4.2494e+01\n",
      "std_grad_bcs: 0.030876\n",
      "std_grad_res: 19.376698\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23400, Loss: 2.098e+02, Loss_bcs: 5.627e-02, Loss_res: 1.159e+00,Time: 0.01\n",
      " kurtosis_grad_res: 5.9793e+01\n",
      " kurtosis_grad_bcs: 4.8419e+01\n",
      "std_grad_bcs: 0.038680\n",
      "std_grad_res: 14.089068\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23500, Loss: 1.208e+02, Loss_bcs: 4.568e-02, Loss_res: 6.086e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.7696e+01\n",
      " kurtosis_grad_bcs: 6.0625e+01\n",
      "std_grad_bcs: 0.036077\n",
      "std_grad_res: 4.068187\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23600, Loss: 1.437e+02, Loss_bcs: 4.342e-02, Loss_res: 7.723e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.8039e+01\n",
      " kurtosis_grad_bcs: 4.5542e+01\n",
      "std_grad_bcs: 0.030101\n",
      "std_grad_res: 6.102988\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23700, Loss: 1.284e+02, Loss_bcs: 4.930e-02, Loss_res: 6.435e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.2655e+01\n",
      " kurtosis_grad_bcs: 4.6187e+01\n",
      "std_grad_bcs: 0.030688\n",
      "std_grad_res: 4.446126\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23800, Loss: 1.040e+02, Loss_bcs: 4.779e-02, Loss_res: 4.865e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.8182e+01\n",
      " kurtosis_grad_bcs: 3.9117e+01\n",
      "std_grad_bcs: 0.038020\n",
      "std_grad_res: 5.415081\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 23900, Loss: 1.370e+02, Loss_bcs: 4.524e-02, Loss_res: 7.197e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7446e+01\n",
      " kurtosis_grad_bcs: 4.2747e+01\n",
      "std_grad_bcs: 0.038558\n",
      "std_grad_res: 7.488934\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24000, Loss: 1.025e+02, Loss_bcs: 4.794e-02, Loss_res: 4.758e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.6705e+01\n",
      " kurtosis_grad_bcs: 3.4925e+01\n",
      "std_grad_bcs: 0.034208\n",
      "std_grad_res: 5.412597\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24100, Loss: 1.114e+02, Loss_bcs: 5.234e-02, Loss_res: 5.160e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7855e+01\n",
      " kurtosis_grad_bcs: 4.6832e+01\n",
      "std_grad_bcs: 0.033697\n",
      "std_grad_res: 5.068857\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24200, Loss: 1.440e+02, Loss_bcs: 4.746e-02, Loss_res: 7.565e-01,Time: 0.00\n",
      " kurtosis_grad_res: 1.9135e+01\n",
      " kurtosis_grad_bcs: 4.5309e+01\n",
      "std_grad_bcs: 0.037981\n",
      "std_grad_res: 11.716088\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24300, Loss: 1.913e+02, Loss_bcs: 5.443e-02, Loss_res: 1.043e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.2063e+01\n",
      " kurtosis_grad_bcs: 4.7334e+01\n",
      "std_grad_bcs: 0.044055\n",
      "std_grad_res: 10.777388\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24400, Loss: 1.180e+02, Loss_bcs: 4.997e-02, Loss_res: 5.709e-01,Time: 0.03\n",
      " kurtosis_grad_res: 2.1966e+01\n",
      " kurtosis_grad_bcs: 5.3859e+01\n",
      "std_grad_bcs: 0.031656\n",
      "std_grad_res: 11.569540\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24500, Loss: 1.303e+02, Loss_bcs: 4.070e-02, Loss_res: 6.948e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.8296e+01\n",
      " kurtosis_grad_bcs: 3.4157e+01\n",
      "std_grad_bcs: 0.032463\n",
      "std_grad_res: 14.845828\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24600, Loss: 1.614e+02, Loss_bcs: 4.792e-02, Loss_res: 8.710e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.8010e+01\n",
      " kurtosis_grad_bcs: 3.4949e+01\n",
      "std_grad_bcs: 0.032125\n",
      "std_grad_res: 5.363696\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24700, Loss: 1.416e+02, Loss_bcs: 4.638e-02, Loss_res: 7.451e-01,Time: 0.01\n",
      " kurtosis_grad_res: 7.1810e+01\n",
      " kurtosis_grad_bcs: 4.0538e+01\n",
      "std_grad_bcs: 0.032021\n",
      "std_grad_res: 2.219624\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24800, Loss: 1.133e+02, Loss_bcs: 5.469e-02, Loss_res: 5.188e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.6784e+01\n",
      " kurtosis_grad_bcs: 4.3756e+01\n",
      "std_grad_bcs: 0.035722\n",
      "std_grad_res: 10.856915\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 24900, Loss: 1.001e+02, Loss_bcs: 4.367e-02, Loss_res: 4.786e-01,Time: 0.01\n",
      " kurtosis_grad_res: 6.0703e+01\n",
      " kurtosis_grad_bcs: 3.3555e+01\n",
      "std_grad_bcs: 0.036678\n",
      "std_grad_res: 3.958764\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25000, Loss: 1.900e+02, Loss_bcs: 5.090e-02, Loss_res: 1.050e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.1924e+01\n",
      " kurtosis_grad_bcs: 3.5930e+01\n",
      "std_grad_bcs: 0.033126\n",
      "std_grad_res: 8.809967\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25100, Loss: 1.379e+02, Loss_bcs: 5.113e-02, Loss_res: 6.997e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5137e+01\n",
      " kurtosis_grad_bcs: 2.9264e+01\n",
      "std_grad_bcs: 0.031780\n",
      "std_grad_res: 3.703851\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25200, Loss: 2.172e+02, Loss_bcs: 4.992e-02, Loss_res: 1.237e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.0590e+01\n",
      " kurtosis_grad_bcs: 5.6375e+01\n",
      "std_grad_bcs: 0.023230\n",
      "std_grad_res: 14.100278\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25300, Loss: 1.095e+02, Loss_bcs: 5.134e-02, Loss_res: 5.082e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.4411e+01\n",
      " kurtosis_grad_bcs: 4.2309e+01\n",
      "std_grad_bcs: 0.036815\n",
      "std_grad_res: 6.362560\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25400, Loss: 8.420e+01, Loss_bcs: 4.375e-02, Loss_res: 3.717e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.0649e+01\n",
      " kurtosis_grad_bcs: 5.1198e+01\n",
      "std_grad_bcs: 0.032479\n",
      "std_grad_res: 7.552574\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25500, Loss: 1.455e+02, Loss_bcs: 5.785e-02, Loss_res: 7.206e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.4335e+01\n",
      " kurtosis_grad_bcs: 4.5299e+01\n",
      "std_grad_bcs: 0.037844\n",
      "std_grad_res: 11.155704\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25600, Loss: 1.110e+02, Loss_bcs: 3.743e-02, Loss_res: 5.795e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.8931e+01\n",
      " kurtosis_grad_bcs: 5.3980e+01\n",
      "std_grad_bcs: 0.043836\n",
      "std_grad_res: 10.799956\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25700, Loss: 1.832e+02, Loss_bcs: 4.349e-02, Loss_res: 1.037e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.0238e+01\n",
      " kurtosis_grad_bcs: 3.4107e+01\n",
      "std_grad_bcs: 0.036226\n",
      "std_grad_res: 11.440262\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25800, Loss: 8.165e+01, Loss_bcs: 4.492e-02, Loss_res: 3.494e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.4964e+01\n",
      " kurtosis_grad_bcs: 5.0586e+01\n",
      "std_grad_bcs: 0.034719\n",
      "std_grad_res: 5.644282\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 25900, Loss: 1.548e+02, Loss_bcs: 4.495e-02, Loss_res: 8.403e-01,Time: 0.02\n",
      " kurtosis_grad_res: 3.0760e+01\n",
      " kurtosis_grad_bcs: 4.3483e+01\n",
      "std_grad_bcs: 0.028816\n",
      "std_grad_res: 5.685135\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26000, Loss: 9.583e+01, Loss_bcs: 4.581e-02, Loss_res: 4.406e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.8355e+01\n",
      " kurtosis_grad_bcs: 3.4681e+01\n",
      "std_grad_bcs: 0.036106\n",
      "std_grad_res: 6.205483\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26100, Loss: 1.187e+02, Loss_bcs: 4.759e-02, Loss_res: 5.862e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7722e+01\n",
      " kurtosis_grad_bcs: 4.8781e+01\n",
      "std_grad_bcs: 0.028142\n",
      "std_grad_res: 8.723054\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26200, Loss: 1.105e+02, Loss_bcs: 4.423e-02, Loss_res: 5.461e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.6894e+01\n",
      " kurtosis_grad_bcs: 6.8151e+01\n",
      "std_grad_bcs: 0.040171\n",
      "std_grad_res: 5.575575\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26300, Loss: 1.257e+02, Loss_bcs: 4.718e-02, Loss_res: 6.348e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.3141e+01\n",
      " kurtosis_grad_bcs: 5.0345e+01\n",
      "std_grad_bcs: 0.028549\n",
      "std_grad_res: 9.237468\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26400, Loss: 1.128e+02, Loss_bcs: 5.591e-02, Loss_res: 5.097e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.4538e+01\n",
      " kurtosis_grad_bcs: 4.1958e+01\n",
      "std_grad_bcs: 0.037324\n",
      "std_grad_res: 9.040547\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26500, Loss: 1.379e+02, Loss_bcs: 4.566e-02, Loss_res: 7.235e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9428e+01\n",
      " kurtosis_grad_bcs: 6.1269e+01\n",
      "std_grad_bcs: 0.039368\n",
      "std_grad_res: 10.863803\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26600, Loss: 1.200e+02, Loss_bcs: 3.903e-02, Loss_res: 6.325e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.2745e+01\n",
      " kurtosis_grad_bcs: 6.2223e+01\n",
      "std_grad_bcs: 0.042388\n",
      "std_grad_res: 6.325068\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26700, Loss: 9.574e+01, Loss_bcs: 4.396e-02, Loss_res: 4.482e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.0018e+01\n",
      " kurtosis_grad_bcs: 5.3473e+01\n",
      "std_grad_bcs: 0.031165\n",
      "std_grad_res: 6.236701\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26800, Loss: 2.276e+02, Loss_bcs: 4.594e-02, Loss_res: 1.324e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.0214e+01\n",
      " kurtosis_grad_bcs: 4.5650e+01\n",
      "std_grad_bcs: 0.030518\n",
      "std_grad_res: 14.333457\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 26900, Loss: 9.368e+01, Loss_bcs: 5.315e-02, Loss_res: 3.937e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4396e+01\n",
      " kurtosis_grad_bcs: 5.2931e+01\n",
      "std_grad_bcs: 0.029799\n",
      "std_grad_res: 3.021953\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27000, Loss: 2.167e+02, Loss_bcs: 5.038e-02, Loss_res: 1.231e+00,Time: 0.01\n",
      " kurtosis_grad_res: 4.5409e+01\n",
      " kurtosis_grad_bcs: 4.8437e+01\n",
      "std_grad_bcs: 0.034206\n",
      "std_grad_res: 11.358885\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27100, Loss: 9.807e+01, Loss_bcs: 4.801e-02, Loss_res: 4.459e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.6523e+01\n",
      " kurtosis_grad_bcs: 4.0072e+01\n",
      "std_grad_bcs: 0.039063\n",
      "std_grad_res: 5.788936\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27200, Loss: 1.322e+02, Loss_bcs: 3.858e-02, Loss_res: 7.169e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.6499e+01\n",
      " kurtosis_grad_bcs: 3.9259e+01\n",
      "std_grad_bcs: 0.030966\n",
      "std_grad_res: 6.575404\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27300, Loss: 7.439e+01, Loss_bcs: 4.125e-02, Loss_res: 3.169e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.2452e+01\n",
      " kurtosis_grad_bcs: 4.5061e+01\n",
      "std_grad_bcs: 0.031221\n",
      "std_grad_res: 3.440451\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27400, Loss: 1.347e+02, Loss_bcs: 4.611e-02, Loss_res: 7.004e-01,Time: 0.00\n",
      " kurtosis_grad_res: 2.4324e+01\n",
      " kurtosis_grad_bcs: 4.7909e+01\n",
      "std_grad_bcs: 0.031551\n",
      "std_grad_res: 11.890026\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27500, Loss: 1.241e+02, Loss_bcs: 5.059e-02, Loss_res: 6.092e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.0998e+01\n",
      " kurtosis_grad_bcs: 5.3846e+01\n",
      "std_grad_bcs: 0.042099\n",
      "std_grad_res: 4.153695\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27600, Loss: 1.105e+02, Loss_bcs: 4.919e-02, Loss_res: 5.244e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.3358e+01\n",
      " kurtosis_grad_bcs: 4.4264e+01\n",
      "std_grad_bcs: 0.028978\n",
      "std_grad_res: 8.711189\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27700, Loss: 1.462e+02, Loss_bcs: 5.252e-02, Loss_res: 7.489e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9787e+01\n",
      " kurtosis_grad_bcs: 4.3898e+01\n",
      "std_grad_bcs: 0.022346\n",
      "std_grad_res: 15.338899\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27800, Loss: 1.147e+02, Loss_bcs: 4.594e-02, Loss_res: 5.669e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.0314e+01\n",
      " kurtosis_grad_bcs: 4.3382e+01\n",
      "std_grad_bcs: 0.034466\n",
      "std_grad_res: 10.978435\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 27900, Loss: 9.809e+01, Loss_bcs: 4.254e-02, Loss_res: 4.702e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.4490e+01\n",
      " kurtosis_grad_bcs: 4.5983e+01\n",
      "std_grad_bcs: 0.029318\n",
      "std_grad_res: 8.067399\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28000, Loss: 1.119e+02, Loss_bcs: 4.615e-02, Loss_res: 5.470e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.3246e+01\n",
      " kurtosis_grad_bcs: 3.2991e+01\n",
      "std_grad_bcs: 0.032120\n",
      "std_grad_res: 12.077746\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28100, Loss: 1.204e+02, Loss_bcs: 3.738e-02, Loss_res: 6.428e-01,Time: 0.00\n",
      " kurtosis_grad_res: 2.1494e+01\n",
      " kurtosis_grad_bcs: 6.1063e+01\n",
      "std_grad_bcs: 0.042923\n",
      "std_grad_res: 9.487987\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28200, Loss: 1.378e+02, Loss_bcs: 5.085e-02, Loss_res: 6.999e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9365e+01\n",
      " kurtosis_grad_bcs: 3.8604e+01\n",
      "std_grad_bcs: 0.035606\n",
      "std_grad_res: 6.456569\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28300, Loss: 1.094e+02, Loss_bcs: 5.361e-02, Loss_res: 4.972e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.2100e+01\n",
      " kurtosis_grad_bcs: 4.2555e+01\n",
      "std_grad_bcs: 0.029319\n",
      "std_grad_res: 6.240125\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28400, Loss: 1.106e+02, Loss_bcs: 4.368e-02, Loss_res: 5.492e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.3656e+01\n",
      " kurtosis_grad_bcs: 4.7641e+01\n",
      "std_grad_bcs: 0.037423\n",
      "std_grad_res: 3.416051\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28500, Loss: 1.427e+02, Loss_bcs: 5.581e-02, Loss_res: 7.108e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.3513e+01\n",
      " kurtosis_grad_bcs: 5.9967e+01\n",
      "std_grad_bcs: 0.042101\n",
      "std_grad_res: 6.214097\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28600, Loss: 1.140e+02, Loss_bcs: 4.730e-02, Loss_res: 5.558e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5892e+01\n",
      " kurtosis_grad_bcs: 3.3080e+01\n",
      "std_grad_bcs: 0.031543\n",
      "std_grad_res: 3.971968\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28700, Loss: 1.544e+02, Loss_bcs: 4.288e-02, Loss_res: 8.469e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.3392e+01\n",
      " kurtosis_grad_bcs: 5.5692e+01\n",
      "std_grad_bcs: 0.038818\n",
      "std_grad_res: 12.335655\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28800, Loss: 9.198e+01, Loss_bcs: 4.235e-02, Loss_res: 4.301e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.3737e+01\n",
      " kurtosis_grad_bcs: 4.5855e+01\n",
      "std_grad_bcs: 0.035230\n",
      "std_grad_res: 9.783458\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 28900, Loss: 1.788e+02, Loss_bcs: 4.099e-02, Loss_res: 1.018e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.2287e+01\n",
      " kurtosis_grad_bcs: 4.6324e+01\n",
      "std_grad_bcs: 0.028285\n",
      "std_grad_res: 11.760345\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29000, Loss: 1.237e+02, Loss_bcs: 4.287e-02, Loss_res: 6.404e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.1955e+01\n",
      " kurtosis_grad_bcs: 3.7917e+01\n",
      "std_grad_bcs: 0.029681\n",
      "std_grad_res: 3.688287\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29100, Loss: 1.423e+02, Loss_bcs: 4.064e-02, Loss_res: 7.753e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.6820e+01\n",
      " kurtosis_grad_bcs: 3.3298e+01\n",
      "std_grad_bcs: 0.031272\n",
      "std_grad_res: 10.834066\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29200, Loss: 1.302e+02, Loss_bcs: 4.137e-02, Loss_res: 6.906e-01,Time: 0.00\n",
      " kurtosis_grad_res: 2.4257e+01\n",
      " kurtosis_grad_bcs: 3.9384e+01\n",
      "std_grad_bcs: 0.034443\n",
      "std_grad_res: 7.957228\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29300, Loss: 1.139e+02, Loss_bcs: 4.111e-02, Loss_res: 5.830e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1356e+01\n",
      " kurtosis_grad_bcs: 5.0809e+01\n",
      "std_grad_bcs: 0.034814\n",
      "std_grad_res: 8.034883\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29400, Loss: 1.045e+02, Loss_bcs: 3.822e-02, Loss_res: 5.326e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.0397e+01\n",
      " kurtosis_grad_bcs: 4.7729e+01\n",
      "std_grad_bcs: 0.038265\n",
      "std_grad_res: 7.726950\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29500, Loss: 1.235e+02, Loss_bcs: 4.950e-02, Loss_res: 6.101e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.2841e+01\n",
      " kurtosis_grad_bcs: 6.0602e+01\n",
      "std_grad_bcs: 0.035547\n",
      "std_grad_res: 3.750316\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29600, Loss: 1.383e+02, Loss_bcs: 4.083e-02, Loss_res: 7.477e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9171e+01\n",
      " kurtosis_grad_bcs: 5.2091e+01\n",
      "std_grad_bcs: 0.034313\n",
      "std_grad_res: 3.688003\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29700, Loss: 1.411e+02, Loss_bcs: 4.018e-02, Loss_res: 7.695e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.5522e+01\n",
      " kurtosis_grad_bcs: 3.5389e+01\n",
      "std_grad_bcs: 0.030916\n",
      "std_grad_res: 6.234155\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29800, Loss: 9.072e+01, Loss_bcs: 4.795e-02, Loss_res: 3.969e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9691e+01\n",
      " kurtosis_grad_bcs: 4.2054e+01\n",
      "std_grad_bcs: 0.031464\n",
      "std_grad_res: 4.647579\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 29900, Loss: 1.137e+02, Loss_bcs: 4.332e-02, Loss_res: 5.717e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.5106e+01\n",
      " kurtosis_grad_bcs: 5.1269e+01\n",
      "std_grad_bcs: 0.030632\n",
      "std_grad_res: 4.774459\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30000, Loss: 1.393e+02, Loss_bcs: 4.605e-02, Loss_res: 7.313e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1058e+01\n",
      " kurtosis_grad_bcs: 4.5882e+01\n",
      "std_grad_bcs: 0.026817\n",
      "std_grad_res: 5.850742\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30100, Loss: 9.032e+01, Loss_bcs: 4.188e-02, Loss_res: 4.210e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.2409e+01\n",
      " kurtosis_grad_bcs: 4.7739e+01\n",
      "std_grad_bcs: 0.038025\n",
      "std_grad_res: 3.634589\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30200, Loss: 1.120e+02, Loss_bcs: 3.998e-02, Loss_res: 5.748e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.1391e+01\n",
      " kurtosis_grad_bcs: 3.6676e+01\n",
      "std_grad_bcs: 0.031883\n",
      "std_grad_res: 7.162488\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30300, Loss: 2.233e+02, Loss_bcs: 4.321e-02, Loss_res: 1.307e+00,Time: 0.01\n",
      " kurtosis_grad_res: 2.8543e+01\n",
      " kurtosis_grad_bcs: 5.5161e+01\n",
      "std_grad_bcs: 0.040936\n",
      "std_grad_res: 13.868864\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30400, Loss: 9.774e+01, Loss_bcs: 4.677e-02, Loss_res: 4.492e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.3312e+01\n",
      " kurtosis_grad_bcs: 6.0614e+01\n",
      "std_grad_bcs: 0.037140\n",
      "std_grad_res: 9.483571\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30500, Loss: 1.713e+02, Loss_bcs: 4.371e-02, Loss_res: 9.560e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.4677e+01\n",
      " kurtosis_grad_bcs: 3.8245e+01\n",
      "std_grad_bcs: 0.035844\n",
      "std_grad_res: 6.962314\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30600, Loss: 9.412e+01, Loss_bcs: 4.300e-02, Loss_res: 4.416e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9892e+01\n",
      " kurtosis_grad_bcs: 4.8834e+01\n",
      "std_grad_bcs: 0.035059\n",
      "std_grad_res: 4.961653\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30700, Loss: 8.130e+01, Loss_bcs: 4.014e-02, Loss_res: 3.682e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9036e+01\n",
      " kurtosis_grad_bcs: 4.0348e+01\n",
      "std_grad_bcs: 0.025430\n",
      "std_grad_res: 7.789046\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30800, Loss: 1.147e+02, Loss_bcs: 4.602e-02, Loss_res: 5.663e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.3338e+01\n",
      " kurtosis_grad_bcs: 3.3671e+01\n",
      "std_grad_bcs: 0.032588\n",
      "std_grad_res: 7.035829\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 30900, Loss: 8.497e+01, Loss_bcs: 4.696e-02, Loss_res: 3.626e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9143e+01\n",
      " kurtosis_grad_bcs: 3.8437e+01\n",
      "std_grad_bcs: 0.031071\n",
      "std_grad_res: 4.910348\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31000, Loss: 8.156e+01, Loss_bcs: 4.019e-02, Loss_res: 3.697e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.8018e+01\n",
      " kurtosis_grad_bcs: 4.2010e+01\n",
      "std_grad_bcs: 0.035819\n",
      "std_grad_res: 4.758886\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31100, Loss: 7.199e+01, Loss_bcs: 3.909e-02, Loss_res: 3.104e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1393e+01\n",
      " kurtosis_grad_bcs: 3.4853e+01\n",
      "std_grad_bcs: 0.041374\n",
      "std_grad_res: 3.406996\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31200, Loss: 7.684e+01, Loss_bcs: 4.228e-02, Loss_res: 3.288e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.0521e+01\n",
      " kurtosis_grad_bcs: 5.8972e+01\n",
      "std_grad_bcs: 0.037362\n",
      "std_grad_res: 3.859668\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31300, Loss: 1.118e+02, Loss_bcs: 3.667e-02, Loss_res: 5.882e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.8644e+01\n",
      " kurtosis_grad_bcs: 6.4297e+01\n",
      "std_grad_bcs: 0.036246\n",
      "std_grad_res: 10.503098\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31400, Loss: 1.020e+02, Loss_bcs: 4.399e-02, Loss_res: 4.902e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4780e+01\n",
      " kurtosis_grad_bcs: 4.0362e+01\n",
      "std_grad_bcs: 0.032033\n",
      "std_grad_res: 8.310088\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31500, Loss: 9.580e+01, Loss_bcs: 4.816e-02, Loss_res: 4.300e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.4964e+01\n",
      " kurtosis_grad_bcs: 5.2551e+01\n",
      "std_grad_bcs: 0.038825\n",
      "std_grad_res: 1.622799\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31600, Loss: 1.204e+02, Loss_bcs: 3.851e-02, Loss_res: 6.377e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.3044e+01\n",
      " kurtosis_grad_bcs: 3.2582e+01\n",
      "std_grad_bcs: 0.031833\n",
      "std_grad_res: 5.405012\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31700, Loss: 7.559e+01, Loss_bcs: 4.088e-02, Loss_res: 3.266e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.5421e+01\n",
      " kurtosis_grad_bcs: 4.5576e+01\n",
      "std_grad_bcs: 0.028031\n",
      "std_grad_res: 3.310197\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31800, Loss: 1.830e+02, Loss_bcs: 3.746e-02, Loss_res: 1.063e+00,Time: 0.02\n",
      " kurtosis_grad_res: 3.2603e+01\n",
      " kurtosis_grad_bcs: 5.3219e+01\n",
      "std_grad_bcs: 0.032195\n",
      "std_grad_res: 8.907681\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 31900, Loss: 1.320e+02, Loss_bcs: 4.729e-02, Loss_res: 6.769e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4317e+01\n",
      " kurtosis_grad_bcs: 4.4789e+01\n",
      "std_grad_bcs: 0.034876\n",
      "std_grad_res: 10.695114\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32000, Loss: 8.093e+01, Loss_bcs: 4.341e-02, Loss_res: 3.512e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.9759e+01\n",
      " kurtosis_grad_bcs: 4.4273e+01\n",
      "std_grad_bcs: 0.033480\n",
      "std_grad_res: 2.599972\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32100, Loss: 1.117e+02, Loss_bcs: 4.796e-02, Loss_res: 5.373e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4668e+01\n",
      " kurtosis_grad_bcs: 4.8760e+01\n",
      "std_grad_bcs: 0.038845\n",
      "std_grad_res: 8.784266\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32200, Loss: 1.731e+02, Loss_bcs: 4.365e-02, Loss_res: 9.690e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4034e+01\n",
      " kurtosis_grad_bcs: 4.9503e+01\n",
      "std_grad_bcs: 0.028120\n",
      "std_grad_res: 4.606969\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32300, Loss: 1.778e+02, Loss_bcs: 4.527e-02, Loss_res: 9.930e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7692e+01\n",
      " kurtosis_grad_bcs: 4.8203e+01\n",
      "std_grad_bcs: 0.022508\n",
      "std_grad_res: 10.295496\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32400, Loss: 1.361e+02, Loss_bcs: 4.156e-02, Loss_res: 7.293e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.0561e+01\n",
      " kurtosis_grad_bcs: 4.9700e+01\n",
      "std_grad_bcs: 0.030866\n",
      "std_grad_res: 4.574795\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32500, Loss: 1.100e+02, Loss_bcs: 3.742e-02, Loss_res: 5.729e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.8699e+01\n",
      " kurtosis_grad_bcs: 3.1023e+01\n",
      "std_grad_bcs: 0.026317\n",
      "std_grad_res: 3.909414\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32600, Loss: 9.681e+01, Loss_bcs: 3.806e-02, Loss_res: 4.814e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9968e+01\n",
      " kurtosis_grad_bcs: 6.6357e+01\n",
      "std_grad_bcs: 0.036461\n",
      "std_grad_res: 6.734166\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32700, Loss: 7.892e+01, Loss_bcs: 4.378e-02, Loss_res: 3.361e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1614e+01\n",
      " kurtosis_grad_bcs: 4.6785e+01\n",
      "std_grad_bcs: 0.031985\n",
      "std_grad_res: 2.001988\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32800, Loss: 6.904e+01, Loss_bcs: 4.269e-02, Loss_res: 2.746e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.7233e+01\n",
      " kurtosis_grad_bcs: 4.1071e+01\n",
      "std_grad_bcs: 0.033732\n",
      "std_grad_res: 7.845459\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 32900, Loss: 1.172e+02, Loss_bcs: 3.956e-02, Loss_res: 6.119e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1418e+01\n",
      " kurtosis_grad_bcs: 4.8166e+01\n",
      "std_grad_bcs: 0.029714\n",
      "std_grad_res: 3.393816\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33000, Loss: 9.184e+01, Loss_bcs: 4.149e-02, Loss_res: 4.330e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5724e+01\n",
      " kurtosis_grad_bcs: 3.5974e+01\n",
      "std_grad_bcs: 0.034442\n",
      "std_grad_res: 11.991531\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33100, Loss: 2.135e+02, Loss_bcs: 4.110e-02, Loss_res: 1.251e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.3363e+01\n",
      " kurtosis_grad_bcs: 4.7178e+01\n",
      "std_grad_bcs: 0.035033\n",
      "std_grad_res: 6.017217\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33200, Loss: 9.723e+01, Loss_bcs: 4.422e-02, Loss_res: 4.571e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9938e+01\n",
      " kurtosis_grad_bcs: 5.0116e+01\n",
      "std_grad_bcs: 0.024759\n",
      "std_grad_res: 8.167715\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33300, Loss: 1.276e+02, Loss_bcs: 4.110e-02, Loss_res: 6.749e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.5070e+01\n",
      " kurtosis_grad_bcs: 5.5656e+01\n",
      "std_grad_bcs: 0.027127\n",
      "std_grad_res: 4.610521\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33400, Loss: 7.373e+01, Loss_bcs: 3.984e-02, Loss_res: 3.187e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9123e+01\n",
      " kurtosis_grad_bcs: 4.9168e+01\n",
      "std_grad_bcs: 0.038003\n",
      "std_grad_res: 3.081941\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33500, Loss: 1.004e+02, Loss_bcs: 4.189e-02, Loss_res: 4.888e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.3762e+01\n",
      " kurtosis_grad_bcs: 3.9894e+01\n",
      "std_grad_bcs: 0.028932\n",
      "std_grad_res: 5.675185\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33600, Loss: 1.102e+02, Loss_bcs: 4.502e-02, Loss_res: 5.403e-01,Time: 0.00\n",
      " kurtosis_grad_res: 5.8589e+01\n",
      " kurtosis_grad_bcs: 5.4970e+01\n",
      "std_grad_bcs: 0.045783\n",
      "std_grad_res: 4.908674\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33700, Loss: 9.720e+01, Loss_bcs: 3.400e-02, Loss_res: 5.020e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.6941e+01\n",
      " kurtosis_grad_bcs: 3.6975e+01\n",
      "std_grad_bcs: 0.033650\n",
      "std_grad_res: 6.750728\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33800, Loss: 7.876e+01, Loss_bcs: 4.290e-02, Loss_res: 3.389e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7630e+01\n",
      " kurtosis_grad_bcs: 4.3459e+01\n",
      "std_grad_bcs: 0.030990\n",
      "std_grad_res: 5.223340\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 33900, Loss: 1.019e+02, Loss_bcs: 3.740e-02, Loss_res: 5.186e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.4697e+01\n",
      " kurtosis_grad_bcs: 5.8853e+01\n",
      "std_grad_bcs: 0.034856\n",
      "std_grad_res: 6.357442\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34000, Loss: 7.371e+01, Loss_bcs: 3.310e-02, Loss_res: 3.483e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9989e+01\n",
      " kurtosis_grad_bcs: 4.0206e+01\n",
      "std_grad_bcs: 0.035184\n",
      "std_grad_res: 8.535260\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34100, Loss: 1.142e+02, Loss_bcs: 4.235e-02, Loss_res: 5.794e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1940e+01\n",
      " kurtosis_grad_bcs: 3.7946e+01\n",
      "std_grad_bcs: 0.026830\n",
      "std_grad_res: 8.148314\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34200, Loss: 1.323e+02, Loss_bcs: 3.958e-02, Loss_res: 7.129e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.0696e+01\n",
      " kurtosis_grad_bcs: 4.3736e+01\n",
      "std_grad_bcs: 0.024787\n",
      "std_grad_res: 6.306461\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34300, Loss: 2.855e+02, Loss_bcs: 5.770e-02, Loss_res: 1.661e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.1012e+01\n",
      " kurtosis_grad_bcs: 4.2153e+01\n",
      "std_grad_bcs: 0.036666\n",
      "std_grad_res: 19.083221\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34400, Loss: 2.183e+02, Loss_bcs: 4.547e-02, Loss_res: 1.264e+00,Time: 0.00\n",
      " kurtosis_grad_res: 4.1373e+01\n",
      " kurtosis_grad_bcs: 4.8688e+01\n",
      "std_grad_bcs: 0.029095\n",
      "std_grad_res: 17.180212\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34500, Loss: 8.850e+01, Loss_bcs: 3.966e-02, Loss_res: 4.186e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.6399e+01\n",
      " kurtosis_grad_bcs: 5.1743e+01\n",
      "std_grad_bcs: 0.030126\n",
      "std_grad_res: 4.017119\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34600, Loss: 8.003e+01, Loss_bcs: 4.353e-02, Loss_res: 3.447e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.8891e+01\n",
      " kurtosis_grad_bcs: 4.9572e+01\n",
      "std_grad_bcs: 0.031126\n",
      "std_grad_res: 4.036556\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34700, Loss: 6.966e+01, Loss_bcs: 4.070e-02, Loss_res: 2.876e-01,Time: 0.00\n",
      " kurtosis_grad_res: 6.0193e+01\n",
      " kurtosis_grad_bcs: 6.1822e+01\n",
      "std_grad_bcs: 0.035166\n",
      "std_grad_res: 1.365782\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34800, Loss: 1.816e+02, Loss_bcs: 4.677e-02, Loss_res: 1.012e+00,Time: 0.01\n",
      " kurtosis_grad_res: 3.2447e+01\n",
      " kurtosis_grad_bcs: 3.9671e+01\n",
      "std_grad_bcs: 0.028890\n",
      "std_grad_res: 6.901801\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 34900, Loss: 1.211e+02, Loss_bcs: 4.269e-02, Loss_res: 6.242e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1061e+01\n",
      " kurtosis_grad_bcs: 4.6183e+01\n",
      "std_grad_bcs: 0.029397\n",
      "std_grad_res: 5.881489\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35000, Loss: 9.941e+01, Loss_bcs: 4.534e-02, Loss_res: 4.667e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.9652e+01\n",
      " kurtosis_grad_bcs: 4.9016e+01\n",
      "std_grad_bcs: 0.032886\n",
      "std_grad_res: 4.149173\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35100, Loss: 1.204e+02, Loss_bcs: 4.335e-02, Loss_res: 6.162e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.8198e+01\n",
      " kurtosis_grad_bcs: 4.5301e+01\n",
      "std_grad_bcs: 0.036416\n",
      "std_grad_res: 6.053888\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35200, Loss: 1.020e+02, Loss_bcs: 4.666e-02, Loss_res: 4.779e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.4488e+01\n",
      " kurtosis_grad_bcs: 4.0079e+01\n",
      "std_grad_bcs: 0.026019\n",
      "std_grad_res: 7.304450\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35300, Loss: 1.323e+02, Loss_bcs: 4.113e-02, Loss_res: 7.058e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.5817e+01\n",
      " kurtosis_grad_bcs: 4.2721e+01\n",
      "std_grad_bcs: 0.021434\n",
      "std_grad_res: 10.830839\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35400, Loss: 8.609e+01, Loss_bcs: 3.946e-02, Loss_res: 4.033e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.6580e+01\n",
      " kurtosis_grad_bcs: 4.5412e+01\n",
      "std_grad_bcs: 0.032509\n",
      "std_grad_res: 3.809182\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35500, Loss: 1.057e+02, Loss_bcs: 3.932e-02, Loss_res: 5.356e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1974e+01\n",
      " kurtosis_grad_bcs: 6.3144e+01\n",
      "std_grad_bcs: 0.036571\n",
      "std_grad_res: 4.948151\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35600, Loss: 1.226e+02, Loss_bcs: 3.618e-02, Loss_res: 6.629e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.8082e+01\n",
      " kurtosis_grad_bcs: 4.9554e+01\n",
      "std_grad_bcs: 0.033075\n",
      "std_grad_res: 7.997648\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35700, Loss: 8.794e+01, Loss_bcs: 4.725e-02, Loss_res: 3.813e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.7382e+01\n",
      " kurtosis_grad_bcs: 3.9857e+01\n",
      "std_grad_bcs: 0.027357\n",
      "std_grad_res: 4.719935\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35800, Loss: 1.406e+02, Loss_bcs: 4.544e-02, Loss_res: 7.425e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5656e+01\n",
      " kurtosis_grad_bcs: 3.5006e+01\n",
      "std_grad_bcs: 0.030184\n",
      "std_grad_res: 8.549937\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 35900, Loss: 1.049e+02, Loss_bcs: 3.808e-02, Loss_res: 5.355e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7154e+01\n",
      " kurtosis_grad_bcs: 3.7272e+01\n",
      "std_grad_bcs: 0.030604\n",
      "std_grad_res: 3.528470\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36000, Loss: 8.759e+01, Loss_bcs: 3.829e-02, Loss_res: 4.186e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9113e+01\n",
      " kurtosis_grad_bcs: 5.9306e+01\n",
      "std_grad_bcs: 0.029759\n",
      "std_grad_res: 5.281746\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36100, Loss: 1.260e+02, Loss_bcs: 4.289e-02, Loss_res: 6.558e-01,Time: 0.06\n",
      " kurtosis_grad_res: 3.0476e+01\n",
      " kurtosis_grad_bcs: 5.5532e+01\n",
      "std_grad_bcs: 0.036003\n",
      "std_grad_res: 4.226751\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36200, Loss: 9.618e+01, Loss_bcs: 4.054e-02, Loss_res: 4.662e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.0216e+01\n",
      " kurtosis_grad_bcs: 5.2923e+01\n",
      "std_grad_bcs: 0.029843\n",
      "std_grad_res: 5.734951\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36300, Loss: 8.134e+01, Loss_bcs: 3.878e-02, Loss_res: 3.745e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.2014e+01\n",
      " kurtosis_grad_bcs: 3.9669e+01\n",
      "std_grad_bcs: 0.025031\n",
      "std_grad_res: 5.392457\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36400, Loss: 8.308e+01, Loss_bcs: 4.016e-02, Loss_res: 3.800e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.2945e+01\n",
      " kurtosis_grad_bcs: 3.2925e+01\n",
      "std_grad_bcs: 0.031970\n",
      "std_grad_res: 5.177100\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36500, Loss: 9.028e+01, Loss_bcs: 3.298e-02, Loss_res: 4.601e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7085e+01\n",
      " kurtosis_grad_bcs: 5.2927e+01\n",
      "std_grad_bcs: 0.038081\n",
      "std_grad_res: 4.968177\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36600, Loss: 7.675e+01, Loss_bcs: 3.888e-02, Loss_res: 3.432e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.5383e+01\n",
      " kurtosis_grad_bcs: 5.2627e+01\n",
      "std_grad_bcs: 0.032897\n",
      "std_grad_res: 2.798440\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36700, Loss: 1.223e+02, Loss_bcs: 4.048e-02, Loss_res: 6.416e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7214e+01\n",
      " kurtosis_grad_bcs: 3.6676e+01\n",
      "std_grad_bcs: 0.027250\n",
      "std_grad_res: 11.385744\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36800, Loss: 1.203e+02, Loss_bcs: 3.541e-02, Loss_res: 6.505e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.8545e+01\n",
      " kurtosis_grad_bcs: 3.4829e+01\n",
      "std_grad_bcs: 0.030116\n",
      "std_grad_res: 9.338263\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 36900, Loss: 1.057e+02, Loss_bcs: 3.807e-02, Loss_res: 5.409e-01,Time: 0.01\n",
      " kurtosis_grad_res: 6.5607e+01\n",
      " kurtosis_grad_bcs: 4.0438e+01\n",
      "std_grad_bcs: 0.028785\n",
      "std_grad_res: 6.818157\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37000, Loss: 7.331e+01, Loss_bcs: 3.436e-02, Loss_res: 3.401e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.7944e+01\n",
      " kurtosis_grad_bcs: 5.8088e+01\n",
      "std_grad_bcs: 0.030657\n",
      "std_grad_res: 3.595755\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37100, Loss: 1.128e+02, Loss_bcs: 4.272e-02, Loss_res: 5.680e-01,Time: 0.01\n",
      " kurtosis_grad_res: 6.0284e+01\n",
      " kurtosis_grad_bcs: 6.8423e+01\n",
      "std_grad_bcs: 0.042157\n",
      "std_grad_res: 8.021400\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37200, Loss: 1.370e+02, Loss_bcs: 4.557e-02, Loss_res: 7.179e-01,Time: 0.02\n",
      " kurtosis_grad_res: 3.2217e+01\n",
      " kurtosis_grad_bcs: 4.6630e+01\n",
      "std_grad_bcs: 0.031148\n",
      "std_grad_res: 3.997843\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37300, Loss: 7.436e+01, Loss_bcs: 3.450e-02, Loss_res: 3.465e-01,Time: 0.01\n",
      " kurtosis_grad_res: 1.2478e+02\n",
      " kurtosis_grad_bcs: 7.1160e+01\n",
      "std_grad_bcs: 0.040060\n",
      "std_grad_res: 0.889472\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37400, Loss: 8.518e+01, Loss_bcs: 3.647e-02, Loss_res: 4.104e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.1640e+01\n",
      " kurtosis_grad_bcs: 6.1885e+01\n",
      "std_grad_bcs: 0.027568\n",
      "std_grad_res: 5.686300\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37500, Loss: 1.175e+02, Loss_bcs: 4.796e-02, Loss_res: 5.768e-01,Time: 0.02\n",
      " kurtosis_grad_res: 3.7309e+01\n",
      " kurtosis_grad_bcs: 5.9858e+01\n",
      "std_grad_bcs: 0.031073\n",
      "std_grad_res: 5.986563\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37600, Loss: 8.884e+01, Loss_bcs: 4.125e-02, Loss_res: 4.139e-01,Time: 0.01\n",
      " kurtosis_grad_res: 6.6971e+01\n",
      " kurtosis_grad_bcs: 4.3260e+01\n",
      "std_grad_bcs: 0.028787\n",
      "std_grad_res: 4.018458\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37700, Loss: 8.327e+01, Loss_bcs: 4.121e-02, Loss_res: 3.766e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9949e+01\n",
      " kurtosis_grad_bcs: 5.1974e+01\n",
      "std_grad_bcs: 0.029755\n",
      "std_grad_res: 5.729983\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37800, Loss: 9.952e+01, Loss_bcs: 4.222e-02, Loss_res: 4.813e-01,Time: 0.01\n",
      " kurtosis_grad_res: 6.2194e+01\n",
      " kurtosis_grad_bcs: 3.8789e+01\n",
      "std_grad_bcs: 0.026600\n",
      "std_grad_res: 6.265478\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 37900, Loss: 1.353e+02, Loss_bcs: 3.785e-02, Loss_res: 7.406e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.6355e+01\n",
      " kurtosis_grad_bcs: 5.2415e+01\n",
      "std_grad_bcs: 0.028158\n",
      "std_grad_res: 9.574711\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38000, Loss: 1.406e+02, Loss_bcs: 4.039e-02, Loss_res: 7.647e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.7732e+01\n",
      " kurtosis_grad_bcs: 3.3723e+01\n",
      "std_grad_bcs: 0.031612\n",
      "std_grad_res: 3.435495\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38100, Loss: 8.647e+01, Loss_bcs: 3.822e-02, Loss_res: 4.113e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.6247e+01\n",
      " kurtosis_grad_bcs: 6.0229e+01\n",
      "std_grad_bcs: 0.027947\n",
      "std_grad_res: 3.708767\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38200, Loss: 7.455e+01, Loss_bcs: 4.601e-02, Loss_res: 2.969e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.7438e+01\n",
      " kurtosis_grad_bcs: 6.1569e+01\n",
      "std_grad_bcs: 0.036069\n",
      "std_grad_res: 5.544384\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38300, Loss: 1.160e+02, Loss_bcs: 4.657e-02, Loss_res: 5.729e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4672e+01\n",
      " kurtosis_grad_bcs: 6.3807e+01\n",
      "std_grad_bcs: 0.039067\n",
      "std_grad_res: 3.435969\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38400, Loss: 1.183e+02, Loss_bcs: 3.849e-02, Loss_res: 6.237e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.3346e+01\n",
      " kurtosis_grad_bcs: 5.4103e+01\n",
      "std_grad_bcs: 0.036563\n",
      "std_grad_res: 10.560527\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38500, Loss: 7.560e+01, Loss_bcs: 3.409e-02, Loss_res: 3.567e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.6759e+01\n",
      " kurtosis_grad_bcs: 6.0956e+01\n",
      "std_grad_bcs: 0.027901\n",
      "std_grad_res: 8.355193\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38600, Loss: 1.348e+02, Loss_bcs: 3.926e-02, Loss_res: 7.312e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.0320e+01\n",
      " kurtosis_grad_bcs: 4.3485e+01\n",
      "std_grad_bcs: 0.024838\n",
      "std_grad_res: 7.805753\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38700, Loss: 9.770e+01, Loss_bcs: 3.545e-02, Loss_res: 4.989e-01,Time: 0.02\n",
      " kurtosis_grad_res: 3.9059e+01\n",
      " kurtosis_grad_bcs: 3.5661e+01\n",
      "std_grad_bcs: 0.033462\n",
      "std_grad_res: 9.124074\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38800, Loss: 1.575e+02, Loss_bcs: 4.535e-02, Loss_res: 8.563e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.4490e+01\n",
      " kurtosis_grad_bcs: 4.6009e+01\n",
      "std_grad_bcs: 0.029343\n",
      "std_grad_res: 5.345600\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 38900, Loss: 8.119e+01, Loss_bcs: 4.386e-02, Loss_res: 3.510e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.1419e+01\n",
      " kurtosis_grad_bcs: 4.8305e+01\n",
      "std_grad_bcs: 0.027071\n",
      "std_grad_res: 5.824128\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39000, Loss: 7.434e+01, Loss_bcs: 3.665e-02, Loss_res: 3.368e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.2762e+01\n",
      " kurtosis_grad_bcs: 6.2339e+01\n",
      "std_grad_bcs: 0.032301\n",
      "std_grad_res: 6.537798\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39100, Loss: 6.946e+01, Loss_bcs: 4.103e-02, Loss_res: 2.848e-01,Time: 0.00\n",
      " kurtosis_grad_res: 2.6191e+01\n",
      " kurtosis_grad_bcs: 3.9674e+01\n",
      "std_grad_bcs: 0.032759\n",
      "std_grad_res: 3.567296\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39200, Loss: 1.249e+02, Loss_bcs: 3.946e-02, Loss_res: 6.640e-01,Time: 0.01\n",
      " kurtosis_grad_res: 3.5173e+01\n",
      " kurtosis_grad_bcs: 7.3393e+01\n",
      "std_grad_bcs: 0.035828\n",
      "std_grad_res: 11.418570\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39300, Loss: 9.423e+01, Loss_bcs: 4.314e-02, Loss_res: 4.417e-01,Time: 0.00\n",
      " kurtosis_grad_res: 7.6810e+01\n",
      " kurtosis_grad_bcs: 5.1663e+01\n",
      "std_grad_bcs: 0.023017\n",
      "std_grad_res: 3.546049\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39400, Loss: 9.210e+01, Loss_bcs: 3.731e-02, Loss_res: 4.531e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.4287e+01\n",
      " kurtosis_grad_bcs: 3.6688e+01\n",
      "std_grad_bcs: 0.032212\n",
      "std_grad_res: 3.712082\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39500, Loss: 1.041e+02, Loss_bcs: 4.116e-02, Loss_res: 5.166e-01,Time: 0.01\n",
      " kurtosis_grad_res: 4.3320e+01\n",
      " kurtosis_grad_bcs: 3.7611e+01\n",
      "std_grad_bcs: 0.031727\n",
      "std_grad_res: 10.048876\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39600, Loss: 1.184e+02, Loss_bcs: 4.180e-02, Loss_res: 6.101e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9892e+01\n",
      " kurtosis_grad_bcs: 4.0501e+01\n",
      "std_grad_bcs: 0.030805\n",
      "std_grad_res: 7.860747\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39700, Loss: 1.148e+02, Loss_bcs: 4.092e-02, Loss_res: 5.896e-01,Time: 0.01\n",
      " kurtosis_grad_res: 5.3211e+01\n",
      " kurtosis_grad_bcs: 4.7086e+01\n",
      "std_grad_bcs: 0.029754\n",
      "std_grad_res: 4.016327\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39800, Loss: 1.167e+02, Loss_bcs: 3.637e-02, Loss_res: 6.223e-01,Time: 0.00\n",
      " kurtosis_grad_res: 3.3726e+01\n",
      " kurtosis_grad_bcs: 3.4179e+01\n",
      "std_grad_bcs: 0.029679\n",
      "std_grad_res: 4.267557\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "It: 39900, Loss: 1.023e+02, Loss_bcs: 4.022e-02, Loss_res: 5.086e-01,Time: 0.01\n",
      " kurtosis_grad_res: 2.9962e+01\n",
      " kurtosis_grad_bcs: 4.2706e+01\n",
      "std_grad_bcs: 0.038581\n",
      "std_grad_res: 9.417028\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Gradients information stored ...\n",
      "It: 40000, Loss: 1.303e+02, Loss_bcs: 3.145e-02, Loss_res: 7.350e-01,Time: 0.42\n",
      " kurtosis_grad_res: 5.0331e+01\n",
      " kurtosis_grad_bcs: 4.4402e+01\n",
      "std_grad_bcs: 0.027603\n",
      "std_grad_res: 13.137452\n",
      "adaptive_bcs_val: 6.5849e+02\n",
      "adaptive_res_val: 1.4903e+02\n",
      "Relative L2 error_u: 7.70e-02\n",
      "Relative L2 error_f: 1.11e-02\n",
      "Save uv NN parameters successfully in %s ...checkpoints/Jan-17-2024_12-09-25-521139_M2\n",
      "Final loss total loss: 1.329833e+02\n",
      "Final loss loss_res: 7.534372e-01\n",
      "Final loss loss_bc1: 8.941330e-03\n",
      "Final loss loss_bc2: 4.399592e-03\n",
      "Final loss loss_bc3: 1.087545e-02\n",
      "Final loss loss_bc4: 7.216657e-03\n",
      "average lambda_bc6.5849e+02\n",
      "average lambda_res1.0\n",
      "\n",
      "\n",
      "Method: mini_batch\n",
      "\n",
      "average of time_list:2.7519e+02\n",
      "average of error_u_list:7.7020e-02\n",
      "average of error_v_list:1.1102e-02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "nIter =40001\n",
    "bcbatch_size = 500\n",
    "ubatch_size = 5000\n",
    "mbbatch_size = 128\n",
    "\n",
    "a_1 = 1\n",
    "a_2 = 4\n",
    "\n",
    "# Parameter\n",
    "lam = 1.0\n",
    "\n",
    "# Domain boundaries\n",
    "bc1_coords = np.array([[-1.0, -1.0], [1.0, -1.0]])\n",
    "bc2_coords = np.array([[1.0, -1.0], [1.0, 1.0]])\n",
    "bc3_coords = np.array([[1.0, 1.0], [-1.0, 1.0]])\n",
    "bc4_coords = np.array([[-1.0, 1.0], [-1.0, -1.0]])\n",
    "\n",
    "dom_coords = np.array([[-1.0, -1.0], [1.0, 1.0]])\n",
    "\n",
    "\n",
    "# Train model\n",
    "\n",
    "# Test data\n",
    "nn = 100\n",
    "x1 = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
    "x2 = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
    "x1, x2 = np.meshgrid(x1, x2)\n",
    "X_star = np.hstack((x1.flatten()[:, None], x2.flatten()[:, None]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Exact solution\n",
    "u_star = u(X_star, a_1, a_2)\n",
    "f_star = f(X_star, a_1, a_2, lam)\n",
    "\n",
    "# Create initial conditions samplers\n",
    "ics_sampler = None\n",
    "\n",
    "# Define model\n",
    "mode = 'M2'            # Method: 'M1', 'M2', 'M3', 'M4'\n",
    "stiff_ratio = False    # Log the eigenvalues of Hessian of losses\n",
    "\n",
    "layers = [2, 50, 50, 50, 1]\n",
    "\n",
    "\n",
    "iterations = 1\n",
    "methods = [\"mini_batch\"]\n",
    "\n",
    "result_dict =  dict((mtd, []) for mtd in methods)\n",
    "\n",
    "for mtd in methods:\n",
    "    print(\"Method: \", mtd)\n",
    "    time_list = []\n",
    "    error_u_list = []\n",
    "    error_f_list = []\n",
    "    \n",
    "    for index in range(iterations):\n",
    "\n",
    "        print(\"Epoch: \", str(index+1))\n",
    "\n",
    "\n",
    "        # Create boundary conditions samplers\n",
    "        bc1 = Sampler(2, bc1_coords, lambda x: u(x, a_1, a_2), name='Dirichlet BC1')\n",
    "        bc2 = Sampler(2, bc2_coords, lambda x: u(x, a_1, a_2), name='Dirichlet BC2')\n",
    "        bc3 = Sampler(2, bc3_coords, lambda x: u(x, a_1, a_2), name='Dirichlet BC3')\n",
    "        bc4 = Sampler(2, bc4_coords, lambda x: u(x, a_1, a_2), name='Dirichlet BC4')\n",
    "        bcs_sampler = [bc1, bc2, bc3, bc4]\n",
    "\n",
    "        # Create residual sampler\n",
    "        res_sampler = Sampler(2, dom_coords, lambda x: f(x, a_1, a_2, lam), name='Forcing')\n",
    "\n",
    "        # [elapsed, error_u , error_f ,  mode] = test_method(mtd , layers, operator, ics_sampler, bcs_sampler , res_sampler ,lam , mode , \n",
    "        #                                                                stiff_ratio , X_star ,u_star , f_star , nIter ,bcbatch_size , bcbatch_size , ubatch_size)\n",
    "\n",
    "#test_method(mtd , layers, operator, ics_sampler, bcs_sampler , res_sampler ,lam , mode , stiff_ratio , X_star ,u_star , f_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size)\n",
    "\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
    "        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) as sess:\n",
    "            model = Helmholtz2D(layers, operator, ics_sampler, bcs_sampler, res_sampler, lam, mode, sess)\n",
    " #def __init__(self, layers, operator, ics_sampler, bcs_sampler, res_sampler, lam, mode, sess)\n",
    "            # Train model\n",
    "            start_time = time.time()\n",
    "\n",
    "            if mtd ==\"full_batch\":\n",
    "                model.train(nIter  ,bcbatch_size , ubatch_size )\n",
    "            elif mtd ==\"mini_batch\":\n",
    "                model.trainmb(nIter, batch_size=mbbatch_size )\n",
    "            else:\n",
    "                model.print(\"unknown method!\")\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "\n",
    "            # Predictions\n",
    "            u_pred = model.predict_u(X_star)\n",
    "            f_pred = model.predict_r(X_star)\n",
    "\n",
    "            # Relative error\n",
    "            error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "            error_f = np.linalg.norm(f_star - f_pred, 2) / np.linalg.norm(f_star, 2)\n",
    "\n",
    "            model.print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
    "            model.print('Relative L2 error_f: {:.2e}'.format(error_f))\n",
    "\n",
    "            model.plot_grad()\n",
    "            model.plot_lambda()\n",
    "            model.save_NN()\n",
    "            model.plt_prediction( x1 , x2 , X_star , u_star , u_pred , f_star , f_pred)\n",
    "\n",
    "            model.print(\"average lambda_bc\" , np.average(model.adpative_bcs_log))\n",
    "            model.print(\"average lambda_res\" , str(1.0))\n",
    "            # sess.close()  \n",
    "\n",
    "            time_list.append(elapsed)\n",
    "            error_u_list.append(error_u)\n",
    "            error_f_list.append(error_f)\n",
    "\n",
    "    model.print(\"\\n\\nMethod: \", mtd)\n",
    "    model.print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
    "    model.print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
    "    model.print(\"average of error_v_list:\" , sum(error_f_list) / len(error_f_list) )\n",
    "\n",
    "    result_dict[mtd] = [time_list ,error_u_list ,error_f_list ]\n",
    "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
    "\n",
    "    scipy.io.savemat(os.path.join(model.dirname,\"\"+mtd+\"_Helmholtz_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_exp\"+str(bcbatch_size)+\"nIter\"+str(nIter)+\".mat\") , result_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1408950603.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_116381/1408950603.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    average of time_list:1.7314e+02\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Method: mini_batch\n",
    "\n",
    "average of time_list:1.7314e+02\n",
    "average of error_u_list:5.2605e-03\n",
    "average of error_v_list:9.5779e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'u_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21548/2533309064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Predicted solution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mU_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgriddata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cubic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mF_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgriddata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cubic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'u_pred' is not defined"
     ]
    }
   ],
   "source": [
    "### Plot ###\n",
    "\n",
    "# Exact solution & Predicted solution\n",
    "# Exact soluton\n",
    "U_star = griddata(X_star, u_star.flatten(), (x1, x2), method='cubic')\n",
    "F_star = griddata(X_star, f_star.flatten(), (x1, x2), method='cubic')\n",
    "\n",
    "# Predicted solution\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (x1, x2), method='cubic')\n",
    "F_pred = griddata(X_star, f_pred.flatten(), (x1, x2), method='cubic')\n",
    "\n",
    "fig_1 = plt.figure(1, figsize=(18, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.pcolor(x1, x2, U_star, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title('Exact $u(x)$')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.pcolor(x1, x2, U_pred, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title('Predicted $u(x)$')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.pcolor(x1, x2, np.abs(U_star - U_pred), cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title('Absolute error')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual loss & Boundary loss\n",
    "loss_res = mode.loss_res_log\n",
    "loss_bcs = mode.loss_bcs_log\n",
    "\n",
    "fig_2 = plt.figure(2)\n",
    "ax = fig_2.add_subplot(1, 1, 1)\n",
    "ax.plot(loss_res, label='$\\mathcal{L}_{r}$')\n",
    "ax.plot(loss_bcs, label='$\\mathcal{L}_{u_b}$')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Adaptive Constant\n",
    "adaptive_constant = mode.adpative_constant_log\n",
    "\n",
    "fig_3 = plt.figure(3)\n",
    "ax = fig_3.add_subplot(1, 1, 1)\n",
    "ax.plot(adaptive_constant, label='$\\lambda_{u_b}$')\n",
    "ax.set_xlabel('iterations')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gradients at the end of training\n",
    "data_gradients_res = mode.dict_gradients_res_layers\n",
    "data_gradients_bcs = mode.dict_gradients_bcs_layers\n",
    "\n",
    "gradients_res_list = []\n",
    "gradients_bcs_list = []\n",
    "\n",
    "num_hidden_layers = len(layers) - 1\n",
    "for j in range(num_hidden_layers):\n",
    "    gradient_res = data_gradients_res['layer_' + str(j + 1)][-1]\n",
    "    gradient_bcs = data_gradients_bcs['layer_' + str(j + 1)][-1]\n",
    "\n",
    "    gradients_res_list.append(gradient_res)\n",
    "    gradients_bcs_list.append(gradient_bcs)\n",
    "\n",
    "cnt = 1\n",
    "fig_4 = plt.figure(4, figsize=(13, 4))\n",
    "for j in range(num_hidden_layers):\n",
    "    ax = plt.subplot(1, 4, cnt)\n",
    "    ax.set_title('Layer {}'.format(j + 1))\n",
    "    ax.set_yscale('symlog')\n",
    "    gradients_res = data_gradients_res['layer_' + str(j + 1)][-1]\n",
    "    gradients_bcs = data_gradients_bcs['layer_' + str(j + 1)][-1]\n",
    "    sns.distplot(gradients_bcs, hist=False,\n",
    "                    kde_kws={\"shade\": False},\n",
    "                    norm_hist=True, label=r'$\\nabla_\\theta \\lambda_{u_b} \\mathcal{L}_{u_b}$')\n",
    "    sns.distplot(gradients_res, hist=False,\n",
    "                    kde_kws={\"shade\": False},\n",
    "                    norm_hist=True, label=r'$\\nabla_\\theta \\mathcal{L}_r$')\n",
    "    \n",
    "    ax.get_legend().remove()\n",
    "    ax.set_xlim([-3.0, 3.0])\n",
    "    ax.set_ylim([0,100])\n",
    "    cnt += 1\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig_4.legend(handles, labels, loc=\"upper left\", bbox_to_anchor=(0.35, -0.01),\n",
    "            borderaxespad=0, bbox_transform=fig_4.transFigure, ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Eigenvalues if applicable\n",
    "if stiff_ratio:\n",
    "    eigenvalues_list = mode.eigenvalue_log\n",
    "    eigenvalues_bcs_list = mode.eigenvalue_bcs_log\n",
    "    eigenvalues_res_list = mode.eigenvalue_res_log\n",
    "    eigenvalues_res = eigenvalues_res_list[-1]\n",
    "    eigenvalues_bcs = eigenvalues_bcs_list[-1]\n",
    "\n",
    "    fig_5 = plt.figure(5)\n",
    "    ax = fig_5.add_subplot(1, 1, 1)\n",
    "    ax.plot(eigenvalues_res, label='$\\mathcal{L}_r$')\n",
    "    ax.plot(eigenvalues_bcs, label='$\\mathcal{L}_{u_b}$')\n",
    "    ax.set_xlabel('index')\n",
    "    ax.set_ylabel('eigenvalue')\n",
    "    ax.set_yscale('symlog')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twoPhase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
