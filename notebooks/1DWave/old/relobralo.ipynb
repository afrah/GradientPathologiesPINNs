{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7WkCgnRiYQSY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import timeit\n",
        "from scipy.interpolate import griddata\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"KMP_WARNINGS\"] = \"FALSE\" \n",
        "import timeit\n",
        "\n",
        "import sys\n",
        "\n",
        "import scipy\n",
        "import scipy.io\n",
        "import time\n",
        "\n",
        "\n",
        "import logging\n",
        "\n",
        "import os.path\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "class Sampler:\n",
        "    # Initialize the class\n",
        "    def __init__(self, dim, coords, func, name = None):\n",
        "        self.dim = dim\n",
        "        self.coords = coords\n",
        "        self.func = func\n",
        "        self.name = name\n",
        "    def sample(self, N):\n",
        "        x = self.coords[0:1,:] + (self.coords[1:2,:]-self.coords[0:1,:])*np.random.rand(N, self.dim)\n",
        "        y = self.func(x)\n",
        "        return x, y\n",
        "\n",
        "# Define the exact solution and its derivatives\n",
        "def u(x, a, c):\n",
        "    \"\"\"\n",
        "    :param x: x = (t, x)\n",
        "    \"\"\"\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    return np.sin(np.pi * x) * np.cos(c * np.pi * t) + a * np.sin(2 * c * np.pi* x) * np.cos(4 * c  * np.pi * t)\n",
        "\n",
        "def u_t(x,a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_t = -  c * np.pi * np.sin(np.pi * x) * np.sin(c * np.pi * t) -  a * 4 * c * np.pi * np.sin(2 * c * np.pi* x) * np.sin(4 * c * np.pi * t)\n",
        "    return u_t\n",
        "\n",
        "def u_tt(x, a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_tt = -(c * np.pi)**2 * np.sin( np.pi * x) * np.cos(c * np.pi * t) - a * (4 * c * np.pi)**2 *  np.sin(2 * c * np.pi* x) * np.cos(4 * c * np.pi * t)\n",
        "    return u_tt\n",
        "\n",
        "def u_xx(x, a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_xx = - np.pi**2 * np.sin( np.pi * x) * np.cos(c * np.pi * t) -  a * (2 * c * np.pi)** 2 * np.sin(2 * c * np.pi* x) * np.cos(4 * c * np.pi * t)\n",
        "    return  u_xx\n",
        "\n",
        "\n",
        "def r(x, a, c):\n",
        "    return u_tt(x, a, c) - c**2 * u_xx(x, a, c)\n",
        "\n",
        "def operator(u, t, x, c, sigma_t=1.0, sigma_x=1.0):\n",
        "    u_t = tf.gradients(u, t)[0] / sigma_t\n",
        "    u_x = tf.gradients(u, x)[0] / sigma_x\n",
        "    u_tt = tf.gradients(u_t, t)[0] / sigma_t\n",
        "    u_xx = tf.gradients(u_x, x)[0] / sigma_x\n",
        "    residual = u_tt - c**2 * u_xx\n",
        "    return residual\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SDqDWN3nfSAg"
      },
      "outputs": [],
      "source": [
        "class PINN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, layers, operator, ics_sampler, bcs_sampler, res_sampler, c , mode ,  sess):\n",
        "        # Normalization \n",
        "#            model = PINN(layers, operator,coll_sampler ,  ics_sampler, bcs_sampler, res_sampler, c , mode , sess)\n",
        "\n",
        "\n",
        "        self.mode = mode\n",
        "\n",
        "        self.dirname, logpath = self.make_output_dir()\n",
        "        self.logger = self.get_logger(logpath)     \n",
        "\n",
        "        X, _ = res_sampler.sample(np.int32(1e5))\n",
        "        self.mu_X, self.sigma_X = X.mean(0), X.std(0)\n",
        "        self.mu_t, self.sigma_t = self.mu_X[0], self.sigma_X[0]\n",
        "        self.mu_x, self.sigma_x = self.mu_X[1], self.sigma_X[1]\n",
        "\n",
        "        # Samplers\n",
        "        self.operator = operator\n",
        "        self.ics_sampler = ics_sampler\n",
        "        self.bcs_sampler = bcs_sampler\n",
        "        self.res_sampler = res_sampler\n",
        "\n",
        "        self.sess = sess\n",
        "        # Initialize network weights and biases\n",
        "        self.layers = layers\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # weights\n",
        "        self.adaptive_constant_bcs_val = np.array(1.0)\n",
        "        self.adaptive_constant_ics_val = np.array(1.0)\n",
        "        self.adaptive_constant_res_val = np.array(1.0)\n",
        "        self.rate = 0.5\n",
        "        self.rho = 0.5\n",
        "        self.T = 0.9\n",
        "\n",
        "        # Wave constant\n",
        "        self.c = tf.constant(c, dtype=tf.float32)\n",
        "        \n",
        "        # self.kernel_size = kernel_size # Size of the NTK matrix\n",
        "\n",
        "        # Define Tensorflow session\n",
        "        self.sess = sess #tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
        "\n",
        "        # Define placeholders and computational graph\n",
        "        self.t_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.u_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        \n",
        "        self.adaptive_constant_bcs_tf = tf.placeholder(tf.float32, shape=self.adaptive_constant_bcs_val.shape)\n",
        "        self.adaptive_constant_ics_tf = tf.placeholder(tf.float32, shape=self.adaptive_constant_ics_val.shape)\n",
        "        self.adaptive_constant_res_tf = tf.placeholder(tf.float32, shape=self.adaptive_constant_res_val.shape)\n",
        "        \n",
        "\n",
        "        # Evaluate predictions\n",
        "        self.u_ics_pred = self.net_u(self.t_ics_tf, self.x_ics_tf)\n",
        "        self.u_t_ics_pred = self.net_u_t(self.t_ics_tf, self.x_ics_tf)\n",
        "        self.u_bc1_pred = self.net_u(self.t_bc1_tf, self.x_bc1_tf)\n",
        "        self.u_bc2_pred = self.net_u(self.t_bc2_tf, self.x_bc2_tf)\n",
        "\n",
        "        self.u_pred = self.net_u(self.t_u_tf, self.x_u_tf)\n",
        "        self.r_pred = self.net_r(self.t_r_tf, self.x_r_tf)\n",
        "        \n",
        "\n",
        "        # Boundary loss and Initial loss\n",
        "        self.loss_ics_u = tf.reduce_mean(tf.square(self.u_ics_tf - self.u_ics_pred))\n",
        "        self.loss_ics_u_t = tf.reduce_mean(tf.square(self.u_t_ics_pred))\n",
        "        self.loss_bc1 = tf.reduce_mean(tf.square(self.u_bc1_pred))\n",
        "        self.loss_bc2 = tf.reduce_mean(tf.square(self.u_bc2_pred))\n",
        "\n",
        "        self.loss_bcs = self.loss_ics_u + self.loss_bc1 + self.loss_bc2\n",
        "\n",
        "        # Residual loss\n",
        "        self.loss_res = tf.reduce_mean(tf.square(self.r_pred))\n",
        "\n",
        "        # Total loss\n",
        "        self.loss =  self.adaptive_constant_res_tf * self.loss_res + self.adaptive_constant_bcs_tf * self.loss_bcs + self.adaptive_constant_ics_tf * self.loss_ics_u_t \n",
        "\n",
        "        # Define optimizer with learning rate schedule\n",
        "        self.global_step = tf.Variable(0, trainable=False)\n",
        "        starter_learning_rate = 1e-3\n",
        "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step, 1000, 0.9, staircase=False)\n",
        "        # Passing global_step to minimize() will increment it at each step.\n",
        "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss, global_step=self.global_step)\n",
        "\n",
        "\n",
        "        self.loss_tensor_list = [self.loss ,  self.loss_res ,  self.loss_bcs ,  self.loss_bc1 , self.loss_bc2 , self.loss_ics_u, self.loss_ics_u_t] \n",
        "        self.loss_list = [\"total loss\" , \"loss_res\" , \"loss_bcs\" , \"loss_bc1\", \"loss_bc2\", \"loss_ics_u\", \"loss_ics_u_t\"] \n",
        "\n",
        "        self.epoch_loss = dict.fromkeys(self.loss_list, 0)\n",
        "        self.loss_history = dict((loss, []) for loss in self.loss_list)\n",
        "        # Logger\n",
        "        self.loss_u_log = []\n",
        "        self.loss_r_log = []\n",
        "\n",
        "        # self.saver = tf.train.Saver()\n",
        "\n",
        "        # # Generate dicts for gradients storage\n",
        "        self.dict_gradients_res_layers = self.generate_grad_dict()\n",
        "        self.dict_gradients_bcs_layers = self.generate_grad_dict()\n",
        "        self.dict_gradients_ics_layers = self.generate_grad_dict()\n",
        "        \n",
        "   # Gradients Storage\n",
        "        self.grad_res = []\n",
        "        self.grad_ics = []\n",
        "        self.grad_bcs = []\n",
        "\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            self.grad_res.append(tf.gradients(self.loss_res, self.weights[i])[0])\n",
        "            self.grad_bcs.append(tf.gradients(self.loss_bcs, self.weights[i])[0])\n",
        "            self.grad_ics.append(tf.gradients(self.loss_ics_u_t, self.weights[i])[0])\n",
        "\n",
        "           \n",
        "        self.max_grad_res_list = []\n",
        "        self.mean_grad_bcs_list = []\n",
        "        self.mean_grad_ics_list = []\n",
        "\n",
        "        self.adaptive_constant_bcs_log = []\n",
        "        self.adaptive_constant_ics_log = []\n",
        "        self.adaptive_constant_res_log = []\n",
        "\n",
        "        self.max_grad_res_log = []\n",
        "        self.mean_grad_bcs_log = []\n",
        "        self.mean_grad_ics_log = []\n",
        "\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            self.max_grad_res_list.append(tf.math.reduce_max(tf.abs(self.grad_res[i]))) \n",
        "            self.mean_grad_bcs_list.append(tf.math.reduce_mean(tf.abs(self.grad_bcs[i])))\n",
        "            self.mean_grad_ics_list.append(tf.math.reduce_mean(tf.abs(self.grad_ics[i])))\n",
        "        \n",
        "        self.max_grad_res = tf.math.reduce_mean(tf.stack(self.max_grad_res_list))\n",
        "        self.mean_grad_bcs = tf.math.reduce_mean(tf.stack(self.mean_grad_bcs_list))\n",
        "        self.mean_grad_ics = tf.math.reduce_mean(tf.stack(self.mean_grad_ics_list))\n",
        "        \n",
        "        self.adaptive_constant_bcs = self.max_grad_res  / self.mean_grad_bcs\n",
        "        self.adaptive_constant_ics = self.max_grad_res  / self.mean_grad_ics\n",
        "        self.adaptive_constant_res = self.max_grad_res\n",
        "\n",
        "\n",
        "        self.prev_lam_ics_u_t = 1\n",
        "        self.prev_lam_bc = 1\n",
        "        self.prev_lam_res =1\n",
        "        self.index = 1\n",
        "        # self.prev2_loss_ics_u = 0\n",
        "        # self.prev2_loss_ics_u_t = 0\n",
        "        # self.prev2_loss_bc1  = 0\n",
        "        # self.prev2_loss_bc2 = 0\n",
        "        # self.prev2_loss_res = 0\n",
        "\n",
        "         # Initialize Tensorflow variables\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    # Initialize network weights and biases using Xavier initialization\n",
        "    def initialize_NN(self, layers):\n",
        "        # Xavier initialization\n",
        "        def xavier_init(size):\n",
        "            in_dim = size[0]\n",
        "            out_dim = size[1]\n",
        "            xavier_stddev = 1. / np.sqrt((in_dim + out_dim) / 2.)\n",
        "            return tf.Variable(tf.random.normal([in_dim, out_dim], dtype=tf.float32) * xavier_stddev, dtype=tf.float32)\n",
        "\n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 1):\n",
        "            W = xavier_init(size=[layers[l], layers[l + 1]])\n",
        "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "\n",
        "    # Evaluates the forward pass\n",
        "    def forward_pass(self, H, layers, weights, biases):\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        H = tf.add(tf.matmul(H, W), b)\n",
        "        return H\n",
        "\n",
        "    # Forward pass for u\n",
        "    def net_u(self, t, x):\n",
        "        u = self.forward_pass(tf.concat([t, x], 1), self.layers, self.weights,  self.biases)\n",
        "        return u\n",
        "\n",
        "    # Forward pass for du/dt\n",
        "    def net_u_t(self, t, x):\n",
        "        u_t = tf.gradients(self.net_u(t, x), t)[0] / self.sigma_t\n",
        "        return u_t\n",
        "\n",
        "    # Forward pass for the residual\n",
        "    def net_r(self, t, x):\n",
        "        u = self.net_u(t, x)\n",
        "        residual = self.operator(u, t, x, self.c, self.sigma_t,  self.sigma_x)\n",
        "        return residual\n",
        "    \n",
        "    def fetch_minibatch(self, sampler, N):\n",
        "        X, Y = sampler.sample(N)\n",
        "        X = (X - self.mu_X) / self.sigma_X\n",
        "        return X, Y\n",
        "\n",
        "        # Trains the model by minimizing the MSE loss\n",
        "\n",
        "    def lambda_balance(self ,term , index):\n",
        "        loss_list = [\"loss_res\" , \"loss_bcs\" , \"loss_ics_u_t\"] \n",
        "\n",
        "        m = len(loss_list)\n",
        "        num = np.exp(self.loss_history[term][-1] /(self.T * self.loss_history[term][index]))\n",
        "        denum = 0 \n",
        "\n",
        "        for  key in loss_list:\n",
        "            denum +=  np.exp(self.loss_history[key][-1] /(self.T * self.loss_history[key][index]))\n",
        "        return m * (num / denum)\n",
        "     \n",
        "    def relobralo( self, term ,prev_lamda ):\n",
        "\n",
        "        lambda_hist = self.rho  * prev_lamda + (1.0 - self.rho) *  self.lambda_balance( term , 1)\n",
        "        lambda_i = self.rate  * lambda_hist + (1.0 - self.rate) *  self.lambda_balance( term , self.index)\n",
        "\n",
        "        return lambda_i\n",
        "    \n",
        "    def trainmb(self,batch_size=128,  nIter=10000):\n",
        "\n",
        "        itValues = [1,100,1000,39999]\n",
        "\n",
        "        start_time = timeit.default_timer()\n",
        "        for it in range(1, nIter):\n",
        "            # Fetch boundary mini-batches\n",
        "            X_ics_batch, u_ics_batch = self.fetch_minibatch(self.ics_sampler, batch_size // 3)\n",
        "            X_bc1_batch, _ = self.fetch_minibatch(self.bcs_sampler[0], batch_size // 3)\n",
        "            X_bc2_batch, _ = self.fetch_minibatch(self.bcs_sampler[1], batch_size // 3)\n",
        "            \n",
        "            # Fetch residual mini-batch\n",
        "            X_res_batch, _ = self.fetch_minibatch(self.res_sampler, batch_size)\n",
        "\n",
        "            # Define a dictionary for associating placeholders with data\n",
        "            tf_dict = {self.t_ics_tf: X_ics_batch[:, 0:1],\n",
        "                       self.x_ics_tf: X_ics_batch[:, 1:2],\n",
        "                       self.u_ics_tf: u_ics_batch,\n",
        "                       self.t_bc1_tf: X_bc1_batch[:, 0:1],\n",
        "                        self.x_bc1_tf: X_bc1_batch[:, 1:2],\n",
        "                       self.t_bc2_tf: X_bc2_batch[:, 0:1], \n",
        "                       self.x_bc2_tf: X_bc2_batch[:, 1:2],\n",
        "                       self.t_r_tf: X_res_batch[:, 0:1], \n",
        "                       self.x_r_tf: X_res_batch[:, 1:2],\n",
        "                       self.adaptive_constant_bcs_tf: self.adaptive_constant_bcs_val,\n",
        "                       self.adaptive_constant_ics_tf: self.adaptive_constant_ics_val,\n",
        "                       self.adaptive_constant_res_tf: self.adaptive_constant_res_val\n",
        "                       }#self.lam_r_val}\n",
        "\n",
        "            # Run the Tensorflow session to minimize the loss\n",
        "            _ , batch_losses = self.sess.run( [  self.train_op , self.loss_tensor_list ] ,tf_dict)\n",
        "            \n",
        "            self.assign_batch_losses(batch_losses)\n",
        "            for key in self.loss_history:\n",
        "                self.loss_history[key].append(self.epoch_loss[key])\n",
        "\n",
        "            # self.print\n",
        "            if it % 100== 0:\n",
        "                elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "                loss = self.sess.run(self.loss, tf_dict)\n",
        "                loss_bc1 = self.sess.run(self.loss_bc1, tf_dict)\n",
        "                loss_bc2 = self.sess.run(self.loss_bc2, tf_dict)\n",
        "                loss_ics_u = self.sess.run(self.loss_ics_u, tf_dict)\n",
        "                loss_ics_u_t = self.sess.run(self.loss_ics_u_t, tf_dict)\n",
        "                loss_res = self.sess.run(self.loss_res, tf_dict)\n",
        "\n",
        "                self.print('It: %d |  Loss: %.3e |  Loss_res: %.3e |   Loss_bcs1: %.3e | Loss_bc2s: %.3e |  loss_ics_u: %.3e |  Loss_ut_ics: %.3e |  Time: %.2f' %(it ,  \n",
        "                                                                                                                                                                   loss ,\n",
        "                                                                                                                                                                       loss_res ,\n",
        "                                                                                                                                                                           loss_bc1 ,\n",
        "                                                                                                                                                                               loss_bc2  , \n",
        "                                                                                                                                                                                 loss_ics_u ,\n",
        "                                                                                                                                                                                     loss_ics_u_t  ,\n",
        "                                                                                                                                                                                         elapsed))\n",
        "\n",
        "\n",
        "                # batch_losses = [loss ,  loss_res,  loss_bc1 , loss_bc2 , loss_ics_u] \n",
        "            if it % 100 == 0:\n",
        "\n",
        "                self.adaptive_constant_res_val =  self.relobralo( \"loss_res\"  ,self.prev_lam_res )  #fres *  np.exp(self.rate * fres)  /norm\n",
        "                self.adaptive_constant_ics_val =  self.relobralo( \"loss_ics_u_t\"  ,self.prev_lam_ics_u_t )  #fic *np.exp(self.rate * fic) /norm\n",
        "                self.adaptive_constant_bcs_val =  self.relobralo( \"loss_bcs\"  ,self.prev_lam_bc )  #fbc *np.exp(self.rate * fbc)/norm\n",
        "\n",
        "\n",
        "                self.print('adaptive_constant_res_val: {:.3e}'.format(  self.adaptive_constant_res_val))\n",
        "                self.print('adaptive_constant_ics_val: {:.3e}'.format(  self.adaptive_constant_ics_val))\n",
        "                self.print('adaptive_constant_bcs_val: {:.3e}'.format(  self.adaptive_constant_bcs_val))\n",
        "                \n",
        "                self.adaptive_constant_res_log.append( self.adaptive_constant_res_val)\n",
        "                self.adaptive_constant_bcs_log.append( self.adaptive_constant_bcs_val)\n",
        "                self.adaptive_constant_ics_log.append( self.adaptive_constant_ics_val)\n",
        "\n",
        "                self.prev_lam_ics_u_t = self.adaptive_constant_ics_val\n",
        "                self.prev_lam_bc = self.adaptive_constant_bcs_val\n",
        "                self.prev_lam_res = self.adaptive_constant_res_val\n",
        "                self.index = it\n",
        "\n",
        "            max_grad_res , mean_grad_bcs, mean_grad_ics = self.sess.run( [ self.max_grad_res , self.mean_grad_bcs, self.mean_grad_ics  ], tf_dict)\n",
        "            self.max_grad_res_log.append(max_grad_res)\n",
        "            self.mean_grad_bcs_log.append(mean_grad_bcs)\n",
        "            self.mean_grad_ics_log.append(mean_grad_ics)\n",
        "\n",
        "            start_time = timeit.default_timer()\n",
        "            \n",
        "            if it in itValues:\n",
        "                    self.plot_layerLoss(tf_dict , it)\n",
        "                    self.print(\"Gradients information stored ...\")\n",
        "\n",
        "            sys.stdout.flush()\n",
        " \n",
        "\n",
        "    def train(self, bcbatch_size , ubatch_size , nIter):\n",
        "\n",
        "   \n",
        "        itValues = [1,100,1000,39999]\n",
        "\n",
        "        start_time = timeit.default_timer()\n",
        "        # Fetch boundary mini-batches\n",
        "        X_ics_batch, u_ics_batch = self.fetch_minibatch(self.ics_sampler, bcbatch_size)\n",
        "        X_bc1_batch, _ = self.fetch_minibatch(self.bcs_sampler[0], bcbatch_size)\n",
        "        X_bc2_batch, _ = self.fetch_minibatch(self.bcs_sampler[1], bcbatch_size)\n",
        "        \n",
        "        # Fetch residual mini-batch\n",
        "        X_res_batch, _ = self.fetch_minibatch(self.res_sampler, ubatch_size)\n",
        "\n",
        "        # Define a dictionary for associating placeholders with data\n",
        "        tf_dict = {self.t_ics_tf: X_ics_batch[:, 0:1],\n",
        "                    self.x_ics_tf: X_ics_batch[:, 1:2],\n",
        "                    self.u_ics_tf: u_ics_batch,\n",
        "                    self.t_bc1_tf: X_bc1_batch[:, 0:1],\n",
        "                    self.x_bc1_tf: X_bc1_batch[:, 1:2],\n",
        "                    self.t_bc2_tf: X_bc2_batch[:, 0:1], \n",
        "                    self.x_bc2_tf: X_bc2_batch[:, 1:2],\n",
        "                    self.t_r_tf: X_res_batch[:, 0:1], \n",
        "                    self.x_r_tf: X_res_batch[:, 1:2],\n",
        "                    self.adaptive_constant_bcs_tf: self.adaptive_constant_bcs_val,\n",
        "                    self.adaptive_constant_ics_tf: self.adaptive_constant_ics_val,\n",
        "                    self.adaptive_constant_res_tf: self.adaptive_constant_res_val\n",
        "                    }#self.lam_r_val}\n",
        "\n",
        "        for it in range(1, nIter):\n",
        "\n",
        "            # Run the Tensorflow session to minimize the loss\n",
        "            _ , batch_losses = self.sess.run( [  self.train_op , self.loss_tensor_list ] ,tf_dict)\n",
        "            \n",
        "            self.assign_batch_losses(batch_losses)\n",
        "            for key in self.loss_history:\n",
        "                self.loss_history[key].append(self.epoch_loss[key])\n",
        "\n",
        "            # self.print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "                loss = self.sess.run(self.loss, tf_dict)\n",
        "                loss_bc1 = self.sess.run(self.loss_bc1, tf_dict)\n",
        "                loss_bc2 = self.sess.run(self.loss_bc2, tf_dict)\n",
        "                loss_ics_u = self.sess.run(self.loss_ics_u, tf_dict)\n",
        "                loss_ics_u_t = self.sess.run(self.loss_ics_u_t, tf_dict)\n",
        "                loss_res = self.sess.run(self.loss_res, tf_dict)\n",
        "\n",
        "                self.print('It: %d |  Loss: %.3e |  Loss_res: %.3e |   Loss_bcs1: %.3e | Loss_bc2s: %.3e |  loss_ics_u: %.3e |  Loss_ut_ics: %.3e |  Time: %.2f' %(it ,  \n",
        "                                                                                                                                                                   loss ,\n",
        "                                                                                                                                                                       loss_res ,\n",
        "                                                                                                                                                                           loss_bc1 ,\n",
        "                                                                                                                                                                               loss_bc2  , \n",
        "                                                                                                                                                                                 loss_ics_u ,\n",
        "                                                                                                                                                                                     loss_ics_u_t  ,\n",
        "                                                                                                                                                                                         elapsed))\n",
        "\n",
        "\n",
        "                # batch_losses = [loss ,  loss_res,  loss_bc1 , loss_bc2 , loss_ics_u] \n",
        "            if it % 100 == 0:\n",
        "\n",
        "                self.adaptive_constant_res_val =  self.relobralo( \"loss_res\"  ,self.prev_lam_res )  #fres *  np.exp(self.rate * fres)  /norm\n",
        "                self.adaptive_constant_ics_val =  self.relobralo( \"loss_ics_u_t\"  ,self.prev_lam_ics_u_t )  #fic *np.exp(self.rate * fic) /norm\n",
        "                self.adaptive_constant_bcs_val =  self.relobralo( \"loss_bcs\"  ,self.prev_lam_bc )  #fbc *np.exp(self.rate * fbc)/norm\n",
        "\n",
        "\n",
        "                self.print('adaptive_constant_res_val: {:.3e}'.format(  self.adaptive_constant_res_val))\n",
        "                self.print('adaptive_constant_ics_val: {:.3e}'.format(  self.adaptive_constant_ics_val))\n",
        "                self.print('adaptive_constant_bcs_val: {:.3e}'.format(  self.adaptive_constant_bcs_val))\n",
        "                \n",
        "                self.adaptive_constant_res_log.append( self.adaptive_constant_res_val)\n",
        "                self.adaptive_constant_bcs_log.append( self.adaptive_constant_bcs_val)\n",
        "                self.adaptive_constant_ics_log.append( self.adaptive_constant_ics_val)\n",
        "\n",
        "                self.prev_lam_ics_u_t = self.adaptive_constant_ics_val\n",
        "                self.prev_lam_bc = self.adaptive_constant_bcs_val\n",
        "                self.prev_lam_res = self.adaptive_constant_res_val\n",
        "                self.index = it\n",
        "\n",
        "            max_grad_res , mean_grad_bcs, mean_grad_ics = self.sess.run( [ self.max_grad_res , self.mean_grad_bcs, self.mean_grad_ics  ], tf_dict)\n",
        "            self.max_grad_res_log.append(max_grad_res)\n",
        "            self.mean_grad_bcs_log.append(mean_grad_bcs)\n",
        "            self.mean_grad_ics_log.append(mean_grad_ics)\n",
        "\n",
        "            start_time = timeit.default_timer()\n",
        "            \n",
        "            if it in itValues:\n",
        "                    self.plot_layerLoss(tf_dict , it)\n",
        "                    self.print(\"Gradients information stored ...\")\n",
        "\n",
        "            sys.stdout.flush()\n",
        "                         \n",
        "    # Evaluates predictions at test points\n",
        "    def predict_u(self, X_star):\n",
        "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
        "        tf_dict = {self.t_u_tf: X_star[:, 0:1], self.x_u_tf: X_star[:, 1:2]}\n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        return u_star\n",
        "\n",
        "        # Evaluates predictions at test points\n",
        "\n",
        "    def predict_r(self, X_star):\n",
        "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
        "        tf_dict = {self.t_r_tf: X_star[:, 0:1], self.x_r_tf: X_star[:, 1:2]}\n",
        "        r_star = self.sess.run(self.r_pred, tf_dict)\n",
        "        return r_star\n",
        "    \n",
        "   ###############################################################################################################################################\n",
        "   # \n",
        "   # ###############################################################################################################################################\n",
        "   # \n",
        "   # ###############################################################################################################################################\n",
        "   # \n",
        "   #  \n",
        "    def plot_layerLoss(self , tf_dict , epoch):\n",
        "        ## Gradients #\n",
        "        num_layers = len(self.layers)\n",
        "        for i in range(num_layers - 1):\n",
        "            grad_res, grad_bc1  , grad_ics  = self.sess.run([ self.grad_res[i],self.grad_bcs[i],self.grad_ics[i]], feed_dict=tf_dict)\n",
        "\n",
        "            # save gradients of loss_r and loss_u\n",
        "            self.dict_gradients_res_layers['layer_' + str(i + 1)].append(grad_res.flatten())\n",
        "            self.dict_gradients_bcs_layers['layer_' + str(i + 1)].append(grad_bc1.flatten())\n",
        "            self.dict_gradients_ics_layers['layer_' + str(i + 1)].append(grad_ics.flatten())\n",
        "\n",
        "        num_hidden_layers = num_layers -1\n",
        "        cnt = 1\n",
        "        fig = plt.figure(4, figsize=(13, 4))\n",
        "        for j in range(num_hidden_layers):\n",
        "            ax = plt.subplot(1, num_hidden_layers, cnt)\n",
        "            ax.set_title('Layer {}'.format(j + 1))\n",
        "            ax.set_yscale('symlog')\n",
        "            gradients_res = self.dict_gradients_res_layers['layer_' + str(j + 1)][-1]\n",
        "            gradients_bc1 = self.dict_gradients_bcs_layers['layer_' + str(j + 1)][-1]\n",
        "            gradients_ics = self.dict_gradients_ics_layers['layer_' + str(j + 1)][-1]\n",
        "\n",
        "            sns.distplot(gradients_res, hist=False,kde_kws={\"shade\": False},norm_hist=True,  label=r'$\\nabla_\\theta \\mathcal{L}_r$')\n",
        "\n",
        "            sns.distplot(gradients_bc1, hist=False,kde_kws={\"shade\": False},norm_hist=True,   label=r'$\\nabla_\\theta \\mathcal{L}_{u_{bc1}}$')\n",
        "            sns.distplot(gradients_ics, hist=False,kde_kws={\"shade\": False},norm_hist=True,   label=r'$\\nabla_\\theta \\mathcal{L}_{u_{ics}}$')\n",
        "\n",
        "            #ax.get_legend().remove()\n",
        "            ax.set_xlim([-1.0, 1.0])\n",
        "            #ax.set_ylim([0, 150])\n",
        "            cnt += 1\n",
        "        handles, labels = ax.get_legend_handles_labels()\n",
        "\n",
        "        fig.legend(handles, labels, loc=\"center\",  bbox_to_anchor=(0.5, -0.03),borderaxespad=0,bbox_transform=fig.transFigure, ncol=3)\n",
        "        text = 'layerLoss_epoch' + str(epoch) +'.png'\n",
        "        plt.savefig(os.path.join(self.dirname,text) , bbox_inches='tight')\n",
        "        plt.close(\"all\")\n",
        "    # #########################\n",
        "    # def make_output_dir(self):\n",
        "        \n",
        "    #     if not os.path.exists(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\"):\n",
        "    #         os.mkdir(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\")\n",
        "    #     dirname = os.path.join(\"/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/checkpoints\", datetime.now().strftime(\"%b-%d-%Y_%H-%M-%S-%f_\") + self.mode)\n",
        "    #     os.mkdir(dirname)\n",
        "    #     text = 'output.log'\n",
        "    #     logpath = os.path.join(dirname, text)\n",
        "    #     shutil.copyfile('/okyanus/users/afarea/PINN/Adaptive_PINN/IB_PINN/M2.py', os.path.join(dirname, 'M2.py'))\n",
        "\n",
        "    #     return dirname, logpath\n",
        "    \n",
        "    # # ###########################################################\n",
        "    def make_output_dir(self):\n",
        "        \n",
        "        if not os.path.exists(\"checkpoints\"):\n",
        "            os.mkdir(\"checkpoints\")\n",
        "        dirname = os.path.join(\"checkpoints\", datetime.now().strftime(\"%b-%d-%Y_%H-%M-%S-%f_\") + self.mode)\n",
        "        os.mkdir(dirname)\n",
        "        text = 'output.log'\n",
        "        logpath = os.path.join(dirname, text)\n",
        "        shutil.copyfile('M1.ipynb', os.path.join(dirname, 'M1.ipynb'))\n",
        "        return dirname, logpath\n",
        "    \n",
        "\n",
        "    def get_logger(self, logpath):\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "        sh = logging.StreamHandler()\n",
        "        sh.setLevel(logging.DEBUG)        \n",
        "        sh.setFormatter(logging.Formatter('%(message)s'))\n",
        "        fh = logging.FileHandler(logpath)\n",
        "        logger.addHandler(sh)\n",
        "        logger.addHandler(fh)\n",
        "        return logger\n",
        "\n",
        "\n",
        "   \n",
        "    def print(self, *args):\n",
        "        for word in args:\n",
        "            if len(args) == 1:\n",
        "                self.logger.info(word)\n",
        "            elif word != args[-1]:\n",
        "                for handler in self.logger.handlers:\n",
        "                    handler.terminator = \"\"\n",
        "                if type(word) == float or type(word) == np.float64 or type(word) == np.float32: \n",
        "                    self.logger.info(\"%.4e\" % (word))\n",
        "                else:\n",
        "                    self.logger.info(word)\n",
        "            else:\n",
        "                for handler in self.logger.handlers:\n",
        "                    handler.terminator = \"\\n\"\n",
        "                if type(word) == float or type(word) == np.float64 or type(word) == np.float32:\n",
        "                    self.logger.info(\"%.4e\" % (word))\n",
        "                else:\n",
        "                    self.logger.info(word)\n",
        "\n",
        "\n",
        "    def plot_loss_history(self , path):\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches([15,8])\n",
        "        for key in self.loss_history:\n",
        "            self.print(\"Final loss %s: %e\" % (key, self.loss_history[key][-1]))\n",
        "            ax.semilogy(self.loss_history[key], label=key)\n",
        "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
        "        ax.set_ylabel(\"loss\", fontsize=15)\n",
        "        ax.tick_params(labelsize=15)\n",
        "        ax.legend()\n",
        "        plt.savefig(path)\n",
        "        #plt.show()\n",
        "       #######################\n",
        "    def save_NN(self):\n",
        "\n",
        "        uv_weights = self.sess.run(self.weights)\n",
        "        uv_biases = self.sess.run(self.biases)\n",
        "\n",
        "        with open(os.path.join(self.dirname,'model.pickle'), 'wb') as f:\n",
        "            pickle.dump([uv_weights, uv_biases], f)\n",
        "            self.print(\"Save uv NN parameters successfully in %s ...\" , self.dirname)\n",
        "\n",
        "        # with open(os.path.join(self.dirname,'loss_history_BFS.pickle'), 'wb') as f:\n",
        "        #     pickle.dump(self.loss_rec, f)\n",
        "        with open(os.path.join(self.dirname,'loss_history_BFS.png'), 'wb') as f:\n",
        "            self.plot_loss_history(f)\n",
        "\n",
        "\n",
        "    def assign_batch_losses(self, batch_losses):\n",
        "        for loss_values, key in zip(batch_losses, self.epoch_loss):\n",
        "            self.epoch_loss[key] = loss_values\n",
        "\n",
        "\n",
        "    def generate_grad_dict(self):\n",
        "        num = len(self.layers) - 1\n",
        "        grad_dict = {}\n",
        "        for i in range(num):\n",
        "            grad_dict['layer_{}'.format(i + 1)] = []\n",
        "        return grad_dict\n",
        "    \n",
        "    def plt_prediction(self , t , x , X_star , u_star , u_pred , r_star , r_pred):\n",
        "        \n",
        "        U_star = griddata(X_star, u_star.flatten(), (t, x), method='cubic')\n",
        "        r_star = griddata(X_star, r_star.flatten(), (t, x), method='cubic')\n",
        "        U_pred = griddata(X_star, u_pred.flatten(), (t, x), method='cubic')\n",
        "        R_pred = griddata(X_star, r_pred.flatten(), (t, x), method='cubic')\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(18, 9))\n",
        "        plt.subplot(2, 3, 1)\n",
        "        plt.pcolor(t, x, U_star, cmap='jet')\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('$x_1$')\n",
        "        plt.ylabel('$x_2$')\n",
        "        plt.title('Exact u(t, x)')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(2, 3, 2)\n",
        "        plt.pcolor(t, x, U_pred, cmap='jet')\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('$t$')\n",
        "        plt.ylabel('$x$')\n",
        "        plt.title('Predicted u(t, x)')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(2, 3, 3)\n",
        "        plt.pcolor(t, x, np.abs(U_star - U_pred), cmap='jet')\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('$t$')\n",
        "        plt.ylabel('$x$')\n",
        "        plt.title('Absolute error')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(2, 3, 4)\n",
        "        plt.pcolor(t, x, r_star, cmap='jet')\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('$t$')\n",
        "        plt.ylabel('$x$')\n",
        "        plt.title('Exact r(t, x)')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(2, 3, 5)\n",
        "        plt.pcolor(t, x, R_pred, cmap='jet')\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('$t$')\n",
        "        plt.ylabel('$x$')\n",
        "        plt.title('Predicted r(t, x)')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(2, 3, 6)\n",
        "        plt.pcolor(t, x, np.abs(r_star - R_pred), cmap='jet')\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('$t$')\n",
        "        plt.ylabel('$x$')\n",
        "        plt.title('Absolute error')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.dirname,\"prediction.png\"))\n",
        "        plt.close(\"all\")\n",
        "\n",
        "    def plot_lambda(self ):\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches([15,8])\n",
        "        ax.semilogy(self.adaptive_constant_bcs_log, label=\"adaptive_constant_bcs_log\")\n",
        "        ax.semilogy(self.adaptive_constant_ics_log, label=\"adaptive_constant_ics_log\")\n",
        "        ax.semilogy(self.adaptive_constant_res_log, label=\"adaptive_constant_res_log\")\n",
        "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
        "        ax.set_ylabel(\"loss\", fontsize=15)\n",
        "        ax.tick_params(labelsize=15)\n",
        "        ax.legend()\n",
        "        path = os.path.join(self.dirname,'lambda_history.png')\n",
        "        plt.savefig(path)\n",
        "\n",
        "    def plot_grad(self ):\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches([15,8])\n",
        "        ax.semilogy(self.max_grad_res_log, label=\"max_grad_res_log\")\n",
        "        ax.semilogy(self.mean_grad_bcs_log, label=\"mean_grad_bcs_log\")\n",
        "        ax.semilogy(self.mean_grad_ics_log, label=\"mean_grad_ics_log\")\n",
        "        ax.set_xlabel(\"epochs\", fontsize=15)\n",
        "        ax.set_ylabel(\"loss\", fontsize=15)\n",
        "        ax.tick_params(labelsize=15)\n",
        "        ax.legend()\n",
        "        path = os.path.join(self.dirname,'grad_history.png')\n",
        "        plt.savefig(path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#test_method(mtd , layers,  X_u, Y_u, X_r, Y_r ,  X_star , u_star , r_star  , nIter ,batch_size , bcbatch_size , ubatch_size)\n",
        "def test_method(method , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size ):\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) as sess:\n",
        "        # sess.run(init)\n",
        "\n",
        "        model = PINN(layers, operator, ics_sampler, bcs_sampler, res_sampler, c, kernel_size , sess)\n",
        "        # Train model\n",
        "        start_time = time.time()\n",
        "\n",
        "        if method ==\"full_batch\":\n",
        "            print(\"full_batch method is used\")\n",
        "            model.train(nIter  , bcbatch_size , ubatch_size  )\n",
        "        elif method ==\"mini_batch\":\n",
        "            print(\"mini_batch method is used\")\n",
        "            model.trainmb(nIter, mbbatch_size)\n",
        "        else:\n",
        "            print(\"unknown method!\")\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        # Predictions\n",
        "        u_pred = model.predict_u(X_star)\n",
        "        r_pred = model.predict_r(X_star)\n",
        "        # Predictions\n",
        "\n",
        "        sess.close()   \n",
        "\n",
        "    error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "    print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "    print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "\n",
        "    return [elapsed, error_u  ]\n",
        "\n",
        "###############################################################################################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method:  mini_batch\n",
            "Epoch:  1\n",
            "WARNING:tensorflow:From /tmp/ipykernel_8885/2520404152.py:66: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_8885/2520404152.py:67: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_8885/2520404152.py:68: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_8885/2520404152.py:68: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_8885/1543852918.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-17 23:44:04.262230: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-17 23:44:04.287363: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
            "2023-12-17 23:44:04.287927: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a4f53015e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-12-17 23:44:04.287946: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-12-17 23:44:04.288765: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tmp/ipykernel_8885/1543852918.py:94: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_8885/1543852918.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_8885/1543852918.py:163: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "mini_batch method is used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Gradients information stored ...\n",
            "It: 100 |  Loss: 5.018e-01 |  Loss_res: 3.554e-04 |   Loss_bcs1: 5.457e-02 | Loss_bc2s: 3.167e-02 |  loss_ics_u: 3.921e-01 |  Loss_ut_ics: 2.309e-02 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.727e-01\n",
            "adaptive_constant_ics_val: 9.738e-01\n",
            "adaptive_constant_bcs_val: 1.054e+00\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Gradients information stored ...\n",
            "It: 200 |  Loss: 3.505e-01 |  Loss_res: 3.536e-03 |   Loss_bcs1: 4.963e-02 | Loss_bc2s: 2.937e-02 |  loss_ics_u: 2.468e-01 |  Loss_ut_ics: 3.900e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.988e+00\n",
            "adaptive_constant_ics_val: 4.873e-01\n",
            "adaptive_constant_bcs_val: 5.250e-01\n",
            "It: 300 |  Loss: 1.703e-01 |  Loss_res: 8.740e-04 |   Loss_bcs1: 4.779e-02 | Loss_bc2s: 2.777e-02 |  loss_ics_u: 2.349e-01 |  Loss_ut_ics: 1.138e-02 |  Time: 0.08\n",
            "adaptive_constant_res_val: 7.446e-01\n",
            "adaptive_constant_ics_val: 1.857e+00\n",
            "adaptive_constant_bcs_val: 3.986e-01\n",
            "It: 400 |  Loss: 1.474e-01 |  Loss_res: 3.765e-03 |   Loss_bcs1: 5.492e-02 | Loss_bc2s: 3.428e-02 |  loss_ics_u: 2.690e-01 |  Loss_ut_ics: 1.009e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.863e+00\n",
            "adaptive_constant_ics_val: 7.286e-01\n",
            "adaptive_constant_bcs_val: 4.083e-01\n",
            "It: 500 |  Loss: 1.394e-01 |  Loss_res: 1.846e-03 |   Loss_bcs1: 5.427e-02 | Loss_bc2s: 2.468e-02 |  loss_ics_u: 2.512e-01 |  Loss_ut_ics: 1.575e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 9.860e-01\n",
            "adaptive_constant_ics_val: 1.273e+00\n",
            "adaptive_constant_bcs_val: 7.413e-01\n",
            "It: 600 |  Loss: 2.838e-01 |  Loss_res: 6.677e-02 |   Loss_bcs1: 3.545e-02 | Loss_bc2s: 1.395e-02 |  loss_ics_u: 2.267e-01 |  Loss_ut_ics: 1.049e-02 |  Time: 0.05\n",
            "adaptive_constant_res_val: 1.998e+00\n",
            "adaptive_constant_ics_val: 5.604e-01\n",
            "adaptive_constant_bcs_val: 4.414e-01\n",
            "It: 700 |  Loss: 1.738e-01 |  Loss_res: 7.182e-04 |   Loss_bcs1: 5.222e-02 | Loss_bc2s: 2.105e-02 |  loss_ics_u: 3.081e-01 |  Loss_ut_ics: 7.165e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.481e-01\n",
            "adaptive_constant_ics_val: 7.164e-01\n",
            "adaptive_constant_bcs_val: 1.336e+00\n",
            "It: 800 |  Loss: 4.341e-01 |  Loss_res: 5.400e-03 |   Loss_bcs1: 5.583e-02 | Loss_bc2s: 4.100e-02 |  loss_ics_u: 2.129e-01 |  Loss_ut_ics: 2.144e-02 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.978e+00\n",
            "adaptive_constant_ics_val: 4.269e-01\n",
            "adaptive_constant_bcs_val: 5.952e-01\n",
            "It: 900 |  Loss: 2.201e-01 |  Loss_res: 1.828e-03 |   Loss_bcs1: 5.014e-02 | Loss_bc2s: 3.166e-02 |  loss_ics_u: 2.766e-01 |  Loss_ut_ics: 7.355e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.101e+00\n",
            "adaptive_constant_ics_val: 7.210e-01\n",
            "adaptive_constant_bcs_val: 1.178e+00\n",
            "It: 1000 |  Loss: 3.749e-01 |  Loss_res: 7.684e-03 |   Loss_bcs1: 3.506e-02 | Loss_bc2s: 2.801e-02 |  loss_ics_u: 2.390e-01 |  Loss_ut_ics: 1.476e-02 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.939e+00\n",
            "adaptive_constant_ics_val: 4.950e-01\n",
            "adaptive_constant_bcs_val: 5.656e-01\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Gradients information stored ...\n",
            "It: 1100 |  Loss: 1.970e-01 |  Loss_res: 8.313e-04 |   Loss_bcs1: 6.544e-02 | Loss_bc2s: 4.010e-02 |  loss_ics_u: 2.293e-01 |  Loss_ut_ics: 1.223e-02 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.437e-01\n",
            "adaptive_constant_ics_val: 1.006e+00\n",
            "adaptive_constant_bcs_val: 1.051e+00\n",
            "It: 1200 |  Loss: 2.665e-01 |  Loss_res: 2.924e-03 |   Loss_bcs1: 4.164e-02 | Loss_bc2s: 2.334e-02 |  loss_ics_u: 1.848e-01 |  Loss_ut_ics: 1.350e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.830e+00\n",
            "adaptive_constant_ics_val: 5.503e-01\n",
            "adaptive_constant_bcs_val: 6.198e-01\n",
            "It: 1300 |  Loss: 1.912e-01 |  Loss_res: 1.222e-03 |   Loss_bcs1: 5.646e-02 | Loss_bc2s: 2.946e-02 |  loss_ics_u: 2.148e-01 |  Loss_ut_ics: 4.737e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.203e-01\n",
            "adaptive_constant_ics_val: 1.519e+00\n",
            "adaptive_constant_bcs_val: 6.608e-01\n",
            "It: 1400 |  Loss: 2.351e-01 |  Loss_res: 2.509e-03 |   Loss_bcs1: 4.144e-02 | Loss_bc2s: 3.764e-02 |  loss_ics_u: 2.383e-01 |  Loss_ut_ics: 1.538e-02 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.078e+00\n",
            "adaptive_constant_ics_val: 1.238e+00\n",
            "adaptive_constant_bcs_val: 6.848e-01\n",
            "It: 1500 |  Loss: 1.690e-01 |  Loss_res: 4.319e-03 |   Loss_bcs1: 3.005e-02 | Loss_bc2s: 1.627e-02 |  loss_ics_u: 1.888e-01 |  Loss_ut_ics: 2.722e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.296e+00\n",
            "adaptive_constant_ics_val: 8.533e-01\n",
            "adaptive_constant_bcs_val: 8.508e-01\n",
            "It: 1600 |  Loss: 2.053e-01 |  Loss_res: 7.797e-03 |   Loss_bcs1: 2.187e-02 | Loss_bc2s: 1.779e-02 |  loss_ics_u: 1.827e-01 |  Loss_ut_ics: 7.008e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 2.074e+00\n",
            "adaptive_constant_ics_val: 4.571e-01\n",
            "adaptive_constant_bcs_val: 4.688e-01\n",
            "It: 1700 |  Loss: 1.343e-01 |  Loss_res: 5.295e-04 |   Loss_bcs1: 3.464e-02 | Loss_bc2s: 2.052e-02 |  loss_ics_u: 2.276e-01 |  Loss_ut_ics: 1.374e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.030e+00\n",
            "adaptive_constant_ics_val: 6.391e-01\n",
            "adaptive_constant_bcs_val: 1.331e+00\n",
            "It: 1800 |  Loss: 2.779e-01 |  Loss_res: 2.252e-03 |   Loss_bcs1: 4.647e-02 | Loss_bc2s: 1.697e-02 |  loss_ics_u: 1.374e-01 |  Loss_ut_ics: 1.311e-02 |  Time: 0.04\n",
            "adaptive_constant_res_val: 6.197e-01\n",
            "adaptive_constant_ics_val: 1.780e+00\n",
            "adaptive_constant_bcs_val: 6.005e-01\n",
            "It: 1900 |  Loss: 2.061e-01 |  Loss_res: 2.094e-03 |   Loss_bcs1: 4.143e-02 | Loss_bc2s: 2.068e-02 |  loss_ics_u: 2.613e-01 |  Loss_ut_ics: 5.986e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.051e-01\n",
            "adaptive_constant_ics_val: 9.404e-01\n",
            "adaptive_constant_bcs_val: 1.255e+00\n",
            "It: 2000 |  Loss: 3.170e-01 |  Loss_res: 2.334e-03 |   Loss_bcs1: 4.051e-02 | Loss_bc2s: 1.024e-02 |  loss_ics_u: 1.920e-01 |  Loss_ut_ics: 1.120e-02 |  Time: 0.03\n",
            "adaptive_constant_res_val: 6.735e-01\n",
            "adaptive_constant_ics_val: 1.516e+00\n",
            "adaptive_constant_bcs_val: 8.103e-01\n",
            "It: 2100 |  Loss: 1.837e-01 |  Loss_res: 3.000e-03 |   Loss_bcs1: 2.768e-02 | Loss_bc2s: 1.209e-02 |  loss_ics_u: 1.788e-01 |  Loss_ut_ics: 3.020e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.375e+00\n",
            "adaptive_constant_ics_val: 8.076e-01\n",
            "adaptive_constant_bcs_val: 8.176e-01\n",
            "It: 2200 |  Loss: 1.648e-01 |  Loss_res: 1.713e-03 |   Loss_bcs1: 3.317e-02 | Loss_bc2s: 1.446e-02 |  loss_ics_u: 1.451e-01 |  Loss_ut_ics: 6.063e-03 |  Time: 0.06\n",
            "adaptive_constant_res_val: 9.534e-01\n",
            "adaptive_constant_ics_val: 1.151e+00\n",
            "adaptive_constant_bcs_val: 8.956e-01\n",
            "It: 2300 |  Loss: 1.715e-01 |  Loss_res: 1.725e-03 |   Loss_bcs1: 2.805e-02 | Loss_bc2s: 1.121e-02 |  loss_ics_u: 1.464e-01 |  Loss_ut_ics: 3.130e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.818e-01\n",
            "adaptive_constant_ics_val: 8.937e-01\n",
            "adaptive_constant_bcs_val: 1.125e+00\n",
            "It: 2400 |  Loss: 1.843e-01 |  Loss_res: 2.570e-03 |   Loss_bcs1: 2.704e-02 | Loss_bc2s: 1.401e-02 |  loss_ics_u: 1.181e-01 |  Loss_ut_ics: 3.127e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.147e+00\n",
            "adaptive_constant_ics_val: 1.036e+00\n",
            "adaptive_constant_bcs_val: 8.163e-01\n",
            "It: 2500 |  Loss: 1.683e-01 |  Loss_res: 2.348e-02 |   Loss_bcs1: 3.162e-02 | Loss_bc2s: 1.657e-02 |  loss_ics_u: 1.144e-01 |  Loss_ut_ics: 8.347e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.994e+00\n",
            "adaptive_constant_ics_val: 5.326e-01\n",
            "adaptive_constant_bcs_val: 4.733e-01\n",
            "It: 2600 |  Loss: 1.414e-01 |  Loss_res: 1.015e-03 |   Loss_bcs1: 4.197e-02 | Loss_bc2s: 1.444e-02 |  loss_ics_u: 2.345e-01 |  Loss_ut_ics: 3.145e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.029e-01\n",
            "adaptive_constant_ics_val: 6.068e-01\n",
            "adaptive_constant_bcs_val: 1.490e+00\n",
            "It: 2700 |  Loss: 2.817e-01 |  Loss_res: 3.251e-03 |   Loss_bcs1: 2.969e-02 | Loss_bc2s: 1.018e-02 |  loss_ics_u: 1.447e-01 |  Loss_ut_ics: 5.998e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.347e+00\n",
            "adaptive_constant_ics_val: 9.554e-01\n",
            "adaptive_constant_bcs_val: 6.972e-01\n",
            "It: 2800 |  Loss: 1.319e-01 |  Loss_res: 1.861e-03 |   Loss_bcs1: 2.616e-02 | Loss_bc2s: 1.214e-02 |  loss_ics_u: 1.412e-01 |  Loss_ut_ics: 4.471e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.037e+00\n",
            "adaptive_constant_ics_val: 8.340e-01\n",
            "adaptive_constant_bcs_val: 1.129e+00\n",
            "It: 2900 |  Loss: 2.242e-01 |  Loss_res: 3.396e-03 |   Loss_bcs1: 3.788e-02 | Loss_bc2s: 2.191e-02 |  loss_ics_u: 1.331e-01 |  Loss_ut_ics: 3.531e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.763e+00\n",
            "adaptive_constant_ics_val: 5.591e-01\n",
            "adaptive_constant_bcs_val: 6.779e-01\n",
            "It: 3000 |  Loss: 1.074e-01 |  Loss_res: 1.243e-03 |   Loss_bcs1: 2.634e-02 | Loss_bc2s: 1.585e-02 |  loss_ics_u: 1.079e-01 |  Loss_ut_ics: 6.169e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.505e-01\n",
            "adaptive_constant_ics_val: 1.119e+00\n",
            "adaptive_constant_bcs_val: 9.301e-01\n",
            "It: 3100 |  Loss: 1.379e-01 |  Loss_res: 7.427e-04 |   Loss_bcs1: 2.922e-02 | Loss_bc2s: 1.328e-02 |  loss_ics_u: 9.870e-02 |  Loss_ut_ics: 5.231e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.042e+00\n",
            "adaptive_constant_ics_val: 9.676e-01\n",
            "adaptive_constant_bcs_val: 9.907e-01\n",
            "It: 3200 |  Loss: 1.829e-01 |  Loss_res: 6.120e-03 |   Loss_bcs1: 2.467e-02 | Loss_bc2s: 1.321e-02 |  loss_ics_u: 1.233e-01 |  Loss_ut_ics: 1.741e-02 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.569e-01\n",
            "adaptive_constant_ics_val: 1.509e+00\n",
            "adaptive_constant_bcs_val: 6.336e-01\n",
            "It: 3300 |  Loss: 1.124e-01 |  Loss_res: 1.032e-03 |   Loss_bcs1: 3.401e-02 | Loss_bc2s: 1.048e-02 |  loss_ics_u: 1.246e-01 |  Loss_ut_ics: 2.886e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 7.720e-01\n",
            "adaptive_constant_ics_val: 9.834e-01\n",
            "adaptive_constant_bcs_val: 1.245e+00\n",
            "It: 3400 |  Loss: 2.068e-01 |  Loss_res: 1.549e-03 |   Loss_bcs1: 2.261e-02 | Loss_bc2s: 1.174e-02 |  loss_ics_u: 1.297e-01 |  Loss_ut_ics: 1.464e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.878e+00\n",
            "adaptive_constant_ics_val: 5.325e-01\n",
            "adaptive_constant_bcs_val: 5.891e-01\n",
            "It: 3500 |  Loss: 9.373e-02 |  Loss_res: 1.204e-03 |   Loss_bcs1: 2.473e-02 | Loss_bc2s: 1.031e-02 |  loss_ics_u: 1.190e-01 |  Loss_ut_ics: 1.323e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.626e+00\n",
            "adaptive_constant_ics_val: 6.285e-01\n",
            "adaptive_constant_bcs_val: 7.459e-01\n",
            "It: 3600 |  Loss: 1.346e-01 |  Loss_res: 7.937e-04 |   Loss_bcs1: 2.611e-02 | Loss_bc2s: 1.186e-02 |  loss_ics_u: 1.391e-01 |  Loss_ut_ics: 2.044e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.491e+00\n",
            "adaptive_constant_ics_val: 7.023e-01\n",
            "adaptive_constant_bcs_val: 8.064e-01\n",
            "It: 3700 |  Loss: 1.335e-01 |  Loss_res: 1.005e-02 |   Loss_bcs1: 2.391e-02 | Loss_bc2s: 1.483e-02 |  loss_ics_u: 1.054e-01 |  Loss_ut_ics: 3.291e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 2.121e+00\n",
            "adaptive_constant_ics_val: 4.225e-01\n",
            "adaptive_constant_bcs_val: 4.564e-01\n",
            "It: 3800 |  Loss: 7.449e-02 |  Loss_res: 5.497e-04 |   Loss_bcs1: 2.902e-02 | Loss_bc2s: 8.953e-03 |  loss_ics_u: 1.209e-01 |  Loss_ut_ics: 1.921e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.036e+00\n",
            "adaptive_constant_ics_val: 8.375e-01\n",
            "adaptive_constant_bcs_val: 1.126e+00\n",
            "It: 3900 |  Loss: 1.728e-01 |  Loss_res: 3.798e-03 |   Loss_bcs1: 2.311e-02 | Loss_bc2s: 1.094e-02 |  loss_ics_u: 1.152e-01 |  Loss_ut_ics: 9.576e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.938e+00\n",
            "adaptive_constant_ics_val: 4.868e-01\n",
            "adaptive_constant_bcs_val: 5.749e-01\n",
            "It: 4000 |  Loss: 9.562e-02 |  Loss_res: 2.745e-03 |   Loss_bcs1: 3.105e-02 | Loss_bc2s: 1.094e-02 |  loss_ics_u: 1.142e-01 |  Loss_ut_ics: 1.044e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.122e+00\n",
            "adaptive_constant_ics_val: 9.846e-01\n",
            "adaptive_constant_bcs_val: 8.930e-01\n",
            "It: 4100 |  Loss: 1.527e-01 |  Loss_res: 3.853e-03 |   Loss_bcs1: 3.319e-02 | Loss_bc2s: 1.219e-02 |  loss_ics_u: 1.188e-01 |  Loss_ut_ics: 1.802e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.235e-01\n",
            "adaptive_constant_ics_val: 1.043e+00\n",
            "adaptive_constant_bcs_val: 1.034e+00\n",
            "It: 4200 |  Loss: 1.846e-01 |  Loss_res: 1.769e-03 |   Loss_bcs1: 3.404e-02 | Loss_bc2s: 1.409e-02 |  loss_ics_u: 1.273e-01 |  Loss_ut_ics: 1.508e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 7.421e-01\n",
            "adaptive_constant_ics_val: 1.044e+00\n",
            "adaptive_constant_bcs_val: 1.214e+00\n",
            "It: 4300 |  Loss: 2.079e-01 |  Loss_res: 4.418e-03 |   Loss_bcs1: 3.264e-02 | Loss_bc2s: 1.307e-02 |  loss_ics_u: 1.148e-01 |  Loss_ut_ics: 9.258e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.064e+00\n",
            "adaptive_constant_ics_val: 9.649e-01\n",
            "adaptive_constant_bcs_val: 9.713e-01\n",
            "It: 4400 |  Loss: 1.402e-01 |  Loss_res: 2.203e-03 |   Loss_bcs1: 3.212e-02 | Loss_bc2s: 1.400e-02 |  loss_ics_u: 9.449e-02 |  Loss_ut_ics: 1.283e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.154e+00\n",
            "adaptive_constant_ics_val: 8.326e-01\n",
            "adaptive_constant_bcs_val: 1.013e+00\n",
            "It: 4500 |  Loss: 1.652e-01 |  Loss_res: 4.059e-03 |   Loss_bcs1: 3.075e-02 | Loss_bc2s: 1.222e-02 |  loss_ics_u: 1.140e-01 |  Loss_ut_ics: 1.727e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.721e-01\n",
            "adaptive_constant_ics_val: 1.102e+00\n",
            "adaptive_constant_bcs_val: 9.261e-01\n",
            "It: 4600 |  Loss: 1.476e-01 |  Loss_res: 1.794e-03 |   Loss_bcs1: 3.087e-02 | Loss_bc2s: 1.305e-02 |  loss_ics_u: 1.120e-01 |  Loss_ut_ics: 1.327e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.367e+00\n",
            "adaptive_constant_ics_val: 7.676e-01\n",
            "adaptive_constant_bcs_val: 8.651e-01\n",
            "It: 4700 |  Loss: 1.422e-01 |  Loss_res: 3.056e-03 |   Loss_bcs1: 2.811e-02 | Loss_bc2s: 1.176e-02 |  loss_ics_u: 1.074e-01 |  Loss_ut_ics: 1.378e-02 |  Time: 0.04\n",
            "adaptive_constant_res_val: 6.493e-01\n",
            "adaptive_constant_ics_val: 1.784e+00\n",
            "adaptive_constant_bcs_val: 5.663e-01\n",
            "It: 4800 |  Loss: 9.094e-02 |  Loss_res: 6.241e-04 |   Loss_bcs1: 3.087e-02 | Loss_bc2s: 1.086e-02 |  loss_ics_u: 1.127e-01 |  Loss_ut_ics: 1.732e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 7.910e-01\n",
            "adaptive_constant_ics_val: 1.015e+00\n",
            "adaptive_constant_bcs_val: 1.194e+00\n",
            "It: 4900 |  Loss: 1.571e-01 |  Loss_res: 2.421e-03 |   Loss_bcs1: 2.612e-02 | Loss_bc2s: 1.208e-02 |  loss_ics_u: 9.067e-02 |  Loss_ut_ics: 1.347e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.777e+00\n",
            "adaptive_constant_ics_val: 5.825e-01\n",
            "adaptive_constant_bcs_val: 6.404e-01\n",
            "It: 5000 |  Loss: 1.093e-01 |  Loss_res: 4.391e-04 |   Loss_bcs1: 2.761e-02 | Loss_bc2s: 8.864e-03 |  loss_ics_u: 1.317e-01 |  Loss_ut_ics: 1.324e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.947e-01\n",
            "adaptive_constant_ics_val: 9.368e-01\n",
            "adaptive_constant_bcs_val: 1.068e+00\n",
            "It: 5100 |  Loss: 1.781e-01 |  Loss_res: 1.082e-03 |   Loss_bcs1: 3.573e-02 | Loss_bc2s: 1.332e-02 |  loss_ics_u: 1.152e-01 |  Loss_ut_ics: 1.618e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.909e+00\n",
            "adaptive_constant_ics_val: 5.199e-01\n",
            "adaptive_constant_bcs_val: 5.713e-01\n",
            "It: 5200 |  Loss: 8.518e-02 |  Loss_res: 2.501e-03 |   Loss_bcs1: 2.436e-02 | Loss_bc2s: 1.048e-02 |  loss_ics_u: 1.039e-01 |  Loss_ut_ics: 2.242e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.409e+00\n",
            "adaptive_constant_ics_val: 9.957e-01\n",
            "adaptive_constant_bcs_val: 5.955e-01\n",
            "It: 5300 |  Loss: 9.566e-02 |  Loss_res: 8.595e-04 |   Loss_bcs1: 2.661e-02 | Loss_bc2s: 1.285e-02 |  loss_ics_u: 1.153e-01 |  Loss_ut_ics: 2.288e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.233e-01\n",
            "adaptive_constant_ics_val: 9.521e-01\n",
            "adaptive_constant_bcs_val: 1.125e+00\n",
            "It: 5400 |  Loss: 1.813e-01 |  Loss_res: 6.904e-04 |   Loss_bcs1: 2.757e-02 | Loss_bc2s: 1.159e-02 |  loss_ics_u: 1.202e-01 |  Loss_ut_ics: 1.529e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.263e+00\n",
            "adaptive_constant_ics_val: 9.198e-01\n",
            "adaptive_constant_bcs_val: 8.173e-01\n",
            "It: 5500 |  Loss: 1.233e-01 |  Loss_res: 1.266e-03 |   Loss_bcs1: 2.466e-02 | Loss_bc2s: 1.225e-02 |  loss_ics_u: 1.094e-01 |  Loss_ut_ics: 2.339e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 2.023e+00\n",
            "adaptive_constant_ics_val: 5.043e-01\n",
            "adaptive_constant_bcs_val: 4.725e-01\n",
            "It: 5600 |  Loss: 1.025e-01 |  Loss_res: 1.394e-02 |   Loss_bcs1: 2.709e-02 | Loss_bc2s: 8.288e-03 |  loss_ics_u: 1.150e-01 |  Loss_ut_ics: 6.551e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 2.254e+00\n",
            "adaptive_constant_ics_val: 3.733e-01\n",
            "adaptive_constant_bcs_val: 3.729e-01\n",
            "It: 5700 |  Loss: 5.727e-02 |  Loss_res: 5.399e-04 |   Loss_bcs1: 2.983e-02 | Loss_bc2s: 1.033e-02 |  loss_ics_u: 1.091e-01 |  Loss_ut_ics: 1.050e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.122e+00\n",
            "adaptive_constant_ics_val: 7.114e-01\n",
            "adaptive_constant_bcs_val: 1.167e+00\n",
            "It: 5800 |  Loss: 1.858e-01 |  Loss_res: 6.482e-04 |   Loss_bcs1: 2.491e-02 | Loss_bc2s: 1.109e-02 |  loss_ics_u: 1.199e-01 |  Loss_ut_ics: 4.465e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.220e+00\n",
            "adaptive_constant_ics_val: 1.105e+00\n",
            "adaptive_constant_bcs_val: 6.751e-01\n",
            "It: 5900 |  Loss: 9.931e-02 |  Loss_res: 6.458e-04 |   Loss_bcs1: 2.920e-02 | Loss_bc2s: 1.243e-02 |  loss_ics_u: 1.020e-01 |  Loss_ut_ics: 1.422e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.479e+00\n",
            "adaptive_constant_ics_val: 7.011e-01\n",
            "adaptive_constant_bcs_val: 8.197e-01\n",
            "It: 6000 |  Loss: 1.332e-01 |  Loss_res: 4.093e-03 |   Loss_bcs1: 2.504e-02 | Loss_bc2s: 1.390e-02 |  loss_ics_u: 1.139e-01 |  Loss_ut_ics: 2.533e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 2.108e+00\n",
            "adaptive_constant_ics_val: 4.260e-01\n",
            "adaptive_constant_bcs_val: 4.659e-01\n",
            "It: 6100 |  Loss: 6.782e-02 |  Loss_res: 9.279e-04 |   Loss_bcs1: 2.741e-02 | Loss_bc2s: 9.517e-03 |  loss_ics_u: 1.036e-01 |  Loss_ut_ics: 9.297e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.187e+00\n",
            "adaptive_constant_ics_val: 7.555e-01\n",
            "adaptive_constant_bcs_val: 1.058e+00\n",
            "It: 6200 |  Loss: 1.503e-01 |  Loss_res: 7.218e-04 |   Loss_bcs1: 2.623e-02 | Loss_bc2s: 1.189e-02 |  loss_ics_u: 1.021e-01 |  Loss_ut_ics: 1.416e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 7.878e-01\n",
            "adaptive_constant_ics_val: 1.289e+00\n",
            "adaptive_constant_bcs_val: 9.236e-01\n",
            "It: 6300 |  Loss: 1.408e-01 |  Loss_res: 1.122e-03 |   Loss_bcs1: 2.706e-02 | Loss_bc2s: 1.307e-02 |  loss_ics_u: 1.001e-01 |  Loss_ut_ics: 8.116e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.327e+00\n",
            "adaptive_constant_ics_val: 1.055e+00\n",
            "adaptive_constant_bcs_val: 6.184e-01\n",
            "It: 6400 |  Loss: 9.060e-02 |  Loss_res: 3.743e-04 |   Loss_bcs1: 2.439e-02 | Loss_bc2s: 1.232e-02 |  loss_ics_u: 1.043e-01 |  Loss_ut_ics: 2.744e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.187e+00\n",
            "adaptive_constant_ics_val: 7.644e-01\n",
            "adaptive_constant_bcs_val: 1.049e+00\n",
            "It: 6500 |  Loss: 1.559e-01 |  Loss_res: 1.825e-03 |   Loss_bcs1: 2.885e-02 | Loss_bc2s: 1.060e-02 |  loss_ics_u: 1.065e-01 |  Loss_ut_ics: 8.660e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.843e+00\n",
            "adaptive_constant_ics_val: 5.010e-01\n",
            "adaptive_constant_bcs_val: 6.561e-01\n",
            "It: 6600 |  Loss: 8.704e-02 |  Loss_res: 6.342e-04 |   Loss_bcs1: 2.931e-02 | Loss_bc2s: 1.072e-02 |  loss_ics_u: 9.003e-02 |  Loss_ut_ics: 1.092e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.289e-01\n",
            "adaptive_constant_ics_val: 1.234e+00\n",
            "adaptive_constant_bcs_val: 8.371e-01\n",
            "It: 6700 |  Loss: 1.277e-01 |  Loss_res: 1.450e-03 |   Loss_bcs1: 2.440e-02 | Loss_bc2s: 1.051e-02 |  loss_ics_u: 1.082e-01 |  Loss_ut_ics: 5.340e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 7.751e-01\n",
            "adaptive_constant_ics_val: 1.609e+00\n",
            "adaptive_constant_bcs_val: 6.163e-01\n",
            "It: 6800 |  Loss: 1.003e-01 |  Loss_res: 4.539e-04 |   Loss_bcs1: 2.926e-02 | Loss_bc2s: 1.261e-02 |  loss_ics_u: 1.108e-01 |  Loss_ut_ics: 3.626e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.091e-01\n",
            "adaptive_constant_ics_val: 1.224e+00\n",
            "adaptive_constant_bcs_val: 9.672e-01\n",
            "It: 6900 |  Loss: 1.320e-01 |  Loss_res: 3.486e-03 |   Loss_bcs1: 2.532e-02 | Loss_bc2s: 1.362e-02 |  loss_ics_u: 9.403e-02 |  Loss_ut_ics: 4.841e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.949e+00\n",
            "adaptive_constant_ics_val: 5.534e-01\n",
            "adaptive_constant_bcs_val: 4.971e-01\n",
            "It: 7000 |  Loss: 8.226e-02 |  Loss_res: 2.603e-04 |   Loss_bcs1: 2.679e-02 | Loss_bc2s: 6.219e-03 |  loss_ics_u: 1.297e-01 |  Loss_ut_ics: 1.533e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.363e-01\n",
            "adaptive_constant_ics_val: 1.472e+00\n",
            "adaptive_constant_bcs_val: 6.913e-01\n",
            "It: 7100 |  Loss: 1.201e-01 |  Loss_res: 4.918e-04 |   Loss_bcs1: 3.105e-02 | Loss_bc2s: 9.274e-03 |  loss_ics_u: 1.282e-01 |  Loss_ut_ics: 2.173e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.430e+00\n",
            "adaptive_constant_ics_val: 7.286e-01\n",
            "adaptive_constant_bcs_val: 8.418e-01\n",
            "It: 7200 |  Loss: 1.214e-01 |  Loss_res: 1.690e-03 |   Loss_bcs1: 2.335e-02 | Loss_bc2s: 1.072e-02 |  loss_ics_u: 1.055e-01 |  Loss_ut_ics: 2.095e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.217e+00\n",
            "adaptive_constant_ics_val: 1.002e+00\n",
            "adaptive_constant_bcs_val: 7.809e-01\n",
            "It: 7300 |  Loss: 1.183e-01 |  Loss_res: 4.830e-04 |   Loss_bcs1: 2.646e-02 | Loss_bc2s: 1.082e-02 |  loss_ics_u: 1.118e-01 |  Loss_ut_ics: 1.243e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.231e-01\n",
            "adaptive_constant_ics_val: 8.129e-01\n",
            "adaptive_constant_bcs_val: 1.264e+00\n",
            "It: 7400 |  Loss: 1.950e-01 |  Loss_res: 2.648e-03 |   Loss_bcs1: 2.180e-02 | Loss_bc2s: 1.183e-02 |  loss_ics_u: 1.168e-01 |  Loss_ut_ics: 2.955e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.024e+00\n",
            "adaptive_constant_ics_val: 9.501e-01\n",
            "adaptive_constant_bcs_val: 1.026e+00\n",
            "It: 7500 |  Loss: 1.433e-01 |  Loss_res: 9.093e-04 |   Loss_bcs1: 2.226e-02 | Loss_bc2s: 1.259e-02 |  loss_ics_u: 1.028e-01 |  Loss_ut_ics: 1.133e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.291e-01\n",
            "adaptive_constant_ics_val: 1.265e+00\n",
            "adaptive_constant_bcs_val: 9.063e-01\n",
            "It: 7600 |  Loss: 1.297e-01 |  Loss_res: 7.224e-04 |   Loss_bcs1: 2.192e-02 | Loss_bc2s: 1.324e-02 |  loss_ics_u: 1.061e-01 |  Loss_ut_ics: 8.567e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 6.647e-01\n",
            "adaptive_constant_ics_val: 1.719e+00\n",
            "adaptive_constant_bcs_val: 6.166e-01\n",
            "It: 7700 |  Loss: 8.131e-02 |  Loss_res: 5.722e-04 |   Loss_bcs1: 2.369e-02 | Loss_bc2s: 1.098e-02 |  loss_ics_u: 9.487e-02 |  Loss_ut_ics: 6.141e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.009e+00\n",
            "adaptive_constant_ics_val: 1.097e+00\n",
            "adaptive_constant_bcs_val: 8.943e-01\n",
            "It: 7800 |  Loss: 1.119e-01 |  Loss_res: 7.925e-04 |   Loss_bcs1: 3.156e-02 | Loss_bc2s: 1.309e-02 |  loss_ics_u: 7.826e-02 |  Loss_ut_ics: 1.031e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.153e+00\n",
            "adaptive_constant_ics_val: 1.240e+00\n",
            "adaptive_constant_bcs_val: 6.064e-01\n",
            "It: 7900 |  Loss: 9.380e-02 |  Loss_res: 3.910e-04 |   Loss_bcs1: 2.238e-02 | Loss_bc2s: 1.195e-02 |  loss_ics_u: 1.181e-01 |  Loss_ut_ics: 7.249e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.078e+00\n",
            "adaptive_constant_ics_val: 1.205e+00\n",
            "adaptive_constant_bcs_val: 7.168e-01\n",
            "It: 8000 |  Loss: 1.012e-01 |  Loss_res: 6.135e-04 |   Loss_bcs1: 2.482e-02 | Loss_bc2s: 1.076e-02 |  loss_ics_u: 1.037e-01 |  Loss_ut_ics: 5.368e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.530e+00\n",
            "adaptive_constant_ics_val: 8.241e-01\n",
            "adaptive_constant_bcs_val: 6.458e-01\n",
            "It: 8100 |  Loss: 9.001e-02 |  Loss_res: 1.086e-03 |   Loss_bcs1: 2.228e-02 | Loss_bc2s: 1.174e-02 |  loss_ics_u: 1.023e-01 |  Loss_ut_ics: 3.770e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.171e+00\n",
            "adaptive_constant_ics_val: 1.222e+00\n",
            "adaptive_constant_bcs_val: 6.071e-01\n",
            "It: 8200 |  Loss: 8.744e-02 |  Loss_res: 9.486e-04 |   Loss_bcs1: 2.033e-02 | Loss_bc2s: 1.296e-02 |  loss_ics_u: 1.041e-01 |  Loss_ut_ics: 2.388e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 7.000e-01\n",
            "adaptive_constant_ics_val: 1.682e+00\n",
            "adaptive_constant_bcs_val: 6.176e-01\n",
            "It: 8300 |  Loss: 9.703e-02 |  Loss_res: 5.321e-04 |   Loss_bcs1: 2.381e-02 | Loss_bc2s: 1.298e-02 |  loss_ics_u: 1.155e-01 |  Loss_ut_ics: 1.563e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.389e-01\n",
            "adaptive_constant_ics_val: 9.542e-01\n",
            "adaptive_constant_bcs_val: 1.207e+00\n",
            "It: 8400 |  Loss: 1.796e-01 |  Loss_res: 5.357e-03 |   Loss_bcs1: 1.978e-02 | Loss_bc2s: 1.293e-02 |  loss_ics_u: 1.107e-01 |  Loss_ut_ics: 2.044e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.958e+00\n",
            "adaptive_constant_ics_val: 4.854e-01\n",
            "adaptive_constant_bcs_val: 5.564e-01\n",
            "It: 8500 |  Loss: 8.526e-02 |  Loss_res: 3.140e-04 |   Loss_bcs1: 2.976e-02 | Loss_bc2s: 1.024e-02 |  loss_ics_u: 1.111e-01 |  Loss_ut_ics: 1.186e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.010e+00\n",
            "adaptive_constant_ics_val: 7.232e-01\n",
            "adaptive_constant_bcs_val: 1.267e+00\n",
            "It: 8600 |  Loss: 1.800e-01 |  Loss_res: 6.152e-04 |   Loss_bcs1: 2.077e-02 | Loss_bc2s: 1.277e-02 |  loss_ics_u: 1.070e-01 |  Loss_ut_ics: 1.846e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 5.230e-01\n",
            "adaptive_constant_ics_val: 1.901e+00\n",
            "adaptive_constant_bcs_val: 5.760e-01\n",
            "It: 8700 |  Loss: 7.873e-02 |  Loss_res: 7.414e-04 |   Loss_bcs1: 2.072e-02 | Loss_bc2s: 1.227e-02 |  loss_ics_u: 1.019e-01 |  Loss_ut_ics: 3.466e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.037e+00\n",
            "adaptive_constant_ics_val: 1.006e+00\n",
            "adaptive_constant_bcs_val: 9.573e-01\n",
            "It: 8800 |  Loss: 1.347e-01 |  Loss_res: 6.942e-04 |   Loss_bcs1: 1.738e-02 | Loss_bc2s: 1.164e-02 |  loss_ics_u: 1.094e-01 |  Loss_ut_ics: 1.469e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.217e-01\n",
            "adaptive_constant_ics_val: 1.365e+00\n",
            "adaptive_constant_bcs_val: 8.137e-01\n",
            "It: 8900 |  Loss: 1.274e-01 |  Loss_res: 9.739e-04 |   Loss_bcs1: 1.910e-02 | Loss_bc2s: 1.521e-02 |  loss_ics_u: 1.206e-01 |  Loss_ut_ics: 3.799e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 8.855e-01\n",
            "adaptive_constant_ics_val: 8.476e-01\n",
            "adaptive_constant_bcs_val: 1.267e+00\n",
            "It: 9000 |  Loss: 1.793e-01 |  Loss_res: 1.017e-03 |   Loss_bcs1: 1.764e-02 | Loss_bc2s: 1.261e-02 |  loss_ics_u: 1.100e-01 |  Loss_ut_ics: 8.864e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 7.860e-01\n",
            "adaptive_constant_ics_val: 1.231e+00\n",
            "adaptive_constant_bcs_val: 9.829e-01\n",
            "It: 9100 |  Loss: 1.276e-01 |  Loss_res: 1.616e-03 |   Loss_bcs1: 1.631e-02 | Loss_bc2s: 1.624e-02 |  loss_ics_u: 9.496e-02 |  Loss_ut_ics: 7.748e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.669e-01\n",
            "adaptive_constant_ics_val: 1.084e+00\n",
            "adaptive_constant_bcs_val: 1.049e+00\n",
            "It: 9200 |  Loss: 1.409e-01 |  Loss_res: 1.696e-03 |   Loss_bcs1: 2.184e-02 | Loss_bc2s: 1.347e-02 |  loss_ics_u: 9.698e-02 |  Loss_ut_ics: 6.454e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 5.617e-01\n",
            "adaptive_constant_ics_val: 1.827e+00\n",
            "adaptive_constant_bcs_val: 6.109e-01\n",
            "It: 9300 |  Loss: 8.924e-02 |  Loss_res: 1.665e-03 |   Loss_bcs1: 1.721e-02 | Loss_bc2s: 1.314e-02 |  loss_ics_u: 1.125e-01 |  Loss_ut_ics: 5.553e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 4.632e-01\n",
            "adaptive_constant_ics_val: 2.082e+00\n",
            "adaptive_constant_bcs_val: 4.547e-01\n",
            "It: 9400 |  Loss: 6.195e-02 |  Loss_res: 6.888e-04 |   Loss_bcs1: 1.743e-02 | Loss_bc2s: 1.427e-02 |  loss_ics_u: 1.016e-01 |  Loss_ut_ics: 4.931e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 7.620e-01\n",
            "adaptive_constant_ics_val: 1.181e+00\n",
            "adaptive_constant_bcs_val: 1.057e+00\n",
            "It: 9500 |  Loss: 1.423e-01 |  Loss_res: 4.447e-03 |   Loss_bcs1: 1.479e-02 | Loss_bc2s: 1.514e-02 |  loss_ics_u: 9.988e-02 |  Loss_ut_ics: 1.453e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.892e+00\n",
            "adaptive_constant_ics_val: 5.740e-01\n",
            "adaptive_constant_bcs_val: 5.335e-01\n",
            "It: 9600 |  Loss: 9.607e-02 |  Loss_res: 5.099e-04 |   Loss_bcs1: 3.363e-02 | Loss_bc2s: 8.581e-03 |  loss_ics_u: 1.308e-01 |  Loss_ut_ics: 4.835e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 7.317e-01\n",
            "adaptive_constant_ics_val: 1.827e+00\n",
            "adaptive_constant_bcs_val: 4.412e-01\n",
            "It: 9700 |  Loss: 6.496e-02 |  Loss_res: 4.238e-04 |   Loss_bcs1: 3.245e-02 | Loss_bc2s: 8.479e-03 |  loss_ics_u: 1.026e-01 |  Loss_ut_ics: 7.302e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.042e+00\n",
            "adaptive_constant_ics_val: 9.780e-01\n",
            "adaptive_constant_bcs_val: 9.803e-01\n",
            "It: 9800 |  Loss: 1.453e-01 |  Loss_res: 2.408e-03 |   Loss_bcs1: 2.322e-02 | Loss_bc2s: 1.011e-02 |  loss_ics_u: 1.072e-01 |  Loss_ut_ics: 5.207e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 5.328e-01\n",
            "adaptive_constant_ics_val: 1.960e+00\n",
            "adaptive_constant_bcs_val: 5.073e-01\n",
            "It: 9900 |  Loss: 8.135e-02 |  Loss_res: 4.665e-04 |   Loss_bcs1: 2.848e-02 | Loss_bc2s: 1.327e-02 |  loss_ics_u: 1.173e-01 |  Loss_ut_ics: 2.063e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 7.124e-01\n",
            "adaptive_constant_ics_val: 9.971e-01\n",
            "adaptive_constant_bcs_val: 1.290e+00\n",
            "It: 10000 |  Loss: 1.849e-01 |  Loss_res: 1.057e-03 |   Loss_bcs1: 2.452e-02 | Loss_bc2s: 1.244e-02 |  loss_ics_u: 1.049e-01 |  Loss_ut_ics: 9.876e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 4.258e-01\n",
            "adaptive_constant_ics_val: 1.996e+00\n",
            "adaptive_constant_bcs_val: 5.779e-01\n",
            "It: 10100 |  Loss: 8.253e-02 |  Loss_res: 7.267e-04 |   Loss_bcs1: 2.424e-02 | Loss_bc2s: 9.656e-03 |  loss_ics_u: 1.028e-01 |  Loss_ut_ics: 1.607e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 7.232e-01\n",
            "adaptive_constant_ics_val: 1.337e+00\n",
            "adaptive_constant_bcs_val: 9.398e-01\n",
            "It: 10200 |  Loss: 1.420e-01 |  Loss_res: 8.241e-04 |   Loss_bcs1: 2.499e-02 | Loss_bc2s: 1.348e-02 |  loss_ics_u: 1.115e-01 |  Loss_ut_ics: 3.629e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 9.875e-01\n",
            "adaptive_constant_ics_val: 8.285e-01\n",
            "adaptive_constant_bcs_val: 1.184e+00\n",
            "It: 10300 |  Loss: 1.627e-01 |  Loss_res: 7.977e-04 |   Loss_bcs1: 1.970e-02 | Loss_bc2s: 1.507e-02 |  loss_ics_u: 1.015e-01 |  Loss_ut_ics: 6.499e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 4.949e-01\n",
            "adaptive_constant_ics_val: 1.954e+00\n",
            "adaptive_constant_bcs_val: 5.512e-01\n",
            "It: 10400 |  Loss: 8.120e-02 |  Loss_res: 7.141e-04 |   Loss_bcs1: 2.568e-02 | Loss_bc2s: 1.196e-02 |  loss_ics_u: 1.011e-01 |  Loss_ut_ics: 2.236e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.536e-01\n",
            "adaptive_constant_ics_val: 1.329e+00\n",
            "adaptive_constant_bcs_val: 8.174e-01\n",
            "It: 10500 |  Loss: 1.171e-01 |  Loss_res: 1.366e-03 |   Loss_bcs1: 2.198e-02 | Loss_bc2s: 1.450e-02 |  loss_ics_u: 1.042e-01 |  Loss_ut_ics: 7.562e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.269e+00\n",
            "adaptive_constant_ics_val: 7.965e-01\n",
            "adaptive_constant_bcs_val: 9.340e-01\n",
            "It: 10600 |  Loss: 1.463e-01 |  Loss_res: 1.013e-03 |   Loss_bcs1: 2.250e-02 | Loss_bc2s: 1.813e-02 |  loss_ics_u: 1.131e-01 |  Loss_ut_ics: 1.864e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 5.658e-01\n",
            "adaptive_constant_ics_val: 1.943e+00\n",
            "adaptive_constant_bcs_val: 4.909e-01\n",
            "It: 10700 |  Loss: 6.785e-02 |  Loss_res: 4.759e-04 |   Loss_bcs1: 2.250e-02 | Loss_bc2s: 1.394e-02 |  loss_ics_u: 9.965e-02 |  Loss_ut_ics: 3.995e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.361e-01\n",
            "adaptive_constant_ics_val: 1.025e+00\n",
            "adaptive_constant_bcs_val: 1.139e+00\n",
            "It: 10800 |  Loss: 1.534e-01 |  Loss_res: 7.334e-04 |   Loss_bcs1: 2.110e-02 | Loss_bc2s: 1.209e-02 |  loss_ics_u: 1.003e-01 |  Loss_ut_ics: 7.849e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.025e+00\n",
            "adaptive_constant_ics_val: 1.196e+00\n",
            "adaptive_constant_bcs_val: 7.781e-01\n",
            "It: 10900 |  Loss: 1.066e-01 |  Loss_res: 4.263e-04 |   Loss_bcs1: 2.078e-02 | Loss_bc2s: 1.227e-02 |  loss_ics_u: 1.016e-01 |  Loss_ut_ics: 1.205e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.491e-01\n",
            "adaptive_constant_ics_val: 1.325e+00\n",
            "adaptive_constant_bcs_val: 8.257e-01\n",
            "It: 11000 |  Loss: 1.064e-01 |  Loss_res: 7.284e-04 |   Loss_bcs1: 1.969e-02 | Loss_bc2s: 1.395e-02 |  loss_ics_u: 9.278e-02 |  Loss_ut_ics: 1.066e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.482e+00\n",
            "adaptive_constant_ics_val: 7.411e-01\n",
            "adaptive_constant_bcs_val: 7.769e-01\n",
            "It: 11100 |  Loss: 1.244e-01 |  Loss_res: 1.022e-03 |   Loss_bcs1: 2.140e-02 | Loss_bc2s: 1.775e-02 |  loss_ics_u: 1.158e-01 |  Loss_ut_ics: 3.454e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.315e+00\n",
            "adaptive_constant_ics_val: 6.922e-01\n",
            "adaptive_constant_bcs_val: 9.926e-01\n",
            "It: 11200 |  Loss: 1.503e-01 |  Loss_res: 1.418e-03 |   Loss_bcs1: 2.114e-02 | Loss_bc2s: 1.298e-02 |  loss_ics_u: 1.133e-01 |  Loss_ut_ics: 2.978e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.234e+00\n",
            "adaptive_constant_ics_val: 7.134e-01\n",
            "adaptive_constant_bcs_val: 1.053e+00\n",
            "It: 11300 |  Loss: 1.466e-01 |  Loss_res: 3.561e-03 |   Loss_bcs1: 1.591e-02 | Loss_bc2s: 1.612e-02 |  loss_ics_u: 1.014e-01 |  Loss_ut_ics: 2.556e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.810e+00\n",
            "adaptive_constant_ics_val: 5.487e-01\n",
            "adaptive_constant_bcs_val: 6.414e-01\n",
            "It: 11400 |  Loss: 8.342e-02 |  Loss_res: 2.417e-04 |   Loss_bcs1: 2.268e-02 | Loss_bc2s: 1.063e-02 |  loss_ics_u: 9.577e-02 |  Loss_ut_ics: 3.631e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.009e+00\n",
            "adaptive_constant_ics_val: 7.066e-01\n",
            "adaptive_constant_bcs_val: 1.284e+00\n",
            "It: 11500 |  Loss: 1.704e-01 |  Loss_res: 5.490e-04 |   Loss_bcs1: 2.110e-02 | Loss_bc2s: 1.112e-02 |  loss_ics_u: 9.887e-02 |  Loss_ut_ics: 2.179e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 5.019e-01\n",
            "adaptive_constant_ics_val: 1.921e+00\n",
            "adaptive_constant_bcs_val: 5.773e-01\n",
            "It: 11600 |  Loss: 7.752e-02 |  Loss_res: 3.903e-04 |   Loss_bcs1: 1.821e-02 | Loss_bc2s: 1.357e-02 |  loss_ics_u: 1.011e-01 |  Loss_ut_ics: 3.177e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 8.848e-01\n",
            "adaptive_constant_ics_val: 1.041e+00\n",
            "adaptive_constant_bcs_val: 1.074e+00\n",
            "It: 11700 |  Loss: 1.436e-01 |  Loss_res: 1.658e-03 |   Loss_bcs1: 1.681e-02 | Loss_bc2s: 1.278e-02 |  loss_ics_u: 1.020e-01 |  Loss_ut_ics: 8.655e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.910e+00\n",
            "adaptive_constant_ics_val: 5.471e-01\n",
            "adaptive_constant_bcs_val: 5.428e-01\n",
            "It: 11800 |  Loss: 7.458e-02 |  Loss_res: 5.201e-04 |   Loss_bcs1: 2.287e-02 | Loss_bc2s: 1.467e-02 |  loss_ics_u: 9.688e-02 |  Loss_ut_ics: 1.134e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.044e+00\n",
            "adaptive_constant_ics_val: 8.607e-01\n",
            "adaptive_constant_bcs_val: 1.096e+00\n",
            "It: 11900 |  Loss: 1.357e-01 |  Loss_res: 6.831e-04 |   Loss_bcs1: 1.579e-02 | Loss_bc2s: 1.471e-02 |  loss_ics_u: 9.156e-02 |  Loss_ut_ics: 1.441e-03 |  Time: 0.05\n",
            "adaptive_constant_res_val: 6.456e-01\n",
            "adaptive_constant_ics_val: 1.750e+00\n",
            "adaptive_constant_bcs_val: 6.046e-01\n",
            "It: 12000 |  Loss: 8.472e-02 |  Loss_res: 5.811e-04 |   Loss_bcs1: 1.673e-02 | Loss_bc2s: 1.496e-02 |  loss_ics_u: 1.042e-01 |  Loss_ut_ics: 1.252e-03 |  Time: 0.03\n",
            "adaptive_constant_res_val: 8.826e-01\n",
            "adaptive_constant_ics_val: 1.194e+00\n",
            "adaptive_constant_bcs_val: 9.236e-01\n",
            "It: 12100 |  Loss: 1.157e-01 |  Loss_res: 1.750e-03 |   Loss_bcs1: 1.470e-02 | Loss_bc2s: 1.495e-02 |  loss_ics_u: 9.310e-02 |  Loss_ut_ics: 6.345e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.014e+00\n",
            "adaptive_constant_ics_val: 1.099e+00\n",
            "adaptive_constant_bcs_val: 8.871e-01\n",
            "It: 12200 |  Loss: 1.215e-01 |  Loss_res: 6.410e-04 |   Loss_bcs1: 1.644e-02 | Loss_bc2s: 1.362e-02 |  loss_ics_u: 1.049e-01 |  Loss_ut_ics: 1.010e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 5.526e-01\n",
            "adaptive_constant_ics_val: 1.891e+00\n",
            "adaptive_constant_bcs_val: 5.565e-01\n",
            "It: 12300 |  Loss: 7.591e-02 |  Loss_res: 5.417e-04 |   Loss_bcs1: 1.502e-02 | Loss_bc2s: 1.552e-02 |  loss_ics_u: 1.045e-01 |  Loss_ut_ics: 2.321e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.041e+00\n",
            "adaptive_constant_ics_val: 1.045e+00\n",
            "adaptive_constant_bcs_val: 9.138e-01\n",
            "It: 12400 |  Loss: 1.244e-01 |  Loss_res: 9.336e-04 |   Loss_bcs1: 1.494e-02 | Loss_bc2s: 1.500e-02 |  loss_ics_u: 1.045e-01 |  Loss_ut_ics: 5.592e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 6.853e-01\n",
            "adaptive_constant_ics_val: 1.684e+00\n",
            "adaptive_constant_bcs_val: 6.303e-01\n",
            "It: 12500 |  Loss: 8.129e-02 |  Loss_res: 9.414e-04 |   Loss_bcs1: 1.518e-02 | Loss_bc2s: 1.549e-02 |  loss_ics_u: 9.554e-02 |  Loss_ut_ics: 6.559e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 9.064e-01\n",
            "adaptive_constant_ics_val: 1.127e+00\n",
            "adaptive_constant_bcs_val: 9.664e-01\n",
            "It: 12600 |  Loss: 1.533e-01 |  Loss_res: 1.453e-03 |   Loss_bcs1: 1.426e-02 | Loss_bc2s: 1.476e-02 |  loss_ics_u: 1.272e-01 |  Loss_ut_ics: 8.744e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 4.817e-01\n",
            "adaptive_constant_ics_val: 2.016e+00\n",
            "adaptive_constant_bcs_val: 5.026e-01\n",
            "It: 12700 |  Loss: 6.549e-02 |  Loss_res: 5.391e-04 |   Loss_bcs1: 1.412e-02 | Loss_bc2s: 1.472e-02 |  loss_ics_u: 9.986e-02 |  Loss_ut_ics: 2.675e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 7.389e-01\n",
            "adaptive_constant_ics_val: 1.181e+00\n",
            "adaptive_constant_bcs_val: 1.080e+00\n",
            "It: 12800 |  Loss: 1.405e-01 |  Loss_res: 6.980e-04 |   Loss_bcs1: 1.215e-02 | Loss_bc2s: 1.496e-02 |  loss_ics_u: 1.021e-01 |  Loss_ut_ics: 3.874e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 6.657e-01\n",
            "adaptive_constant_ics_val: 1.668e+00\n",
            "adaptive_constant_bcs_val: 6.661e-01\n",
            "It: 12900 |  Loss: 8.885e-02 |  Loss_res: 7.732e-04 |   Loss_bcs1: 1.085e-02 | Loss_bc2s: 1.513e-02 |  loss_ics_u: 1.051e-01 |  Loss_ut_ics: 6.022e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 8.385e-01\n",
            "adaptive_constant_ics_val: 1.491e+00\n",
            "adaptive_constant_bcs_val: 6.702e-01\n",
            "It: 13000 |  Loss: 9.151e-02 |  Loss_res: 8.000e-04 |   Loss_bcs1: 1.322e-02 | Loss_bc2s: 1.618e-02 |  loss_ics_u: 1.045e-01 |  Loss_ut_ics: 7.224e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 9.365e-01\n",
            "adaptive_constant_ics_val: 1.020e+00\n",
            "adaptive_constant_bcs_val: 1.044e+00\n",
            "It: 13100 |  Loss: 1.423e-01 |  Loss_res: 1.593e-03 |   Loss_bcs1: 1.905e-02 | Loss_bc2s: 1.549e-02 |  loss_ics_u: 9.960e-02 |  Loss_ut_ics: 7.487e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.129e+00\n",
            "adaptive_constant_ics_val: 1.163e+00\n",
            "adaptive_constant_bcs_val: 7.086e-01\n",
            "It: 13200 |  Loss: 8.216e-02 |  Loss_res: 6.522e-04 |   Loss_bcs1: 1.138e-02 | Loss_bc2s: 1.452e-02 |  loss_ics_u: 8.622e-02 |  Loss_ut_ics: 1.704e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 9.423e-01\n",
            "adaptive_constant_ics_val: 9.480e-01\n",
            "adaptive_constant_bcs_val: 1.110e+00\n",
            "It: 13300 |  Loss: 1.339e-01 |  Loss_res: 8.007e-04 |   Loss_bcs1: 1.099e-02 | Loss_bc2s: 1.675e-02 |  loss_ics_u: 9.125e-02 |  Loss_ut_ics: 1.115e-03 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.816e+00\n",
            "adaptive_constant_ics_val: 5.446e-01\n",
            "adaptive_constant_bcs_val: 6.390e-01\n",
            "It: 13400 |  Loss: 8.239e-02 |  Loss_res: 3.732e-04 |   Loss_bcs1: 2.202e-02 | Loss_bc2s: 9.004e-03 |  loss_ics_u: 9.646e-02 |  Loss_ut_ics: 4.695e-04 |  Time: 0.12\n",
            "adaptive_constant_res_val: 9.952e-01\n",
            "adaptive_constant_ics_val: 1.017e+00\n",
            "adaptive_constant_bcs_val: 9.882e-01\n",
            "It: 13500 |  Loss: 1.390e-01 |  Loss_res: 8.048e-04 |   Loss_bcs1: 1.586e-02 | Loss_bc2s: 1.717e-02 |  loss_ics_u: 1.065e-01 |  Loss_ut_ics: 3.635e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.207e+00\n",
            "adaptive_constant_ics_val: 1.008e+00\n",
            "adaptive_constant_bcs_val: 7.845e-01\n",
            "It: 13600 |  Loss: 1.166e-01 |  Loss_res: 6.771e-04 |   Loss_bcs1: 1.469e-02 | Loss_bc2s: 1.347e-02 |  loss_ics_u: 1.184e-01 |  Loss_ut_ics: 7.748e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 6.171e-01\n",
            "adaptive_constant_ics_val: 1.766e+00\n",
            "adaptive_constant_bcs_val: 6.172e-01\n",
            "It: 13700 |  Loss: 8.156e-02 |  Loss_res: 4.982e-04 |   Loss_bcs1: 1.495e-02 | Loss_bc2s: 1.385e-02 |  loss_ics_u: 1.002e-01 |  Loss_ut_ics: 9.363e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 5.754e-01\n",
            "adaptive_constant_ics_val: 1.681e+00\n",
            "adaptive_constant_bcs_val: 7.440e-01\n",
            "It: 13800 |  Loss: 9.064e-02 |  Loss_res: 6.378e-04 |   Loss_bcs1: 1.699e-02 | Loss_bc2s: 1.591e-02 |  loss_ics_u: 8.792e-02 |  Loss_ut_ics: 2.303e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 1.446e+00\n",
            "adaptive_constant_ics_val: 8.815e-01\n",
            "adaptive_constant_bcs_val: 6.724e-01\n",
            "It: 13900 |  Loss: 9.394e-02 |  Loss_res: 4.447e-04 |   Loss_bcs1: 1.423e-02 | Loss_bc2s: 1.457e-02 |  loss_ics_u: 1.087e-01 |  Loss_ut_ics: 9.213e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 6.326e-01\n",
            "adaptive_constant_ics_val: 1.917e+00\n",
            "adaptive_constant_bcs_val: 4.503e-01\n",
            "It: 14000 |  Loss: 5.883e-02 |  Loss_res: 4.189e-04 |   Loss_bcs1: 9.809e-03 | Loss_bc2s: 1.726e-02 |  loss_ics_u: 1.019e-01 |  Loss_ut_ics: 2.471e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.037e+00\n",
            "adaptive_constant_ics_val: 9.583e-01\n",
            "adaptive_constant_bcs_val: 1.004e+00\n",
            "It: 14100 |  Loss: 1.266e-01 |  Loss_res: 1.405e-03 |   Loss_bcs1: 1.100e-02 | Loss_bc2s: 1.703e-02 |  loss_ics_u: 9.600e-02 |  Loss_ut_ics: 5.756e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.433e+00\n",
            "adaptive_constant_ics_val: 8.447e-01\n",
            "adaptive_constant_bcs_val: 7.219e-01\n",
            "It: 14200 |  Loss: 8.795e-02 |  Loss_res: 7.095e-04 |   Loss_bcs1: 1.117e-02 | Loss_bc2s: 1.683e-02 |  loss_ics_u: 9.190e-02 |  Loss_ut_ics: 4.387e-04 |  Time: 0.03\n",
            "adaptive_constant_res_val: 1.054e+00\n",
            "adaptive_constant_ics_val: 8.809e-01\n",
            "adaptive_constant_bcs_val: 1.065e+00\n",
            "It: 14300 |  Loss: 1.330e-01 |  Loss_res: 2.152e-03 |   Loss_bcs1: 8.312e-03 | Loss_bc2s: 1.422e-02 |  loss_ics_u: 9.820e-02 |  Loss_ut_ics: 2.362e-03 |  Time: 0.33\n",
            "adaptive_constant_res_val: 1.927e+00\n",
            "adaptive_constant_ics_val: 5.406e-01\n",
            "adaptive_constant_bcs_val: 5.326e-01\n",
            "It: 14400 |  Loss: 7.615e-02 |  Loss_res: 1.063e-03 |   Loss_bcs1: 8.754e-03 | Loss_bc2s: 1.557e-02 |  loss_ics_u: 1.141e-01 |  Loss_ut_ics: 7.327e-04 |  Time: 0.05\n",
            "adaptive_constant_res_val: 1.105e+00\n",
            "adaptive_constant_ics_val: 6.698e-01\n",
            "adaptive_constant_bcs_val: 1.226e+00\n",
            "It: 14500 |  Loss: 1.449e-01 |  Loss_res: 1.362e-03 |   Loss_bcs1: 8.971e-03 | Loss_bc2s: 1.829e-02 |  loss_ics_u: 8.886e-02 |  Loss_ut_ics: 1.566e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 5.795e-01\n",
            "adaptive_constant_ics_val: 1.816e+00\n",
            "adaptive_constant_bcs_val: 6.041e-01\n",
            "It: 14600 |  Loss: 7.657e-02 |  Loss_res: 1.046e-03 |   Loss_bcs1: 1.110e-02 | Loss_bc2s: 1.586e-02 |  loss_ics_u: 9.764e-02 |  Loss_ut_ics: 3.772e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.286e-01\n",
            "adaptive_constant_ics_val: 1.028e+00\n",
            "adaptive_constant_bcs_val: 1.043e+00\n",
            "It: 14700 |  Loss: 1.256e-01 |  Loss_res: 5.093e-04 |   Loss_bcs1: 7.752e-03 | Loss_bc2s: 1.590e-02 |  loss_ics_u: 9.577e-02 |  Loss_ut_ics: 4.816e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 7.308e-01\n",
            "adaptive_constant_ics_val: 1.390e+00\n",
            "adaptive_constant_bcs_val: 8.791e-01\n",
            "It: 14800 |  Loss: 1.025e-01 |  Loss_res: 8.501e-04 |   Loss_bcs1: 7.332e-03 | Loss_bc2s: 1.443e-02 |  loss_ics_u: 9.291e-02 |  Loss_ut_ics: 7.828e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.090e+00\n",
            "adaptive_constant_ics_val: 1.031e+00\n",
            "adaptive_constant_bcs_val: 8.792e-01\n",
            "It: 14900 |  Loss: 1.064e-01 |  Loss_res: 4.869e-04 |   Loss_bcs1: 1.174e-02 | Loss_bc2s: 1.457e-02 |  loss_ics_u: 9.336e-02 |  Loss_ut_ics: 6.799e-04 |  Time: 0.15\n",
            "adaptive_constant_res_val: 9.830e-01\n",
            "adaptive_constant_ics_val: 9.676e-01\n",
            "adaptive_constant_bcs_val: 1.049e+00\n",
            "It: 15000 |  Loss: 1.464e-01 |  Loss_res: 8.481e-04 |   Loss_bcs1: 9.079e-03 | Loss_bc2s: 1.654e-02 |  loss_ics_u: 1.111e-01 |  Loss_ut_ics: 2.111e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.379e+00\n",
            "adaptive_constant_ics_val: 8.781e-01\n",
            "adaptive_constant_bcs_val: 7.432e-01\n",
            "It: 15100 |  Loss: 9.821e-02 |  Loss_res: 1.337e-03 |   Loss_bcs1: 9.354e-03 | Loss_bc2s: 1.236e-02 |  loss_ics_u: 1.074e-01 |  Loss_ut_ics: 4.395e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.029e+00\n",
            "adaptive_constant_ics_val: 7.687e-01\n",
            "adaptive_constant_bcs_val: 1.202e+00\n",
            "It: 15200 |  Loss: 1.624e-01 |  Loss_res: 1.978e-03 |   Loss_bcs1: 6.472e-03 | Loss_bc2s: 1.329e-02 |  loss_ics_u: 1.119e-01 |  Loss_ut_ics: 2.599e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 5.049e-01\n",
            "adaptive_constant_ics_val: 1.940e+00\n",
            "adaptive_constant_bcs_val: 5.556e-01\n",
            "It: 15300 |  Loss: 6.807e-02 |  Loss_res: 6.988e-04 |   Loss_bcs1: 9.904e-03 | Loss_bc2s: 1.340e-02 |  loss_ics_u: 9.785e-02 |  Loss_ut_ics: 2.069e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 7.513e-01\n",
            "adaptive_constant_ics_val: 1.081e+00\n",
            "adaptive_constant_bcs_val: 1.167e+00\n",
            "It: 15400 |  Loss: 1.432e-01 |  Loss_res: 6.586e-04 |   Loss_bcs1: 8.024e-03 | Loss_bc2s: 1.531e-02 |  loss_ics_u: 9.842e-02 |  Loss_ut_ics: 5.085e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.503e+00\n",
            "adaptive_constant_ics_val: 9.069e-01\n",
            "adaptive_constant_bcs_val: 5.904e-01\n",
            "It: 15500 |  Loss: 7.792e-02 |  Loss_res: 7.180e-04 |   Loss_bcs1: 8.691e-03 | Loss_bc2s: 1.479e-02 |  loss_ics_u: 1.045e-01 |  Loss_ut_ics: 1.450e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.424e+00\n",
            "adaptive_constant_ics_val: 8.164e-01\n",
            "adaptive_constant_bcs_val: 7.594e-01\n",
            "It: 15600 |  Loss: 8.313e-02 |  Loss_res: 3.725e-04 |   Loss_bcs1: 7.277e-03 | Loss_bc2s: 1.410e-02 |  loss_ics_u: 8.682e-02 |  Loss_ut_ics: 5.419e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.227e+00\n",
            "adaptive_constant_ics_val: 7.249e-01\n",
            "adaptive_constant_bcs_val: 1.048e+00\n",
            "It: 15700 |  Loss: 1.276e-01 |  Loss_res: 1.077e-03 |   Loss_bcs1: 7.320e-03 | Loss_bc2s: 1.616e-02 |  loss_ics_u: 9.563e-02 |  Loss_ut_ics: 1.943e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.241e+00\n",
            "adaptive_constant_ics_val: 1.033e+00\n",
            "adaptive_constant_bcs_val: 7.263e-01\n",
            "It: 15800 |  Loss: 9.110e-02 |  Loss_res: 4.033e-04 |   Loss_bcs1: 5.550e-03 | Loss_bc2s: 1.489e-02 |  loss_ics_u: 1.024e-01 |  Loss_ut_ics: 1.367e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 8.406e-01\n",
            "adaptive_constant_ics_val: 1.218e+00\n",
            "adaptive_constant_bcs_val: 9.414e-01\n",
            "It: 15900 |  Loss: 1.212e-01 |  Loss_res: 1.830e-03 |   Loss_bcs1: 4.268e-03 | Loss_bc2s: 1.560e-02 |  loss_ics_u: 1.062e-01 |  Loss_ut_ics: 8.559e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.906e+00\n",
            "adaptive_constant_ics_val: 5.713e-01\n",
            "adaptive_constant_bcs_val: 5.223e-01\n",
            "It: 16000 |  Loss: 6.552e-02 |  Loss_res: 8.860e-04 |   Loss_bcs1: 1.056e-02 | Loss_bc2s: 1.057e-02 |  loss_ics_u: 1.004e-01 |  Loss_ut_ics: 6.078e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.223e+00\n",
            "adaptive_constant_ics_val: 8.259e-01\n",
            "adaptive_constant_bcs_val: 9.510e-01\n",
            "It: 16100 |  Loss: 1.209e-01 |  Loss_res: 2.643e-04 |   Loss_bcs1: 9.806e-03 | Loss_bc2s: 1.188e-02 |  loss_ics_u: 1.046e-01 |  Loss_ut_ics: 6.226e-04 |  Time: 0.12\n",
            "adaptive_constant_res_val: 8.092e-01\n",
            "adaptive_constant_ics_val: 1.131e+00\n",
            "adaptive_constant_bcs_val: 1.060e+00\n",
            "It: 16200 |  Loss: 1.157e-01 |  Loss_res: 4.925e-04 |   Loss_bcs1: 6.568e-03 | Loss_bc2s: 1.411e-02 |  loss_ics_u: 8.723e-02 |  Loss_ut_ics: 8.727e-04 |  Time: 0.15\n",
            "adaptive_constant_res_val: 1.406e+00\n",
            "adaptive_constant_ics_val: 9.736e-01\n",
            "adaptive_constant_bcs_val: 6.206e-01\n",
            "It: 16300 |  Loss: 7.705e-02 |  Loss_res: 2.181e-04 |   Loss_bcs1: 1.054e-02 | Loss_bc2s: 1.169e-02 |  loss_ics_u: 1.007e-01 |  Loss_ut_ics: 4.810e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.146e+00\n",
            "adaptive_constant_ics_val: 9.180e-01\n",
            "adaptive_constant_bcs_val: 9.361e-01\n",
            "It: 16400 |  Loss: 1.153e-01 |  Loss_res: 2.266e-03 |   Loss_bcs1: 5.496e-03 | Loss_bc2s: 1.322e-02 |  loss_ics_u: 9.772e-02 |  Loss_ut_ics: 4.052e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.591e-01\n",
            "adaptive_constant_ics_val: 1.312e+00\n",
            "adaptive_constant_bcs_val: 7.286e-01\n",
            "It: 16500 |  Loss: 9.250e-02 |  Loss_res: 3.766e-04 |   Loss_bcs1: 6.041e-03 | Loss_bc2s: 1.281e-02 |  loss_ics_u: 1.068e-01 |  Loss_ut_ics: 4.661e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 8.158e-01\n",
            "adaptive_constant_ics_val: 8.845e-01\n",
            "adaptive_constant_bcs_val: 1.300e+00\n",
            "It: 16600 |  Loss: 1.535e-01 |  Loss_res: 1.053e-03 |   Loss_bcs1: 7.176e-03 | Loss_bc2s: 1.425e-02 |  loss_ics_u: 9.484e-02 |  Loss_ut_ics: 1.748e-03 |  Time: 0.14\n",
            "adaptive_constant_res_val: 4.717e-01\n",
            "adaptive_constant_ics_val: 1.940e+00\n",
            "adaptive_constant_bcs_val: 5.885e-01\n",
            "It: 16700 |  Loss: 7.191e-02 |  Loss_res: 4.073e-04 |   Loss_bcs1: 5.028e-03 | Loss_bc2s: 1.385e-02 |  loss_ics_u: 1.021e-01 |  Loss_ut_ics: 2.738e-04 |  Time: 0.13\n",
            "adaptive_constant_res_val: 7.733e-01\n",
            "adaptive_constant_ics_val: 1.043e+00\n",
            "adaptive_constant_bcs_val: 1.184e+00\n",
            "It: 16800 |  Loss: 1.476e-01 |  Loss_res: 1.747e-03 |   Loss_bcs1: 6.824e-03 | Loss_bc2s: 1.535e-02 |  loss_ics_u: 1.008e-01 |  Loss_ut_ics: 6.283e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 4.413e-01\n",
            "adaptive_constant_ics_val: 2.008e+00\n",
            "adaptive_constant_bcs_val: 5.503e-01\n",
            "It: 16900 |  Loss: 6.731e-02 |  Loss_res: 7.460e-04 |   Loss_bcs1: 9.247e-03 | Loss_bc2s: 1.577e-02 |  loss_ics_u: 9.397e-02 |  Loss_ut_ics: 7.468e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 6.942e-01\n",
            "adaptive_constant_ics_val: 1.218e+00\n",
            "adaptive_constant_bcs_val: 1.087e+00\n",
            "It: 17000 |  Loss: 1.357e-01 |  Loss_res: 2.230e-03 |   Loss_bcs1: 8.627e-03 | Loss_bc2s: 1.240e-02 |  loss_ics_u: 1.010e-01 |  Loss_ut_ics: 1.249e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.174e+00\n",
            "adaptive_constant_ics_val: 8.911e-01\n",
            "adaptive_constant_bcs_val: 9.353e-01\n",
            "It: 17100 |  Loss: 1.201e-01 |  Loss_res: 5.532e-04 |   Loss_bcs1: 6.905e-03 | Loss_bc2s: 1.482e-02 |  loss_ics_u: 1.053e-01 |  Loss_ut_ics: 7.306e-04 |  Time: 0.05\n",
            "adaptive_constant_res_val: 8.407e-01\n",
            "adaptive_constant_ics_val: 8.962e-01\n",
            "adaptive_constant_bcs_val: 1.263e+00\n",
            "It: 17200 |  Loss: 1.582e-01 |  Loss_res: 2.238e-03 |   Loss_bcs1: 6.546e-03 | Loss_bc2s: 1.380e-02 |  loss_ics_u: 9.930e-02 |  Loss_ut_ics: 5.796e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.948e+00\n",
            "adaptive_constant_ics_val: 4.785e-01\n",
            "adaptive_constant_bcs_val: 5.735e-01\n",
            "It: 17300 |  Loss: 6.290e-02 |  Loss_res: 4.425e-04 |   Loss_bcs1: 8.959e-03 | Loss_bc2s: 1.392e-02 |  loss_ics_u: 8.419e-02 |  Loss_ut_ics: 1.327e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.052e+00\n",
            "adaptive_constant_ics_val: 7.635e-01\n",
            "adaptive_constant_bcs_val: 1.185e+00\n",
            "It: 17400 |  Loss: 1.510e-01 |  Loss_res: 8.493e-04 |   Loss_bcs1: 7.211e-03 | Loss_bc2s: 1.350e-02 |  loss_ics_u: 1.048e-01 |  Loss_ut_ics: 1.805e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.314e+00\n",
            "adaptive_constant_ics_val: 7.041e-01\n",
            "adaptive_constant_bcs_val: 9.821e-01\n",
            "It: 17500 |  Loss: 1.218e-01 |  Loss_res: 1.284e-03 |   Loss_bcs1: 4.479e-03 | Loss_bc2s: 1.278e-02 |  loss_ics_u: 1.041e-01 |  Loss_ut_ics: 1.312e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.601e-01\n",
            "adaptive_constant_ics_val: 8.548e-01\n",
            "adaptive_constant_bcs_val: 1.185e+00\n",
            "It: 17600 |  Loss: 1.531e-01 |  Loss_res: 9.596e-04 |   Loss_bcs1: 1.029e-02 | Loss_bc2s: 1.588e-02 |  loss_ics_u: 1.011e-01 |  Loss_ut_ics: 1.512e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.157e-01\n",
            "adaptive_constant_ics_val: 8.882e-01\n",
            "adaptive_constant_bcs_val: 1.196e+00\n",
            "It: 17700 |  Loss: 1.471e-01 |  Loss_res: 9.023e-04 |   Loss_bcs1: 1.017e-02 | Loss_bc2s: 1.296e-02 |  loss_ics_u: 9.865e-02 |  Loss_ut_ics: 6.642e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.094e+00\n",
            "adaptive_constant_ics_val: 7.756e-01\n",
            "adaptive_constant_bcs_val: 1.131e+00\n",
            "It: 17800 |  Loss: 1.325e-01 |  Loss_res: 5.284e-04 |   Loss_bcs1: 7.681e-03 | Loss_bc2s: 1.196e-02 |  loss_ics_u: 9.649e-02 |  Loss_ut_ics: 8.344e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 8.116e-01\n",
            "adaptive_constant_ics_val: 1.085e+00\n",
            "adaptive_constant_bcs_val: 1.103e+00\n",
            "It: 17900 |  Loss: 1.281e-01 |  Loss_res: 1.027e-03 |   Loss_bcs1: 5.544e-03 | Loss_bc2s: 1.235e-02 |  loss_ics_u: 9.531e-02 |  Loss_ut_ics: 2.252e-03 |  Time: 0.05\n",
            "adaptive_constant_res_val: 1.126e+00\n",
            "adaptive_constant_ics_val: 9.050e-01\n",
            "adaptive_constant_bcs_val: 9.692e-01\n",
            "It: 18000 |  Loss: 9.872e-02 |  Loss_res: 6.788e-04 |   Loss_bcs1: 5.684e-03 | Loss_bc2s: 1.157e-02 |  loss_ics_u: 8.346e-02 |  Loss_ut_ics: 3.882e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.746e-01\n",
            "adaptive_constant_ics_val: 8.202e-01\n",
            "adaptive_constant_bcs_val: 1.205e+00\n",
            "It: 18100 |  Loss: 1.431e-01 |  Loss_res: 5.607e-04 |   Loss_bcs1: 8.983e-03 | Loss_bc2s: 1.282e-02 |  loss_ics_u: 9.590e-02 |  Loss_ut_ics: 8.139e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 6.803e-01\n",
            "adaptive_constant_ics_val: 1.616e+00\n",
            "adaptive_constant_bcs_val: 7.042e-01\n",
            "It: 18200 |  Loss: 8.074e-02 |  Loss_res: 4.574e-04 |   Loss_bcs1: 7.098e-03 | Loss_bc2s: 1.375e-02 |  loss_ics_u: 9.050e-02 |  Loss_ut_ics: 1.244e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.059e+00\n",
            "adaptive_constant_ics_val: 1.005e+00\n",
            "adaptive_constant_bcs_val: 9.361e-01\n",
            "It: 18300 |  Loss: 1.133e-01 |  Loss_res: 8.073e-04 |   Loss_bcs1: 6.280e-03 | Loss_bc2s: 1.186e-02 |  loss_ics_u: 1.016e-01 |  Loss_ut_ics: 4.115e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.364e+00\n",
            "adaptive_constant_ics_val: 6.994e-01\n",
            "adaptive_constant_bcs_val: 9.365e-01\n",
            "It: 18400 |  Loss: 1.306e-01 |  Loss_res: 1.373e-03 |   Loss_bcs1: 8.066e-03 | Loss_bc2s: 1.693e-02 |  loss_ics_u: 1.118e-01 |  Loss_ut_ics: 8.261e-04 |  Time: 0.15\n",
            "adaptive_constant_res_val: 1.030e+00\n",
            "adaptive_constant_ics_val: 1.098e+00\n",
            "adaptive_constant_bcs_val: 8.721e-01\n",
            "It: 18500 |  Loss: 9.861e-02 |  Loss_res: 8.896e-04 |   Loss_bcs1: 7.662e-03 | Loss_bc2s: 1.228e-02 |  loss_ics_u: 9.149e-02 |  Loss_ut_ics: 4.705e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 7.763e-01\n",
            "adaptive_constant_ics_val: 1.487e+00\n",
            "adaptive_constant_bcs_val: 7.369e-01\n",
            "It: 18600 |  Loss: 9.080e-02 |  Loss_res: 1.098e-03 |   Loss_bcs1: 7.867e-03 | Loss_bc2s: 1.237e-02 |  loss_ics_u: 1.010e-01 |  Loss_ut_ics: 3.870e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.628e-01\n",
            "adaptive_constant_ics_val: 1.089e+00\n",
            "adaptive_constant_bcs_val: 9.486e-01\n",
            "It: 18700 |  Loss: 1.047e-01 |  Loss_res: 1.014e-03 |   Loss_bcs1: 4.596e-03 | Loss_bc2s: 1.427e-02 |  loss_ics_u: 8.909e-02 |  Loss_ut_ics: 1.229e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 8.104e-01\n",
            "adaptive_constant_ics_val: 1.328e+00\n",
            "adaptive_constant_bcs_val: 8.616e-01\n",
            "It: 18800 |  Loss: 9.837e-02 |  Loss_res: 6.086e-04 |   Loss_bcs1: 9.270e-03 | Loss_bc2s: 1.282e-02 |  loss_ics_u: 8.987e-02 |  Loss_ut_ics: 1.068e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.267e+00\n",
            "adaptive_constant_ics_val: 8.364e-01\n",
            "adaptive_constant_bcs_val: 8.962e-01\n",
            "It: 18900 |  Loss: 1.045e-01 |  Loss_res: 8.317e-04 |   Loss_bcs1: 6.306e-03 | Loss_bc2s: 1.371e-02 |  loss_ics_u: 9.488e-02 |  Loss_ut_ics: 5.017e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.158e+00\n",
            "adaptive_constant_ics_val: 9.548e-01\n",
            "adaptive_constant_bcs_val: 8.871e-01\n",
            "It: 19000 |  Loss: 1.083e-01 |  Loss_res: 7.724e-04 |   Loss_bcs1: 6.743e-03 | Loss_bc2s: 1.424e-02 |  loss_ics_u: 9.845e-02 |  Loss_ut_ics: 1.480e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.390e+00\n",
            "adaptive_constant_ics_val: 7.507e-01\n",
            "adaptive_constant_bcs_val: 8.590e-01\n",
            "It: 19100 |  Loss: 9.859e-02 |  Loss_res: 2.337e-03 |   Loss_bcs1: 3.934e-03 | Loss_bc2s: 1.390e-02 |  loss_ics_u: 9.255e-02 |  Loss_ut_ics: 7.059e-04 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.807e+00\n",
            "adaptive_constant_ics_val: 5.337e-01\n",
            "adaptive_constant_bcs_val: 6.591e-01\n",
            "It: 19200 |  Loss: 7.736e-02 |  Loss_res: 3.967e-04 |   Loss_bcs1: 5.985e-03 | Loss_bc2s: 1.116e-02 |  loss_ics_u: 9.853e-02 |  Loss_ut_ics: 7.509e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 8.889e-01\n",
            "adaptive_constant_ics_val: 1.324e+00\n",
            "adaptive_constant_bcs_val: 7.869e-01\n",
            "It: 19300 |  Loss: 9.071e-02 |  Loss_res: 4.772e-04 |   Loss_bcs1: 7.428e-03 | Loss_bc2s: 1.315e-02 |  loss_ics_u: 9.291e-02 |  Loss_ut_ics: 7.387e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.120e+00\n",
            "adaptive_constant_ics_val: 9.859e-01\n",
            "adaptive_constant_bcs_val: 8.941e-01\n",
            "It: 19400 |  Loss: 1.075e-01 |  Loss_res: 7.238e-04 |   Loss_bcs1: 4.412e-03 | Loss_bc2s: 1.391e-02 |  loss_ics_u: 1.003e-01 |  Loss_ut_ics: 6.807e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.976e-01\n",
            "adaptive_constant_ics_val: 1.022e+00\n",
            "adaptive_constant_bcs_val: 9.807e-01\n",
            "It: 19500 |  Loss: 1.078e-01 |  Loss_res: 5.437e-04 |   Loss_bcs1: 7.418e-03 | Loss_bc2s: 1.236e-02 |  loss_ics_u: 8.868e-02 |  Loss_ut_ics: 8.406e-04 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.008e+00\n",
            "adaptive_constant_ics_val: 1.034e+00\n",
            "adaptive_constant_bcs_val: 9.575e-01\n",
            "It: 19600 |  Loss: 1.106e-01 |  Loss_res: 5.895e-04 |   Loss_bcs1: 7.251e-03 | Loss_bc2s: 1.156e-02 |  loss_ics_u: 9.495e-02 |  Loss_ut_ics: 1.024e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 9.124e-01\n",
            "adaptive_constant_ics_val: 1.177e+00\n",
            "adaptive_constant_bcs_val: 9.108e-01\n",
            "It: 19700 |  Loss: 1.027e-01 |  Loss_res: 8.079e-04 |   Loss_bcs1: 4.829e-03 | Loss_bc2s: 1.620e-02 |  loss_ics_u: 9.024e-02 |  Loss_ut_ics: 5.651e-04 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.019e+00\n",
            "adaptive_constant_ics_val: 1.095e+00\n",
            "adaptive_constant_bcs_val: 8.868e-01\n",
            "It: 19800 |  Loss: 1.069e-01 |  Loss_res: 5.673e-04 |   Loss_bcs1: 4.252e-03 | Loss_bc2s: 1.315e-02 |  loss_ics_u: 1.014e-01 |  Loss_ut_ics: 8.963e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.065e+00\n",
            "adaptive_constant_ics_val: 9.219e-01\n",
            "adaptive_constant_bcs_val: 1.013e+00\n",
            "It: 19900 |  Loss: 1.216e-01 |  Loss_res: 9.378e-04 |   Loss_bcs1: 4.041e-03 | Loss_bc2s: 1.213e-02 |  loss_ics_u: 1.018e-01 |  Loss_ut_ics: 1.154e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.376e+00\n",
            "adaptive_constant_ics_val: 8.326e-01\n",
            "adaptive_constant_bcs_val: 7.918e-01\n",
            "It: 20000 |  Loss: 9.686e-02 |  Loss_res: 9.036e-04 |   Loss_bcs1: 4.733e-03 | Loss_bc2s: 1.314e-02 |  loss_ics_u: 1.021e-01 |  Loss_ut_ics: 7.816e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 7.763e-01\n",
            "adaptive_constant_ics_val: 1.485e+00\n",
            "adaptive_constant_bcs_val: 7.384e-01\n",
            "It: 20100 |  Loss: 8.954e-02 |  Loss_res: 5.035e-04 |   Loss_bcs1: 6.274e-03 | Loss_bc2s: 1.253e-02 |  loss_ics_u: 1.008e-01 |  Loss_ut_ics: 5.558e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 8.011e-01\n",
            "adaptive_constant_ics_val: 1.154e+00\n",
            "adaptive_constant_bcs_val: 1.044e+00\n",
            "It: 20200 |  Loss: 1.168e-01 |  Loss_res: 1.086e-03 |   Loss_bcs1: 4.198e-03 | Loss_bc2s: 1.353e-02 |  loss_ics_u: 8.989e-02 |  Loss_ut_ics: 3.029e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 7.466e-01\n",
            "adaptive_constant_ics_val: 1.312e+00\n",
            "adaptive_constant_bcs_val: 9.412e-01\n",
            "It: 20300 |  Loss: 1.107e-01 |  Loss_res: 1.263e-03 |   Loss_bcs1: 8.695e-03 | Loss_bc2s: 1.318e-02 |  loss_ics_u: 9.406e-02 |  Loss_ut_ics: 4.969e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.055e+00\n",
            "adaptive_constant_ics_val: 8.120e-01\n",
            "adaptive_constant_bcs_val: 1.133e+00\n",
            "It: 20400 |  Loss: 1.310e-01 |  Loss_res: 8.253e-04 |   Loss_bcs1: 4.358e-03 | Loss_bc2s: 1.205e-02 |  loss_ics_u: 9.787e-02 |  Loss_ut_ics: 8.440e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 8.882e-01\n",
            "adaptive_constant_ics_val: 1.322e+00\n",
            "adaptive_constant_bcs_val: 7.902e-01\n",
            "It: 20500 |  Loss: 1.013e-01 |  Loss_res: 7.687e-04 |   Loss_bcs1: 5.133e-03 | Loss_bc2s: 1.898e-02 |  loss_ics_u: 1.023e-01 |  Loss_ut_ics: 5.306e-04 |  Time: 0.06\n",
            "adaptive_constant_res_val: 1.130e+00\n",
            "adaptive_constant_ics_val: 9.511e-01\n",
            "adaptive_constant_bcs_val: 9.192e-01\n",
            "It: 20600 |  Loss: 8.914e-02 |  Loss_res: 5.436e-04 |   Loss_bcs1: 4.453e-03 | Loss_bc2s: 1.218e-02 |  loss_ics_u: 7.921e-02 |  Loss_ut_ics: 4.541e-04 |  Time: 0.12\n",
            "adaptive_constant_res_val: 9.157e-01\n",
            "adaptive_constant_ics_val: 1.038e+00\n",
            "adaptive_constant_bcs_val: 1.046e+00\n",
            "It: 20700 |  Loss: 1.197e-01 |  Loss_res: 1.236e-03 |   Loss_bcs1: 5.839e-03 | Loss_bc2s: 1.275e-02 |  loss_ics_u: 9.408e-02 |  Loss_ut_ics: 7.343e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 5.966e-01\n",
            "adaptive_constant_ics_val: 1.695e+00\n",
            "adaptive_constant_bcs_val: 7.079e-01\n",
            "It: 20800 |  Loss: 7.804e-02 |  Loss_res: 8.678e-04 |   Loss_bcs1: 4.717e-03 | Loss_bc2s: 1.284e-02 |  loss_ics_u: 9.008e-02 |  Loss_ut_ics: 7.807e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 7.918e-01\n",
            "adaptive_constant_ics_val: 1.096e+00\n",
            "adaptive_constant_bcs_val: 1.113e+00\n",
            "It: 20900 |  Loss: 1.259e-01 |  Loss_res: 8.874e-04 |   Loss_bcs1: 5.544e-03 | Loss_bc2s: 1.236e-02 |  loss_ics_u: 9.324e-02 |  Loss_ut_ics: 1.394e-03 |  Time: 0.06\n",
            "adaptive_constant_res_val: 7.797e-01\n",
            "adaptive_constant_ics_val: 1.412e+00\n",
            "adaptive_constant_bcs_val: 8.085e-01\n",
            "It: 21000 |  Loss: 9.548e-02 |  Loss_res: 8.013e-04 |   Loss_bcs1: 4.434e-03 | Loss_bc2s: 1.275e-02 |  loss_ics_u: 9.818e-02 |  Loss_ut_ics: 1.120e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.071e+00\n",
            "adaptive_constant_ics_val: 9.352e-01\n",
            "adaptive_constant_bcs_val: 9.939e-01\n",
            "It: 21100 |  Loss: 1.102e-01 |  Loss_res: 1.207e-03 |   Loss_bcs1: 8.859e-03 | Loss_bc2s: 1.315e-02 |  loss_ics_u: 8.714e-02 |  Loss_ut_ics: 4.849e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.135e+00\n",
            "adaptive_constant_ics_val: 1.012e+00\n",
            "adaptive_constant_bcs_val: 8.533e-01\n",
            "It: 21200 |  Loss: 1.095e-01 |  Loss_res: 8.080e-04 |   Loss_bcs1: 8.816e-03 | Loss_bc2s: 1.158e-02 |  loss_ics_u: 1.058e-01 |  Loss_ut_ics: 9.020e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 5.731e-01\n",
            "adaptive_constant_ics_val: 1.887e+00\n",
            "adaptive_constant_bcs_val: 5.400e-01\n",
            "It: 21300 |  Loss: 5.812e-02 |  Loss_res: 6.904e-04 |   Loss_bcs1: 5.980e-03 | Loss_bc2s: 1.180e-02 |  loss_ics_u: 8.455e-02 |  Loss_ut_ics: 1.303e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.368e-01\n",
            "adaptive_constant_ics_val: 1.191e+00\n",
            "adaptive_constant_bcs_val: 8.719e-01\n",
            "It: 21400 |  Loss: 9.145e-02 |  Loss_res: 1.115e-03 |   Loss_bcs1: 4.263e-03 | Loss_bc2s: 1.319e-02 |  loss_ics_u: 8.575e-02 |  Loss_ut_ics: 3.585e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.314e+00\n",
            "adaptive_constant_ics_val: 7.677e-01\n",
            "adaptive_constant_bcs_val: 9.180e-01\n",
            "It: 21500 |  Loss: 9.818e-02 |  Loss_res: 1.884e-03 |   Loss_bcs1: 7.450e-03 | Loss_bc2s: 1.020e-02 |  loss_ics_u: 8.548e-02 |  Loss_ut_ics: 1.330e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.061e+00\n",
            "adaptive_constant_ics_val: 1.223e+00\n",
            "adaptive_constant_bcs_val: 7.160e-01\n",
            "It: 21600 |  Loss: 6.876e-02 |  Loss_res: 8.074e-04 |   Loss_bcs1: 3.712e-03 | Loss_bc2s: 1.164e-02 |  loss_ics_u: 7.795e-02 |  Loss_ut_ics: 8.987e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 8.746e-01\n",
            "adaptive_constant_ics_val: 9.955e-01\n",
            "adaptive_constant_bcs_val: 1.130e+00\n",
            "It: 21700 |  Loss: 1.353e-01 |  Loss_res: 1.104e-03 |   Loss_bcs1: 8.999e-03 | Loss_bc2s: 9.632e-03 |  loss_ics_u: 9.970e-02 |  Loss_ut_ics: 6.793e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.039e+00\n",
            "adaptive_constant_ics_val: 8.259e-01\n",
            "adaptive_constant_bcs_val: 1.135e+00\n",
            "It: 21800 |  Loss: 1.241e-01 |  Loss_res: 1.776e-03 |   Loss_bcs1: 7.118e-03 | Loss_bc2s: 1.036e-02 |  loss_ics_u: 8.824e-02 |  Loss_ut_ics: 2.707e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.361e+00\n",
            "adaptive_constant_ics_val: 8.404e-01\n",
            "adaptive_constant_bcs_val: 7.987e-01\n",
            "It: 21900 |  Loss: 8.589e-02 |  Loss_res: 1.447e-03 |   Loss_bcs1: 3.601e-03 | Loss_bc2s: 1.162e-02 |  loss_ics_u: 8.891e-02 |  Loss_ut_ics: 8.973e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.014e+00\n",
            "adaptive_constant_ics_val: 8.122e-01\n",
            "adaptive_constant_bcs_val: 1.174e+00\n",
            "It: 22000 |  Loss: 1.203e-01 |  Loss_res: 1.483e-03 |   Loss_bcs1: 5.372e-03 | Loss_bc2s: 1.144e-02 |  loss_ics_u: 8.396e-02 |  Loss_ut_ics: 6.794e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 8.829e-01\n",
            "adaptive_constant_ics_val: 1.088e+00\n",
            "adaptive_constant_bcs_val: 1.029e+00\n",
            "It: 22100 |  Loss: 1.186e-01 |  Loss_res: 1.397e-03 |   Loss_bcs1: 8.475e-03 | Loss_bc2s: 1.154e-02 |  loss_ics_u: 9.319e-02 |  Loss_ut_ics: 8.299e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 7.687e-01\n",
            "adaptive_constant_ics_val: 1.366e+00\n",
            "adaptive_constant_bcs_val: 8.654e-01\n",
            "It: 22200 |  Loss: 8.842e-02 |  Loss_res: 8.079e-04 |   Loss_bcs1: 8.161e-03 | Loss_bc2s: 1.009e-02 |  loss_ics_u: 8.154e-02 |  Loss_ut_ics: 1.057e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.431e-01\n",
            "adaptive_constant_ics_val: 1.041e+00\n",
            "adaptive_constant_bcs_val: 1.016e+00\n",
            "It: 22300 |  Loss: 1.117e-01 |  Loss_res: 8.604e-04 |   Loss_bcs1: 7.161e-03 | Loss_bc2s: 1.164e-02 |  loss_ics_u: 8.991e-02 |  Loss_ut_ics: 4.673e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.161e+00\n",
            "adaptive_constant_ics_val: 9.035e-01\n",
            "adaptive_constant_bcs_val: 9.356e-01\n",
            "It: 22400 |  Loss: 1.042e-01 |  Loss_res: 1.663e-03 |   Loss_bcs1: 5.357e-03 | Loss_bc2s: 1.128e-02 |  loss_ics_u: 9.165e-02 |  Loss_ut_ics: 1.096e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.040e-01\n",
            "adaptive_constant_ics_val: 1.162e+00\n",
            "adaptive_constant_bcs_val: 9.340e-01\n",
            "It: 22500 |  Loss: 1.015e-01 |  Loss_res: 7.582e-04 |   Loss_bcs1: 4.391e-03 | Loss_bc2s: 1.012e-02 |  loss_ics_u: 9.220e-02 |  Loss_ut_ics: 9.511e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.953e-01\n",
            "adaptive_constant_ics_val: 9.314e-01\n",
            "adaptive_constant_bcs_val: 1.073e+00\n",
            "It: 22600 |  Loss: 1.177e-01 |  Loss_res: 1.250e-03 |   Loss_bcs1: 7.388e-03 | Loss_bc2s: 1.043e-02 |  loss_ics_u: 9.010e-02 |  Loss_ut_ics: 7.190e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.406e+00\n",
            "adaptive_constant_ics_val: 7.667e-01\n",
            "adaptive_constant_bcs_val: 8.275e-01\n",
            "It: 22700 |  Loss: 9.119e-02 |  Loss_res: 8.526e-04 |   Loss_bcs1: 4.917e-03 | Loss_bc2s: 1.011e-02 |  loss_ics_u: 9.300e-02 |  Loss_ut_ics: 7.729e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.073e-01\n",
            "adaptive_constant_ics_val: 1.212e+00\n",
            "adaptive_constant_bcs_val: 8.811e-01\n",
            "It: 22800 |  Loss: 9.690e-02 |  Loss_res: 8.577e-04 |   Loss_bcs1: 3.342e-03 | Loss_bc2s: 1.024e-02 |  loss_ics_u: 9.305e-02 |  Loss_ut_ics: 1.792e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 5.647e-01\n",
            "adaptive_constant_ics_val: 1.889e+00\n",
            "adaptive_constant_bcs_val: 5.463e-01\n",
            "It: 22900 |  Loss: 5.793e-02 |  Loss_res: 7.352e-04 |   Loss_bcs1: 5.191e-03 | Loss_bc2s: 1.007e-02 |  loss_ics_u: 8.835e-02 |  Loss_ut_ics: 4.844e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.040e+00\n",
            "adaptive_constant_ics_val: 1.000e+00\n",
            "adaptive_constant_bcs_val: 9.599e-01\n",
            "It: 23000 |  Loss: 9.976e-02 |  Loss_res: 7.443e-04 |   Loss_bcs1: 4.605e-03 | Loss_bc2s: 1.178e-02 |  loss_ics_u: 8.592e-02 |  Loss_ut_ics: 7.873e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 8.925e-01\n",
            "adaptive_constant_ics_val: 1.319e+00\n",
            "adaptive_constant_bcs_val: 7.884e-01\n",
            "It: 23100 |  Loss: 9.653e-02 |  Loss_res: 7.624e-04 |   Loss_bcs1: 7.111e-03 | Loss_bc2s: 1.302e-02 |  loss_ics_u: 1.003e-01 |  Loss_ut_ics: 6.612e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.320e+00\n",
            "adaptive_constant_ics_val: 8.825e-01\n",
            "adaptive_constant_bcs_val: 7.972e-01\n",
            "It: 23200 |  Loss: 8.882e-02 |  Loss_res: 2.477e-03 |   Loss_bcs1: 7.382e-03 | Loss_bc2s: 1.036e-02 |  loss_ics_u: 8.871e-02 |  Loss_ut_ics: 7.764e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.827e+00\n",
            "adaptive_constant_ics_val: 5.629e-01\n",
            "adaptive_constant_bcs_val: 6.100e-01\n",
            "It: 23300 |  Loss: 7.436e-02 |  Loss_res: 1.457e-03 |   Loss_bcs1: 4.511e-03 | Loss_bc2s: 8.068e-03 |  loss_ics_u: 1.044e-01 |  Loss_ut_ics: 6.318e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.300e+00\n",
            "adaptive_constant_ics_val: 7.461e-01\n",
            "adaptive_constant_bcs_val: 9.534e-01\n",
            "It: 23400 |  Loss: 1.103e-01 |  Loss_res: 7.853e-04 |   Loss_bcs1: 7.087e-03 | Loss_bc2s: 1.054e-02 |  loss_ics_u: 9.657e-02 |  Loss_ut_ics: 5.202e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.792e-01\n",
            "adaptive_constant_ics_val: 1.039e+00\n",
            "adaptive_constant_bcs_val: 9.818e-01\n",
            "It: 23500 |  Loss: 1.081e-01 |  Loss_res: 8.143e-04 |   Loss_bcs1: 8.880e-03 | Loss_bc2s: 7.646e-03 |  loss_ics_u: 9.194e-02 |  Loss_ut_ics: 7.764e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.138e-01\n",
            "adaptive_constant_ics_val: 1.149e+00\n",
            "adaptive_constant_bcs_val: 9.372e-01\n",
            "It: 23600 |  Loss: 9.965e-02 |  Loss_res: 9.098e-04 |   Loss_bcs1: 5.439e-03 | Loss_bc2s: 1.313e-02 |  loss_ics_u: 8.589e-02 |  Loss_ut_ics: 7.942e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.971e-01\n",
            "adaptive_constant_ics_val: 1.097e+00\n",
            "adaptive_constant_bcs_val: 9.064e-01\n",
            "It: 23700 |  Loss: 9.418e-02 |  Loss_res: 8.052e-04 |   Loss_bcs1: 6.177e-03 | Loss_bc2s: 1.244e-02 |  loss_ics_u: 8.371e-02 |  Loss_ut_ics: 5.695e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.315e+00\n",
            "adaptive_constant_ics_val: 8.199e-01\n",
            "adaptive_constant_bcs_val: 8.652e-01\n",
            "It: 23800 |  Loss: 9.147e-02 |  Loss_res: 1.262e-03 |   Loss_bcs1: 4.153e-03 | Loss_bc2s: 1.034e-02 |  loss_ics_u: 8.878e-02 |  Loss_ut_ics: 5.571e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.028e+00\n",
            "adaptive_constant_ics_val: 9.054e-01\n",
            "adaptive_constant_bcs_val: 1.066e+00\n",
            "It: 23900 |  Loss: 1.084e-01 |  Loss_res: 9.996e-04 |   Loss_bcs1: 7.870e-03 | Loss_bc2s: 9.067e-03 |  loss_ics_u: 8.322e-02 |  Loss_ut_ics: 5.951e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 8.735e-01\n",
            "adaptive_constant_ics_val: 1.069e+00\n",
            "adaptive_constant_bcs_val: 1.058e+00\n",
            "It: 24000 |  Loss: 1.076e-01 |  Loss_res: 7.153e-04 |   Loss_bcs1: 4.218e-03 | Loss_bc2s: 1.050e-02 |  loss_ics_u: 8.567e-02 |  Loss_ut_ics: 7.187e-04 |  Time: 0.06\n",
            "adaptive_constant_res_val: 7.491e-01\n",
            "adaptive_constant_ics_val: 1.411e+00\n",
            "adaptive_constant_bcs_val: 8.399e-01\n",
            "It: 24100 |  Loss: 8.080e-02 |  Loss_res: 7.614e-04 |   Loss_bcs1: 4.541e-03 | Loss_bc2s: 1.048e-02 |  loss_ics_u: 7.844e-02 |  Loss_ut_ics: 1.224e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.048e-01\n",
            "adaptive_constant_ics_val: 1.177e+00\n",
            "adaptive_constant_bcs_val: 9.181e-01\n",
            "It: 24200 |  Loss: 9.646e-02 |  Loss_res: 8.630e-04 |   Loss_bcs1: 3.961e-03 | Loss_bc2s: 1.002e-02 |  loss_ics_u: 8.944e-02 |  Loss_ut_ics: 6.248e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.039e+00\n",
            "adaptive_constant_ics_val: 8.694e-01\n",
            "adaptive_constant_bcs_val: 1.092e+00\n",
            "It: 24300 |  Loss: 1.250e-01 |  Loss_res: 1.047e-03 |   Loss_bcs1: 4.753e-03 | Loss_bc2s: 1.067e-02 |  loss_ics_u: 9.624e-02 |  Loss_ut_ics: 2.324e-03 |  Time: 0.22\n",
            "adaptive_constant_res_val: 9.203e-01\n",
            "adaptive_constant_ics_val: 9.770e-01\n",
            "adaptive_constant_bcs_val: 1.103e+00\n",
            "It: 24400 |  Loss: 1.235e-01 |  Loss_res: 7.173e-04 |   Loss_bcs1: 5.766e-03 | Loss_bc2s: 1.273e-02 |  loss_ics_u: 9.226e-02 |  Loss_ut_ics: 6.875e-04 |  Time: 0.13\n",
            "adaptive_constant_res_val: 9.139e-01\n",
            "adaptive_constant_ics_val: 8.127e-01\n",
            "adaptive_constant_bcs_val: 1.273e+00\n",
            "It: 24500 |  Loss: 1.367e-01 |  Loss_res: 1.373e-03 |   Loss_bcs1: 2.989e-03 | Loss_bc2s: 9.445e-03 |  loss_ics_u: 9.336e-02 |  Loss_ut_ics: 9.555e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.122e+00\n",
            "adaptive_constant_ics_val: 8.657e-01\n",
            "adaptive_constant_bcs_val: 1.013e+00\n",
            "It: 24600 |  Loss: 1.054e-01 |  Loss_res: 8.852e-04 |   Loss_bcs1: 4.810e-03 | Loss_bc2s: 8.911e-03 |  loss_ics_u: 8.846e-02 |  Loss_ut_ics: 1.053e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.094e-01\n",
            "adaptive_constant_ics_val: 9.890e-01\n",
            "adaptive_constant_bcs_val: 1.102e+00\n",
            "It: 24700 |  Loss: 1.175e-01 |  Loss_res: 8.191e-04 |   Loss_bcs1: 6.234e-03 | Loss_bc2s: 1.137e-02 |  loss_ics_u: 8.758e-02 |  Loss_ut_ics: 8.751e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.582e-01\n",
            "adaptive_constant_ics_val: 9.587e-01\n",
            "adaptive_constant_bcs_val: 1.083e+00\n",
            "It: 24800 |  Loss: 1.166e-01 |  Loss_res: 1.149e-03 |   Loss_bcs1: 2.474e-03 | Loss_bc2s: 9.899e-03 |  loss_ics_u: 9.319e-02 |  Loss_ut_ics: 1.219e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.104e+00\n",
            "adaptive_constant_ics_val: 8.956e-01\n",
            "adaptive_constant_bcs_val: 1.001e+00\n",
            "It: 24900 |  Loss: 1.163e-01 |  Loss_res: 8.757e-04 |   Loss_bcs1: 5.040e-03 | Loss_bc2s: 1.182e-02 |  loss_ics_u: 9.750e-02 |  Loss_ut_ics: 9.839e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.677e-01\n",
            "adaptive_constant_ics_val: 8.719e-01\n",
            "adaptive_constant_bcs_val: 1.160e+00\n",
            "It: 25000 |  Loss: 1.183e-01 |  Loss_res: 9.130e-04 |   Loss_bcs1: 4.248e-03 | Loss_bc2s: 8.831e-03 |  loss_ics_u: 8.749e-02 |  Loss_ut_ics: 8.217e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.093e+00\n",
            "adaptive_constant_ics_val: 9.810e-01\n",
            "adaptive_constant_bcs_val: 9.259e-01\n",
            "It: 25100 |  Loss: 9.381e-02 |  Loss_res: 1.242e-03 |   Loss_bcs1: 7.550e-03 | Loss_bc2s: 8.285e-03 |  loss_ics_u: 8.323e-02 |  Loss_ut_ics: 7.416e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.025e+00\n",
            "adaptive_constant_ics_val: 1.013e+00\n",
            "adaptive_constant_bcs_val: 9.617e-01\n",
            "It: 25200 |  Loss: 9.536e-02 |  Loss_res: 9.929e-04 |   Loss_bcs1: 7.962e-03 | Loss_bc2s: 8.078e-03 |  loss_ics_u: 8.112e-02 |  Loss_ut_ics: 8.918e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.687e-01\n",
            "adaptive_constant_ics_val: 1.108e+00\n",
            "adaptive_constant_bcs_val: 9.229e-01\n",
            "It: 25300 |  Loss: 9.919e-02 |  Loss_res: 1.838e-03 |   Loss_bcs1: 5.478e-03 | Loss_bc2s: 9.651e-03 |  loss_ics_u: 8.919e-02 |  Loss_ut_ics: 1.024e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 9.447e-01\n",
            "adaptive_constant_ics_val: 1.197e+00\n",
            "adaptive_constant_bcs_val: 8.583e-01\n",
            "It: 25400 |  Loss: 9.019e-02 |  Loss_res: 8.338e-04 |   Loss_bcs1: 5.094e-03 | Loss_bc2s: 8.790e-03 |  loss_ics_u: 8.904e-02 |  Loss_ut_ics: 8.903e-04 |  Time: 0.13\n",
            "adaptive_constant_res_val: 8.131e-01\n",
            "adaptive_constant_ics_val: 1.131e+00\n",
            "adaptive_constant_bcs_val: 1.056e+00\n",
            "It: 25500 |  Loss: 1.073e-01 |  Loss_res: 8.921e-04 |   Loss_bcs1: 4.764e-03 | Loss_bc2s: 7.718e-03 |  loss_ics_u: 8.764e-02 |  Loss_ut_ics: 7.486e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.291e-01\n",
            "adaptive_constant_ics_val: 9.684e-01\n",
            "adaptive_constant_bcs_val: 1.102e+00\n",
            "It: 25600 |  Loss: 1.155e-01 |  Loss_res: 1.025e-03 |   Loss_bcs1: 4.346e-03 | Loss_bc2s: 7.244e-03 |  loss_ics_u: 9.102e-02 |  Loss_ut_ics: 1.453e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.088e+00\n",
            "adaptive_constant_ics_val: 9.743e-01\n",
            "adaptive_constant_bcs_val: 9.381e-01\n",
            "It: 25700 |  Loss: 1.018e-01 |  Loss_res: 1.492e-03 |   Loss_bcs1: 4.857e-03 | Loss_bc2s: 1.006e-02 |  loss_ics_u: 9.108e-02 |  Loss_ut_ics: 8.103e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.917e+00\n",
            "adaptive_constant_ics_val: 5.322e-01\n",
            "adaptive_constant_bcs_val: 5.511e-01\n",
            "It: 25800 |  Loss: 5.468e-02 |  Loss_res: 5.870e-04 |   Loss_bcs1: 3.794e-03 | Loss_bc2s: 8.613e-03 |  loss_ics_u: 8.414e-02 |  Loss_ut_ics: 6.559e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.042e+00\n",
            "adaptive_constant_ics_val: 8.590e-01\n",
            "adaptive_constant_bcs_val: 1.099e+00\n",
            "It: 25900 |  Loss: 1.097e-01 |  Loss_res: 8.485e-04 |   Loss_bcs1: 3.820e-03 | Loss_bc2s: 8.430e-03 |  loss_ics_u: 8.597e-02 |  Loss_ut_ics: 9.901e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.083e+00\n",
            "adaptive_constant_ics_val: 1.044e+00\n",
            "adaptive_constant_bcs_val: 8.726e-01\n",
            "It: 26000 |  Loss: 8.424e-02 |  Loss_res: 7.538e-04 |   Loss_bcs1: 4.301e-03 | Loss_bc2s: 8.353e-03 |  loss_ics_u: 8.207e-02 |  Loss_ut_ics: 7.390e-04 |  Time: 0.06\n",
            "adaptive_constant_res_val: 1.081e+00\n",
            "adaptive_constant_ics_val: 9.083e-01\n",
            "adaptive_constant_bcs_val: 1.011e+00\n",
            "It: 26100 |  Loss: 9.339e-02 |  Loss_res: 9.450e-04 |   Loss_bcs1: 5.222e-03 | Loss_bc2s: 6.562e-03 |  loss_ics_u: 7.870e-02 |  Loss_ut_ics: 1.010e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.732e-01\n",
            "adaptive_constant_ics_val: 1.126e+00\n",
            "adaptive_constant_bcs_val: 9.011e-01\n",
            "It: 26200 |  Loss: 9.060e-02 |  Loss_res: 7.574e-04 |   Loss_bcs1: 3.703e-03 | Loss_bc2s: 8.055e-03 |  loss_ics_u: 8.705e-02 |  Loss_ut_ics: 7.412e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.528e-01\n",
            "adaptive_constant_ics_val: 1.051e+00\n",
            "adaptive_constant_bcs_val: 9.959e-01\n",
            "It: 26300 |  Loss: 1.128e-01 |  Loss_res: 1.424e-03 |   Loss_bcs1: 1.076e-02 | Loss_bc2s: 6.567e-03 |  loss_ics_u: 9.357e-02 |  Loss_ut_ics: 9.203e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.138e+00\n",
            "adaptive_constant_ics_val: 1.040e+00\n",
            "adaptive_constant_bcs_val: 8.224e-01\n",
            "It: 26400 |  Loss: 8.857e-02 |  Loss_res: 8.697e-04 |   Loss_bcs1: 3.882e-03 | Loss_bc2s: 7.291e-03 |  loss_ics_u: 9.338e-02 |  Loss_ut_ics: 1.527e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 8.939e-01\n",
            "adaptive_constant_ics_val: 1.155e+00\n",
            "adaptive_constant_bcs_val: 9.512e-01\n",
            "It: 26500 |  Loss: 9.761e-02 |  Loss_res: 1.044e-03 |   Loss_bcs1: 4.102e-03 | Loss_bc2s: 1.038e-02 |  loss_ics_u: 8.593e-02 |  Loss_ut_ics: 1.006e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.093e+00\n",
            "adaptive_constant_ics_val: 8.914e-01\n",
            "adaptive_constant_bcs_val: 1.016e+00\n",
            "It: 26600 |  Loss: 1.177e-01 |  Loss_res: 1.201e-03 |   Loss_bcs1: 5.542e-03 | Loss_bc2s: 8.573e-03 |  loss_ics_u: 9.966e-02 |  Loss_ut_ics: 9.388e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.107e+00\n",
            "adaptive_constant_ics_val: 8.754e-01\n",
            "adaptive_constant_bcs_val: 1.017e+00\n",
            "It: 26700 |  Loss: 1.082e-01 |  Loss_res: 9.865e-04 |   Loss_bcs1: 3.914e-03 | Loss_bc2s: 7.243e-03 |  loss_ics_u: 9.295e-02 |  Loss_ut_ics: 1.308e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.857e-01\n",
            "adaptive_constant_ics_val: 1.065e+00\n",
            "adaptive_constant_bcs_val: 9.496e-01\n",
            "It: 26800 |  Loss: 9.386e-02 |  Loss_res: 1.766e-03 |   Loss_bcs1: 6.170e-03 | Loss_bc2s: 6.586e-03 |  loss_ics_u: 8.269e-02 |  Loss_ut_ics: 1.395e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.345e+00\n",
            "adaptive_constant_ics_val: 8.890e-01\n",
            "adaptive_constant_bcs_val: 7.661e-01\n",
            "It: 26900 |  Loss: 7.993e-02 |  Loss_res: 9.735e-04 |   Loss_bcs1: 4.512e-03 | Loss_bc2s: 1.210e-02 |  loss_ics_u: 8.505e-02 |  Loss_ut_ics: 8.246e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.135e+00\n",
            "adaptive_constant_ics_val: 7.956e-01\n",
            "adaptive_constant_bcs_val: 1.069e+00\n",
            "It: 27000 |  Loss: 1.054e-01 |  Loss_res: 1.103e-03 |   Loss_bcs1: 5.915e-03 | Loss_bc2s: 8.434e-03 |  loss_ics_u: 8.215e-02 |  Loss_ut_ics: 1.196e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.000e-01\n",
            "adaptive_constant_ics_val: 1.103e+00\n",
            "adaptive_constant_bcs_val: 9.974e-01\n",
            "It: 27100 |  Loss: 1.144e-01 |  Loss_res: 1.166e-03 |   Loss_bcs1: 4.766e-03 | Loss_bc2s: 4.667e-03 |  loss_ics_u: 1.032e-01 |  Loss_ut_ics: 9.124e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 8.818e-01\n",
            "adaptive_constant_ics_val: 9.793e-01\n",
            "adaptive_constant_bcs_val: 1.139e+00\n",
            "It: 27200 |  Loss: 1.146e-01 |  Loss_res: 8.488e-04 |   Loss_bcs1: 5.030e-03 | Loss_bc2s: 7.911e-03 |  loss_ics_u: 8.599e-02 |  Loss_ut_ics: 1.213e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 7.294e-01\n",
            "adaptive_constant_ics_val: 1.280e+00\n",
            "adaptive_constant_bcs_val: 9.907e-01\n",
            "It: 27300 |  Loss: 1.027e-01 |  Loss_res: 1.605e-03 |   Loss_bcs1: 2.889e-03 | Loss_bc2s: 7.928e-03 |  loss_ics_u: 8.995e-02 |  Loss_ut_ics: 1.315e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.026e+00\n",
            "adaptive_constant_ics_val: 9.546e-01\n",
            "adaptive_constant_bcs_val: 1.020e+00\n",
            "It: 27400 |  Loss: 9.314e-02 |  Loss_res: 1.330e-03 |   Loss_bcs1: 3.225e-03 | Loss_bc2s: 4.144e-03 |  loss_ics_u: 8.181e-02 |  Loss_ut_ics: 8.603e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 8.559e-01\n",
            "adaptive_constant_ics_val: 1.187e+00\n",
            "adaptive_constant_bcs_val: 9.569e-01\n",
            "It: 27500 |  Loss: 8.742e-02 |  Loss_res: 8.838e-04 |   Loss_bcs1: 5.370e-03 | Loss_bc2s: 8.434e-03 |  loss_ics_u: 7.570e-02 |  Loss_ut_ics: 8.552e-04 |  Time: 0.12\n",
            "adaptive_constant_res_val: 8.132e-01\n",
            "adaptive_constant_ics_val: 1.257e+00\n",
            "adaptive_constant_bcs_val: 9.296e-01\n",
            "It: 27600 |  Loss: 7.449e-02 |  Loss_res: 1.068e-03 |   Loss_bcs1: 4.174e-03 | Loss_bc2s: 7.013e-03 |  loss_ics_u: 6.682e-02 |  Loss_ut_ics: 8.824e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.054e+00\n",
            "adaptive_constant_ics_val: 1.079e+00\n",
            "adaptive_constant_bcs_val: 8.670e-01\n",
            "It: 27700 |  Loss: 8.365e-02 |  Loss_res: 2.446e-03 |   Loss_bcs1: 4.578e-03 | Loss_bc2s: 6.483e-03 |  loss_ics_u: 8.132e-02 |  Loss_ut_ics: 9.033e-04 |  Time: 0.17\n",
            "adaptive_constant_res_val: 1.289e+00\n",
            "adaptive_constant_ics_val: 1.021e+00\n",
            "adaptive_constant_bcs_val: 6.900e-01\n",
            "It: 27800 |  Loss: 7.332e-02 |  Loss_res: 1.193e-03 |   Loss_bcs1: 4.085e-03 | Loss_bc2s: 8.482e-03 |  loss_ics_u: 9.040e-02 |  Loss_ut_ics: 7.215e-04 |  Time: 0.12\n",
            "adaptive_constant_res_val: 8.615e-01\n",
            "adaptive_constant_ics_val: 1.262e+00\n",
            "adaptive_constant_bcs_val: 8.766e-01\n",
            "It: 27900 |  Loss: 7.416e-02 |  Loss_res: 9.675e-04 |   Loss_bcs1: 4.436e-03 | Loss_bc2s: 8.718e-03 |  loss_ics_u: 6.921e-02 |  Loss_ut_ics: 8.931e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 7.919e-01\n",
            "adaptive_constant_ics_val: 1.359e+00\n",
            "adaptive_constant_bcs_val: 8.494e-01\n",
            "It: 28000 |  Loss: 7.614e-02 |  Loss_res: 1.196e-03 |   Loss_bcs1: 2.728e-03 | Loss_bc2s: 8.298e-03 |  loss_ics_u: 7.609e-02 |  Loss_ut_ics: 8.769e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 8.198e-01\n",
            "adaptive_constant_ics_val: 1.365e+00\n",
            "adaptive_constant_bcs_val: 8.150e-01\n",
            "It: 28100 |  Loss: 8.184e-02 |  Loss_res: 1.101e-03 |   Loss_bcs1: 3.688e-03 | Loss_bc2s: 5.548e-03 |  loss_ics_u: 8.874e-02 |  Loss_ut_ics: 7.986e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.026e+00\n",
            "adaptive_constant_ics_val: 1.056e+00\n",
            "adaptive_constant_bcs_val: 9.182e-01\n",
            "It: 28200 |  Loss: 8.920e-02 |  Loss_res: 1.322e-03 |   Loss_bcs1: 3.595e-03 | Loss_bc2s: 7.130e-03 |  loss_ics_u: 8.360e-02 |  Loss_ut_ics: 1.159e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.171e+00\n",
            "adaptive_constant_ics_val: 9.580e-01\n",
            "adaptive_constant_bcs_val: 8.710e-01\n",
            "It: 28300 |  Loss: 8.599e-02 |  Loss_res: 1.160e-03 |   Loss_bcs1: 4.030e-03 | Loss_bc2s: 6.597e-03 |  loss_ics_u: 8.569e-02 |  Loss_ut_ics: 7.641e-04 |  Time: 0.24\n",
            "adaptive_constant_res_val: 9.326e-01\n",
            "adaptive_constant_ics_val: 1.010e+00\n",
            "adaptive_constant_bcs_val: 1.057e+00\n",
            "It: 28400 |  Loss: 1.105e-01 |  Loss_res: 1.170e-03 |   Loss_bcs1: 5.331e-03 | Loss_bc2s: 8.254e-03 |  loss_ics_u: 8.919e-02 |  Loss_ut_ics: 7.989e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.002e+00\n",
            "adaptive_constant_ics_val: 9.621e-01\n",
            "adaptive_constant_bcs_val: 1.036e+00\n",
            "It: 28500 |  Loss: 9.244e-02 |  Loss_res: 1.200e-03 |   Loss_bcs1: 2.743e-03 | Loss_bc2s: 7.198e-03 |  loss_ics_u: 7.743e-02 |  Loss_ut_ics: 7.770e-04 |  Time: 0.28\n",
            "adaptive_constant_res_val: 1.013e+00\n",
            "adaptive_constant_ics_val: 1.057e+00\n",
            "adaptive_constant_bcs_val: 9.293e-01\n",
            "It: 28600 |  Loss: 9.163e-02 |  Loss_res: 1.018e-03 |   Loss_bcs1: 2.564e-03 | Loss_bc2s: 1.059e-02 |  loss_ics_u: 8.343e-02 |  Loss_ut_ics: 7.997e-04 |  Time: 0.20\n",
            "adaptive_constant_res_val: 1.062e+00\n",
            "adaptive_constant_ics_val: 9.472e-01\n",
            "adaptive_constant_bcs_val: 9.913e-01\n",
            "It: 28700 |  Loss: 1.066e-01 |  Loss_res: 1.345e-03 |   Loss_bcs1: 3.205e-03 | Loss_bc2s: 7.529e-03 |  loss_ics_u: 9.427e-02 |  Loss_ut_ics: 1.150e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.049e+00\n",
            "adaptive_constant_ics_val: 1.177e+00\n",
            "adaptive_constant_bcs_val: 7.741e-01\n",
            "It: 28800 |  Loss: 8.577e-02 |  Loss_res: 1.145e-03 |   Loss_bcs1: 2.979e-03 | Loss_bc2s: 6.966e-03 |  loss_ics_u: 9.830e-02 |  Loss_ut_ics: 6.672e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.947e-01\n",
            "adaptive_constant_ics_val: 9.538e-01\n",
            "adaptive_constant_bcs_val: 1.052e+00\n",
            "It: 28900 |  Loss: 9.502e-02 |  Loss_res: 1.141e-03 |   Loss_bcs1: 3.275e-03 | Loss_bc2s: 5.578e-03 |  loss_ics_u: 8.002e-02 |  Loss_ut_ics: 4.545e-04 |  Time: 0.06\n",
            "adaptive_constant_res_val: 1.048e+00\n",
            "adaptive_constant_ics_val: 9.225e-01\n",
            "adaptive_constant_bcs_val: 1.030e+00\n",
            "It: 29000 |  Loss: 1.057e-01 |  Loss_res: 1.258e-03 |   Loss_bcs1: 4.202e-03 | Loss_bc2s: 7.497e-03 |  loss_ics_u: 8.913e-02 |  Loss_ut_ics: 5.818e-04 |  Time: 0.13\n",
            "adaptive_constant_res_val: 1.015e+00\n",
            "adaptive_constant_ics_val: 9.052e-01\n",
            "adaptive_constant_bcs_val: 1.080e+00\n",
            "It: 29100 |  Loss: 1.103e-01 |  Loss_res: 9.859e-04 |   Loss_bcs1: 5.027e-03 | Loss_bc2s: 6.340e-03 |  loss_ics_u: 8.939e-02 |  Loss_ut_ics: 5.780e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.012e+00\n",
            "adaptive_constant_ics_val: 9.238e-01\n",
            "adaptive_constant_bcs_val: 1.064e+00\n",
            "It: 29200 |  Loss: 1.001e-01 |  Loss_res: 1.767e-03 |   Loss_bcs1: 3.080e-03 | Loss_bc2s: 8.224e-03 |  loss_ics_u: 8.047e-02 |  Loss_ut_ics: 6.900e-04 |  Time: 0.15\n",
            "adaptive_constant_res_val: 1.110e+00\n",
            "adaptive_constant_ics_val: 9.308e-01\n",
            "adaptive_constant_bcs_val: 9.595e-01\n",
            "It: 29300 |  Loss: 9.420e-02 |  Loss_res: 1.644e-03 |   Loss_bcs1: 5.020e-03 | Loss_bc2s: 4.220e-03 |  loss_ics_u: 8.651e-02 |  Loss_ut_ics: 5.490e-04 |  Time: 0.04\n",
            "adaptive_constant_res_val: 8.953e-01\n",
            "adaptive_constant_ics_val: 1.063e+00\n",
            "adaptive_constant_bcs_val: 1.041e+00\n",
            "It: 29400 |  Loss: 9.311e-02 |  Loss_res: 1.596e-03 |   Loss_bcs1: 3.567e-03 | Loss_bc2s: 7.900e-03 |  loss_ics_u: 7.590e-02 |  Loss_ut_ics: 6.689e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 8.341e-01\n",
            "adaptive_constant_ics_val: 1.308e+00\n",
            "adaptive_constant_bcs_val: 8.577e-01\n",
            "It: 29500 |  Loss: 8.583e-02 |  Loss_res: 1.471e-03 |   Loss_bcs1: 5.123e-03 | Loss_bc2s: 7.829e-03 |  loss_ics_u: 8.487e-02 |  Loss_ut_ics: 5.298e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 8.388e-01\n",
            "adaptive_constant_ics_val: 1.169e+00\n",
            "adaptive_constant_bcs_val: 9.917e-01\n",
            "It: 29600 |  Loss: 9.680e-02 |  Loss_res: 1.817e-03 |   Loss_bcs1: 5.521e-03 | Loss_bc2s: 7.396e-03 |  loss_ics_u: 8.228e-02 |  Loss_ut_ics: 7.421e-04 |  Time: 0.26\n",
            "adaptive_constant_res_val: 1.062e+00\n",
            "adaptive_constant_ics_val: 1.079e+00\n",
            "adaptive_constant_bcs_val: 8.593e-01\n",
            "It: 29700 |  Loss: 8.565e-02 |  Loss_res: 1.774e-03 |   Loss_bcs1: 6.302e-03 | Loss_bc2s: 9.927e-03 |  loss_ics_u: 8.000e-02 |  Loss_ut_ics: 9.963e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 8.912e-01\n",
            "adaptive_constant_ics_val: 1.076e+00\n",
            "adaptive_constant_bcs_val: 1.033e+00\n",
            "It: 29800 |  Loss: 9.642e-02 |  Loss_res: 1.593e-03 |   Loss_bcs1: 5.939e-03 | Loss_bc2s: 4.883e-03 |  loss_ics_u: 8.026e-02 |  Loss_ut_ics: 8.955e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.015e-01\n",
            "adaptive_constant_ics_val: 1.063e+00\n",
            "adaptive_constant_bcs_val: 1.035e+00\n",
            "It: 29900 |  Loss: 1.069e-01 |  Loss_res: 9.603e-04 |   Loss_bcs1: 5.543e-03 | Loss_bc2s: 5.924e-03 |  loss_ics_u: 9.035e-02 |  Loss_ut_ics: 5.677e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 9.142e-01\n",
            "adaptive_constant_ics_val: 9.421e-01\n",
            "adaptive_constant_bcs_val: 1.144e+00\n",
            "It: 30000 |  Loss: 1.096e-01 |  Loss_res: 1.637e-03 |   Loss_bcs1: 6.732e-03 | Loss_bc2s: 5.657e-03 |  loss_ics_u: 8.163e-02 |  Loss_ut_ics: 6.349e-04 |  Time: 0.19\n",
            "adaptive_constant_res_val: 1.042e+00\n",
            "adaptive_constant_ics_val: 1.011e+00\n",
            "adaptive_constant_bcs_val: 9.471e-01\n",
            "It: 30100 |  Loss: 9.116e-02 |  Loss_res: 1.233e-03 |   Loss_bcs1: 2.317e-03 | Loss_bc2s: 7.827e-03 |  loss_ics_u: 8.391e-02 |  Loss_ut_ics: 7.894e-04 |  Time: 0.07\n",
            "adaptive_constant_res_val: 9.773e-01\n",
            "adaptive_constant_ics_val: 1.018e+00\n",
            "adaptive_constant_bcs_val: 1.005e+00\n",
            "It: 30200 |  Loss: 8.669e-02 |  Loss_res: 1.743e-03 |   Loss_bcs1: 3.399e-03 | Loss_bc2s: 4.786e-03 |  loss_ics_u: 7.535e-02 |  Loss_ut_ics: 1.010e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.135e+00\n",
            "adaptive_constant_ics_val: 9.531e-01\n",
            "adaptive_constant_bcs_val: 9.120e-01\n",
            "It: 30300 |  Loss: 8.506e-02 |  Loss_res: 1.643e-03 |   Loss_bcs1: 4.161e-03 | Loss_bc2s: 5.428e-03 |  loss_ics_u: 8.069e-02 |  Loss_ut_ics: 9.044e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.396e-01\n",
            "adaptive_constant_ics_val: 1.168e+00\n",
            "adaptive_constant_bcs_val: 8.924e-01\n",
            "It: 30400 |  Loss: 8.299e-02 |  Loss_res: 1.473e-03 |   Loss_bcs1: 2.939e-03 | Loss_bc2s: 5.380e-03 |  loss_ics_u: 8.198e-02 |  Loss_ut_ics: 8.712e-04 |  Time: 0.09\n",
            "adaptive_constant_res_val: 8.743e-01\n",
            "adaptive_constant_ics_val: 1.073e+00\n",
            "adaptive_constant_bcs_val: 1.053e+00\n",
            "It: 30500 |  Loss: 1.043e-01 |  Loss_res: 1.610e-03 |   Loss_bcs1: 3.409e-03 | Loss_bc2s: 5.810e-03 |  loss_ics_u: 8.699e-02 |  Loss_ut_ics: 1.482e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 8.190e-01\n",
            "adaptive_constant_ics_val: 1.147e+00\n",
            "adaptive_constant_bcs_val: 1.034e+00\n",
            "It: 30600 |  Loss: 8.821e-02 |  Loss_res: 1.568e-03 |   Loss_bcs1: 2.036e-03 | Loss_bc2s: 5.895e-03 |  loss_ics_u: 7.474e-02 |  Loss_ut_ics: 1.283e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 8.380e-01\n",
            "adaptive_constant_ics_val: 1.092e+00\n",
            "adaptive_constant_bcs_val: 1.070e+00\n",
            "It: 30700 |  Loss: 9.375e-02 |  Loss_res: 1.535e-03 |   Loss_bcs1: 3.850e-03 | Loss_bc2s: 5.981e-03 |  loss_ics_u: 7.531e-02 |  Loss_ut_ics: 1.253e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.448e-01\n",
            "adaptive_constant_ics_val: 1.009e+00\n",
            "adaptive_constant_bcs_val: 1.046e+00\n",
            "It: 30800 |  Loss: 9.459e-02 |  Loss_res: 1.425e-03 |   Loss_bcs1: 3.700e-03 | Loss_bc2s: 7.628e-03 |  loss_ics_u: 7.665e-02 |  Loss_ut_ics: 1.169e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.173e-01\n",
            "adaptive_constant_ics_val: 9.662e-01\n",
            "adaptive_constant_bcs_val: 1.117e+00\n",
            "It: 30900 |  Loss: 1.050e-01 |  Loss_res: 1.275e-03 |   Loss_bcs1: 6.109e-03 | Loss_bc2s: 6.260e-03 |  loss_ics_u: 7.954e-02 |  Loss_ut_ics: 1.239e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.490e-01\n",
            "adaptive_constant_ics_val: 9.104e-01\n",
            "adaptive_constant_bcs_val: 1.141e+00\n",
            "It: 31000 |  Loss: 9.785e-02 |  Loss_res: 1.571e-03 |   Loss_bcs1: 3.083e-03 | Loss_bc2s: 8.290e-03 |  loss_ics_u: 7.197e-02 |  Loss_ut_ics: 1.426e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.364e+00\n",
            "adaptive_constant_ics_val: 8.668e-01\n",
            "adaptive_constant_bcs_val: 7.688e-01\n",
            "It: 31100 |  Loss: 7.516e-02 |  Loss_res: 2.783e-03 |   Loss_bcs1: 3.584e-03 | Loss_bc2s: 8.192e-03 |  loss_ics_u: 7.974e-02 |  Loss_ut_ics: 1.164e-03 |  Time: 0.13\n",
            "adaptive_constant_res_val: 1.090e+00\n",
            "adaptive_constant_ics_val: 9.725e-01\n",
            "adaptive_constant_bcs_val: 9.373e-01\n",
            "It: 31200 |  Loss: 7.828e-02 |  Loss_res: 1.326e-03 |   Loss_bcs1: 5.569e-03 | Loss_bc2s: 4.902e-03 |  loss_ics_u: 7.031e-02 |  Loss_ut_ics: 1.146e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 8.211e-01\n",
            "adaptive_constant_ics_val: 1.082e+00\n",
            "adaptive_constant_bcs_val: 1.097e+00\n",
            "It: 31300 |  Loss: 9.395e-02 |  Loss_res: 1.380e-03 |   Loss_bcs1: 4.139e-03 | Loss_bc2s: 7.539e-03 |  loss_ics_u: 7.102e-02 |  Loss_ut_ics: 1.969e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 6.838e-01\n",
            "adaptive_constant_ics_val: 1.553e+00\n",
            "adaptive_constant_bcs_val: 7.637e-01\n",
            "It: 31400 |  Loss: 7.213e-02 |  Loss_res: 1.150e-03 |   Loss_bcs1: 5.043e-03 | Loss_bc2s: 9.868e-03 |  loss_ics_u: 7.606e-02 |  Loss_ut_ics: 1.201e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.887e-01\n",
            "adaptive_constant_ics_val: 1.020e+00\n",
            "adaptive_constant_bcs_val: 9.916e-01\n",
            "It: 31500 |  Loss: 9.604e-02 |  Loss_res: 1.437e-03 |   Loss_bcs1: 3.424e-03 | Loss_bc2s: 6.457e-03 |  loss_ics_u: 8.378e-02 |  Loss_ut_ics: 1.717e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.108e-01\n",
            "adaptive_constant_ics_val: 1.198e+00\n",
            "adaptive_constant_bcs_val: 8.910e-01\n",
            "It: 31600 |  Loss: 7.525e-02 |  Loss_res: 1.260e-03 |   Loss_bcs1: 4.307e-03 | Loss_bc2s: 6.941e-03 |  loss_ics_u: 7.052e-02 |  Loss_ut_ics: 1.042e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 8.794e-01\n",
            "adaptive_constant_ics_val: 1.039e+00\n",
            "adaptive_constant_bcs_val: 1.082e+00\n",
            "It: 31700 |  Loss: 8.924e-02 |  Loss_res: 1.186e-03 |   Loss_bcs1: 2.785e-03 | Loss_bc2s: 7.042e-03 |  loss_ics_u: 7.034e-02 |  Loss_ut_ics: 1.394e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 9.080e-01\n",
            "adaptive_constant_ics_val: 1.099e+00\n",
            "adaptive_constant_bcs_val: 9.925e-01\n",
            "It: 31800 |  Loss: 9.758e-02 |  Loss_res: 1.485e-03 |   Loss_bcs1: 4.616e-03 | Loss_bc2s: 5.978e-03 |  loss_ics_u: 8.470e-02 |  Loss_ut_ics: 1.502e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.128e+00\n",
            "adaptive_constant_ics_val: 8.782e-01\n",
            "adaptive_constant_bcs_val: 9.934e-01\n",
            "It: 31900 |  Loss: 8.374e-02 |  Loss_res: 1.620e-03 |   Loss_bcs1: 4.102e-03 | Loss_bc2s: 7.873e-03 |  loss_ics_u: 6.956e-02 |  Loss_ut_ics: 1.047e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.042e+00\n",
            "adaptive_constant_ics_val: 9.697e-01\n",
            "adaptive_constant_bcs_val: 9.885e-01\n",
            "It: 32000 |  Loss: 9.103e-02 |  Loss_res: 1.489e-03 |   Loss_bcs1: 3.898e-03 | Loss_bc2s: 4.649e-03 |  loss_ics_u: 8.072e-02 |  Loss_ut_ics: 1.271e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.434e-01\n",
            "adaptive_constant_ics_val: 1.038e+00\n",
            "adaptive_constant_bcs_val: 1.019e+00\n",
            "It: 32100 |  Loss: 8.787e-02 |  Loss_res: 1.608e-03 |   Loss_bcs1: 3.977e-03 | Loss_bc2s: 6.166e-03 |  loss_ics_u: 7.304e-02 |  Loss_ut_ics: 1.563e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.864e-01\n",
            "adaptive_constant_ics_val: 1.047e+00\n",
            "adaptive_constant_bcs_val: 9.666e-01\n",
            "It: 32200 |  Loss: 9.103e-02 |  Loss_res: 1.198e-03 |   Loss_bcs1: 3.830e-03 | Loss_bc2s: 7.280e-03 |  loss_ics_u: 8.036e-02 |  Loss_ut_ics: 1.364e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.003e+00\n",
            "adaptive_constant_ics_val: 9.489e-01\n",
            "adaptive_constant_bcs_val: 1.048e+00\n",
            "It: 32300 |  Loss: 1.016e-01 |  Loss_res: 1.188e-03 |   Loss_bcs1: 3.436e-03 | Loss_bc2s: 5.164e-03 |  loss_ics_u: 8.602e-02 |  Loss_ut_ics: 1.386e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.099e+00\n",
            "adaptive_constant_ics_val: 8.643e-01\n",
            "adaptive_constant_bcs_val: 1.037e+00\n",
            "It: 32400 |  Loss: 7.550e-02 |  Loss_res: 1.293e-03 |   Loss_bcs1: 4.295e-03 | Loss_bc2s: 4.441e-03 |  loss_ics_u: 6.139e-02 |  Loss_ut_ics: 1.610e-03 |  Time: 0.14\n",
            "adaptive_constant_res_val: 9.770e-01\n",
            "adaptive_constant_ics_val: 1.070e+00\n",
            "adaptive_constant_bcs_val: 9.528e-01\n",
            "It: 32500 |  Loss: 7.664e-02 |  Loss_res: 1.447e-03 |   Loss_bcs1: 3.137e-03 | Loss_bc2s: 6.750e-03 |  loss_ics_u: 6.745e-02 |  Loss_ut_ics: 1.437e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.211e+00\n",
            "adaptive_constant_ics_val: 9.040e-01\n",
            "adaptive_constant_bcs_val: 8.849e-01\n",
            "It: 32600 |  Loss: 7.435e-02 |  Loss_res: 1.582e-03 |   Loss_bcs1: 4.137e-03 | Loss_bc2s: 4.415e-03 |  loss_ics_u: 7.220e-02 |  Loss_ut_ics: 1.073e-03 |  Time: 0.14\n",
            "adaptive_constant_res_val: 9.534e-01\n",
            "adaptive_constant_ics_val: 9.724e-01\n",
            "adaptive_constant_bcs_val: 1.074e+00\n",
            "It: 32700 |  Loss: 8.438e-02 |  Loss_res: 1.501e-03 |   Loss_bcs1: 7.526e-03 | Loss_bc2s: 5.021e-03 |  loss_ics_u: 6.333e-02 |  Loss_ut_ics: 1.482e-03 |  Time: 0.06\n",
            "adaptive_constant_res_val: 9.471e-01\n",
            "adaptive_constant_ics_val: 1.204e+00\n",
            "adaptive_constant_bcs_val: 8.488e-01\n",
            "It: 32800 |  Loss: 8.054e-02 |  Loss_res: 1.751e-03 |   Loss_bcs1: 2.938e-03 | Loss_bc2s: 6.942e-03 |  loss_ics_u: 8.126e-02 |  Loss_ut_ics: 1.263e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.763e-01\n",
            "adaptive_constant_ics_val: 9.846e-01\n",
            "adaptive_constant_bcs_val: 1.039e+00\n",
            "It: 32900 |  Loss: 9.958e-02 |  Loss_res: 1.419e-03 |   Loss_bcs1: 2.595e-03 | Loss_bc2s: 5.869e-03 |  loss_ics_u: 8.485e-02 |  Loss_ut_ics: 1.240e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 8.584e-01\n",
            "adaptive_constant_ics_val: 1.186e+00\n",
            "adaptive_constant_bcs_val: 9.551e-01\n",
            "It: 33000 |  Loss: 8.242e-02 |  Loss_res: 1.344e-03 |   Loss_bcs1: 4.378e-03 | Loss_bc2s: 5.804e-03 |  loss_ics_u: 7.362e-02 |  Loss_ut_ics: 1.029e-03 |  Time: 0.05\n",
            "adaptive_constant_res_val: 9.519e-01\n",
            "adaptive_constant_ics_val: 9.568e-01\n",
            "adaptive_constant_bcs_val: 1.091e+00\n",
            "It: 33100 |  Loss: 9.782e-02 |  Loss_res: 1.496e-03 |   Loss_bcs1: 5.612e-03 | Loss_bc2s: 8.184e-03 |  loss_ics_u: 7.311e-02 |  Loss_ut_ics: 1.622e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.052e-01\n",
            "adaptive_constant_ics_val: 1.147e+00\n",
            "adaptive_constant_bcs_val: 9.474e-01\n",
            "It: 33200 |  Loss: 8.489e-02 |  Loss_res: 1.474e-03 |   Loss_bcs1: 5.628e-03 | Loss_bc2s: 8.053e-03 |  loss_ics_u: 7.322e-02 |  Loss_ut_ics: 1.068e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.025e+00\n",
            "adaptive_constant_ics_val: 9.643e-01\n",
            "adaptive_constant_bcs_val: 1.011e+00\n",
            "It: 33300 |  Loss: 8.830e-02 |  Loss_res: 1.360e-03 |   Loss_bcs1: 4.448e-03 | Loss_bc2s: 5.412e-03 |  loss_ics_u: 7.430e-02 |  Loss_ut_ics: 1.897e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.025e+00\n",
            "adaptive_constant_ics_val: 1.036e+00\n",
            "adaptive_constant_bcs_val: 9.390e-01\n",
            "It: 33400 |  Loss: 8.342e-02 |  Loss_res: 1.376e-03 |   Loss_bcs1: 4.256e-03 | Loss_bc2s: 6.243e-03 |  loss_ics_u: 7.533e-02 |  Loss_ut_ics: 1.370e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.077e+00\n",
            "adaptive_constant_ics_val: 8.338e-01\n",
            "adaptive_constant_bcs_val: 1.089e+00\n",
            "It: 33500 |  Loss: 9.706e-02 |  Loss_res: 9.559e-04 |   Loss_bcs1: 3.468e-03 | Loss_bc2s: 3.996e-03 |  loss_ics_u: 7.982e-02 |  Loss_ut_ics: 1.143e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.549e-01\n",
            "adaptive_constant_ics_val: 1.034e+00\n",
            "adaptive_constant_bcs_val: 1.011e+00\n",
            "It: 33600 |  Loss: 7.827e-02 |  Loss_res: 1.619e-03 |   Loss_bcs1: 4.723e-03 | Loss_bc2s: 1.281e-03 |  loss_ics_u: 6.841e-02 |  Loss_ut_ics: 1.432e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.042e+00\n",
            "adaptive_constant_ics_val: 1.057e+00\n",
            "adaptive_constant_bcs_val: 9.005e-01\n",
            "It: 33700 |  Loss: 7.432e-02 |  Loss_res: 1.124e-03 |   Loss_bcs1: 4.977e-03 | Loss_bc2s: 5.083e-03 |  loss_ics_u: 6.966e-02 |  Loss_ut_ics: 1.287e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.242e-01\n",
            "adaptive_constant_ics_val: 9.694e-01\n",
            "adaptive_constant_bcs_val: 1.106e+00\n",
            "It: 33800 |  Loss: 9.295e-02 |  Loss_res: 1.451e-03 |   Loss_bcs1: 2.714e-03 | Loss_bc2s: 4.500e-03 |  loss_ics_u: 7.440e-02 |  Loss_ut_ics: 1.347e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.308e-01\n",
            "adaptive_constant_ics_val: 1.038e+00\n",
            "adaptive_constant_bcs_val: 1.031e+00\n",
            "It: 33900 |  Loss: 8.156e-02 |  Loss_res: 1.214e-03 |   Loss_bcs1: 3.383e-03 | Loss_bc2s: 3.556e-03 |  loss_ics_u: 7.008e-02 |  Loss_ut_ics: 9.671e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.577e-01\n",
            "adaptive_constant_ics_val: 9.220e-01\n",
            "adaptive_constant_bcs_val: 1.120e+00\n",
            "It: 34000 |  Loss: 1.018e-01 |  Loss_res: 1.503e-03 |   Loss_bcs1: 4.375e-03 | Loss_bc2s: 5.989e-03 |  loss_ics_u: 7.800e-02 |  Loss_ut_ics: 1.456e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.214e+00\n",
            "adaptive_constant_ics_val: 8.802e-01\n",
            "adaptive_constant_bcs_val: 9.058e-01\n",
            "It: 34100 |  Loss: 8.284e-02 |  Loss_res: 1.794e-03 |   Loss_bcs1: 4.579e-03 | Loss_bc2s: 4.784e-03 |  loss_ics_u: 7.842e-02 |  Loss_ut_ics: 1.301e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.221e+00\n",
            "adaptive_constant_ics_val: 7.890e-01\n",
            "adaptive_constant_bcs_val: 9.903e-01\n",
            "It: 34200 |  Loss: 8.037e-02 |  Loss_res: 1.166e-03 |   Loss_bcs1: 5.426e-03 | Loss_bc2s: 2.961e-03 |  loss_ics_u: 7.012e-02 |  Loss_ut_ics: 1.517e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.622e-01\n",
            "adaptive_constant_ics_val: 1.105e+00\n",
            "adaptive_constant_bcs_val: 9.327e-01\n",
            "It: 34300 |  Loss: 8.352e-02 |  Loss_res: 1.817e-03 |   Loss_bcs1: 4.089e-03 | Loss_bc2s: 4.285e-03 |  loss_ics_u: 7.778e-02 |  Loss_ut_ics: 1.284e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.033e+00\n",
            "adaptive_constant_ics_val: 9.903e-01\n",
            "adaptive_constant_bcs_val: 9.767e-01\n",
            "It: 34400 |  Loss: 8.746e-02 |  Loss_res: 1.303e-03 |   Loss_bcs1: 5.812e-03 | Loss_bc2s: 8.020e-03 |  loss_ics_u: 7.279e-02 |  Loss_ut_ics: 1.525e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 8.930e-01\n",
            "adaptive_constant_ics_val: 1.098e+00\n",
            "adaptive_constant_bcs_val: 1.009e+00\n",
            "It: 34500 |  Loss: 9.615e-02 |  Loss_res: 1.121e-03 |   Loss_bcs1: 5.161e-03 | Loss_bc2s: 3.440e-03 |  loss_ics_u: 8.397e-02 |  Loss_ut_ics: 1.614e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 8.919e-01\n",
            "adaptive_constant_ics_val: 1.105e+00\n",
            "adaptive_constant_bcs_val: 1.003e+00\n",
            "It: 34600 |  Loss: 8.748e-02 |  Loss_res: 1.852e-03 |   Loss_bcs1: 2.898e-03 | Loss_bc2s: 5.344e-03 |  loss_ics_u: 7.591e-02 |  Loss_ut_ics: 1.308e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 9.692e-01\n",
            "adaptive_constant_ics_val: 9.929e-01\n",
            "adaptive_constant_bcs_val: 1.038e+00\n",
            "It: 34700 |  Loss: 8.335e-02 |  Loss_res: 1.424e-03 |   Loss_bcs1: 6.399e-03 | Loss_bc2s: 5.759e-03 |  loss_ics_u: 6.522e-02 |  Loss_ut_ics: 1.660e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 9.311e-01\n",
            "adaptive_constant_ics_val: 1.095e+00\n",
            "adaptive_constant_bcs_val: 9.743e-01\n",
            "It: 34800 |  Loss: 8.205e-02 |  Loss_res: 1.362e-03 |   Loss_bcs1: 3.290e-03 | Loss_bc2s: 4.827e-03 |  loss_ics_u: 7.302e-02 |  Loss_ut_ics: 1.586e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.021e+00\n",
            "adaptive_constant_ics_val: 9.421e-01\n",
            "adaptive_constant_bcs_val: 1.037e+00\n",
            "It: 34900 |  Loss: 8.371e-02 |  Loss_res: 1.658e-03 |   Loss_bcs1: 3.638e-03 | Loss_bc2s: 4.141e-03 |  loss_ics_u: 6.993e-02 |  Loss_ut_ics: 1.558e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.084e+00\n",
            "adaptive_constant_ics_val: 8.784e-01\n",
            "adaptive_constant_bcs_val: 1.037e+00\n",
            "It: 35000 |  Loss: 8.425e-02 |  Loss_res: 1.282e-03 |   Loss_bcs1: 4.407e-03 | Loss_bc2s: 5.014e-03 |  loss_ics_u: 6.910e-02 |  Loss_ut_ics: 1.623e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 8.818e-01\n",
            "adaptive_constant_ics_val: 1.085e+00\n",
            "adaptive_constant_bcs_val: 1.033e+00\n",
            "It: 35100 |  Loss: 8.767e-02 |  Loss_res: 1.003e-03 |   Loss_bcs1: 4.183e-03 | Loss_bc2s: 3.349e-03 |  loss_ics_u: 7.500e-02 |  Loss_ut_ics: 1.388e-03 |  Time: 0.13\n",
            "adaptive_constant_res_val: 9.095e-01\n",
            "adaptive_constant_ics_val: 1.040e+00\n",
            "adaptive_constant_bcs_val: 1.050e+00\n",
            "It: 35200 |  Loss: 8.317e-02 |  Loss_res: 1.480e-03 |   Loss_bcs1: 3.454e-03 | Loss_bc2s: 3.773e-03 |  loss_ics_u: 6.944e-02 |  Loss_ut_ics: 1.269e-03 |  Time: 0.06\n",
            "adaptive_constant_res_val: 1.167e+00\n",
            "adaptive_constant_ics_val: 9.488e-01\n",
            "adaptive_constant_bcs_val: 8.839e-01\n",
            "It: 35300 |  Loss: 7.455e-02 |  Loss_res: 1.908e-03 |   Loss_bcs1: 2.171e-03 | Loss_bc2s: 6.810e-03 |  loss_ics_u: 7.155e-02 |  Loss_ut_ics: 1.206e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.003e+00\n",
            "adaptive_constant_ics_val: 9.403e-01\n",
            "adaptive_constant_bcs_val: 1.057e+00\n",
            "It: 35400 |  Loss: 8.085e-02 |  Loss_res: 1.434e-03 |   Loss_bcs1: 4.450e-03 | Loss_bc2s: 3.160e-03 |  loss_ics_u: 6.627e-02 |  Loss_ut_ics: 1.390e-03 |  Time: 0.19\n",
            "adaptive_constant_res_val: 9.800e-01\n",
            "adaptive_constant_ics_val: 9.904e-01\n",
            "adaptive_constant_bcs_val: 1.030e+00\n",
            "It: 35500 |  Loss: 8.038e-02 |  Loss_res: 1.374e-03 |   Loss_bcs1: 2.830e-03 | Loss_bc2s: 3.498e-03 |  loss_ics_u: 6.897e-02 |  Loss_ut_ics: 1.525e-03 |  Time: 0.13\n",
            "adaptive_constant_res_val: 1.143e+00\n",
            "adaptive_constant_ics_val: 9.270e-01\n",
            "adaptive_constant_bcs_val: 9.305e-01\n",
            "It: 35600 |  Loss: 7.278e-02 |  Loss_res: 1.534e-03 |   Loss_bcs1: 4.080e-03 | Loss_bc2s: 2.874e-03 |  loss_ics_u: 6.803e-02 |  Loss_ut_ics: 1.360e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.264e+00\n",
            "adaptive_constant_ics_val: 8.578e-01\n",
            "adaptive_constant_bcs_val: 8.782e-01\n",
            "It: 35700 |  Loss: 7.816e-02 |  Loss_res: 1.124e-03 |   Loss_bcs1: 4.600e-03 | Loss_bc2s: 8.482e-03 |  loss_ics_u: 7.304e-02 |  Loss_ut_ics: 1.301e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.266e+00\n",
            "adaptive_constant_ics_val: 7.734e-01\n",
            "adaptive_constant_bcs_val: 9.611e-01\n",
            "It: 35800 |  Loss: 8.457e-02 |  Loss_res: 1.299e-03 |   Loss_bcs1: 5.770e-03 | Loss_bc2s: 4.360e-03 |  loss_ics_u: 7.497e-02 |  Loss_ut_ics: 1.467e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 1.099e+00\n",
            "adaptive_constant_ics_val: 8.417e-01\n",
            "adaptive_constant_bcs_val: 1.059e+00\n",
            "It: 35900 |  Loss: 8.691e-02 |  Loss_res: 1.364e-03 |   Loss_bcs1: 2.901e-03 | Loss_bc2s: 5.194e-03 |  loss_ics_u: 7.141e-02 |  Loss_ut_ics: 1.442e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.071e+00\n",
            "adaptive_constant_ics_val: 9.612e-01\n",
            "adaptive_constant_bcs_val: 9.675e-01\n",
            "It: 36000 |  Loss: 7.362e-02 |  Loss_res: 1.442e-03 |   Loss_bcs1: 3.486e-03 | Loss_bc2s: 3.289e-03 |  loss_ics_u: 6.625e-02 |  Loss_ut_ics: 1.476e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.106e+00\n",
            "adaptive_constant_ics_val: 9.365e-01\n",
            "adaptive_constant_bcs_val: 9.574e-01\n",
            "It: 36100 |  Loss: 8.728e-02 |  Loss_res: 1.279e-03 |   Loss_bcs1: 4.837e-03 | Loss_bc2s: 6.046e-03 |  loss_ics_u: 7.774e-02 |  Loss_ut_ics: 1.078e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.200e+00\n",
            "adaptive_constant_ics_val: 8.633e-01\n",
            "adaptive_constant_bcs_val: 9.365e-01\n",
            "It: 36200 |  Loss: 7.348e-02 |  Loss_res: 1.198e-03 |   Loss_bcs1: 4.353e-03 | Loss_bc2s: 3.547e-03 |  loss_ics_u: 6.765e-02 |  Loss_ut_ics: 1.494e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.207e+00\n",
            "adaptive_constant_ics_val: 8.593e-01\n",
            "adaptive_constant_bcs_val: 9.335e-01\n",
            "It: 36300 |  Loss: 8.203e-02 |  Loss_res: 1.355e-03 |   Loss_bcs1: 4.079e-03 | Loss_bc2s: 7.259e-03 |  loss_ics_u: 7.370e-02 |  Loss_ut_ics: 1.179e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.063e+00\n",
            "adaptive_constant_ics_val: 9.335e-01\n",
            "adaptive_constant_bcs_val: 1.004e+00\n",
            "It: 36400 |  Loss: 7.626e-02 |  Loss_res: 1.321e-03 |   Loss_bcs1: 5.167e-03 | Loss_bc2s: 4.539e-03 |  loss_ics_u: 6.386e-02 |  Loss_ut_ics: 1.081e-03 |  Time: 0.06\n",
            "adaptive_constant_res_val: 1.071e+00\n",
            "adaptive_constant_ics_val: 8.920e-01\n",
            "adaptive_constant_bcs_val: 1.037e+00\n",
            "It: 36500 |  Loss: 9.597e-02 |  Loss_res: 1.463e-03 |   Loss_bcs1: 3.213e-03 | Loss_bc2s: 3.421e-03 |  loss_ics_u: 8.329e-02 |  Loss_ut_ics: 1.283e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.058e+00\n",
            "adaptive_constant_ics_val: 9.118e-01\n",
            "adaptive_constant_bcs_val: 1.030e+00\n",
            "It: 36600 |  Loss: 7.992e-02 |  Loss_res: 1.432e-03 |   Loss_bcs1: 3.862e-03 | Loss_bc2s: 5.637e-03 |  loss_ics_u: 6.545e-02 |  Loss_ut_ics: 1.350e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.054e+00\n",
            "adaptive_constant_ics_val: 9.373e-01\n",
            "adaptive_constant_bcs_val: 1.008e+00\n",
            "It: 36700 |  Loss: 8.331e-02 |  Loss_res: 1.661e-03 |   Loss_bcs1: 7.007e-03 | Loss_bc2s: 6.130e-03 |  loss_ics_u: 6.625e-02 |  Loss_ut_ics: 1.602e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.070e+00\n",
            "adaptive_constant_ics_val: 9.398e-01\n",
            "adaptive_constant_bcs_val: 9.902e-01\n",
            "It: 36800 |  Loss: 8.185e-02 |  Loss_res: 1.138e-03 |   Loss_bcs1: 4.038e-03 | Loss_bc2s: 2.615e-03 |  loss_ics_u: 7.350e-02 |  Loss_ut_ics: 1.351e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.207e+00\n",
            "adaptive_constant_ics_val: 7.911e-01\n",
            "adaptive_constant_bcs_val: 1.002e+00\n",
            "It: 36900 |  Loss: 7.699e-02 |  Loss_res: 1.053e-03 |   Loss_bcs1: 6.376e-03 | Loss_bc2s: 7.427e-03 |  loss_ics_u: 6.074e-02 |  Loss_ut_ics: 1.322e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.040e+00\n",
            "adaptive_constant_ics_val: 9.622e-01\n",
            "adaptive_constant_bcs_val: 9.973e-01\n",
            "It: 37000 |  Loss: 7.795e-02 |  Loss_res: 1.158e-03 |   Loss_bcs1: 4.075e-03 | Loss_bc2s: 4.261e-03 |  loss_ics_u: 6.737e-02 |  Loss_ut_ics: 1.292e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 9.256e-01\n",
            "adaptive_constant_ics_val: 1.030e+00\n",
            "adaptive_constant_bcs_val: 1.044e+00\n",
            "It: 37100 |  Loss: 9.299e-02 |  Loss_res: 1.512e-03 |   Loss_bcs1: 3.297e-03 | Loss_bc2s: 5.081e-03 |  loss_ics_u: 7.811e-02 |  Loss_ut_ics: 1.247e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.749e-01\n",
            "adaptive_constant_ics_val: 1.087e+00\n",
            "adaptive_constant_bcs_val: 9.377e-01\n",
            "It: 37200 |  Loss: 7.965e-02 |  Loss_res: 1.322e-03 |   Loss_bcs1: 5.835e-03 | Loss_bc2s: 4.374e-03 |  loss_ics_u: 7.178e-02 |  Loss_ut_ics: 1.356e-03 |  Time: 0.13\n",
            "adaptive_constant_res_val: 9.212e-01\n",
            "adaptive_constant_ics_val: 1.065e+00\n",
            "adaptive_constant_bcs_val: 1.014e+00\n",
            "It: 37300 |  Loss: 8.496e-02 |  Loss_res: 1.589e-03 |   Loss_bcs1: 3.546e-03 | Loss_bc2s: 7.295e-03 |  loss_ics_u: 7.008e-02 |  Loss_ut_ics: 1.352e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.049e+00\n",
            "adaptive_constant_ics_val: 9.814e-01\n",
            "adaptive_constant_bcs_val: 9.698e-01\n",
            "It: 37400 |  Loss: 7.449e-02 |  Loss_res: 1.188e-03 |   Loss_bcs1: 3.488e-03 | Loss_bc2s: 6.894e-03 |  loss_ics_u: 6.404e-02 |  Loss_ut_ics: 1.087e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.089e+00\n",
            "adaptive_constant_ics_val: 9.040e-01\n",
            "adaptive_constant_bcs_val: 1.007e+00\n",
            "It: 37500 |  Loss: 8.435e-02 |  Loss_res: 1.324e-03 |   Loss_bcs1: 3.655e-03 | Loss_bc2s: 4.717e-03 |  loss_ics_u: 7.283e-02 |  Loss_ut_ics: 1.301e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.755e-01\n",
            "adaptive_constant_ics_val: 1.026e+00\n",
            "adaptive_constant_bcs_val: 9.987e-01\n",
            "It: 37600 |  Loss: 8.232e-02 |  Loss_res: 1.141e-03 |   Loss_bcs1: 4.420e-03 | Loss_bc2s: 5.350e-03 |  loss_ics_u: 7.046e-02 |  Loss_ut_ics: 1.050e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 9.421e-01\n",
            "adaptive_constant_ics_val: 9.122e-01\n",
            "adaptive_constant_bcs_val: 1.146e+00\n",
            "It: 37700 |  Loss: 8.680e-02 |  Loss_res: 1.990e-03 |   Loss_bcs1: 3.890e-03 | Loss_bc2s: 3.390e-03 |  loss_ics_u: 6.609e-02 |  Loss_ut_ics: 9.497e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.205e+00\n",
            "adaptive_constant_ics_val: 8.389e-01\n",
            "adaptive_constant_bcs_val: 9.561e-01\n",
            "It: 37800 |  Loss: 8.059e-02 |  Loss_res: 1.317e-03 |   Loss_bcs1: 2.681e-03 | Loss_bc2s: 7.178e-03 |  loss_ics_u: 7.160e-02 |  Loss_ut_ics: 1.337e-03 |  Time: 0.07\n",
            "adaptive_constant_res_val: 9.320e-01\n",
            "adaptive_constant_ics_val: 1.078e+00\n",
            "adaptive_constant_bcs_val: 9.902e-01\n",
            "It: 37900 |  Loss: 7.289e-02 |  Loss_res: 1.212e-03 |   Loss_bcs1: 4.592e-03 | Loss_bc2s: 5.625e-03 |  loss_ics_u: 6.070e-02 |  Loss_ut_ics: 1.428e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.129e-01\n",
            "adaptive_constant_ics_val: 1.077e+00\n",
            "adaptive_constant_bcs_val: 1.010e+00\n",
            "It: 38000 |  Loss: 8.389e-02 |  Loss_res: 1.139e-03 |   Loss_bcs1: 4.736e-03 | Loss_bc2s: 6.812e-03 |  loss_ics_u: 6.932e-02 |  Loss_ut_ics: 1.091e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.018e+00\n",
            "adaptive_constant_ics_val: 1.003e+00\n",
            "adaptive_constant_bcs_val: 9.791e-01\n",
            "It: 38100 |  Loss: 9.605e-02 |  Loss_res: 1.322e-03 |   Loss_bcs1: 7.036e-03 | Loss_bc2s: 1.331e-02 |  loss_ics_u: 7.539e-02 |  Loss_ut_ics: 9.655e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.436e-01\n",
            "adaptive_constant_ics_val: 9.237e-01\n",
            "adaptive_constant_bcs_val: 1.133e+00\n",
            "It: 38200 |  Loss: 8.260e-02 |  Loss_res: 1.045e-03 |   Loss_bcs1: 2.312e-03 | Loss_bc2s: 5.229e-03 |  loss_ics_u: 6.351e-02 |  Loss_ut_ics: 1.230e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 8.646e-01\n",
            "adaptive_constant_ics_val: 1.048e+00\n",
            "adaptive_constant_bcs_val: 1.087e+00\n",
            "It: 38300 |  Loss: 8.812e-02 |  Loss_res: 2.036e-03 |   Loss_bcs1: 3.425e-03 | Loss_bc2s: 6.864e-03 |  loss_ics_u: 6.823e-02 |  Loss_ut_ics: 9.336e-04 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.118e+00\n",
            "adaptive_constant_ics_val: 8.958e-01\n",
            "adaptive_constant_bcs_val: 9.863e-01\n",
            "It: 38400 |  Loss: 8.128e-02 |  Loss_res: 1.337e-03 |   Loss_bcs1: 1.952e-03 | Loss_bc2s: 4.699e-03 |  loss_ics_u: 7.304e-02 |  Loss_ut_ics: 1.323e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 9.758e-01\n",
            "adaptive_constant_ics_val: 1.031e+00\n",
            "adaptive_constant_bcs_val: 9.928e-01\n",
            "It: 38500 |  Loss: 7.771e-02 |  Loss_res: 1.403e-03 |   Loss_bcs1: 2.835e-03 | Loss_bc2s: 6.460e-03 |  loss_ics_u: 6.614e-02 |  Loss_ut_ics: 1.400e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 1.019e+00\n",
            "adaptive_constant_ics_val: 9.107e-01\n",
            "adaptive_constant_bcs_val: 1.070e+00\n",
            "It: 38600 |  Loss: 8.330e-02 |  Loss_res: 1.231e-03 |   Loss_bcs1: 3.836e-03 | Loss_bc2s: 3.467e-03 |  loss_ics_u: 6.817e-02 |  Loss_ut_ics: 1.403e-03 |  Time: 0.14\n",
            "adaptive_constant_res_val: 9.430e-01\n",
            "adaptive_constant_ics_val: 1.026e+00\n",
            "adaptive_constant_bcs_val: 1.031e+00\n",
            "It: 38700 |  Loss: 7.618e-02 |  Loss_res: 1.356e-03 |   Loss_bcs1: 4.157e-03 | Loss_bc2s: 4.283e-03 |  loss_ics_u: 6.291e-02 |  Loss_ut_ics: 1.326e-03 |  Time: 0.17\n",
            "adaptive_constant_res_val: 8.695e-01\n",
            "adaptive_constant_ics_val: 1.189e+00\n",
            "adaptive_constant_bcs_val: 9.413e-01\n",
            "It: 38800 |  Loss: 7.910e-02 |  Loss_res: 1.305e-03 |   Loss_bcs1: 3.641e-03 | Loss_bc2s: 2.404e-03 |  loss_ics_u: 7.531e-02 |  Loss_ut_ics: 1.167e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 8.788e-01\n",
            "adaptive_constant_ics_val: 1.080e+00\n",
            "adaptive_constant_bcs_val: 1.042e+00\n",
            "It: 38900 |  Loss: 7.039e-02 |  Loss_res: 1.749e-03 |   Loss_bcs1: 5.438e-03 | Loss_bc2s: 4.240e-03 |  loss_ics_u: 5.523e-02 |  Loss_ut_ics: 1.153e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.246e+00\n",
            "adaptive_constant_ics_val: 9.182e-01\n",
            "adaptive_constant_bcs_val: 8.357e-01\n",
            "It: 39000 |  Loss: 6.334e-02 |  Loss_res: 1.386e-03 |   Loss_bcs1: 3.284e-03 | Loss_bc2s: 5.868e-03 |  loss_ics_u: 6.326e-02 |  Loss_ut_ics: 1.196e-03 |  Time: 0.11\n",
            "adaptive_constant_res_val: 1.059e+00\n",
            "adaptive_constant_ics_val: 1.070e+00\n",
            "adaptive_constant_bcs_val: 8.712e-01\n",
            "It: 39100 |  Loss: 7.184e-02 |  Loss_res: 1.189e-03 |   Loss_bcs1: 4.807e-03 | Loss_bc2s: 6.439e-03 |  loss_ics_u: 6.853e-02 |  Loss_ut_ics: 1.013e-03 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.927e-01\n",
            "adaptive_constant_ics_val: 9.529e-01\n",
            "adaptive_constant_bcs_val: 1.054e+00\n",
            "It: 39200 |  Loss: 8.855e-02 |  Loss_res: 1.154e-03 |   Loss_bcs1: 3.924e-03 | Loss_bc2s: 4.361e-03 |  loss_ics_u: 7.322e-02 |  Loss_ut_ics: 1.535e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 8.720e-01\n",
            "adaptive_constant_ics_val: 1.297e+00\n",
            "adaptive_constant_bcs_val: 8.306e-01\n",
            "It: 39300 |  Loss: 7.103e-02 |  Loss_res: 1.414e-03 |   Loss_bcs1: 4.319e-03 | Loss_bc2s: 3.281e-03 |  loss_ics_u: 7.503e-02 |  Loss_ut_ics: 9.016e-04 |  Time: 0.08\n",
            "adaptive_constant_res_val: 1.017e+00\n",
            "adaptive_constant_ics_val: 9.796e-01\n",
            "adaptive_constant_bcs_val: 1.004e+00\n",
            "It: 39400 |  Loss: 8.024e-02 |  Loss_res: 1.525e-03 |   Loss_bcs1: 2.235e-03 | Loss_bc2s: 7.011e-03 |  loss_ics_u: 6.792e-02 |  Loss_ut_ics: 1.276e-03 |  Time: 0.08\n",
            "adaptive_constant_res_val: 9.907e-01\n",
            "adaptive_constant_ics_val: 9.966e-01\n",
            "adaptive_constant_bcs_val: 1.013e+00\n",
            "It: 39500 |  Loss: 8.827e-02 |  Loss_res: 1.358e-03 |   Loss_bcs1: 6.276e-03 | Loss_bc2s: 2.147e-03 |  loss_ics_u: 7.623e-02 |  Loss_ut_ics: 1.189e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 9.165e-01\n",
            "adaptive_constant_ics_val: 9.708e-01\n",
            "adaptive_constant_bcs_val: 1.113e+00\n",
            "It: 39600 |  Loss: 7.217e-02 |  Loss_res: 1.322e-03 |   Loss_bcs1: 4.127e-03 | Loss_bc2s: 4.957e-03 |  loss_ics_u: 5.375e-02 |  Loss_ut_ics: 1.071e-03 |  Time: 0.09\n",
            "adaptive_constant_res_val: 1.021e+00\n",
            "adaptive_constant_ics_val: 9.954e-01\n",
            "adaptive_constant_bcs_val: 9.834e-01\n",
            "It: 39700 |  Loss: 7.545e-02 |  Loss_res: 9.632e-04 |   Loss_bcs1: 6.620e-03 | Loss_bc2s: 4.703e-03 |  loss_ics_u: 6.345e-02 |  Loss_ut_ics: 9.460e-04 |  Time: 0.10\n",
            "adaptive_constant_res_val: 9.259e-01\n",
            "adaptive_constant_ics_val: 9.910e-01\n",
            "adaptive_constant_bcs_val: 1.083e+00\n",
            "It: 39800 |  Loss: 8.223e-02 |  Loss_res: 2.781e-03 |   Loss_bcs1: 2.318e-03 | Loss_bc2s: 3.724e-03 |  loss_ics_u: 6.660e-02 |  Loss_ut_ics: 9.882e-04 |  Time: 0.15\n",
            "adaptive_constant_res_val: 1.665e+00\n",
            "adaptive_constant_ics_val: 6.573e-01\n",
            "adaptive_constant_bcs_val: 6.781e-01\n",
            "It: 39900 |  Loss: 5.005e-02 |  Loss_res: 1.357e-03 |   Loss_bcs1: 4.459e-03 | Loss_bc2s: 6.598e-03 |  loss_ics_u: 5.820e-02 |  Loss_ut_ics: 1.263e-03 |  Time: 0.12\n",
            "adaptive_constant_res_val: 1.361e+00\n",
            "adaptive_constant_ics_val: 8.453e-01\n",
            "adaptive_constant_bcs_val: 7.936e-01\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/home/afrah2/anaconda3/envs/twoPhase/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Gradients information stored ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "elapsed: 8.10e+03\n",
            "Relative L2 error_u: 4.59e-01\n",
            "Relative L2 error_r: 6.97e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Save uv NN parameters successfully in %s ...checkpoints/Dec-17-2023_23-44-04-289437_relobralo\n",
            "Final loss total loss: 5.927569e-02\n",
            "Final loss loss_res: 1.134874e-03\n",
            "Final loss loss_bcs: 7.158311e-02\n",
            "Final loss loss_bc1: 3.539233e-03\n",
            "Final loss loss_bc2: 4.687181e-03\n",
            "Final loss loss_ics_u: 6.335670e-02\n",
            "Final loss loss_ics_u_t: 1.091474e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "elapsed: 8.10e+03\n",
            "Relative L2 error_u: 4.59e-01\n",
            "Relative L2 error_r: 6.97e-02\n",
            "\n",
            "\n",
            "Method:  mini_batch\n",
            "\n",
            "average of time_list: 8100.970547914505\n",
            "average of error_u_list: 0.4590385150795734\n",
            "average of error_r_list: 0.06970314521178032\n"
          ]
        }
      ],
      "source": [
        "# Define PINN model\n",
        "a = 0.5\n",
        "c = 2\n",
        "\n",
        "kernel_size = 300\n",
        "\n",
        "# Domain boundaries\n",
        "ics_coords = np.array([[0.0, 0.0],  [0.0, 1.0]])\n",
        "bc1_coords = np.array([[0.0, 0.0],  [1.0, 0.0]])\n",
        "bc2_coords = np.array([[0.0, 1.0],  [1.0, 1.0]])\n",
        "dom_coords = np.array([[0.0, 0.0],  [1.0, 1.0]])\n",
        "\n",
        "# Create initial conditions samplers\n",
        "ics_sampler = Sampler(2, ics_coords, lambda x: u(x, a, c), name='Initial Condition 1')\n",
        "\n",
        "# Create boundary conditions samplers\n",
        "bc1 = Sampler(2, bc1_coords, lambda x: u(x, a, c), name='Dirichlet BC1')\n",
        "bc2 = Sampler(2, bc2_coords, lambda x: u(x, a, c), name='Dirichlet BC2')\n",
        "bcs_sampler = [bc1, bc2]\n",
        "\n",
        "# Create residual sampler\n",
        "res_sampler = Sampler(2, dom_coords, lambda x: r(x, a, c), name='Forcing')\n",
        "coll_sampler = Sampler(2, dom_coords, lambda x: u(x, a, c), name='coll')\n",
        "\n",
        "\n",
        "\n",
        "nIter =40000\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 300\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'relobralo'\n",
        "layers = [2, 500, 500, 500, 1]\n",
        "\n",
        "\n",
        "nn = 200\n",
        "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
        "t, x = np.meshgrid(t, x)\n",
        "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
        "\n",
        "u_star = u(X_star, a,c)\n",
        "r_star = r(X_star, a, c)\n",
        "\n",
        "iterations = 1\n",
        "methods = [  \"mini_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    error_r_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "\n",
        "        # [elapsed, error_u , model] = test_method(mtd , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size )\n",
        "        tf.reset_default_graph()\n",
        "        gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) as sess:\n",
        "            # sess.run(init)\n",
        "\n",
        "            model = PINN(layers, operator ,  ics_sampler, bcs_sampler, res_sampler, c , mode , sess)\n",
        "            # Train model\n",
        "            start_time = time.time()\n",
        "\n",
        "            if mtd ==\"full_batch\":\n",
        "                print(\"full_batch method is used\")\n",
        "                model.train( bcbatch_size , ubatch_size , nIter )\n",
        "            elif mtd ==\"mini_batch\":\n",
        "                print(\"mini_batch method is used\")\n",
        "                model.trainmb( mbbatch_size , nIter)\n",
        "            else:\n",
        "                print(\"unknown method!\")\n",
        "            elapsed = time.time() - start_time\n",
        "\n",
        "            # Predictions\n",
        "            u_pred = model.predict_u(X_star)\n",
        "            r_pred = model.predict_r(X_star)\n",
        "            # Predictions\n",
        "\n",
        "            error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "            error_r = np.linalg.norm(r_star - r_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "            print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "            print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "            print('Relative L2 error_r: {:.2e}'.format(error_r))\n",
        "            \n",
        "            model.print(\"mean : adaptive_constant_bcs_log:\" , model.adaptive_constant_bcs_log)\n",
        "            model.print(\"mean : adaptive_constant_ics_log\" , model.adaptive_constant_ics_log)\n",
        "            model.print(\"mean : adaptive_constant_res_log\" , model.adaptive_constant_res_log)\n",
        "\n",
        "            model.plot_lambda()\n",
        "            model.plot_grad()\n",
        "            model.save_NN()\n",
        "            model.plt_prediction( t , x , X_star , u_star , u_pred , r_star , r_pred)\n",
        "            # sess.close()  \n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "        print('Relative L2 error_r: {:.2e}'.format(error_r))\n",
        "\n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "        error_r_list.append(error_r)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    print(\"average of error_r_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list,error_r_list]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(os.path.join(model.dirname,\"\"+mtd+\"_1Dwave_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(bcbatch_size)+\"_exp\"+str(bcbatch_size)+\"nIter\"+str(nIter)+\".mat\") , result_dict)\n",
        "\n",
        "###############################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lambda_balance(loss_list , term ,min ):\n",
        "    m = len(loss_list)\n",
        "    num = np.exp(loss_history[term][-1] /(T * min + 1e-12))\n",
        "    denum = 0 \n",
        "\n",
        "    for  key in loss_list:\n",
        "        denum +=  np.exp(loss_history[key][-1] /(T * min+ 1e-12))\n",
        "    return m * (num / denum)\n",
        "\n",
        "loss_list = [\"loss_res\" , \"loss_bc1\", \"loss_bc2\", \"loss_ics_u\", \"loss_ics_u_t\"] \n",
        "\n",
        "T = 1.0\n",
        "epoch_loss = dict.fromkeys(loss_list, 0)\n",
        "loss_history = dict((loss, []) for loss in loss_list)\n",
        "minValmean_lamdas = dict((loss, 0) for loss in loss_list)\n",
        "minValstd_lamdas = dict((loss, 0) for loss in loss_list)\n",
        "\n",
        "loss_history[\"loss_res\"].append(5000.999)\n",
        "loss_history[\"loss_res\"].append(2000.4)\n",
        "loss_history[\"loss_res\"].append(500.23)\n",
        "loss_history[\"loss_res\"].append(18.564)\n",
        "loss_history[\"loss_res\"].append(0.2333)\n",
        "loss_history[\"loss_res\"].append(0.23)\n",
        "loss_history[\"loss_res\"].append(0.23)\n",
        "\n",
        "\n",
        "loss_history[\"loss_bc1\"].append(4533343.999)\n",
        "loss_history[\"loss_bc1\"].append(4344.44)\n",
        "loss_history[\"loss_bc1\"].append(333.33)\n",
        "loss_history[\"loss_bc1\"].append(34.92499)\n",
        "loss_history[\"loss_bc1\"].append(45.43)\n",
        "loss_history[\"loss_bc1\"].append(100.43)\n",
        "loss_history[\"loss_bc1\"].append(100.43)\n",
        "\n",
        "loss_history[\"loss_bc2\"].append(4333.999)\n",
        "loss_history[\"loss_bc2\"].append(453.999)\n",
        "loss_history[\"loss_bc2\"].append(66.999)\n",
        "loss_history[\"loss_bc2\"].append(7.999)\n",
        "loss_history[\"loss_bc2\"].append(0.999)\n",
        "loss_history[\"loss_bc2\"].append(10.999)\n",
        "loss_history[\"loss_bc2\"].append(10.999)\n",
        "\n",
        "\n",
        "loss_history[\"loss_ics_u\"].append(453.999)\n",
        "loss_history[\"loss_ics_u\"].append(344.999)\n",
        "loss_history[\"loss_ics_u\"].append(3333.999)\n",
        "loss_history[\"loss_ics_u\"].append(34944.999)\n",
        "loss_history[\"loss_ics_u\"].append(359092.999)\n",
        "loss_history[\"loss_ics_u\"].append(3494.999)\n",
        "loss_history[\"loss_ics_u\"].append(3494.999)\n",
        "\n",
        "\n",
        "loss_history[\"loss_ics_u_t\"].append(4153.999)\n",
        "loss_history[\"loss_ics_u_t\"].append(444.999)\n",
        "loss_history[\"loss_ics_u_t\"].append(123.999)\n",
        "loss_history[\"loss_ics_u_t\"].append(50.999)\n",
        "loss_history[\"loss_ics_u_t\"].append(2344.999)\n",
        "loss_history[\"loss_ics_u_t\"].append(3546.999)\n",
        "loss_history[\"loss_ics_u_t\"].append(3546.999)\n",
        "\n",
        "for term in loss_list:\n",
        "    minValmean =  np.mean(loss_history[term])\n",
        "    minValstd =  np.std(loss_history[term])\n",
        "    minValmean_lamdas[term] = lambda_balance(loss_list , term ,minValmean )\n",
        "    minValstd_lamdas[term] = lambda_balance(loss_list , term ,minValstd )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'loss_res': 0.08910795815918005,\n",
              " 'loss_bc1': 0.9979467504147977,\n",
              " 'loss_bc2': 0.01619223871943361,\n",
              " 'loss_ics_u': 1.0358557370381585,\n",
              " 'loss_ics_u_t': 1.9940586993933134}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "minValmean_lamdas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'loss_res': 0.27466472884512977,\n",
              " 'loss_bc1': 0.9991610223058828,\n",
              " 'loss_bc2': 0.2076423760326426,\n",
              " 'loss_ics_u': 1.0167587904612982,\n",
              " 'loss_ics_u_t': 2.144874972017525}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "minValstd_lamdas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Method:  mini_batch\n",
        "\n",
        "# average of time_list: 1495.849406003952\n",
        "# average of error_u_list: 0.20815852255570721\n",
        "# average of error_r_list: 0.08826000007246695"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_14832/2998510943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mu_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mr_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Predictions\n",
        "u_pred = model.predict_u(X_star)\n",
        "r_pred = model.predict_r(X_star)\n",
        "# Predictions\n",
        "\n",
        "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "error_r = np.linalg.norm(r_star - r_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "print('Relative L2 error_r: {:.2e}'.format(error_r))\n",
        "\n",
        "model.save_NN()\n",
        "model.plt_prediction( t , x , X_star , u_star , u_pred , r_star , r_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plt_prediction(self , t , x , X_star , u_star , u_pred , r_star , r_pred):\n",
        "    \n",
        "    U_star = griddata(X_star, u_star.flatten(), (t, x), method='cubic')\n",
        "    r_star = griddata(X_star, r_star.flatten(), (t, x), method='cubic')\n",
        "    U_pred = griddata(X_star, u_pred.flatten(), (t, x), method='cubic')\n",
        "    R_pred = griddata(X_star, r_pred.flatten(), (t, x), method='cubic')\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(18, 9))\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.pcolor(t, x, U_star, cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$x_1$')\n",
        "    plt.ylabel('$x_2$')\n",
        "    plt.title('Exact u(t, x)')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.pcolor(t, x, U_pred, cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$t$')\n",
        "    plt.ylabel('$x$')\n",
        "    plt.title('Predicted u(t, x)')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.subplot(2, 3, 3)\n",
        "    plt.pcolor(t, x, np.abs(U_star - U_pred), cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$t$')\n",
        "    plt.ylabel('$x$')\n",
        "    plt.title('Absolute error')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.subplot(2, 3, 4)\n",
        "    plt.pcolor(t, x, r_star, cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$t$')\n",
        "    plt.ylabel('$x$')\n",
        "    plt.title('Exact r(t, x)')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    plt.pcolor(t, x, R_pred, cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$t$')\n",
        "    plt.ylabel('$x$')\n",
        "    plt.title('Predicted r(t, x)')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.subplot(2, 3, 6)\n",
        "    plt.pcolor(t, x, np.abs(r_star - R_pred), cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$t$')\n",
        "    plt.ylabel('$x$')\n",
        "    plt.title('Absolute error')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(self.dirname,\"prediction.png\"))\n",
        "    plt.close(\"all\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200, 200)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'u_pred' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_24403/89554458.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt_prediction\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX_star\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mu_star\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mu_pred\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mr_star\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mr_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'u_pred' is not defined"
          ]
        }
      ],
      "source": [
        "plt_prediction( model , t , x , X_star , u_star , u_pred , r_star , r_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFLIBq5xjZ3v"
      },
      "source": [
        "**Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To0PDN17cc0v",
        "outputId": "1f47f288-322a-46b5-f173-45485191a68d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Predictions\n",
        "u_pred = model.predict_u(X_star)\n",
        "r_pred = model.predict_r(X_star)\n",
        "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "print('Relative L2 error_u: %e' % (error_u))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "K428lOuXhdc8",
        "outputId": "015f591b-d8a4-4e47-8020-84fcf219d7ca"
      },
      "outputs": [],
      "source": [
        "U_star = griddata(X_star, u_star.flatten(), (t, x), method='cubic')\n",
        "r_star = griddata(X_star, r_star.flatten(), (t, x), method='cubic')\n",
        "U_pred = griddata(X_star, u_pred.flatten(), (t, x), method='cubic')\n",
        "R_pred = griddata(X_star, r_pred.flatten(), (t, x), method='cubic')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18, 9))\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.pcolor(t, x, U_star, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.title('Exact u(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.pcolor(t, x, U_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Predicted u(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.pcolor(t, x, np.abs(U_star - U_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.pcolor(t, x, r_star, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Exact r(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.pcolor(t, x, R_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Predicted r(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.pcolor(t, x, np.abs(r_star - R_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EYdfKGLj6h0"
      },
      "source": [
        "**NTK Eigenvalues**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3dByeQjhBYj"
      },
      "outputs": [],
      "source": [
        "# Create empty lists for storing the eigenvalues of NTK\n",
        "lam_K_u_log = []\n",
        "lam_K_ut_log = []\n",
        "lam_K_r_log = []\n",
        "\n",
        "# Restore the NTK\n",
        "K_u_list = model.K_u_log\n",
        "K_ut_list = model.K_ut_log\n",
        "K_r_list = model.K_r_log\n",
        "\n",
        "K_list = []\n",
        "    \n",
        "for k in range(len(K_u_list)):\n",
        "    K_u = K_u_list[k]\n",
        "    K_ut = K_ut_list[k]\n",
        "    K_r = K_r_list[k]\n",
        "    \n",
        "    # Compute eigenvalues\n",
        "    lam_K_u, _ = np.linalg.eig(K_u)\n",
        "    lam_K_ut, _ = np.linalg.eig(K_ut)\n",
        "    lam_K_r, _ = np.linalg.eig(K_r)\n",
        "    # Sort in descresing order\n",
        "    lam_K_u = np.sort(np.real(lam_K_u))[::-1]\n",
        "    lam_K_ut = np.sort(np.real(lam_K_ut))[::-1]\n",
        "    lam_K_r = np.sort(np.real(lam_K_r))[::-1]\n",
        "    \n",
        "    # Store eigenvalues\n",
        "    lam_K_u_log.append(lam_K_u)\n",
        "    lam_K_ut_log.append(lam_K_ut)\n",
        "    lam_K_r_log.append(lam_K_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "vSn3Q_1IhisN",
        "outputId": "886908b3-c316-48d6-933f-81b1180ff954"
      },
      "outputs": [],
      "source": [
        "#  Eigenvalues of NTK\n",
        "fig = plt.figure(figsize=(18, 5))\n",
        "plt.subplot(1,3,1)\n",
        "\n",
        "plt.plot(lam_K_u_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_u_log[1], '--', label = '$n=10,000$')\n",
        "plt.plot(lam_K_u_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_u_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.title(r'Eigenvalues of ${K}_u$')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(lam_K_ut_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_ut_log[1], '--',label = '$n=10,000$')\n",
        "plt.plot(lam_K_ut_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_ut_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title(r'Eigenvalues of ${K}_{u_t}$')\n",
        "\n",
        "ax =plt.subplot(1,3,3)\n",
        "plt.plot(lam_K_r_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_r_log[1], '--', label = '$n=10,000$')\n",
        "plt.plot(lam_K_r_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_r_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title(r'Eigenvalues of ${K}_{r}$')\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc=\"upper left\", bbox_to_anchor=(0.35, -0.02),\n",
        "            borderaxespad=0, bbox_transform=fig.transFigure, ncol=4)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbUn_fcowojl"
      },
      "source": [
        "**Evolution of NTK Weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYbzkhfMjJ8k"
      },
      "outputs": [],
      "source": [
        "if update_lam == True:\n",
        "\n",
        "  lam_u_log = model.lam_u_log\n",
        "  lam_ut_log = model.lam_ut_log\n",
        "  lam_r_log = model.lam_r_log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "xzFzPCA2w1ML",
        "outputId": "71452cf9-3ebb-4aeb-9708-c7664b88e65d"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 5))\n",
        "plt.plot(lam_u_log, label='$\\lambda_u$')\n",
        "plt.plot(lam_ut_log, label='$\\lambda_{u_t}$')\n",
        "plt.plot(lam_r_log, label='$\\lambda_{r}$')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('$\\lambda$')\n",
        "plt.yscale('log')\n",
        "plt.legend( )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mimIv2Z5xlip"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PINNsNTK_Wave.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
